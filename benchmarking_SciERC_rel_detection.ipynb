{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "207471af",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b97276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using conda library 'ontogpt_fork'; naming irrelevant as this was previously going to be used to work on a different project.\n",
    "\n",
    "# increase cell-width\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm # progress bar tracking\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 50)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "import json\n",
    "import jsonschema\n",
    "from jsonschema import validate\n",
    "\n",
    "# prompts for OpenAI\n",
    "\n",
    "import openai_secret_manager\n",
    "import openai\n",
    "import time\n",
    "import random\n",
    "\n",
    "import tiktoken\n",
    "from typing import List, Tuple\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f615246d",
   "metadata": {},
   "source": [
    "# Load SciERC dataset\n",
    "* http://nlp.cs.washington.edu/sciIE/\n",
    "* annotation guideline: http://nlp.cs.washington.edu/sciIE/annotation_guideline.pdf\n",
    "\n",
    "* SciERC is an annotated dataset of 500 scientific abstracts (multi-sentence).\n",
    "* Each article has 3 files:\n",
    "    * .txt being the raw text.\n",
    "    * .xml being the post-processed article.\n",
    "    * .ann being the annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b5abb2",
   "metadata": {},
   "source": [
    "## Annotation guideline\n",
    "\n",
    "Relation link can not go beyond sentence boundary.\n",
    "\n",
    "We define 4 asymmetric relation types (Used-for, Feature-of, Hyponym-of, Part-of), together with 2 symmetric relation types (Compare, Conjunction).\n",
    "B always points to A for asymmetric relations.\n",
    "\n",
    "* Used-for: B is used for A, B models A, A is trained on B, B exploits A, A is based on B. E.g.\n",
    "    * The TISPER system has been designed to enable many text applications.\n",
    "    * Our method models user proficiency.\n",
    "    * Our algorithms exploits local soothness.\n",
    "\n",
    "* Feature-of: B belongs to A, B is a feature of A, B is under A domain. E.g.\n",
    "    * prior knowledge of the model\n",
    "    * genre-specific regularities of discourse structure\n",
    "    * English text in science domain\n",
    "\n",
    "* Hyponym-of: B is a hyponym of A, B is a type of A. E.g.\n",
    "    * TUIT is a software library\n",
    "    * NLP applications such as machine translation and language generation\n",
    "\n",
    "* Part-of: B is a part of A... E.g.\n",
    "    * The system includes two models: speech recognition and natural language understanding\n",
    "    * We incorporate NLU module to the system.\n",
    "\n",
    "* Compare: Symmetric relation (use blue to denote entity). Opposite of conjunction, compare two models/methods, or listing two opposing entities. E.g.\n",
    "    * Unlike the quantitative prior, the qualitative prior is often ignored...\n",
    "\n",
    "* Conjunction: Symmetric relation (use blue to denote entity). Function as similar role or use/incorporate\n",
    "with. E.g.\n",
    "    * obtained from human expert or knowledge base\n",
    "    * NLP applications such as machine translation and language generation\n",
    "\n",
    "Coreference:\n",
    "* Anaphora and Cataphora:\n",
    "    * We introduce a machine reading system... The system...\n",
    "    * The prior knowledge include...Such knowledge can be applied to...\n",
    "\n",
    "* Coreferring noun phrase:\n",
    "    * We develop a part-of-speech tagging system...The POS tagger..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b338a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2308ae0e",
   "metadata": {},
   "source": [
    "## Explore .ann files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1924b4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\A00-1024.ann\n",
      "T1\tGeneric 26 32\tsystem\n",
      "T2\tTask 37 63\tcategorizing unknown words\n",
      "T3\tGeneric 71 77\tsystem\n",
      "T4\tMethod 94 122\tmulti-component architecture\n",
      "T5\tGeneric 136 145\tcomponent\n",
      "T6\tOtherScientificTerm 192 205\tunknown words\n",
      "T7\tGeneric 240 250\tcomponents\n",
      "T8\tOtherScientificTerm 267 272\tnames\n",
      "T9\tOtherScientificTerm 279 294\tspelling errors\n",
      "T10\tGeneric 303 312\tcomponent\n",
      "T11\tMethod 322 348\tdecision tree architecture\n",
      "T12\tOtherScientificTerm 401 413\tunknown word\n",
      "T13\tGeneric 421 427\tsystem\n",
      "T14\tMaterial 459 479\tlive closed captions\n",
      "T15\tOtherScientificTerm 523 536\tunknown words\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R4\tPART-OF Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R6\tHYPONYM-OF Arg1:T7 Arg2:T5\n",
      "R7\tCOREF Arg1:T13 Arg2:T3\n",
      "R8\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R9\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R10\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R11\tCOREF Arg1:T10 Arg2:T7\n",
      "R12\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R13\tCOREF Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A00-2023.ann\n",
      "T1\tGeneric 27 35\tapproach\n",
      "T2\tTask 40 71\tstatistical sentence generation\n",
      "T3\tOtherScientificTerm 139 144\ttrees\n",
      "T4\tOtherScientificTerm 151 158\tforests\n",
      "T5\tGeneric 220 234\trepresentation\n",
      "T6\tOtherScientificTerm 301 322\tsyntactic information\n",
      "T7\tGeneric 325 327\tIt\n",
      "T8\tMethod 361 380\tstatistical ranking\n",
      "T9\tGeneric 398 406\tapproach\n",
      "T10\tTask 411 433\tstatistical generation\n",
      "T11\tMethod 450 467\tranking algorithm\n",
      "T12\tMethod 563 574\tenumeration\n",
      "T13\tMethod 581 603\tlattice-based approach\n",
      "R1\tCOMPARE Arg1:T11 Arg2:T13\n",
      "R2\tCOMPARE Arg1:T11 Arg2:T12\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R4\tCOREF Arg1:T7 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tCOREF Arg1:T5 Arg2:T1\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R8\tCOMPARE Arg1:T7 Arg2:T9\n",
      "R9\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A88-1001.ann\n",
      "T1\tMethod 26 53\tdomain independent strategy\n",
      "T2\tTask 63 97\tmultimedia articulation of answers\n",
      "T3\tOtherScientificTerm 114 140\tnatural language interface\n",
      "T4\tTask 146 173\tdatabase query applications\n",
      "T5\tMaterial 178 196\tMultimedia answers\n",
      "T6\tMaterial 207 223\tvideodisc images\n",
      "T7\tOtherScientificTerm 287 306\ttext-to-speech form\n",
      "T8\tOtherScientificTerm 311 328\tDeictic reference\n",
      "T9\tOtherScientificTerm 335 343\tfeedback\n",
      "T10\tOtherScientificTerm 356 365\tdiscourse\n",
      "T11\tGeneric 385 394\tinterface\n",
      "T12\tGeneric 414 425\tapplication\n",
      "R1\tFEATURE-OF Arg1:T9 Arg2:T10\n",
      "R2\tPART-OF Arg1:T6 Arg2:T5\n",
      "R3\tFEATURE-OF Arg1:T8 Arg2:T10\n",
      "R4\tCOREF Arg1:T11 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R7\tCOREF Arg1:T12 Arg2:T4\n",
      "R8\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R9\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A88-1003.ann\n",
      "T1\tMethod 35 72\tpronominal anaphora resolution module\n",
      "T2\tMethod 78 82\tLucy\n",
      "T3\tMethod 98 126\tEnglish understanding system\n",
      "T4\tGeneric 149 155\tmodule\n",
      "T5\tTask 234 253\tanaphora resolution\n",
      "T6\tMethod 323 351\tblackboard-like architecture\n",
      "R1\tPART-OF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T4 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T2 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A92-1010.ann\n",
      "T1\tTask 45 82\tcognitively well-motivated interfaces\n",
      "T2\tOtherScientificTerm 110 142\tdisplay of graphical information\n",
      "T3\tOtherScientificTerm 168 189\tgraphical information\n",
      "T4\tTask 512 539\tnatural language generation\n",
      "T5\tGeneric 557 568\tinteraction\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tCOREF Arg1:T3 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A92-1023.ann\n",
      "T1\tTask 14 36\tevaluation methodology\n",
      "T2\tTask 151 161\tEvaluation\n",
      "T3\tGeneric 244 254\tapproaches\n",
      "T4\tTask 271 294\tspeech recognition (SR)\n",
      "T5\tGeneric 313 337\tevaluation methodologies\n",
      "T6\tOtherScientificTerm 448 480\tnatural language (NL) interfaces\n",
      "T7\tTask 501 526\tspeech understanding (SU)\n",
      "T8\tGeneric 723 734\tmethodology\n",
      "T9\tTask 751 777\tevaluation of  SLS systems\n",
      "T10\tMethod 766 777\tSLS systems\n",
      "T11\tGeneric 789 800\tmethodology\n",
      "T12\tMethod 875 886\tSLS systems\n",
      "T13\tGeneric 895 906\tevaluations\n",
      "T14\tTask 930 944\tNL evaluations\n",
      "T15\tMaterial 972 1005\tMessage Understanding Conferences\n",
      "T16\tMetric 1278 1301\t\"black-box\" methodology\n",
      "T17\tTask 1307 1361\tautomatic evaluation of  question-answering NL systems\n",
      "T18\tGeneric 1467 1478\tmethodology\n",
      "T19\tGeneric 1506 1508\tit\n",
      "T20\tOtherScientificTerm 1534 1554\tspeech or text input\n",
      "T21\tGeneric 1595 1603\tapproach\n",
      "R1\tCOREF Arg1:T12 Arg2:T10\n",
      "R2\tCOREF Arg1:T18 Arg2:T16\n",
      "R3\tCOREF Arg1:T21 Arg2:T18\n",
      "R4\tCOREF Arg1:T11 Arg2:T8\n",
      "R5\tEVALUATE-FOR Arg1:T11 Arg2:T12\n",
      "R6\tHYPONYM-OF Arg1:T13 Arg2:T14\n",
      "R7\tCOREF Arg1:T2 Arg2:T1\n",
      "R8\tCOREF Arg1:T2 Arg2:T5\n",
      "R9\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R10\tEVALUATE-FOR Arg1:T8 Arg2:T9\n",
      "R11\tCOREF Arg1:T9 Arg2:T13\n",
      "R12\tCONJUNCTION Arg1:T13 Arg2:T15\n",
      "R13\tCOREF Arg1:T18 Arg2:T19\n",
      "R14\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R15\tEVALUATE-FOR Arg1:T16 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A92-1026.ann\n",
      "T1\tTask 34 61\tnatural language processing\n",
      "T2\tMethod 197 204\tTACITUS\n",
      "T3\tMetric 227 243\tMUC-3 evaluation\n",
      "T4\tGeneric 273 283\ttechniques\n",
      "T5\tTask 289 321\tsyntactic and pragmatic analysis\n",
      "T6\tGeneric 345 352\tmethods\n",
      "T7\tMetric 367 377\trobustness\n",
      "T8\tGeneric 391 407\tthree techniques\n",
      "T9\tTask 420 438\tsyntactic analysis\n",
      "T10\tMethod 458 488\tagenda-based scheduling parser\n",
      "T11\tMethod 495 513\trecovery technique\n",
      "T12\tOtherScientificTerm 518 531\tfailed parses\n",
      "T13\tGeneric 545 554\ttechnique\n",
      "T14\tMethod 563 589\tterminal substring parsing\n",
      "T15\tTask 598 619\tpragmatics processing\n",
      "T16\tMethod 654 673\tabductive inference\n",
      "T17\tOtherScientificTerm 783 798\tworld knowledge\n",
      "T18\tGeneric 843 859\tthese techniques\n",
      "R1\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R2\tHYPONYM-OF Arg1:T15 Arg2:T5\n",
      "R3\tHYPONYM-OF Arg1:T9 Arg2:T5\n",
      "R4\tHYPONYM-OF Arg1:T10 Arg2:T8\n",
      "R5\tHYPONYM-OF Arg1:T8 Arg2:T18\n",
      "R6\tHYPONYM-OF Arg1:T16 Arg2:T18\n",
      "R7\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R8\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R9\tCOREF Arg1:T14 Arg2:T13\n",
      "R10\tHYPONYM-OF Arg1:T13 Arg2:T8\n",
      "R11\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R12\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R13\tCONJUNCTION Arg1:T11 Arg2:T13\n",
      "R14\tHYPONYM-OF Arg1:T11 Arg2:T8\n",
      "R15\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R16\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A92-1027.ann\n",
      "T1\tGeneric 27 36\talgorithm\n",
      "T2\tTask 42 78\tchart-based phrase structure parsing\n",
      "T3\tMaterial 84 100\tnatural language\n",
      "T4\tMethod 288 294\tparser\n",
      "T5\tOtherScientificTerm 355 367\tsearch space\n",
      "T6\tOtherScientificTerm 384 388\tedge\n",
      "T7\tOtherScientificTerm 407 412\tchart\n",
      "T8\tOtherScientificTerm 462 467\tedges\n",
      "T9\tOtherScientificTerm 507 512\tedges\n",
      "T10\tOtherScientificTerm 560 574\tspanning edges\n",
      "T11\tOtherScientificTerm 656 661\tedges\n",
      "T12\tMethod 789 815\tphrase boundary heuristics\n",
      "T13\tOtherScientificTerm 844 858\tfunction words\n",
      "T14\tMethod 870 885\theuristic rules\n",
      "T15\tOtherScientificTerm 965 978\tunknown words\n",
      "T16\tOtherScientificTerm 993 1022\treduction in the search space\n",
      "T17\tOtherScientificTerm 1046 1054\tsemantic\n",
      "T18\tOtherScientificTerm 1069 1089\tsyntactic categories\n",
      "T19\tOtherScientificTerm 1099 1130\tterminal and non-terminal edges\n",
      "T20\tOtherScientificTerm 1201 1206\tedges\n",
      "T21\tOtherScientificTerm 1222 1227\tedges\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R3\tCOMPARE Arg1:T17 Arg2:T18\n",
      "R4\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tCOREF Arg1:T4 Arg2:T1\n",
      "R7\tFEATURE-OF Arg1:T18 Arg2:T19\n",
      "R8\tFEATURE-OF Arg1:T17 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A94-1037.ann\n",
      "T1\tGeneric 1 8\tMethods\n",
      "T2\tTask 24 43\tspelling correction\n",
      "T3\tOtherScientificTerm 50 59\tlanguages\n",
      "T4\tOtherScientificTerm 67 74\tEnglish\n",
      "T5\tOtherScientificTerm 149 172\tagglutinative languages\n",
      "T6\tGeneric 199 207\tapproach\n",
      "T7\tTask 212 231\tspelling correction\n",
      "T8\tOtherScientificTerm 237 260\tagglutinative languages\n",
      "T9\tOtherScientificTerm 280 300\ttwo-level morphology\n",
      "T10\tMethod 309 351\tdynamic-programming based search algorithm\n",
      "T11\tGeneric 379 387\tapproach\n",
      "T12\tTask 431 450\tspelling correction\n",
      "T13\tOtherScientificTerm 456 463\tTurkish\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R4\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R5\tCOREF Arg1:T7 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R9\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R10\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R11\tCOREF Arg1:T11 Arg2:T6\n",
      "R12\tCOREF Arg1:T7 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A97-1020.ann\n",
      "T1\tMethod 2 9\tGLOSSER\n",
      "T2\tTask 34 54\treading and learning\n",
      "T3\tGeneric 104 118\tlanguage pairs\n",
      "T4\tMethod 144 151\tGLOSSER\n",
      "T5\tMaterial 155 172\tEnglish-Bulgarian\n",
      "T6\tMaterial 176 192\tEnglish-Estonian\n",
      "T7\tMaterial 196 213\tEnglish-Hungarian\n",
      "T8\tMaterial 220 232\tFrench-Dutch\n",
      "T9\tGeneric 239 246\tprogram\n",
      "T10\tOtherScientificTerm 265 295\tUNIX and Windows '95 platforms\n",
      "T11\tOtherScientificTerm 323 333\tuser-study\n",
      "T12\tTask 366 401\tApplied Natural Language Processing\n",
      "T13\tGeneric 414 424\tcomponents\n",
      "T14\tTask 457 517\tintelligent computer-assisted morphological analysis (ICALL)\n",
      "T15\tMethod 531 567\tdisambiguated morphological analysis\n",
      "T16\tMethod 574 593\tlemmatized indexing\n",
      "T17\tMaterial 603 627\taligned bilingual corpus\n",
      "R1\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R2\tCOREF Arg1:T4 Arg2:T1\n",
      "R3\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R4\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R5\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R6\tCOREF Arg1:T9 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R8\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R9\tHYPONYM-OF Arg1:T6 Arg2:T3\n",
      "R10\tHYPONYM-OF Arg1:T7 Arg2:T3\n",
      "R11\tHYPONYM-OF Arg1:T8 Arg2:T3\n",
      "R12\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R13\tHYPONYM-OF Arg1:T15 Arg2:T13\n",
      "R14\tHYPONYM-OF Arg1:T16 Arg2:T13\n",
      "R15\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R16\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R17\tUSED-FOR Arg1:T15 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A97-1021.ann\n",
      "T1\tMethod 62 112\tlexical conceptual structure (LCS) representations\n",
      "T2\tOtherScientificTerm 229 251\tbroad semantic classes\n",
      "T3\tMethod 258 280\tLCS meaning components\n",
      "T4\tMethod 288 320\tacquisition program - LEXICALL -\n",
      "T5\tTask 371 390\tverb classification\n",
      "T6\tTask 397 418\tthematic grid tagging\n",
      "T7\tMethod 434 453\tLCS representations\n",
      "T8\tGeneric 489 504\trepresentations\n",
      "T9\tOtherScientificTerm 529 565\tEnglish, Arabic and Spanish lexicons\n",
      "T10\tGeneric 642 650\tlexicons\n",
      "T11\tTask 659 696\toperational foreign language tutoring\n",
      "T12\tTask 703 722\tmachine translation\n",
      "R1\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R3\tCOREF Arg1:T8 Arg2:T7\n",
      "R4\tCOREF Arg1:T10 Arg2:T9\n",
      "R5\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R8\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R9\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R10\tCOREF Arg1:T7 Arg2:T1\n",
      "R11\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R12\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A97-1027.ann\n",
      "T1\tMethod 41 64\tmorphological component\n",
      "T2\tMethod 82 144\tNLP-system for Dutch (Dutch Medical Language Processor - DMLP)\n",
      "T3\tMethod 220 248\tlanguage independent modules\n",
      "T4\tMethod 258 329\tLSP-MLP system (Linguistic String Project - Medical Language Processor)\n",
      "T5\tGeneric 363 369\tformer\n",
      "T6\tGeneric 439 445\tlatter\n",
      "T7\tOtherScientificTerm 466 480\tidiosyncrasies\n",
      "T8\tMaterial 487 492\tDutch\n",
      "T9\tGeneric 552 563\tapplication\n",
      "T10\tTask 576 612\thighlighting of relevant information\n",
      "T11\tGeneric 592 612\trelevant information\n",
      "T12\tOtherScientificTerm 619 650\tpatient discharge summary (PDS)\n",
      "T13\tMethod 672 716\tHyperText Mark-Up Language (HTML) technology\n",
      "T14\tGeneric 727 738\tapplication\n",
      "T15\tTask 757 788\tmedical administrative purposes\n",
      "R1\tPART-OF Arg1:T1 Arg2:T2\n",
      "R2\tPART-OF Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R5\tCOREF Arg1:T14 Arg2:T9\n",
      "R6\tCOREF Arg1:T5 Arg2:T1\n",
      "R7\tCOREF Arg1:T6 Arg2:T3\n",
      "R8\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R9\tCOREF Arg1:T9 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T13 Arg2:T10\n",
      "R11\tPART-OF Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A97-1028.ann\n",
      "T1\tGeneric 29 48\tstatistical profile\n",
      "T2\tTask 58 75\tNamed Entity task\n",
      "T3\tTask 90 117\tinformation extraction task\n",
      "T4\tMethod 205 225\tstatistical analysis\n",
      "T5\tGeneric 243 252\talgorithm\n",
      "T6\tMethod 259 281\tlower bound estimation\n",
      "T7\tMaterial 288 308\tNamed Entity corpora\n",
      "T8\tGeneric 391 399\tanalysis\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tHYPONYM-OF Arg1:T2 Arg2:T3\n",
      "R4\tCOREF Arg1:T8 Arg2:T4\n",
      "R5\tCOREF Arg1:T4 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A97-1042.ann\n",
      "T1\tMethod 169 192\tOptimal Position Policy\n",
      "T2\tGeneric 197 203\tmethod\n",
      "T3\tOtherScientificTerm 227 264\tpositions of  topic-bearing sentences\n",
      "T4\tOtherScientificTerm 276 328\tgenre-specific regularities  of  discourse structure\n",
      "T5\tGeneric 336 342\tmethod\n",
      "T6\tGeneric 358 370\tapplications\n",
      "T7\tTask 380 401\tinformation retrieval\n",
      "T8\tTask 405 412\trouting\n",
      "T9\tTask 420 438\ttext summarization\n",
      "R1\tCOREF Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T5 Arg2:T2\n",
      "R3\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R4\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R5\tHYPONYM-OF Arg1:T7 Arg2:T6\n",
      "R6\tHYPONYM-OF Arg1:T8 Arg2:T6\n",
      "R7\tHYPONYM-OF Arg1:T9 Arg2:T6\n",
      "R8\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R9\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R10\tUSED-FOR Arg1:T4 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A97-1050.ann\n",
      "T1\tGeneric 35 44\talgorithm\n",
      "T2\tTask 49 88\ttranslation lexicon acquisition (SABLE)\n",
      "T3\tOtherScientificTerm 143 172\tgeneral  translation lexicons\n",
      "T4\tGeneric 186 195\talgorithm\n",
      "T5\tOtherScientificTerm 262 298\tdomain-specific translation lexicons\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A97-1052.ann\n",
      "T1\tGeneric 47 53\tsystem\n",
      "T2\tOtherScientificTerm 74 102\tsubcategorization dictionary\n",
      "T3\tMaterial 110 125\ttextual corpora\n",
      "T4\tOtherScientificTerm 165 197\trelative frequency of occurrence\n",
      "T5\tOtherScientificTerm 564 592\tsubcategorization dictionary\n",
      "T6\tGeneric 609 615\tsystem\n",
      "T7\tMetric 630 638\taccuracy\n",
      "T8\tMethod 646 652\tparser\n",
      "R1\tEVALUATE-FOR Arg1:T8 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T6 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R5\tEVALUATE-FOR Arg1:T7 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\AAAI_1993_70_abs.ann\n",
      "T1\tMethod 4 29\tRete and Treat algorithms\n",
      "T2\tMethod 64 89\timplementation techniques\n",
      "T3\tTask 94 123\tForward Chaining rule systems\n",
      "T4\tGeneric 131 141\talgorithms\n",
      "T5\tMethod 152 188\tlanguage of limited expressive power\n",
      "T6\tOtherScientificTerm 190 200\tAssertions\n",
      "T7\tOtherScientificTerm 228 237\tvariables\n",
      "T8\tOtherScientificTerm 246 270\tuniversal quantification\n",
      "T9\tOtherScientificTerm 305 309\trule\n",
      "T10\tTask 348 364\tfull unification\n",
      "T11\tGeneric 374 384\talgorithms\n",
      "T12\tTask 416 432\tfull unification\n",
      "T13\tTask 444 460\tFull unification\n",
      "T14\tMetric 502 514\tcompile time\n",
      "T15\tMetric 519 527\trun time\n",
      "T16\tTask 554 570\tfull unification\n",
      "T17\tTask 638 654\tfull unification\n",
      "T18\tGeneric 703 705\tit\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tCOREF Arg1:T11 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R6\tCOREF Arg1:T17 Arg2:T16\n",
      "R7\tCOREF Arg1:T16 Arg2:T13\n",
      "R8\tCOREF Arg1:T13 Arg2:T12\n",
      "R9\tCOREF Arg1:T18 Arg2:T17\n",
      "R10\tCOREF Arg1:T12 Arg2:T10\n",
      "R11\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R12\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R13\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R14\tEVALUATE-FOR Arg1:T14 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\AAAI_1993_71_abs.ann\n",
      "T1\tTask 40 70\tlogical properties of contexts\n",
      "T2\tOtherScientificTerm 93 99\tsyntax\n",
      "T3\tOtherScientificTerm 104 113\tsemantics\n",
      "T4\tOtherScientificTerm 127 160\tpropositional language of context\n",
      "T5\tMethod 173 199\tHilbert style proof system\n",
      "T6\tGeneric 209 217\tlanguage\n",
      "T7\tOtherScientificTerm 221 251\tpropositional logic of context\n",
      "T8\tOtherScientificTerm 260 289\tclassical propositional logic\n",
      "T9\tOtherScientificTerm 318 326\tmodality\n",
      "T10\tGeneric 351 353\tIt\n",
      "T11\tMethod 620 646\tHilbert style proof system\n",
      "T12\tOtherScientificTerm 705 726\tcorrespondence theory\n",
      "R1\tCOREF Arg1:T4 Arg2:T6\n",
      "R2\tFEATURE-OF Arg1:T3 Arg2:T4\n",
      "R3\tFEATURE-OF Arg1:T2 Arg2:T4\n",
      "R4\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R5\tCOREF Arg1:T9 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R7\tCOREF Arg1:T5 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\AAAI_2008_254_abs.ann\n",
      "T1\tTask 4 33\tconstruction of causal graphs\n",
      "T2\tMaterial 39 60\tnon-experimental data\n",
      "T3\tOtherScientificTerm 79 90\tconstraints\n",
      "T4\tOtherScientificTerm 100 115\tgraph structure\n",
      "T5\tOtherScientificTerm 131 156\tprobability distributions\n",
      "T6\tOtherScientificTerm 177 182\tgraph\n",
      "T7\tGeneric 190 201\tconstraints\n",
      "T8\tOtherScientificTerm 220 247\tconditional inde-pendencies\n",
      "T9\tOtherScientificTerm 252 273\talgebraic constraints\n",
      "T10\tOtherScientificTerm 303 329\tconditional independencies\n",
      "T11\tMethod 370 397\tcausal induction algorithms\n",
      "T12\tOtherScientificTerm 399 416\tVerma constraints\n",
      "T13\tOtherScientificTerm 511 528\tVerma constraints\n",
      "T14\tGeneric 596 600\tthey\n",
      "T15\tOtherScientificTerm 614 636\tdormant independencies\n",
      "T16\tOtherScientificTerm 648 674\tconditional independencies\n",
      "T17\tOtherScientificTerm 688 716\tinterventional distributions\n",
      "T18\tGeneric 737 746\talgorithm\n",
      "T19\tOtherScientificTerm 768 788\tdormant independence\n",
      "T20\tOtherScientificTerm 809 818\tvariables\n",
      "T21\tOtherScientificTerm 838 850\tcausal graph\n",
      "T22\tOtherScientificTerm 867 879\tindependence\n",
      "T23\tGeneric 916 918\tit\n",
      "T24\tOtherScientificTerm 933 960\tinterventional distribution\n",
      "T25\tOtherScientificTerm 1004 1017\tinterventions\n",
      "T26\tOtherScientificTerm 1053 1075\tdormant independencies\n",
      "T27\tTask 1079 1092\tmodel testing\n",
      "T28\tTask 1097 1106\tinduction\n",
      "T29\tGeneric 1120 1129\talgorithm\n",
      "T30\tGeneric 1140 1151\tconstraints\n",
      "T31\tOtherScientificTerm 1164 1186\tdormant independencies\n",
      "T32\tOtherScientificTerm 1196 1212\textraneous edges\n",
      "T33\tOtherScientificTerm 1226 1238\tcausal graph\n",
      "R1\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R2\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R3\tFEATURE-OF Arg1:T5 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R5\tCOMPARE Arg1:T12 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R7\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R8\tFEATURE-OF Arg1:T16 Arg2:T17\n",
      "R9\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R10\tCOREF Arg1:T22 Arg2:T19\n",
      "R11\tCONJUNCTION Arg1:T27 Arg2:T28\n",
      "R12\tCOREF Arg1:T14 Arg2:T13\n",
      "R13\tCOREF Arg1:T23 Arg2:T22\n",
      "R14\tFEATURE-OF Arg1:T24 Arg2:T23\n",
      "R15\tUSED-FOR Arg1:T26 Arg2:T27\n",
      "R16\tUSED-FOR Arg1:T30 Arg2:T29\n",
      "R17\tPART-OF Arg1:T32 Arg2:T33\n",
      "R18\tCOREF Arg1:T7 Arg2:T3\n",
      "R19\tUSED-FOR Arg1:T26 Arg2:T28\n",
      "R20\tUSED-FOR Arg1:T29 Arg2:T32\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\AAAI_2008_255_abs.ann\n",
      "T1\tMethod 38 54\tbase classifiers\n",
      "T2\tTask 92 100\tensemble\n",
      "T3\tMethod 116 132\tensemble methods\n",
      "T4\tTask 263 284\tensemble construction\n",
      "T5\tTask 288 319\tresampling pairwise constraints\n",
      "T6\tOtherScientificTerm 401 421\tpairwise constraints\n",
      "T7\tTask 426 447\tensemble construction\n",
      "T8\tMethod 511 527\tbase classifiers\n",
      "T9\tOtherScientificTerm 537 565\tsampled pairwise constraints\n",
      "T10\tMethod 668 687\tdata representation\n",
      "T11\tOtherScientificTerm 694 705\tprojections\n",
      "T12\tOtherScientificTerm 718 738\tpairwise constraints\n",
      "T13\tMethod 759 776\tbase clas-sifiers\n",
      "T14\tMethod 790 809\tdata representation\n",
      "T15\tTask 838 869\tresampling pairwise constraints\n",
      "T16\tMethod 893 924\tBagging and Boosting algorithms\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tCOREF Arg1:T4 Arg2:T7\n",
      "R4\tCOREF Arg1:T2 Arg2:T4\n",
      "R5\tCOREF Arg1:T1 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R7\tCOREF Arg1:T8 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R9\tCOREF Arg1:T5 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R11\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R12\tCOREF Arg1:T10 Arg2:T14\n",
      "R13\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\AAAI_2008_262_abs.ann\n",
      "T1\tMethod 12 19\tYoopick\n",
      "T2\tMethod 23 61\tcombinatorial sports prediction market\n",
      "T3\tOtherScientificTerm 80 105\tflexible betting language\n",
      "T4\tTask 131 180\tfine-grained probabilistic estimation of outcomes\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\AAAI_2015_10_abs.ann\n",
      "T1\tTask 0 15\tMachine reading\n",
      "T2\tGeneric 36 41\tfield\n",
      "T3\tMethod 56 73\tcomputer programs\n",
      "T4\tMaterial 91 103\tflowing text\n",
      "T5\tOtherScientificTerm 116 131\tfact assertions\n",
      "T6\tMaterial 149 166\tnarrative content\n",
      "T7\tGeneric 173 177\ttask\n",
      "T8\tMethod 210 243\tnatural language processing (NLP)\n",
      "T9\tTask 248 275\tinformation extraction (IE)\n",
      "T10\tTask 305 327\tmachine reading system\n",
      "T11\tMethod 360 382\tcognitive architecture\n",
      "T12\tOtherScientificTerm 499 518\tcognitive semantics\n",
      "T13\tMethod 523 543\tconstruction grammar\n",
      "T14\tTask 561 570\tprior NLP\n",
      "T15\tTask 575 586\tIE research\n",
      "T16\tGeneric 604 610\tsystem\n",
      "T17\tMaterial 674 693\tidiosyncratic texts\n",
      "T18\tMaterial 701 722\tfamily history domain\n",
      "T19\tGeneric 776 782\tsystem\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R4\tFEATURE-OF Arg1:T5 Arg2:T6\n",
      "R5\tCOREF Arg1:T7 Arg2:T1\n",
      "R6\tPART-OF Arg1:T8 Arg2:T7\n",
      "R7\tPART-OF Arg1:T9 Arg2:T7\n",
      "R8\tFEATURE-OF Arg1:T11 Arg2:T10\n",
      "R9\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R10\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R11\tFEATURE-OF Arg1:T18 Arg2:T17\n",
      "R12\tCOREF Arg1:T16 Arg2:T10\n",
      "R13\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R14\tCOREF Arg1:T19 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\AAAI_2015_11_abs.ann\n",
      "T1\tTask 12 39\tconvex optimization problem\n",
      "T2\tTask 56 82\tsegmenting sequential data\n",
      "T3\tOtherScientificTerm 120 128\toutliers\n",
      "T4\tGeneric 146 156\talgorithms\n",
      "T5\tGeneric 174 181\tproblem\n",
      "T6\tMetric 311 321\tRobustness\n",
      "T7\tOtherScientificTerm 325 333\toutliers\n",
      "T8\tTask 354 370\treal-world tasks\n",
      "T9\tTask 382 401\tspeech segmentation\n",
      "T10\tGeneric 407 417\talgorithms\n",
      "T11\tMethod 429 462\tbaseline seg-mentation algorithms\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T5 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tCOMPARE Arg1:T10 Arg2:T11\n",
      "R5\tCOREF Arg1:T4 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R7\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R8\tEVALUATE-FOR Arg1:T8 Arg2:T6\n",
      "R9\tEVALUATE-FOR Arg1:T9 Arg2:T6\n",
      "R10\tFEATURE-OF Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\AAAI_2015_21_abs.ann\n",
      "T1\tMaterial 0 22\tSemantic Web documents\n",
      "T2\tTask 125 143\tCreating summaries\n",
      "T3\tMaterial 147 177\tlengthy Semantic Web documents\n",
      "T4\tTask 188 230\tidentification of the corresponding entity\n",
      "T5\tMethod 298 333\tautomatic summa-rization techniques\n",
      "T6\tOtherScientificTerm 482 513\tdiversified (faceted) summaries\n",
      "T7\tOtherScientificTerm 545 554\tdiversity\n",
      "T8\tOtherScientificTerm 556 566\tuniqueness\n",
      "T9\tOtherScientificTerm 572 582\tpopularity\n",
      "T10\tMethod 594 639\tdiversity-aware entity summarization approach\n",
      "T11\tMethod 647 685\thuman conceptual clustering techniques\n",
      "T12\tGeneric 868 876\tapproach\n",
      "T13\tGeneric 889 916\tstate-of-the-art techniques\n",
      "T14\tMetric 958 965\tquality\n",
      "T15\tMetric 974 984\tefficiency\n",
      "T16\tTask 988 1008\tentity summarization\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "R3\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R4\tFEATURE-OF Arg1:T8 Arg2:T6\n",
      "R5\tFEATURE-OF Arg1:T9 Arg2:T6\n",
      "R6\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R7\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R8\tCOREF Arg1:T10 Arg2:T12\n",
      "R9\tCOMPARE Arg1:T13 Arg2:T12\n",
      "R10\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R11\tEVALUATE-FOR Arg1:T14 Arg2:T16\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T16\n",
      "R13\tUSED-FOR Arg1:T13 Arg2:T16\n",
      "R14\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C00-1054.ann\n",
      "T1\tTask 2 23\tMultimodal interfaces\n",
      "T2\tMethod 43 50\tparsing\n",
      "T3\tGeneric 170 178\tapproach\n",
      "T4\tTask 204 226\tmultimodal integration\n",
      "T5\tMethod 262 287\tunification-based grammar\n",
      "T6\tMethod 308 337\tmultidimensional chart parser\n",
      "T7\tGeneric 363 371\tapproach\n",
      "T8\tOtherScientificTerm 424 434\tinterfaces\n",
      "T9\tMetric 565 589\tcomputational complexity\n",
      "T10\tGeneric 717 725\tapproach\n",
      "T11\tTask 736 772\tmultimodal parsing and understanding\n",
      "T12\tMethod 796 824\tweighted finite-state device\n",
      "T13\tMaterial 839 865\tspeech and gesture streams\n",
      "T14\tGeneric 922 930\tapproach\n",
      "T15\tTask 990 1014\tmultimodal understanding\n",
      "T16\tTask 1021 1039\tspeech recognition\n",
      "T17\tTask 1094 1125\tmultimodal ambiguity resolution\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R3\tCOREF Arg1:T7 Arg2:T3\n",
      "R4\tCOREF Arg1:T14 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R8\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R9\tCONJUNCTION Arg1:T16 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T17\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C00-2123.ann\n",
      "T1\tGeneric 30 46\tsearch procedure\n",
      "T2\tTask 52 88\tstatistical machine translation (MT)\n",
      "T3\tMethod 100 124\tdynamic programming (DP)\n",
      "T4\tMethod 143 160\tDP-based solution\n",
      "T5\tMethod 168 194\ttraveling salesman problem\n",
      "T6\tGeneric 215 224\ttechnique\n",
      "T7\tOtherScientificTerm 251 266\tword reordering\n",
      "T8\tMethod 338 354\tsearch algorithm\n",
      "T9\tMaterial 509 523\tVerbmobil task\n",
      "T10\tMaterial 526 540\tGerman-English\n",
      "T11\tTask 577 612\tlimited-domain spoken-language task\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tHYPONYM-OF Arg1:T9 Arg2:T11\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C02-1071.ann\n",
      "T1\tTask 38 53\tdeep processing\n",
      "T2\tMethod 73 91\tshallow techniques\n",
      "T3\tMethod 112 122\tNLP system\n",
      "T4\tMethod 144 177\tlinguistic PoS tagger and chunker\n",
      "T5\tMethod 211 262\tbroad coverage unification based grammar of Spanish\n",
      "T6\tGeneric 364 370\tsystem\n",
      "T7\tMetric 386 396\trobustness\n",
      "T8\tTask 406 427\tlinguistic processing\n",
      "T9\tMetric 457 465\taccuracy\n",
      "T10\tMetric 476 485\tprecision\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T6 Arg2:T3\n",
      "R3\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T3\n",
      "R6\tPART-OF Arg1:T4 Arg2:T5\n",
      "R7\tEVALUATE-FOR Arg1:T9 Arg2:T6\n",
      "R8\tEVALUATE-FOR Arg1:T10 Arg2:T6\n",
      "R9\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C02-1120.ann\n",
      "T1\tMethod 26 54\tunsupervised learning method\n",
      "T2\tOtherScientificTerm 61 107\tassociative relationships between verb phrases\n",
      "T3\tTask 153 164\tQ&A systems\n",
      "T4\tTask 283 293\tQ&A system\n",
      "T5\tMaterial 537 557\tlarge-scale database\n",
      "T6\tOtherScientificTerm 578 602\tassociative relationship\n",
      "T7\tMethod 665 693\tunsupervised learning method\n",
      "T8\tOtherScientificTerm 720 744\tassociative relationship\n",
      "T9\tOtherScientificTerm 762 782\tscenario consistency\n",
      "T10\tGeneric 789 795\tmethod\n",
      "T11\tMethod 833 894\texpectation-maximization (EM) based word-clustering algorithm\n",
      "T12\tGeneric 945 951\tmethod\n",
      "T13\tMaterial 959 980\tJapanese verb phrases\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R4\tCOREF Arg1:T10 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R6\tCOREF Arg1:T12 Arg2:T10\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R8\tCOREF Arg1:T8 Arg2:T6\n",
      "R9\tCOREF Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1011.ann\n",
      "T1\tMethod 43 68\tKullback-Leibler distance\n",
      "T2\tMethod 88 104\trelative entropy\n",
      "T3\tMethod 118 152\tprobabilistic context-free grammar\n",
      "T4\tOtherScientificTerm 161 191\tprobabilistic finite automaton\n",
      "T5\tMethod 219 252\tclosed-form (analytical) solution\n",
      "T6\tMethod 275 300\tKullback-Leibler distance\n",
      "T7\tMethod 312 325\tcross-entropy\n",
      "T8\tTask 393 421\tdistributional approximation\n",
      "T9\tMethod 427 462\tprobabilistic context-free grammars\n",
      "T10\tMethod 477 506\tprobabilistic finite automata\n",
      "R1\tCOMPARE Arg1:T3 Arg2:T4\n",
      "R2\tPART-OF Arg1:T7 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R4\tCOREF Arg1:T2 Arg2:T1\n",
      "R5\tCOREF Arg1:T10 Arg2:T4\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R8\tCOREF Arg1:T6 Arg2:T1\n",
      "R9\tFEATURE-OF Arg1:T8 Arg2:T9\n",
      "R10\tCOREF Arg1:T9 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1022.ann\n",
      "T1\tMethod 2 31\tStatistical language modeling\n",
      "T2\tGeneric 55 59\ttask\n",
      "T3\tMaterial 80 110\tmorphologically rich languages\n",
      "T4\tGeneric 127 137\tapproaches\n",
      "T5\tMethod 148 172\tfactored language models\n",
      "T6\tGeneric 226 232\tmodels\n",
      "T7\tOtherScientificTerm 283 305\tconditioning variables\n",
      "T8\tOtherScientificTerm 350 385\tmorphological or syntactic features\n",
      "T9\tOtherScientificTerm 433 449\tmodel parameters\n",
      "T10\tMethod 547 593\tentirely data-driven model selection procedure\n",
      "T11\tMethod 605 619\tgenetic search\n",
      "T12\tMethod 657 704\tknowledge-based and random selection procedures\n",
      "T13\tTask 724 747\tlanguage modeling tasks\n",
      "T14\tMaterial 751 757\tArabic\n",
      "T15\tMaterial 764 771\tTurkish\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R2\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R3\tCOREF Arg1:T6 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R5\tCOMPARE Arg1:T10 Arg2:T12\n",
      "R6\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R7\tHYPONYM-OF Arg1:T14 Arg2:T13\n",
      "R8\tHYPONYM-OF Arg1:T15 Arg2:T13\n",
      "R9\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R10\tCOREF Arg1:T2 Arg2:T1\n",
      "R11\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1024.ann\n",
      "T1\tMethod 15 48\tbit-vector-based CKY-style parser\n",
      "T2\tTask 55 75\tcontext-free parsing\n",
      "T3\tMethod 96 102\tparser\n",
      "T4\tMethod 124 151\tparse forest representation\n",
      "T5\tMethod 199 222\tlarge treebank grammars\n",
      "T6\tMethod 257 263\tparser\n",
      "T7\tMethod 271 292\tbit-vector operations\n",
      "T8\tMethod 346 352\tparser\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R3\tCOREF Arg1:T3 Arg2:T1\n",
      "R4\tCOREF Arg1:T6 Arg2:T3\n",
      "R5\tCOREF Arg1:T8 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1035.ann\n",
      "T1\tMethod 24 49\tmachine learning approach\n",
      "T2\tTask 55 80\tbare slice disambiguation\n",
      "T3\tMaterial 86 94\tdialogue\n",
      "T4\tMethod 118 138\theuristic principles\n",
      "T5\tMaterial 148 167\tcorpus-based sample\n",
      "T6\tOtherScientificTerm 192 218\tprobabilistic Horn clauses\n",
      "T7\tOtherScientificTerm 257 264\tclauses\n",
      "T8\tOtherScientificTerm 286 313\tdomain independent features\n",
      "T9\tMethod 370 397\tmachine learning algorithms\n",
      "T10\tGeneric 401 408\tSLIPPER\n",
      "T11\tMethod 413 442\trule-based learning algorithm\n",
      "T12\tGeneric 449 454\tTiMBL\n",
      "T13\tMethod 459 478\tmemory-based system\n",
      "T14\tMetric 527 540\tsuccess rates\n",
      "T15\tOtherScientificTerm 584 592\tfeatures\n",
      "T16\tMethod 630 650\theuristic principles\n",
      "T17\tOtherScientificTerm 697 702\trules\n",
      "T18\tOtherScientificTerm 731 743\tHorn clauses\n",
      "T19\tOtherScientificTerm 785 793\tfeatures\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tFEATURE-OF Arg1:T6 Arg2:T4\n",
      "R3\tCOMPARE Arg1:T11 Arg2:T13\n",
      "R4\tFEATURE-OF Arg1:T15 Arg2:T16\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R6\tPART-OF Arg1:T11 Arg2:T9\n",
      "R7\tPART-OF Arg1:T13 Arg2:T9\n",
      "R8\tHYPONYM-OF Arg1:T12 Arg2:T13\n",
      "R9\tHYPONYM-OF Arg1:T10 Arg2:T11\n",
      "R10\tCOREF Arg1:T9 Arg2:T1\n",
      "R11\tCOREF Arg1:T16 Arg2:T4\n",
      "R12\tCOREF Arg1:T18 Arg2:T6\n",
      "R13\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R14\tCOREF Arg1:T7 Arg2:T6\n",
      "R15\tCOREF Arg1:T19 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1036.ann\n",
      "T1\tMetric 28 48\tevaluation criterion\n",
      "T2\tMetric 55 79\tword similarity measures\n",
      "T3\tGeneric 90 99\tcriterion\n",
      "T4\tMetric 103 137\tmeaning-entailing substitutability\n",
      "T5\tTask 160 194\tsemantic-oriented NLP applications\n",
      "T6\tMetric 278 293\thuman agreement\n",
      "T7\tMetric 315 333\tsemantic criterion\n",
      "T8\tOtherScientificTerm 372 407\tdistributional word feature vectors\n",
      "T9\tTask 428 443\tword similarity\n",
      "T10\tGeneric 477 484\tmeasure\n",
      "T11\tMetric 501 523\tfeature vector quality\n",
      "T12\tMethod 544 584\tfeature weighting and selection function\n",
      "T13\tOtherScientificTerm 623 638\tfeature vectors\n",
      "T14\tTask 652 667\tword similarity\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tEVALUATE-FOR Arg1:T7 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T3 Arg2:T1\n",
      "R5\tCOREF Arg1:T4 Arg2:T3\n",
      "R6\tCOREF Arg1:T7 Arg2:T3\n",
      "R7\tEVALUATE-FOR Arg1:T6 Arg2:T4\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R9\tEVALUATE-FOR Arg1:T10 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R11\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R12\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1058.ann\n",
      "T1\tMethod 87 98\tclassifiers\n",
      "T2\tMethod 109 136\tmaximum entropy classifiers\n",
      "T3\tMethod 140 148\tboosting\n",
      "T4\tMethod 155 159\tSVMs\n",
      "T5\tTask 177 202\tlanguage processing tasks\n",
      "T6\tMethod 373 400\terror correction mechanisms\n",
      "T7\tGeneric 664 679\tbase classifier\n",
      "T8\tMethod 743 797\tN-fold Templated Piped Correction, or NTPC (\"nitpick\")\n",
      "T9\tMethod 815 830\terror corrector\n",
      "T10\tGeneric 920 922\tit\n",
      "T11\tGeneric 1000 1011\tbase models\n",
      "T12\tMethod 1082 1086\tNTPC\n",
      "T13\tOtherScientificTerm 1129 1151\tOccam's Razor argument\n",
      "R1\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R2\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T4 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T5\n",
      "R5\tHYPONYM-OF Arg1:T8 Arg2:T9\n",
      "R6\tCOREF Arg1:T9 Arg2:T6\n",
      "R7\tCOREF Arg1:T10 Arg2:T8\n",
      "R8\tCOMPARE Arg1:T10 Arg2:T11\n",
      "R9\tCOREF Arg1:T11 Arg2:T7\n",
      "R10\tCOREF Arg1:T12 Arg2:T8\n",
      "R11\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R12\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1068.ann\n",
      "T1\tTask 102 124\telectronic discussions\n",
      "T2\tTask 145 167\thelp-desk applications\n",
      "T3\tOtherScientificTerm 306 314\tfeatures\n",
      "T4\tTask 320 342\telectronic discussions\n",
      "T5\tMethod 364 382\tclustering process\n",
      "T6\tMethod 398 417\tfiltering mechanism\n",
      "T7\tMethod 473 507\tclustering and filtering processes\n",
      "T8\tMaterial 513 545\telectronic newsgroup discussions\n",
      "T9\tGeneric 598 609\texperiments\n",
      "T10\tTask 613 636\tcoarse-level clustering\n",
      "T11\tTask 646 667\tinformation retrieval\n",
      "R1\tEVALUATE-FOR Arg1:T8 Arg2:T7\n",
      "R2\tHYPONYM-OF Arg1:T10 Arg2:T9\n",
      "R3\tHYPONYM-OF Arg1:T11 Arg2:T9\n",
      "R4\tEVALUATE-FOR Arg1:T9 Arg2:T7\n",
      "R5\tCOREF Arg1:T4 Arg2:T1\n",
      "R6\tHYPONYM-OF Arg1:T5 Arg2:T7\n",
      "R7\tHYPONYM-OF Arg1:T6 Arg2:T7\n",
      "R8\tPART-OF Arg1:T1 Arg2:T2\n",
      "R9\tFEATURE-OF Arg1:T3 Arg2:T4\n",
      "R10\tEVALUATE-FOR Arg1:T9 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1080.ann\n",
      "T1\tMethod 18 28\tHMM tagger\n",
      "T2\tGeneric 106 108\tit\n",
      "T3\tTask 122 154\tunsupervised and supervised case\n",
      "T4\tMethod 222 242\tunsupervised methods\n",
      "T5\tTask 247 269\tpart-of-speech tagging\n",
      "T6\tMetric 434 442\taccuracy\n",
      "T7\tGeneric 473 483\talgorithms\n",
      "T8\tMethod 510 522\tHMM training\n",
      "T9\tOtherScientificTerm 569 590\tlexical probabilities\n",
      "T10\tGeneric 635 641\ttagger\n",
      "T11\tTask 682 726\tsupervised, non-training intensive framework\n",
      "R1\tCOREF Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tCOREF Arg1:T10 Arg2:T1\n",
      "R4\tEVALUATE-FOR Arg1:T3 Arg2:T2\n",
      "R5\tCOREF Arg1:T7 Arg2:T4\n",
      "R6\tEVALUATE-FOR Arg1:T11 Arg2:T10\n",
      "R7\tEVALUATE-FOR Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1096.ann\n",
      "T1\tOtherScientificTerm 26 47\treferring expressions\n",
      "T2\tOtherScientificTerm 94 110\tbinary relations\n",
      "T3\tOtherScientificTerm 340 355\tn-ary relations\n",
      "T4\tOtherScientificTerm 521 542\treferring expressions\n",
      "T5\tMethod 577 597\tgeneration algorithm\n",
      "T6\tGeneric 687 693\tmethod\n",
      "T7\tOtherScientificTerm 728 749\treferring expressions\n",
      "R1\tCOREF Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1102.ann\n",
      "T1\tMethod 15 31\tdetection method\n",
      "T2\tOtherScientificTerm 37 58\torthographic variants\n",
      "T3\tTask 70 85\ttransliteration\n",
      "T4\tGeneric 112 118\tmethod\n",
      "T5\tGeneric 132 144\tsimilarities\n",
      "T6\tOtherScientificTerm 155 172\tstring similarity\n",
      "T7\tMethod 184 197\tedit distance\n",
      "T8\tOtherScientificTerm 214 235\tcontextual similarity\n",
      "T9\tMethod 243 261\tvector space model\n",
      "T10\tGeneric 299 305\tmethod\n",
      "T11\tMetric 325 334\tF-measure\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R6\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R7\tHYPONYM-OF Arg1:T8 Arg2:T5\n",
      "R8\tCOREF Arg1:T10 Arg2:T4\n",
      "R9\tEVALUATE-FOR Arg1:T11 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1103.ann\n",
      "T1\tTask 2 46\tMachine transliteration/back-transliteration\n",
      "T2\tTask 81 126\tmultilingual speech and language applications\n",
      "T3\tGeneric 152 161\tframework\n",
      "T4\tTask 167 210\tmachine transliteration/backtransliteration\n",
      "T5\tMethod 241 276\tdirect orthographical mapping (DOM)\n",
      "T6\tGeneric 337 346\tframework\n",
      "T7\tMethod 351 393\tjoint source-channel transliteration model\n",
      "T8\tMethod 409 449\tn-gram transliteration model (n-gram TM)\n",
      "T9\tMethod 486 509\ttransliteration process\n",
      "T10\tGeneric 537 544\tmethods\n",
      "T11\tTask 562 597\ttransliteration/backtransliteration\n",
      "T12\tMaterial 616 667\tEnglish/Chinese and English/Japanese language pairs\n",
      "T13\tGeneric 706 712\tmethod\n",
      "T14\tMetric 794 818\ttransliteration accuracy\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tCOREF Arg1:T8 Arg2:T7\n",
      "R6\tCOREF Arg1:T6 Arg2:T3\n",
      "R7\tCOREF Arg1:T10 Arg2:T8\n",
      "R8\tCOREF Arg1:T13 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R10\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R11\tEVALUATE-FOR Arg1:T11 Arg2:T10\n",
      "R12\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R13\tCOREF Arg1:T11 Arg2:T1\n",
      "R14\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1106.ann\n",
      "T1\tTask 17 40\tanalogies between words\n",
      "T2\tTask 234 261\tanalogies between sentences\n",
      "T3\tMaterial 355 374\tmultilingual corpus\n",
      "T4\tOtherScientificTerm 403 412\tanalogies\n",
      "T5\tOtherScientificTerm 514 521\tanalogy\n",
      "R1\tEVALUATE-FOR Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1112.ann\n",
      "T1\tMethod 30 92\tcorpus-based supervised word sense disambiguation (WSD) system\n",
      "T2\tMaterial 99 104\tDutch\n",
      "T3\tMethod 122 148\tstatistical classification\n",
      "T4\tMethod 152 167\tmaximum entropy\n",
      "T5\tOtherScientificTerm 176 198\tlinguistic information\n",
      "T6\tMethod 233 244\tclassifiers\n",
      "T7\tOtherScientificTerm 251 269\tambiguous wordform\n",
      "T8\tMethod 288 308\tlemma-based approach\n",
      "T9\tGeneric 339 345\tmethod\n",
      "T10\tGeneric 354 356\tit\n",
      "T11\tOtherScientificTerm 371 386\tinflected forms\n",
      "T12\tOtherScientificTerm 395 409\tambiguous word\n",
      "T13\tMethod 419 429\tclassifier\n",
      "T14\tGeneric 495 504\talgorithm\n",
      "T15\tMethod 520 537\tlemma-based model\n",
      "T16\tMaterial 547 573\tDutch Senseval-2 test data\n",
      "T17\tMethod 634 648\twordform model\n",
      "T18\tMethod 662 688\tWSD system based on lemmas\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOMPARE Arg1:T6 Arg2:T8\n",
      "R3\tFEATURE-OF Arg1:T11 Arg2:T12\n",
      "R4\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "R5\tCOREF Arg1:T4 Arg2:T3\n",
      "R6\tCONJUNCTION Arg1:T5 Arg2:T4\n",
      "R7\tPART-OF Arg1:T3 Arg2:T1\n",
      "R8\tPART-OF Arg1:T5 Arg2:T1\n",
      "R9\tPART-OF Arg1:T4 Arg2:T1\n",
      "R10\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R11\tCOREF Arg1:T9 Arg2:T8\n",
      "R12\tCOREF Arg1:T14 Arg2:T9\n",
      "R13\tCOMPARE Arg1:T15 Arg2:T17\n",
      "R14\tCOREF Arg1:T18 Arg2:T15\n",
      "R15\tCOREF Arg1:T15 Arg2:T14\n",
      "R16\tCOREF Arg1:T8 Arg2:T1\n",
      "R17\tCOREF Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1116.ann\n",
      "T1\tMethod 15 33\ttext mining method\n",
      "T2\tOtherScientificTerm 48 70\tsynonymous expressions\n",
      "T3\tOtherScientificTerm 86 111\tdistributional hypothesis\n",
      "T4\tGeneric 171 182\tmethodology\n",
      "T5\tMetric 199 207\taccuracy\n",
      "T6\tMethod 215 238\tterm aggregation system\n",
      "T7\tGeneric 295 303\tapproach\n",
      "T8\tOtherScientificTerm 445 469\tsimilar context features\n",
      "T9\tOtherScientificTerm 513 535\tsynonymous expressions\n",
      "T10\tGeneric 551 557\tmethod\n",
      "T11\tMetric 572 580\taccuracy\n",
      "T12\tMethod 590 613\tterm aggregation system\n",
      "T13\tGeneric 633 641\tapproach\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tCOREF Arg1:T7 Arg2:T4\n",
      "R5\tCOREF Arg1:T10 Arg2:T7\n",
      "R6\tCOREF Arg1:T12 Arg2:T6\n",
      "R7\tEVALUATE-FOR Arg1:T6 Arg2:T4\n",
      "R8\tEVALUATE-FOR Arg1:T12 Arg2:T10\n",
      "R9\tCOREF Arg1:T13 Arg2:T10\n",
      "R10\tEVALUATE-FOR Arg1:T5 Arg2:T6\n",
      "R11\tEVALUATE-FOR Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1128.ann\n",
      "T1\tMethod 8 27\tsentence extraction\n",
      "T2\tTask 48 61\tsummarization\n",
      "T3\tMaterial 163 182\temail communication\n",
      "T4\tMethod 249 268\tsentence extraction\n",
      "T5\tTask 405 440\tdetection of  question-answer pairs\n",
      "T6\tMaterial 449 467\temail conversation\n",
      "T7\tTask 486 505\temail summarization\n",
      "T8\tOtherScientificTerm 530 538\tfeatures\n",
      "T9\tOtherScientificTerm 553 579\tstructure of email-threads\n",
      "T10\tOtherScientificTerm 609 627\tlexical similarity\n",
      "T11\tOtherScientificTerm 633 651\tdiscourse segments\n",
      "T12\tTask 658 681\tquestion-answer pairing\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tFEATURE-OF Arg1:T10 Arg2:T11\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T12\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1147.ann\n",
      "T1\tGeneric 14 23\tframework\n",
      "T2\tTask 32 78\tfast  computation  of  lexical affinity models\n",
      "T3\tGeneric 85 94\tframework\n",
      "T4\tGeneric 118 127\talgorithm\n",
      "T5\tOtherScientificTerm 156 182\tco-occurrence distribution\n",
      "T6\tMethod 214 232\tindependence model\n",
      "T7\tMethod 242 267\tparametric affinity model\n",
      "T8\tGeneric 299 305\tmodels\n",
      "T9\tOtherScientificTerm 355 365\tsimilarity\n",
      "T10\tOtherScientificTerm 391 407\tlexical affinity\n",
      "T11\tMethod 420 437\tsequential models\n",
      "T12\tGeneric 467 473\tmodels\n",
      "T13\tOtherScientificTerm 500 522\tco-occurrence patterns\n",
      "T14\tGeneric 597 606\tframework\n",
      "T15\tGeneric 694 696\tit\n",
      "T16\tMaterial 720 735\tterabyte corpus\n",
      "T17\tTask 748 770\tnatural language tests\n",
      "R1\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tPART-OF Arg1:T4 Arg2:T3\n",
      "R4\tPART-OF Arg1:T6 Arg2:T3\n",
      "R5\tPART-OF Arg1:T7 Arg2:T3\n",
      "R6\tCOMPARE Arg1:T12 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R9\tCOREF Arg1:T14 Arg2:T3\n",
      "R10\tCOREF Arg1:T15 Arg2:T14\n",
      "R11\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "R12\tUSED-FOR Arg1:T15 Arg2:T17\n",
      "R13\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R14\tCONJUNCTION Arg1:T4 Arg2:T6\n",
      "R15\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1192.ann\n",
      "T1\tGeneric 22 28\tmethod\n",
      "T2\tTask 34 59\tword sense disambiguation\n",
      "T3\tMaterial 71 87\tparallel corpora\n",
      "T4\tGeneric 94 100\tmethod\n",
      "T5\tTask 130 144\tword alignment\n",
      "T6\tTask 151 166\tword clustering\n",
      "T7\tTask 178 227\tautomatic extraction  of  translation equivalents\n",
      "T8\tMaterial 262 279\taligned  wordnets\n",
      "T9\tMaterial 323 331\twordnets\n",
      "T10\tMaterial 353 370\tPrinceton Wordnet\n",
      "T11\tMaterial 417 428\tEuroWordNet\n",
      "T12\tMethod 454 464\tWSD system\n",
      "T13\tGeneric 484 490\tmethod\n",
      "T14\tGeneric 550 556\tsystem\n",
      "T15\tOtherScientificTerm 615 668\talignment errors  in  multilingually aligned wordnets\n",
      "T16\tMaterial 637 668\tmultilingually aligned wordnets\n",
      "T17\tMaterial 674 682\tBalkaNet\n",
      "T18\tMaterial 689 700\tEuroWordNet\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T4 Arg2:T1\n",
      "R3\tCOREF Arg1:T12 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R6\tCOREF Arg1:T14 Arg2:T12\n",
      "R7\tHYPONYM-OF Arg1:T17 Arg2:T16\n",
      "R8\tHYPONYM-OF Arg1:T18 Arg2:T16\n",
      "R9\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R10\tUSED-FOR Arg1:T7 Arg2:T4\n",
      "R11\tUSED-FOR Arg1:T8 Arg2:T4\n",
      "R12\tCOREF Arg1:T9 Arg2:T8\n",
      "R13\tCOREF Arg1:T13 Arg2:T4\n",
      "R14\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R15\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R16\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C08-1118.ann\n",
      "T1\tMaterial 86 108\tmedium-length speeches\n",
      "T2\tMaterial 117 132\tEUROPARL corpus\n",
      "T3\tMethod 151 185\tfrequency counts  of  word n-grams\n",
      "T4\tOtherScientificTerm 173 185\tword n-grams\n",
      "T5\tMetric 201 209\taccuracy\n",
      "T6\tMethod 225 246\tclassification method\n",
      "T7\tOtherScientificTerm 291 307\tpositive markers\n",
      "R1\tPART-OF Arg1:T1 Arg2:T2\n",
      "R2\tEVALUATE-FOR Arg1:T5 Arg2:T6\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\C08-1128.ann\n",
      "T1\tMaterial 13 25\tChinese text\n",
      "T2\tTask 109 141\tmachine translation (MT) systems\n",
      "T3\tTask 148 150\tMT\n",
      "T4\tMethod 193 215\tChinese word segmenter\n",
      "T5\tMaterial 231 254\tmanually annotated data\n",
      "T6\tMethod 288 305\tword segmentation\n",
      "T7\tTask 339 350\ttranslation\n",
      "T8\tMethod 367 423\tBayesian semi-supervised Chinese word segmentation model\n",
      "T9\tOtherScientificTerm 442 479\tmonolingual and bilingual information\n",
      "T10\tTask 494 506\tsegmentation\n",
      "T11\tTask 522 524\tMT\n",
      "T12\tGeneric 553 559\tmethod\n",
      "T13\tMethod 589 598\tMT system\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R4\tCOREF Arg1:T3 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R6\tCOREF Arg1:T6 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R8\tCOREF Arg1:T7 Arg2:T3\n",
      "R9\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R10\tCOREF Arg1:T12 Arg2:T8\n",
      "R11\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R12\tCOREF Arg1:T11 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C08-2010.ann\n",
      "T1\tMetric 2 27\tLanguage resource quality\n",
      "T2\tTask 44 47\tNLP\n",
      "T3\tTask 134 137\tNLP\n",
      "T4\tTask 170 172\tMT\n",
      "T5\tTask 179 201\treference translations\n",
      "T6\tTask 213 234\tautomatic evaluations\n",
      "T7\tMaterial 242 259\thigh-quality data\n",
      "T8\tGeneric 355 364\tresources\n",
      "T9\tOtherScientificTerm 448 476\tdifferent-quality references\n",
      "T10\tGeneric 482 492\tevaluation\n",
      "T11\tMetric 615 632\tautomatic metrics\n",
      "T12\tTask 647 649\tMT\n",
      "R1\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R2\tEVALUATE-FOR Arg1:T11 Arg2:T12\n",
      "R3\tCOREF Arg1:T10 Arg2:T6\n",
      "R4\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R5\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R6\tCOREF Arg1:T12 Arg2:T4\n",
      "R7\tCOREF Arg1:T3 Arg2:T2\n",
      "R8\tCOREF Arg1:T8 Arg2:T7\n",
      "R9\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R10\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R11\tFEATURE-OF Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C08-3010.ann\n",
      "T1\tMethod 36 47\tsearch tool\n",
      "T2\tOtherScientificTerm 68 74\tngrams\n",
      "T3\tGeneric 81 85\ttool\n",
      "T4\tGeneric 146 148\tIt\n",
      "T5\tGeneric 246 252\tsystem\n",
      "T6\tOtherScientificTerm 301 307\tmemory\n",
      "T7\tOtherScientificTerm 330 340\tdisk space\n",
      "T8\tGeneric 366 372\tsystem\n",
      "T9\tGeneric 394 398\ttool\n",
      "T10\tTask 404 434\tlinguistic knowledge discovery\n",
      "T11\tTask 447 456\tNLP tasks\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T8 Arg2:T5\n",
      "R4\tCOREF Arg1:T9 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R7\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T4 Arg2:T3\n",
      "R9\tCOREF Arg1:T5 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C80-1039.ann\n",
      "T1\tGeneric 147 153\tsystem\n",
      "T2\tMethod 155 160\tFROFF\n",
      "T3\tOtherScientificTerm 361 376\ttyping location\n",
      "T4\tOtherScientificTerm 543 551\tcommands\n",
      "T5\tOtherScientificTerm 556 561\trules\n",
      "T6\tOtherScientificTerm 640 664\tmathematical expressions\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R2\tCOREF Arg1:T2 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R4\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C80-1073.ann\n",
      "T1\tMethod 39 67\tAugmented Transition Network\n",
      "T2\tMethod 86 98\tdialog model\n",
      "T3\tGeneric 129 134\tmodel\n",
      "T4\tGeneric 186 192\tdevice\n",
      "T5\tOtherScientificTerm 228 243\tdialog schemata\n",
      "T6\tMethod 268 289\tconversation analysis\n",
      "T7\tGeneric 298 304\tdevice\n",
      "T8\tGeneric 330 336\tmodels\n",
      "T9\tOtherScientificTerm 340 358\tverbal interaction\n",
      "T10\tGeneric 367 373\tdevice\n",
      "T11\tOtherScientificTerm 401 416\tdialog schemata\n",
      "T12\tOtherScientificTerm 429 447\tverbal interaction\n",
      "T13\tMaterial 471 510\ttask-oriented and goal-directed dialogs\n",
      "T14\tMethod 526 529\tATN\n",
      "T15\tOtherScientificTerm 588 607\tverbal interactions\n",
      "T16\tMaterial 613 634\ttask-oriented dialogs\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tFEATURE-OF Arg1:T15 Arg2:T16\n",
      "R3\tCOREF Arg1:T7 Arg2:T3\n",
      "R4\tCOREF Arg1:T10 Arg2:T3\n",
      "R5\tCOREF Arg1:T14 Arg2:T3\n",
      "R6\tCOREF Arg1:T15 Arg2:T12\n",
      "R7\tCOREF Arg1:T11 Arg2:T5\n",
      "R8\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R9\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R11\tCOREF Arg1:T12 Arg2:T9\n",
      "R12\tCOREF Arg1:T3 Arg2:T1\n",
      "R13\tCOREF Arg1:T3 Arg2:T4\n",
      "R14\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R15\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R16\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C82-1054.ann\n",
      "T1\tMethod 57 86\tleft corner parsing algorithm\n",
      "T2\tMethod 93 114\tcontext-free grammars\n",
      "T3\tGeneric 150 159\talgorithm\n",
      "T4\tMethod 233 239\tparser\n",
      "T5\tTask 252 278\tnatural language interface\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tCOREF Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C86-1021.ann\n",
      "T1\tMethod 6 27\tinterlingual approach\n",
      "T2\tGeneric 31 33\tMT\n",
      "T3\tTask 106 136\tnatural language understanding\n",
      "T4\tTask 148 167\tmachine translation\n",
      "T5\tMethod 384 394\tMu-project\n",
      "T6\tMethod 409 426\ttransfer approach\n",
      "T7\tTask 455 457\tMT\n",
      "T8\tGeneric 515 529\ttransfer phase\n",
      "T9\tGeneric 538 544\tsystem\n",
      "T10\tMaterial 551 559\tJapanese\n",
      "T11\tMaterial 565 572\tEnglish\n",
      "T12\tMethod 649 670\tinterlingual approach\n",
      "T13\tGeneric 709 723\ttransfer phase\n",
      "T14\tGeneric 732 738\tsystem\n",
      "T15\tGeneric 791 801\tprinciples\n",
      "T16\tMethod 858 884\tMultiple Layer of Grammars\n",
      "T17\tMethod 891 918\tMultiple Layer Presentation\n",
      "T18\tMethod 925 950\tLexicon Driven Processing\n",
      "T19\tMethod 957 993\tForm-Oriented Dictionary Description\n",
      "T20\tGeneric 1028 1038\tprinciples\n",
      "T21\tGeneric 1067 1073\tsystem\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T4 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R4\tPART-OF Arg1:T8 Arg2:T9\n",
      "R5\tCOREF Arg1:T9 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R7\tCOREF Arg1:T13 Arg2:T8\n",
      "R8\tCOREF Arg1:T14 Arg2:T9\n",
      "R9\tPART-OF Arg1:T13 Arg2:T14\n",
      "R10\tPART-OF Arg1:T16 Arg2:T15\n",
      "R11\tPART-OF Arg1:T17 Arg2:T15\n",
      "R12\tPART-OF Arg1:T18 Arg2:T15\n",
      "R13\tPART-OF Arg1:T19 Arg2:T15\n",
      "R14\tCOREF Arg1:T21 Arg2:T14\n",
      "R15\tCOREF Arg1:T20 Arg2:T15\n",
      "R16\tPART-OF Arg1:T20 Arg2:T21\n",
      "R17\tCOREF Arg1:T8 Arg2:T6\n",
      "R18\tCOREF Arg1:T12 Arg2:T1\n",
      "R19\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R20\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R21\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C86-1081.ann\n",
      "T1\tMethod 4 15\tDeterminers\n",
      "T2\tMethod 284 295\tdeterminers\n",
      "T3\tOtherScientificTerm 316 325\tambiguity\n",
      "T4\tMethod 357 374\tlogical formalism\n",
      "T5\tTask 435 446\tdeterminers\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tCOREF Arg1:T5 Arg2:T2\n",
      "R4\tCOREF Arg1:T2 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C86-1105.ann\n",
      "T1\tOtherScientificTerm 16 38\thierarchical relations\n",
      "T2\tOtherScientificTerm 46 77\tsuperordinate -hyponym relation\n",
      "T3\tOtherScientificTerm 81 97\tsynonym relation\n",
      "T4\tTask 143 165\tthesaurus construction\n",
      "T5\tGeneric 205 214\trelations\n",
      "T6\tMaterial 248 276\tJapanese language dictionary\n",
      "T7\tOtherScientificTerm 367 375\tfeatures\n",
      "T8\tOtherScientificTerm 384 404\tdefinition sentences\n",
      "T9\tGeneric 414 424\tdictionary\n",
      "T10\tOtherScientificTerm 461 483\thierarchical relations\n",
      "R1\tPART-OF Arg1:T1 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tPART-OF Arg1:T8 Arg2:T9\n",
      "R4\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R5\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R6\tCOREF Arg1:T5 Arg2:T1\n",
      "R7\tCOREF Arg1:T9 Arg2:T6\n",
      "R8\tCOREF Arg1:T10 Arg2:T5\n",
      "R9\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C86-1132.ann\n",
      "T1\tGeneric 26 32\tsystem\n",
      "T2\tMethod 36 42\tRAREAS\n",
      "T3\tTask 64 88\tmarine weather forecasts\n",
      "T4\tMaterial 104 126\tformatted weather data\n",
      "T5\tGeneric 136 145\tsynthesis\n",
      "T6\tMaterial 176 230\tnatural sublanguages  with  stereotyped text structure\n",
      "T7\tMethod 235 241\tRAREAS\n",
      "T8\tOtherScientificTerm 270 309\tlinguistic and non-linguistic knowledge\n",
      "T9\tGeneric 441 449\tapproach\n",
      "T10\tMaterial 487 519\tbilingual or multi-lingual texts\n",
      "R1\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R2\tCOREF Arg1:T2 Arg2:T1\n",
      "R3\tCOREF Arg1:T5 Arg2:T1\n",
      "R4\tCOREF Arg1:T7 Arg2:T5\n",
      "R5\tCOREF Arg1:T9 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R8\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-1007.ann\n",
      "T1\tMethod 44 80\tUnification Categorial Grammar (UCG)\n",
      "T2\tMethod 103 122\tIsomorphic Grammars\n",
      "T3\tTask 129 148\tMachine Translation\n",
      "T4\tMethod 181 209\tIsomorphic Grammars approach\n",
      "T5\tTask 213 215\tMT\n",
      "T6\tOtherScientificTerm 372 392\ttranslation relation\n",
      "T7\tOtherScientificTerm 400 422\tisomorphic derivations\n",
      "T8\tOtherScientificTerm 729 749\ttranslation relation\n",
      "T9\tMethod 771 793\ttextual representation\n",
      "T10\tGeneric 820 828\tapproach\n",
      "T11\tTask 833 850\tMT system  design\n",
      "T12\tTask 871 886\tmonolingual UCG\n",
      "T13\tGeneric 911 914\ttwo\n",
      "T14\tOtherScientificTerm 978 1017\tbi-directional English-Spanish fragment\n",
      "T15\tGeneric 1080 1088\tapproach\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R3\tCOREF Arg1:T15 Arg2:T10\n",
      "R4\tHYPONYM-OF Arg1:T12 Arg2:T13\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tCOREF Arg1:T2 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R8\tCOREF Arg1:T5 Arg2:T3\n",
      "R9\tCOREF Arg1:T4 Arg2:T10\n",
      "R10\tCOREF Arg1:T5 Arg2:T11\n",
      "R11\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R12\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R13\tHYPONYM-OF Arg1:T11 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-1044.ann\n",
      "T1\tOtherScientificTerm 75 100\tdemonstrative expressions\n",
      "T2\tMaterial 106 113\tEnglish\n",
      "T3\tGeneric 129 141\timplications\n",
      "T4\tMethod 155 186\tdiscourse processing algorithms\n",
      "T5\tOtherScientificTerm 259 292\tdemonstrative forms and functions\n",
      "T6\tOtherScientificTerm 361 382\tanaphoric expressions\n",
      "T7\tMethod 436 470\tnatural language generation system\n",
      "R1\tFEATURE-OF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-1066.ann\n",
      "T1\tTask 29 84\tformalism of  Category Cooccurrence Restrictions (CCRs)\n",
      "T2\tOtherScientificTerm 43 84\tCategory Cooccurrence Restrictions (CCRs)\n",
      "T3\tMethod 105 123\tparsing algorithms\n",
      "T4\tGeneric 140 142\tit\n",
      "T5\tOtherScientificTerm 145 149\tCCRs\n",
      "T6\tOtherScientificTerm 156 174\tBoolean conditions\n",
      "T7\tOtherScientificTerm 216 227\tlocal trees\n",
      "T8\tOtherScientificTerm 246 274\tstatement of generalizations\n",
      "T9\tMethod 319 336\tsyntax formalisms\n",
      "T10\tOtherScientificTerm 352 356\tCCRs\n",
      "T11\tOtherScientificTerm 368 390\tsyntactic descriptions\n",
      "T12\tOtherScientificTerm 418 440\trestrictive statements\n",
      "T13\tGeneric 477 487\talgorithms\n",
      "T14\tMaterial 509 531\tcontext free languages\n",
      "T15\tTask 556 569\tCCR formalism\n",
      "T16\tMethod 620 626\tparser\n",
      "T17\tOtherScientificTerm 660 694\tlogical well-formedness conditions\n",
      "T18\tOtherScientificTerm 700 705\ttrees\n",
      "R1\tFEATURE-OF Arg1:T12 Arg2:T11\n",
      "R2\tFEATURE-OF Arg1:T17 Arg2:T18\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T10 Arg2:T5\n",
      "R5\tCOREF Arg1:T5 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R8\tCOREF Arg1:T13 Arg2:T3\n",
      "R9\tCOREF Arg1:T16 Arg2:T13\n",
      "R10\tCOREF Arg1:T15 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-2086.ann\n",
      "T1\tTask 63 95\tnatural language presuppositions\n",
      "T2\tTask 374 406\tnatural language presuppositions\n",
      "T3\tOtherScientificTerm 495 518\tpresuppositional nature\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-2130.ann\n",
      "T1\tGeneric 24 43\tcomputational model\n",
      "T2\tTask 127 141\tdiscourse task\n",
      "T3\tGeneric 200 205\tmodel\n",
      "T4\tGeneric 224 231\tprogram\n",
      "T5\tMethod 234 237\tAPT\n",
      "T6\tMethod 314 353\torganizational and discourse strategies\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tPART-OF Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-2132.ann\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-2160.ann\n",
      "T1\tGeneric 9 17\tapproach\n",
      "T2\tTask 23 54\tInteractive Machine Translation\n",
      "T3\tMethod 278 295\tlinguistic theory\n",
      "T4\tMethod 420 439\ttranslation process\n",
      "T5\tMethod 470 503\tinteractive disambiguation scheme\n",
      "T6\tMethod 519 531\tparaphrasing\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T5 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-2162.ann\n",
      "T1\tGeneric 3 20\tComputer programs\n",
      "T2\tTask 61 81\tlanguage acquisition\n",
      "T3\tMethod 101 121\tlearning methodology\n",
      "T4\tMaterial 138 153\tgeneral domains\n",
      "T5\tMaterial 192 209\tlinguistic domain\n",
      "T6\tMethod 227 252\tlinguistic representation\n",
      "T7\tMethod 263 290\tlanguage processing systems\n",
      "T8\tMethod 343 368\tlinguistic representation\n",
      "T9\tOtherScientificTerm 377 420\tDynamic Hierarchical Phrasal Lexicon (DHPL)\n",
      "T10\tTask 449 469\tlanguage acquisition\n",
      "T11\tMethod 487 510\tlanguage learning model\n",
      "T12\tMethod 544 548\tRINA\n",
      "T13\tOtherScientificTerm 576 593\tlexical hierarchy\n",
      "T14\tOtherScientificTerm 667 686\tlinguistic concepts\n",
      "T15\tGeneric 746 755\thierarchy\n",
      "T16\tOtherScientificTerm 851 868\tlexical hierarchy\n",
      "T17\tOtherScientificTerm 897 916\tlinguistic concepts\n",
      "T18\tGeneric 929 936\tprogram\n",
      "R1\tCOMPARE Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R4\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R6\tPART-OF Arg1:T11 Arg2:T12\n",
      "R7\tPART-OF Arg1:T14 Arg2:T15\n",
      "R8\tCOREF Arg1:T18 Arg2:T1\n",
      "R9\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R11\tCOREF Arg1:T17 Arg2:T14\n",
      "R12\tCOREF Arg1:T10 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-2166.ann\n",
      "T1\tMethod 19 42\tnatural language system\n",
      "T2\tOtherScientificTerm 53 74\tcomputational lexicon\n",
      "T3\tGeneric 83 89\tsystem\n",
      "T4\tMethod 344 351\tCOMPLEX\n",
      "T5\tOtherScientificTerm 358 379\tcomputational lexicon\n",
      "T6\tOtherScientificTerm 413 439\tshared lexical information\n",
      "T7\tTask 453 494\tNatural Language Processing (NLP) systems\n",
      "T8\tMaterial 565 602\tmachine-readable dictionaries (MRD's)\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T7\n",
      "R5\tCOREF Arg1:T5 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-1002.ann\n",
      "T1\tMethod 4 24\tdeterministic parser\n",
      "T2\tMethod 94 115\tdeterministic parsers\n",
      "T3\tGeneric 125 127\tit\n",
      "T4\tMethod 143 180\tsymbolic and connectionist components\n",
      "T5\tMethod 187 210\tconnectionist component\n",
      "T6\tOtherScientificTerm 235 243\tpatterns\n",
      "T7\tMethod 263 297\trules  of a  deterministic grammar\n",
      "T8\tMethod 341 360\thybrid architecture\n",
      "T9\tMethod 377 383\tparser\n",
      "T10\tMethod 417 437\tdeterministic parser\n",
      "T11\tMethod 480 499\ttraining techniques\n",
      "T12\tTask 531 546\tdecision-making\n",
      "T13\tMethod 556 579\tconnectionist component\n",
      "T14\tMethod 589 604\tparsing process\n",
      "T15\tGeneric 612 620\tapproach\n",
      "T16\tOtherScientificTerm 664 669\trules\n",
      "T17\tMethod 681 702\tdeterministic parsers\n",
      "T18\tTask 779 786\tparsing\n",
      "T19\tMethod 887 917\tconnectionist (neural) network\n",
      "T20\tOtherScientificTerm 933 949\tlinguistic rules\n",
      "T21\tMaterial 967 999\texpected (grammatical) sentences\n",
      "T22\tMaterial 1023 1071\t(ungrammatical or lexically ambiguous) sentences\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R2\tPART-OF Arg1:T13 Arg2:T14\n",
      "R3\tUSED-FOR Arg1:T19 Arg2:T21\n",
      "R4\tCOREF Arg1:T3 Arg2:T1\n",
      "R5\tPART-OF Arg1:T4 Arg2:T3\n",
      "R6\tHYPONYM-OF Arg1:T5 Arg2:T4\n",
      "R7\tCOREF Arg1:T8 Arg2:T4\n",
      "R8\tCOMPARE Arg1:T9 Arg2:T10\n",
      "R9\tCOREF Arg1:T9 Arg2:T1\n",
      "R10\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R11\tCOREF Arg1:T15 Arg2:T11\n",
      "R12\tCOREF Arg1:T17 Arg2:T10\n",
      "R13\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R14\tCOMPARE Arg1:T1 Arg2:T2\n",
      "R15\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R16\tUSED-FOR Arg1:T19 Arg2:T22\n",
      "R17\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "R18\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R19\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-1013.ann\n",
      "T1\tMethod 30 69\tbidirectional grammar generation system\n",
      "T2\tMethod 79 116\tfeature structure-directed generation\n",
      "T3\tTask 137 164\tdialogue translation system\n",
      "T4\tGeneric 172 178\tsystem\n",
      "T5\tOtherScientificTerm 189 213\ttyped feature structures\n",
      "T6\tOtherScientificTerm 231 250\ttop-down derivation\n",
      "T7\tMethod 280 297\tgeneration system\n",
      "T8\tOtherScientificTerm 310 340\tdisjunctive feature structures\n",
      "T9\tOtherScientificTerm 381 396\tderivation tree\n",
      "T10\tMethod 405 412\tgrammar\n",
      "T11\tGeneric 424 433\tgenerator\n",
      "T12\tOtherScientificTerm 473 492\tspeaker's intention\n",
      "T13\tOtherScientificTerm 500 518\ttelephone dialogue\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R5\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R7\tCOREF Arg1:T4 Arg2:T2\n",
      "R8\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R9\tCOREF Arg1:T7 Arg2:T4\n",
      "R10\tCOREF Arg1:T11 Arg2:T7\n",
      "R11\tFEATURE-OF Arg1:T13 Arg2:T12\n",
      "R12\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R13\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-2032.ann\n",
      "T1\tMethod 24 63\tdocument oriented preference sets(DoPS)\n",
      "T2\tTask 73 116\tdisambiguation of the  dependency structure\n",
      "T3\tMethod 140 151\tDoPS system\n",
      "T4\tOtherScientificTerm 245 265\tSentence ambiguities\n",
      "T5\tOtherScientificTerm 292 328\tdomain targeted preference knowledge\n",
      "T6\tMaterial 362 376\tknowledgebases\n",
      "T7\tOtherScientificTerm 460 481\tdependency structures\n",
      "T8\tMaterial 487 518\tJapanese patent claim sentences\n",
      "R1\tFEATURE-OF Arg1:T7 Arg2:T8\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R4\tCOMPARE Arg1:T5 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-3007.ann\n",
      "T1\tOtherScientificTerm 40 74\tfeature-based partial descriptions\n",
      "T2\tMethod 93 121\tHalliday's systemic networks\n",
      "T3\tMethod 163 183\tconsistency checking\n",
      "T4\tGeneric 194 206\tdescriptions\n",
      "R1\tCOREF Arg1:T4 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-3014.ann\n",
      "T1\tTask 44 85\tKorean phonological knowledge base system\n",
      "T2\tMethod 98 133\tunification-based grammar formalism\n",
      "T3\tMethod 138 179\tKorean Phonology Structure Grammar (KPSG)\n",
      "T4\tGeneric 187 195\tapproach\n",
      "T5\tMethod 200 204\tKPSG\n",
      "T6\tTask 279 298\tphonological system\n",
      "T7\tTask 303 344\tspeech recognition  and  synthesis system\n",
      "T8\tGeneric 374 382\tapproach\n",
      "T9\tGeneric 414 424\tapproaches\n",
      "T10\tGeneric 433 438\tthose\n",
      "T11\tMethod 464 496\tgenerative phonological approach\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tCOREF Arg1:T5 Arg2:T3\n",
      "R4\tCOMPARE Arg1:T8 Arg2:T9\n",
      "R5\tCOREF Arg1:T8 Arg2:T4\n",
      "R6\tCOREF Arg1:T10 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R8\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R9\tCOREF Arg1:T7 Arg2:T6\n",
      "R10\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-3045.ann\n",
      "T1\tMethod 29 58\ttree-adjoining grammars (TAG)\n",
      "T2\tMethod 104 108\tTAGs\n",
      "T3\tOtherScientificTerm 142 148\tsyntax\n",
      "T4\tTask 182 205\tsemantic interpretation\n",
      "T5\tTask 211 252\tautomatic translation of natural language\n",
      "T6\tMethod 269 285\tvariant of  TAGs\n",
      "T7\tMethod 281 285\tTAGs\n",
      "T8\tMethod 297 313\tsynchronous TAGs\n",
      "T9\tOtherScientificTerm 419 451\texpressions of natural languages\n",
      "T10\tOtherScientificTerm 474 483\tsemantics\n",
      "T11\tOtherScientificTerm 503 524\tlogical form language\n",
      "T12\tOtherScientificTerm 565 581\tnatural language\n",
      "T13\tMethod 620 624\tTAGs\n",
      "T14\tOtherScientificTerm 659 672\tsyntax proper\n",
      "T15\tMethod 707 723\tsynchronous TAGs\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R2\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R3\tCOREF Arg1:T2 Arg2:T1\n",
      "R4\tCOREF Arg1:T7 Arg2:T2\n",
      "R5\tCOREF Arg1:T13 Arg2:T7\n",
      "R6\tCOREF Arg1:T15 Arg2:T8\n",
      "R7\tCOREF Arg1:T8 Arg2:T6\n",
      "R8\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "R9\tUSED-FOR Arg1:T2 Arg2:T5\n",
      "R10\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-3046.ann\n",
      "T1\tTask 29 46\tsentence analysis\n",
      "T2\tMethod 70 90\tdefeasible reasoning\n",
      "T3\tGeneric 114 123\ttreatment\n",
      "T4\tTask 129 155\tJapanese sentence analyses\n",
      "T5\tMethod 167 187\targumentation system\n",
      "T6\tMethod 214 253\tformalization  of  defeasible reasoning\n",
      "T7\tMethod 233 253\tdefeasible reasoning\n",
      "T8\tOtherScientificTerm 272 281\targuments\n",
      "T9\tOtherScientificTerm 288 300\tdefeat rules\n",
      "T10\tOtherScientificTerm 316 329\tdefeasibility\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "R3\tCOREF Arg1:T7 Arg2:T2\n",
      "R4\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R5\tCOREF Arg1:T3 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R8\tFEATURE-OF Arg1:T10 Arg2:T8\n",
      "R9\tPART-OF Arg1:T8 Arg2:T6\n",
      "R10\tPART-OF Arg1:T9 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-3063.ann\n",
      "T1\tTask 2 46\tManual acquisition  of  semantic constraints\n",
      "T2\tOtherScientificTerm 154 175\tcooccurrence patterns\n",
      "T3\tOtherScientificTerm 243 263\tsemantic constraints\n",
      "T4\tOtherScientificTerm 300 319\tanaphora references\n",
      "T5\tOtherScientificTerm 326 347\tsyntactic ambiguities\n",
      "T6\tMethod 424 440\tlinguistic tools\n",
      "T7\tOtherScientificTerm 644 667\tcooccurrence statistics\n",
      "T8\tOtherScientificTerm 689 709\tsemantic constraints\n",
      "T9\tMethod 750 769\tdisambiguation tool\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R4\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-3072.ann\n",
      "T1\tTask 4 21\tSpelling-checkers\n",
      "T2\tTask 61 85\ttext processing software\n",
      "T3\tGeneric 157 161\tthey\n",
      "T4\tOtherScientificTerm 184 210\tdictionaries of word forms\n",
      "T5\tGeneric 238 246\tapproach\n",
      "T6\tMaterial 265 274\tlanguages\n",
      "T7\tOtherScientificTerm 288 298\tinflection\n",
      "T8\tMaterial 309 316\tEnglish\n",
      "T9\tMaterial 335 362\thighly inflective languages\n",
      "T10\tMaterial 373 378\tCzech\n",
      "T11\tMaterial 383 390\tRussian\n",
      "T12\tMaterial 395 401\tSlovak\n",
      "T13\tMaterial 413 431\tSlavonic languages\n",
      "T14\tGeneric 463 469\tmethod\n",
      "T15\tOtherScientificTerm 486 496\tinflection\n",
      "T16\tTask 527 544\tspelling-checkers\n",
      "T17\tGeneric 555 564\tlanguages\n",
      "T18\tGeneric 593 600\tprogram\n",
      "T19\tMethod 656 673\tspelling-checkers\n",
      "T20\tMaterial 680 687\tEnglish\n",
      "T21\tMaterial 824 829\tCzech\n",
      "T22\tGeneric 853 859\tmethod\n",
      "T23\tTask 889 908\tword classification\n",
      "R1\tPART-OF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R3\tCOREF Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R5\tCOREF Arg1:T5 Arg2:T4\n",
      "R6\tHYPONYM-OF Arg1:T8 Arg2:T6\n",
      "R7\tHYPONYM-OF Arg1:T10 Arg2:T9\n",
      "R8\tHYPONYM-OF Arg1:T11 Arg2:T9\n",
      "R9\tHYPONYM-OF Arg1:T12 Arg2:T9\n",
      "R10\tHYPONYM-OF Arg1:T13 Arg2:T9\n",
      "R11\tCOREF Arg1:T16 Arg2:T3\n",
      "R12\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R13\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R14\tCOREF Arg1:T17 Arg2:T9\n",
      "R15\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R16\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R17\tCOREF Arg1:T18 Arg2:T14\n",
      "R18\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R19\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R20\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R21\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R22\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C92-1052.ann\n",
      "T1\tOtherScientificTerm 18 36\tdiscourse segments\n",
      "T2\tGeneric 56 62\tmethod\n",
      "T3\tTask 68 90\tdiscourse segmentation\n",
      "T4\tTask 112 145\tabduction  of  temporal relations\n",
      "T5\tGeneric 184 190\tmethod\n",
      "T6\tTask 283 311\ttemporal anaphora resolution\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tCOREF Arg1:T5 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C92-1055.ann\n",
      "T1\tMethod 60 87\tadaptive learning procedure\n",
      "T2\tTask 127 157\tsyntactic ambiguity resolution\n",
      "T3\tOtherScientificTerm 186 212\tinsufficient training data\n",
      "T4\tOtherScientificTerm 219 238\tapproximation error\n",
      "T5\tMethod 259 273\tlanguage model\n",
      "T6\tMethod 290 312\tstatistical approaches\n",
      "T7\tOtherScientificTerm 331 342\tambiguities\n",
      "T8\tMethod 380 405\tmaximum likelihood method\n",
      "T9\tGeneric 479 485\tmethod\n",
      "T10\tGeneric 501 509\tproblems\n",
      "T11\tGeneric 601 610\talgorithm\n",
      "T12\tOtherScientificTerm 744 761\tseparation margin\n",
      "T13\tMetric 880 893\taccuracy rate\n",
      "T14\tTask 899 923\tsyntactic disambiguation\n",
      "T15\tGeneric 976 984\tapproach\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R3\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R5\tCOREF Arg1:T11 Arg2:T9\n",
      "R6\tCOREF Arg1:T14 Arg2:T2\n",
      "R7\tEVALUATE-FOR Arg1:T13 Arg2:T14\n",
      "R8\tCOREF Arg1:T9 Arg2:T1\n",
      "R9\tHYPONYM-OF Arg1:T3 Arg2:T10\n",
      "R10\tHYPONYM-OF Arg1:T4 Arg2:T10\n",
      "R11\tCOREF Arg1:T15 Arg2:T11\n",
      "R12\tEVALUATE-FOR Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C92-2068.ann\n",
      "T1\tTask 4 21\tGraph unification\n",
      "T2\tTask 59 92\tunification-based grammar parsing\n",
      "T3\tMethod 112 128\tspeed-up element\n",
      "T4\tMethod 147 169\tunification algorithms\n",
      "T5\tOtherScientificTerm 187 220\tcopying  of  unmodified subgraphs\n",
      "T6\tOtherScientificTerm 200 220\tunmodified subgraphs\n",
      "T7\tGeneric 237 243\tmethod\n",
      "T8\tMethod 292 309\tstructure-sharing\n",
      "T9\tOtherScientificTerm 325 341\tlog(d) overheads\n",
      "T10\tOtherScientificTerm 366 393\tstructure-sharing of graphs\n",
      "T11\tMethod 422 441\tdependency pointers\n",
      "T12\tGeneric 458 464\tscheme\n",
      "T13\tOtherScientificTerm 477 494\tredundant copying\n",
      "T14\tOtherScientificTerm 519 553\tquasi-destructive scheme's ability\n",
      "T15\tOtherScientificTerm 565 577\tover copying\n",
      "T16\tOtherScientificTerm 584 597\tearly copying\n",
      "T17\tOtherScientificTerm 636 653\tcyclic structures\n",
      "R1\tPART-OF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T12 Arg2:T7\n",
      "R3\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R4\tFEATURE-OF Arg1:T14 Arg2:T12\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T17\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R7\tPART-OF Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C92-2115.ann\n",
      "T1\tTask 8 22\ttransfer phase\n",
      "T2\tTask 28 60\tmachine translation (MT) systems\n",
      "T3\tTask 111 119\tanalysis\n",
      "T4\tTask 126 136\tgeneration\n",
      "T5\tGeneric 146 148\tit\n",
      "T6\tOtherScientificTerm 195 208\tlexical rules\n",
      "T7\tMethod 259 279\tcase-based reasoning\n",
      "T8\tTask 285 304\tmachine translation\n",
      "T9\tTask 399 401\tMT\n",
      "T10\tMethod 440 455\ttransfer system\n",
      "T11\tMethod 469 512\tSimilarity-driven Transfer System (SimTran)\n",
      "T12\tTask 533 553\tcase-based MT (CBMT)\n",
      "R1\tCOMPARE Arg1:T1 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R4\tPART-OF Arg1:T1 Arg2:T2\n",
      "R5\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R6\tCOMPARE Arg1:T1 Arg2:T4\n",
      "R7\tCOREF Arg1:T8 Arg2:T2\n",
      "R8\tCOREF Arg1:T9 Arg2:T8\n",
      "R9\tHYPONYM-OF Arg1:T11 Arg2:T10\n",
      "R10\tCOREF Arg1:T5 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C92-3165.ann\n",
      "T1\tGeneric 27 53\trobust  interactive method\n",
      "T2\tTask 58 78\tspeech understanding\n",
      "T3\tMethod 87 109\tgeneralized LR parsing\n",
      "T4\tGeneric 131 139\tapproach\n",
      "T5\tMethod 142 149\tParsing\n",
      "T6\tMethod 250 256\tparser\n",
      "T7\tOtherScientificTerm 293 312\tnon-terminal symbol\n",
      "T8\tGeneric 546 552\tmethod\n",
      "T9\tOtherScientificTerm 582 595\tunknown words\n",
      "T10\tGeneric 816 824\tapproach\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R5\tCOREF Arg1:T6 Arg2:T5\n",
      "R6\tCOREF Arg1:T8 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R8\tCOREF Arg1:T10 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C92-4199.ann\n",
      "T1\tTask 4 23\tWord Identification\n",
      "T2\tTask 68 103\tChinese Natural Language Processing\n",
      "T3\tGeneric 128 137\tmechanism\n",
      "T4\tOtherScientificTerm 164 175\tsublanguage\n",
      "T5\tOtherScientificTerm 208 221\tunknown words\n",
      "T6\tOtherScientificTerm 237 251\tpersonal names\n",
      "T7\tMaterial 259 277\tChinese newspapers\n",
      "T8\tGeneric 294 303\tmechanism\n",
      "T9\tTask 314 343\ttitle-driven name recognition\n",
      "T10\tTask 348 379\tadaptive dynamic word formation\n",
      "T11\tTask 384 457\tidentification of 2-character and 3-character Chinese names without title\n",
      "T12\tMethod 559 588\tNTHU's statistic-based system\n",
      "T13\tGeneric 601 607\tsystem\n",
      "T14\tMethod 723 733\tWI systems\n",
      "T15\tTask 748 767\tname identification\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R4\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R5\tCOREF Arg1:T8 Arg2:T3\n",
      "R6\tPART-OF Arg1:T9 Arg2:T8\n",
      "R7\tPART-OF Arg1:T10 Arg2:T8\n",
      "R8\tPART-OF Arg1:T11 Arg2:T8\n",
      "R9\tCOREF Arg1:T13 Arg2:T12\n",
      "R10\tUSED-FOR Arg1:T7 Arg2:T3\n",
      "R11\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R12\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C92-4207.ann\n",
      "T1\tOtherScientificTerm 58 78\tspatial descriptions\n",
      "T2\tMaterial 84 92\tJapanese\n",
      "T3\tMethod 178 193\tgeometric model\n",
      "T4\tMethod 291 316\tcomputer program   SPRINT\n",
      "T5\tMaterial 333 355\tnatural language texts\n",
      "T6\tGeneric 373 378\tmodel\n",
      "T7\tGeneric 427 432\tmodel\n",
      "T8\tOtherScientificTerm 461 492\tqualitative spatial constraints\n",
      "T9\tOtherScientificTerm 539 560\tnumerical constraints\n",
      "T10\tOtherScientificTerm 570 606\tspatial attributes  of the  entities\n",
      "T11\tOtherScientificTerm 666 682\tspatial concepts\n",
      "R1\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T7 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C94-1088.ann\n",
      "T1\tMethod 25 68\tcharacters-based Chinese collocation system\n",
      "T2\tGeneric 102 104\tit\n",
      "T3\tMethod 125 142\tword-based system\n",
      "T4\tMaterial 198 218\tChinese text corpora\n",
      "T5\tMethod 224 258\tcharacter-based collocation system\n",
      "T6\tTask 287 322\tavoiding  pre-processing distortion\n",
      "T7\tTask 337 371\taccessing  sub-lexical information\n",
      "T8\tOtherScientificTerm 388 423\tword-based collocational properties\n",
      "T9\tMethod 452 495\tauxiliary module of  automatic segmentation\n",
      "R1\tCOREF Arg1:T2 Arg2:T1\n",
      "R2\tCOMPARE Arg1:T2 Arg2:T3\n",
      "R3\tCOREF Arg1:T5 Arg2:T2\n",
      "R4\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "R5\tFEATURE-OF Arg1:T7 Arg2:T5\n",
      "R6\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C94-1091.ann\n",
      "T1\tMaterial 99 112\tThai language\n",
      "T2\tMethod 181 191\tclassifier\n",
      "T3\tTask 348 368\tclassifier selection\n",
      "T4\tMethod 399 418\trule-based approach\n",
      "T5\tMethod 476 486\tclassifier\n",
      "T6\tMethod 521 531\tclassifier\n",
      "T7\tOtherScientificTerm 568 591\ttype of unit classifier\n",
      "T8\tMethod 674 693\tcorpus-based method\n",
      "T9\tMethod 750 784\tNoun Classifier Associations (NCA)\n",
      "T10\tTask 815 836\tclassifier assignment\n",
      "T11\tTask 843 879\tsemantic construction of noun phrase\n",
      "T12\tMethod 887 890\tNCA\n",
      "T13\tOtherScientificTerm 961 990\tconcept hierarchy constraints\n",
      "T14\tOtherScientificTerm 997 1021\tfrequency of occurrences\n",
      "R1\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T11\n",
      "R3\tCOREF Arg1:T12 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R8\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R9\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C96-1055.ann\n",
      "T1\tTask 36 56\tword-sense ambiguity\n",
      "T2\tMaterial 78 104\tmachine-readable resources\n",
      "T3\tTask 114 160\tconstruction of  large-scale knowledge sources\n",
      "T4\tOtherScientificTerm 211 234\tword-sense distinctions\n",
      "T5\tMetric 255 263\taccuracy\n",
      "T6\tMethod 269 292\tsemantic classification\n",
      "T7\tOtherScientificTerm 354 377\tword-sense distinctions\n",
      "T8\tMetric 399 407\taccuracy\n",
      "T9\tOtherScientificTerm 523 537\tverb semantics\n",
      "T10\tOtherScientificTerm 544 562\tsyntactic behavior\n",
      "T11\tOtherScientificTerm 664 684\tsemantic information\n",
      "T12\tOtherScientificTerm 692 706\tsyntactic cues\n",
      "T13\tOtherScientificTerm 732 746\tsyntactic cues\n",
      "T14\tOtherScientificTerm 803 814\tword senses\n",
      "T15\tGeneric 876 886\ttechniques\n",
      "T16\tOtherScientificTerm 898 909\tword senses\n",
      "T17\tMaterial 934 948\tonline sources\n",
      "R1\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R3\tCOREF Arg1:T7 Arg2:T4\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R6\tUSED-FOR Arg1:T17 Arg2:T15\n",
      "R7\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R8\tEVALUATE-FOR Arg1:T5 Arg2:T6\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C96-1062.ann\n",
      "T1\tMethod 4 28\tdomain independent model\n",
      "T2\tTask 51 98\tautomated interpretation  of  nominal compounds\n",
      "T3\tOtherScientificTerm 81 98\tnominal compounds\n",
      "T4\tMaterial 104 111\tEnglish\n",
      "T5\tGeneric 120 125\tmodel\n",
      "T6\tOtherScientificTerm 152 186\tproductive rules of interpretation\n",
      "T7\tOtherScientificTerm 217 262\tmorpho-syntactic and semantic characteristics\n",
      "T8\tOtherScientificTerm 272 292\tnominal constituents\n",
      "T9\tMethod 335 359\tPustejovsky's principles\n",
      "T10\tOtherScientificTerm 376 399\tpredicative information\n",
      "T11\tOtherScientificTerm 418 426\tnominals\n",
      "T12\tOtherScientificTerm 483 516\tgeneralizable semantic principles\n",
      "T13\tOtherScientificTerm 523 559\tdomain-specific semantic information\n",
      "T14\tGeneric 611 616\tmodel\n",
      "T15\tTask 640 669\tinterpretation  of  compounds\n",
      "T16\tOtherScientificTerm 717 737\tsemantic information\n",
      "R1\tFEATURE-OF Arg1:T7 Arg2:T8\n",
      "R2\tFEATURE-OF Arg1:T11 Arg2:T10\n",
      "R3\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R4\tCOREF Arg1:T5 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R7\tCOREF Arg1:T14 Arg2:T5\n",
      "R8\tCOREF Arg1:T8 Arg2:T3\n",
      "R9\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R10\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "R11\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C96-2213.ann\n",
      "T1\tTask 12 52\tNatural Language Processing (NLP) system\n",
      "T2\tMaterial 60 70\tnew domain\n",
      "T3\tTask 107 124\tsyntactic parsing\n",
      "T4\tMethod 226 233\tgrammar\n",
      "T5\tOtherScientificTerm 242 280\tidiosyncracies of the  new sublanguage\n",
      "T6\tMethod 330 349\tlexicalized grammar\n",
      "T7\tMethod 412 425\thybrid system\n",
      "T8\tMethod 454 480\tknowledge-based techniques\n",
      "T9\tMethod 490 511\tcorpus-based approach\n",
      "R1\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R2\tPART-OF Arg1:T8 Arg2:T7\n",
      "R3\tPART-OF Arg1:T9 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_1992_10_abs.ann\n",
      "T1\tGeneric 23 32\talgorithm\n",
      "T2\tTask 37 67\tlabeling curvilinear structure\n",
      "T3\tMaterial 90 103\tline drawings\n",
      "T4\tMaterial 108 119\tedge images\n",
      "T5\tOtherScientificTerm 129 149\tCURVE-ELEMENT tokens\n",
      "T6\tOtherScientificTerm 164 214\tspatially-indexed and scale-indexed data structure\n",
      "T7\tMaterial 243 253\timage data\n",
      "T8\tMethod 281 320\tsmall-to-large scale grouping procedure\n",
      "T9\tTask 421 438\timage description\n",
      "T10\tOtherScientificTerm 488 501\timage contour\n",
      "T11\tOtherScientificTerm 697 727\tlocal CURVE-ELEMENT attributes\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R3\tFEATURE-OF Arg1:T4 Arg2:T2\n",
      "R4\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R5\tPART-OF Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_1993_10_abs.ann\n",
      "T1\tMethod 2 22\tmodel-based approach\n",
      "T2\tTask 26 78\ton-line cursive handwriting analysis and recognition\n",
      "T3\tGeneric 115 120\tmodel\n",
      "T4\tTask 122 141\ton-line handwriting\n",
      "T5\tTask 184 204\tcycloidal pen motion\n",
      "T6\tOtherScientificTerm 251 272\tconstant linear drift\n",
      "T7\tOtherScientificTerm 391 405\tpen trajectory\n",
      "T8\tOtherScientificTerm 521 544\twriting intelligibility\n",
      "T9\tOtherScientificTerm 611 638\tcycloidal motion parameters\n",
      "T10\tMaterial 643 664\tarbitrary handwriting\n",
      "T11\tMethod 695 732\tdiscrete motor control representation\n",
      "T12\tOtherScientificTerm 740 761\tcontinuous pen motion\n",
      "T13\tMethod 818 846\tmotor control representation\n",
      "T14\tTask 866 879\tword spotting\n",
      "T15\tTask 884 911\tmatching of cursive scripts\n",
      "T16\tMethod 968 990\tdynamic representation\n",
      "T17\tTask 1004 1035\tcursive handwriting recognition\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tPART-OF Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R7\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R10\tCOREF Arg1:T16 Arg2:T13\n",
      "R11\tCOREF Arg1:T13 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R13\tHYPONYM-OF Arg1:T17 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_1994_10_abs.ann\n",
      "T1\tMethod 0 7\tMINPRAN\n",
      "T2\tMethod 15 30\trobust operator\n",
      "T3\tGeneric 118 128\ttechniques\n",
      "T4\tMetric 141 166\tlarge outlier percentages\n",
      "T5\tMethod 168 175\tMINPRAN\n",
      "T6\tOtherScientificTerm 201 212\terror bound\n",
      "T7\tGeneric 240 242\tit\n",
      "T8\tOtherScientificTerm 317 344\tdynamic range of the sensor\n",
      "T9\tMethod 361 368\tMINPRAN\n",
      "T10\tMethod 374 389\trandom sampling\n",
      "T11\tGeneric 494 496\tIt\n",
      "T12\tMethod 638 645\tMINPRAN\n",
      "T13\tMethod 701 708\tMINPRAN\n",
      "T14\tMetric 785 811\tpercentage of true inliers\n",
      "T15\tMethod 813 820\tMINPRAN\n",
      "T16\tMaterial 865 879\tsynthetic data\n",
      "T17\tMethod 905 928\tleast median of squares\n",
      "T18\tMethod 951 958\tMINPRAN\n",
      "T19\tOtherScientificTerm 962 975\tcomplex range\n",
      "T20\tMaterial 980 994\tintensity data\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tCOREF Arg1:T5 Arg2:T1\n",
      "R4\tCOMPARE Arg1:T3 Arg2:T5\n",
      "R5\tCOREF Arg1:T7 Arg2:T5\n",
      "R6\tCOREF Arg1:T9 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R8\tCOREF Arg1:T11 Arg2:T9\n",
      "R9\tCOREF Arg1:T12 Arg2:T11\n",
      "R10\tCOREF Arg1:T13 Arg2:T12\n",
      "R11\tCOREF Arg1:T15 Arg2:T12\n",
      "R12\tCOREF Arg1:T18 Arg2:T15\n",
      "R13\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "R14\tCOMPARE Arg1:T17 Arg2:T15\n",
      "R15\tUSED-FOR Arg1:T18 Arg2:T20\n",
      "R16\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_1996_15_abs.ann\n",
      "T1\tGeneric 26 35\tframework\n",
      "T2\tTask 40 70\tsegmentation of complex scenes\n",
      "T3\tOtherScientificTerm 86 105\tphysical hypotheses\n",
      "T4\tOtherScientificTerm 110 130\tsimple image regions\n",
      "T5\tGeneric 154 163\tframework\n",
      "T6\tGeneric 189 197\tapproach\n",
      "T7\tTask 205 235\tsegmentation of complex scenes\n",
      "T8\tOtherScientificTerm 266 283\tcoherent surfaces\n",
      "T9\tOtherScientificTerm 303 327\tregions of similar color\n",
      "T10\tGeneric 377 385\tapproach\n",
      "T11\tOtherScientificTerm 403 416\tsegmentations\n",
      "T12\tMaterial 421 427\tscenes\n",
      "T13\tMaterial 439 479\tmulti-colored piece-wise uniform objects\n",
      "T14\tGeneric 491 499\tapproach\n",
      "T15\tMetric 568 578\tcomplexity\n",
      "T16\tMethod 593 630\tphysics-based segmentation algorithms\n",
      "T17\tMethod 671 686\tphysical models\n",
      "T18\tOtherScientificTerm 743 760\tcoherent surfaces\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tCOREF Arg1:T5 Arg2:T1\n",
      "R5\tCOREF Arg1:T7 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R8\tCOMPARE Arg1:T8 Arg2:T9\n",
      "R9\tCOREF Arg1:T10 Arg2:T6\n",
      "R10\tFEATURE-OF Arg1:T13 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R12\tCOREF Arg1:T14 Arg2:T10\n",
      "R13\tCOMPARE Arg1:T14 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_1998_10_abs.ann\n",
      "T1\tTask 4 43\tcompact description of a video sequence\n",
      "T2\tOtherScientificTerm 61 70\timage map\n",
      "T3\tOtherScientificTerm 77 92\tdominant motion\n",
      "T4\tGeneric 121 128\tdomains\n",
      "T5\tTask 140 168\tvideo browsing and retrieval\n",
      "T6\tTask 170 181\tcompression\n",
      "T7\tTask 183 192\tmosaicing\n",
      "T8\tTask 198 218\tvisual summarization\n",
      "T9\tGeneric 236 250\trepresentation\n",
      "T10\tGeneric 354 358\ttask\n",
      "T11\tMethod 417 443\tlocalized motion estimates\n",
      "T12\tOtherScientificTerm 476 504\tlack of temporal consistency\n",
      "T13\tOtherScientificTerm 484 504\ttemporal consistency\n",
      "T14\tGeneric 526 535\testimates\n",
      "T15\tOtherScientificTerm 554 596\tvalidity of the dominant motion assumption\n",
      "T16\tOtherScientificTerm 570 596\tdominant motion assumption\n",
      "T17\tOtherScientificTerm 609 682\toscillation between different scene interpretations and poor registration\n",
      "T18\tGeneric 698 709\toscillation\n",
      "T19\tMethod 726 738\tmotion model\n",
      "T20\tOtherScientificTerm 746 773\tgeneric temporal constraint\n",
      "T21\tMetric 794 804\trobustness\n",
      "T22\tTask 867 888\tcontent summarization\n",
      "R1\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R2\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R3\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R4\tHYPONYM-OF Arg1:T5 Arg2:T4\n",
      "R5\tHYPONYM-OF Arg1:T6 Arg2:T4\n",
      "R6\tHYPONYM-OF Arg1:T7 Arg2:T4\n",
      "R8\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R9\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R10\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R11\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R12\tCOREF Arg1:T9 Arg2:T1\n",
      "R13\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R14\tCOREF Arg1:T14 Arg2:T11\n",
      "R15\tCOREF Arg1:T18 Arg2:T17\n",
      "R16\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R17\tEVALUATE-FOR Arg1:T21 Arg2:T20\n",
      "R18\tUSED-FOR Arg1:T20 Arg2:T22\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_1999_15_abs.ann\n",
      "T1\tMethod 32 83\tprojective unifocal, bifo-cal, and trifocal tensors\n",
      "T2\tOtherScientificTerm 91 102\taffine case\n",
      "T3\tGeneric 121 128\ttensors\n",
      "T4\tOtherScientificTerm 152 170\tregistered tensors\n",
      "T5\tOtherScientificTerm 230 251\taffine specialization\n",
      "T6\tMethod 360 374\taffine cameras\n",
      "T7\tMethod 446 461\ttrifocal tensor\n",
      "T8\tOtherScientificTerm 486 510\tgeometric interpretation\n",
      "T9\tTask 537 562\testimation of the tensors\n",
      "T10\tGeneric 555 562\ttensors\n",
      "T11\tOtherScientificTerm 568 589\tpoint correspondences\n",
      "T12\tMethod 610 623\tfactorization\n",
      "T13\tGeneric 641 651\testimation\n",
      "T14\tOtherScientificTerm 657 677\tline correspondences\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T7 Arg2:T1\n",
      "R4\tCOREF Arg1:T10 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R8\tCOREF Arg1:T13 Arg2:T9\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2001_110_abs.ann\n",
      "T1\tMethod 0 31\tRepresenting images with layers\n",
      "T2\tGeneric 51 63\tapplications\n",
      "T3\tTask 74 91\tvideo compression\n",
      "T4\tTask 93 108\tmotion analysis\n",
      "T5\tTask 114 131\t3D scene analysis\n",
      "T6\tGeneric 156 164\tapproach\n",
      "T7\tOtherScientificTerm 188 194\tlayers\n",
      "T8\tMaterial 200 206\timages\n",
      "T9\tOtherScientificTerm 245 257\thomographies\n",
      "T10\tOtherScientificTerm 269 283\tplanar patches\n",
      "T11\tOtherScientificTerm 291 296\tscene\n",
      "T12\tOtherScientificTerm 304 335\tlow dimensional linear subspace\n",
      "T13\tOtherScientificTerm 337 343\tLayers\n",
      "T14\tMaterial 357 363\timages\n",
      "T15\tOtherScientificTerm 386 394\tsubspace\n",
      "T16\tOtherScientificTerm 443 451\tclusters\n",
      "T17\tMethod 495 532\tmean-shift based clustering algorithm\n",
      "T18\tTask 534 551\tGlobal optimality\n",
      "T19\tOtherScientificTerm 580 587\tregions\n",
      "T20\tOtherScientificTerm 631 636\tnoise\n",
      "T21\tOtherScientificTerm 681 700\tsubspace constraint\n",
      "R1\tPART-OF Arg1:T7 Arg2:T8\n",
      "R2\tPART-OF Arg1:T13 Arg2:T14\n",
      "R3\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R4\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R5\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R6\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R7\tHYPONYM-OF Arg1:T4 Arg2:T2\n",
      "R8\tHYPONYM-OF Arg1:T5 Arg2:T2\n",
      "R9\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R10\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R11\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R12\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R13\tPART-OF Arg1:T10 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2001_111_abs.ann\n",
      "T1\tGeneric 34 40\tmethod\n",
      "T2\tMethod 49 95\tlocal non-negative matrix factorization (LNMF)\n",
      "T3\tTask 110 185\tspatially localized, parts-based subspace representation of visual patterns\n",
      "T4\tOtherScientificTerm 190 208\tobjective function\n",
      "T5\tOtherScientificTerm 230 254\tlo-calization constraint\n",
      "T6\tOtherScientificTerm 275 300\tnon-negativity constraint\n",
      "T7\tMethod 317 320\tNMF\n",
      "T8\tMethod 376 429\tnon-subtractive (part-based) representation of images\n",
      "T9\tOtherScientificTerm 449 467\tlocalized features\n",
      "T10\tGeneric 472 481\talgorithm\n",
      "T11\tTask 503 511\tlearning\n",
      "T12\tMethod 584 588\tLNMF\n",
      "T13\tMethod 598 617\tNMF and PCA methods\n",
      "T14\tTask 622 657\tface representation and recognition\n",
      "T15\tMethod 692 696\tLNMF\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R5\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R6\tCOREF Arg1:T15 Arg2:T12\n",
      "R7\tEVALUATE-FOR Arg1:T14 Arg2:T15\n",
      "R8\tPART-OF Arg1:T6 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R10\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R11\tCOREF Arg1:T1 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2003_10_abs.ann\n",
      "T1\tMethod 2 34\t\" graphics for vision \" approach\n",
      "T2\tTask 73 87\treconstruction\n",
      "T3\tMaterial 95 123\tlarge and imperfect data set\n",
      "T4\tTask 125 139\treconstruction\n",
      "T5\tMethod 153 166\ttensor voting\n",
      "T6\tMethod 171 177\tROD-TV\n",
      "T7\tMethod 179 185\tROD-TV\n",
      "T8\tMetric 215 225\tefficiency\n",
      "T9\tMetric 230 241\trobust-ness\n",
      "T10\tOtherScientificTerm 273 295\tprimitive connectivity\n",
      "T11\tOtherScientificTerm 297 312\tview dependence\n",
      "T12\tOtherScientificTerm 318 340\tlevels of detail (LOD)\n",
      "T13\tOtherScientificTerm 342 375\tLocally inferred surface elements\n",
      "T14\tOtherScientificTerm 390 395\tnoise\n",
      "T15\tOtherScientificTerm 415 427\tlocal shapes\n",
      "T16\tOtherScientificTerm 442 460\tper-vertex normals\n",
      "T17\tMetric 464 483\tsub-voxel precision\n",
      "T18\tTask 511 532\tinterpolative shading\n",
      "T19\tOtherScientificTerm 650 669\tscanning resolution\n",
      "T20\tOtherScientificTerm 687 716\tmesh connectivity requirement\n",
      "T21\tMethod 728 734\tROD-TV\n",
      "T22\tMethod 770 809\tmultiscale feature extraction algorithm\n",
      "T23\tMethod 811 817\tROD-TV\n",
      "T24\tMethod 832 859\thierarchical data structure\n",
      "T25\tMethod 905 935\tlocal reconstruction algorithm\n",
      "T26\tMethod 939 952\ttensor voting\n",
      "T27\tGeneric 954 956\tIt\n",
      "T28\tMethod 1042 1071\ttraversing the data hierarchy\n",
      "T29\tMethod 1076 1104\tcollecting tensorial support\n",
      "T30\tGeneric 1139 1147\tapproach\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R3\tCONJUNCTION Arg1:T9 Arg2:T8\n",
      "R4\tCONJUNCTION Arg1:T11 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R6\tEVALUATE-FOR Arg1:T9 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T16 Arg2:T18\n",
      "R8\tUSED-FOR Arg1:T20 Arg2:T22\n",
      "R9\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R10\tPART-OF Arg1:T24 Arg2:T23\n",
      "R11\tHYPONYM-OF Arg1:T26 Arg2:T25\n",
      "R12\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R13\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R14\tCOREF Arg1:T7 Arg2:T6\n",
      "R15\tCONJUNCTION Arg1:T12 Arg2:T11\n",
      "R16\tEVALUATE-FOR Arg1:T8 Arg2:T7\n",
      "R17\tCOREF Arg1:T21 Arg2:T7\n",
      "R18\tCOREF Arg1:T23 Arg2:T21\n",
      "R19\tUSED-FOR Arg1:T28 Arg2:T27\n",
      "R20\tUSED-FOR Arg1:T29 Arg2:T27\n",
      "R21\tCONJUNCTION Arg1:T28 Arg2:T29\n",
      "R22\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R23\tCOREF Arg1:T1 Arg2:T30\n",
      "R24\tCOREF Arg1:T2 Arg2:T4\n",
      "R25\tCOREF Arg1:T26 Arg2:T27\n",
      "R26\tFEATURE-OF Arg1:T17 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2003_11_abs.ann\n",
      "T1\tOtherScientificTerm 4 12\tfeatures\n",
      "T2\tMethod 22 54\tMarkov random field (MRF) models\n",
      "T3\tOtherScientificTerm 84 110\trotation of image textures\n",
      "T4\tMethod 135 183\tanisotropic circular Gaussian MRF (ACGMRF) model\n",
      "T5\tTask 188 220\tmodelling rotated image textures\n",
      "T6\tTask 225 271\tretrieving rotation-invariant texture features\n",
      "T7\tOtherScientificTerm 289 308\tsingularity problem\n",
      "T8\tMethod 316 351\tleast squares estimate (LSE) method\n",
      "T9\tMethod 356 404\tapproximate least squares estimate (ALSE) method\n",
      "T10\tOtherScientificTerm 433 463\tparameters of the ACGMRF model\n",
      "T11\tMethod 451 463\tACGMRF model\n",
      "T12\tOtherScientificTerm 469 496\trotation-invariant features\n",
      "T13\tOtherScientificTerm 522 552\tparameters of the ACGMRF model\n",
      "T14\tMethod 540 552\tACGMRF model\n",
      "T15\tMethod 560 614\tone-dimensional (1-D) discrete Fourier transform (DFT)\n",
      "T16\tMetric 639 647\taccuracy\n",
      "T17\tOtherScientificTerm 680 707\trotation-invariant features\n",
      "T18\tOtherScientificTerm 720 749\tSAR (synthetic aperture radar\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R3\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R5\tFEATURE-OF Arg1:T7 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T12\n",
      "R9\tCOREF Arg1:T4 Arg2:T11\n",
      "R10\tCOREF Arg1:T11 Arg2:T14\n",
      "R11\tCOREF Arg1:T10 Arg2:T13\n",
      "R12\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2003_18_abs.ann\n",
      "T1\tMethod 23 29\tmethod\n",
      "T2\tOtherScientificTerm 43 69\tintrinsic object structure\n",
      "T3\tTask 74 96\trobust visual tracking\n",
      "T4\tOtherScientificTerm 143 169\tparameterized object state\n",
      "T5\tOtherScientificTerm 180 204\tlow dimensional manifold\n",
      "T6\tMethod 293 350\tdimensionality reduction and density estimation algorithm\n",
      "T7\tTask 355 411\tunsupervised learning of object intrinsic representation\n",
      "T8\tMethod 380 411\tobject intrinsic representation\n",
      "T9\tOtherScientificTerm 426 456\tnon-rigid part of object state\n",
      "T10\tMethod 500 515\tdynamical model\n",
      "T11\tMethod 553 577\tintrinsic representation\n",
      "T12\tOtherScientificTerm 599 625\tintrinsic object structure\n",
      "T13\tMethod 647 676\tparticle-filter style tracker\n",
      "T14\tMethod 701 732\tintrinsic object representation\n",
      "T15\tMethod 802 817\tdynamical model\n",
      "T16\tMethod 824 853\tparticle-filter style tracker\n",
      "T17\tGeneric 914 921\ttracker\n",
      "T18\tGeneric 957 965\ttrackers\n",
      "T19\tTask 973 1010\ttracking of complex non-rigid motions\n",
      "T20\tOtherScientificTerm 985 1010\tcomplex non-rigid motions\n",
      "T21\tOtherScientificTerm 1019 1032\tfish twisting\n",
      "T22\tOtherScientificTerm 1038 1052\tself-occlusion\n",
      "T23\tOtherScientificTerm 1063 1085\tinter-frame lip motion\n",
      "T24\tGeneric 1100 1106\tmethod\n",
      "T25\tTask 1153 1170\ttracking problems\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R5\tCOREF Arg1:T11 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R7\tPART-OF Arg1:T12 Arg2:T13\n",
      "R8\tCOREF Arg1:T14 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R10\tCOREF Arg1:T17 Arg2:T16\n",
      "R11\tCOMPARE Arg1:T17 Arg2:T18\n",
      "R12\tUSED-FOR Arg1:T17 Arg2:T19\n",
      "R13\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R14\tHYPONYM-OF Arg1:T21 Arg2:T20\n",
      "R15\tCONJUNCTION Arg1:T22 Arg2:T23\n",
      "R16\tFEATURE-OF Arg1:T22 Arg2:T21\n",
      "R17\tFEATURE-OF Arg1:T23 Arg2:T21\n",
      "R18\tUSED-FOR Arg1:T24 Arg2:T25\n",
      "R19\tCOREF Arg1:T15 Arg2:T10\n",
      "R20\tCOREF Arg1:T12 Arg2:T11\n",
      "R21\tCOREF Arg1:T24 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2003_21_abs.ann\n",
      "T1\tTask 52 77\tprojective reconstruction\n",
      "T2\tMaterial 92 98\timages\n",
      "T3\tTask 144 169\tProjective reconstruction\n",
      "T4\tOtherScientificTerm 203 231\t3D geometrical configuration\n",
      "T5\tOtherScientificTerm 244 265\t3D points and cameras\n",
      "T6\tOtherScientificTerm 451 468\timage coordinates\n",
      "T7\tOtherScientificTerm 753 775\trational quartic curve\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tFEATURE-OF Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2003_30_abs.ann\n",
      "T1\tGeneric 28 42\trepresentation\n",
      "T2\tOtherScientificTerm 47 72\tthree-dimensional objects\n",
      "T3\tOtherScientificTerm 85 115\taffine-invariant image patches\n",
      "T4\tOtherScientificTerm 126 147\tspatial relationships\n",
      "T5\tOtherScientificTerm 149 171\tMulti-view constraints\n",
      "T6\tMethod 226 251\tnormalized representation\n",
      "T7\tTask 281 289\tmatching\n",
      "T8\tTask 294 308\treconstruction\n",
      "T9\tTask 323 388\tacquisition of true three-dimensional affine and Euclidean models\n",
      "T10\tMaterial 403 409\timages\n",
      "T11\tGeneric 503 511\tapproach\n",
      "T12\tMethod 540 558\tsegmentation stage\n",
      "T13\tOtherScientificTerm 580 596\tcluttered scenes\n",
      "T14\tTask 623 634\trecognition\n",
      "R1\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R4\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R8\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R9\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "R10\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R11\tCOREF Arg1:T1 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2004_10_abs.ann\n",
      "T1\tTask 0 32\tImage composition (or mosaicing)\n",
      "T2\tTask 114 147\tvideo analysis and representation\n",
      "T3\tTask 191 207\tglobal alignment\n",
      "T4\tTask 212 228\tsuper-resolution\n",
      "T5\tTask 287 293\tmosaic\n",
      "T6\tMetric 311 329\tamount of blurring\n",
      "T7\tTask 331 350\tGlobal registration\n",
      "T8\tMethod 378 399\tgraph-based technique\n",
      "T9\tOtherScientificTerm 420 441\ttopological structure\n",
      "T10\tOtherScientificTerm 473 488\tspatial overlap\n",
      "T11\tMethod 498 515\tbundle adjustment\n",
      "T12\tOtherScientificTerm 536 548\thomographies\n",
      "T13\tGeneric 616 626\ttechniques\n",
      "T14\tGeneric 658 666\tapproach\n",
      "R1\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R2\tEVALUATE-FOR Arg1:T6 Arg2:T5\n",
      "R3\tCONJUNCTION Arg1:T8 Arg2:T11\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R8\tCOREF Arg1:T14 Arg2:T8\n",
      "R9\tCOMPARE Arg1:T14 Arg2:T13\n",
      "R10\tPART-OF Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2004_18_abs.ann\n",
      "T1\tTask 4 26\tautomated segmentation\n",
      "T2\tMaterial 30 36\timages\n",
      "T3\tOtherScientificTerm 81 98\tshape information\n",
      "T4\tMethod 105 131\tlow-level feature analysis\n",
      "T5\tMethod 191 197\tmethod\n",
      "T6\tTask 201 237\tshape constrained image segmentation\n",
      "T7\tOtherScientificTerm 256 289\tmixtures of feature distributions\n",
      "T8\tOtherScientificTerm 294 299\tcolor\n",
      "T9\tOtherScientificTerm 304 311\ttexture\n",
      "T10\tOtherScientificTerm 323 352\tprobabilistic shape knowledge\n",
      "T11\tGeneric 367 375\tapproach\n",
      "T12\tMethod 410 429\tBayesian statistics\n",
      "T13\tTask 449 495\trobust-ness requirement in image understanding\n",
      "T14\tMaterial 588 598\timage data\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R4\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T7 Arg2:T10\n",
      "R9\tCOREF Arg1:T11 Arg2:T5\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R11\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2004_21_abs.ann\n",
      "T1\tTask 0 20\tUncertainty handling\n",
      "T2\tTask 52 66\tshape tracking\n",
      "T3\tMethod 100 171\tfusion of measurement information with system dynamics and shape priors\n",
      "T4\tTask 193 201\ttracking\n",
      "T5\tMaterial 223 235\tnoisy images\n",
      "T6\tMaterial 244 264\tultrasound sequences\n",
      "T7\tGeneric 291 299\tapproach\n",
      "T8\tOtherScientificTerm 309 328\tuser initialization\n",
      "T9\tMethod 336 352\ttracking process\n",
      "T10\tTask 376 409\tautomatic initial-ization problem\n",
      "T11\tMethod 424 447\tboosted shape detection\n",
      "T12\tMethod 453 480\tgeneric measurement process\n",
      "T13\tGeneric 497 499\tit\n",
      "T14\tMethod 507 525\ttracking framework\n",
      "T15\tOtherScientificTerm 556 585\tlocal detection uncertainties\n",
      "T16\tOtherScientificTerm 556 614\tlocal detection uncertainties of multiple shape candidates\n",
      "T17\tOtherScientificTerm 622 637\tshape alignment\n",
      "T18\tOtherScientificTerm 655 676\tpredicted shape prior\n",
      "T19\tOtherScientificTerm 694 714\tsubspace constraints\n",
      "T20\tMethod 797 818\tposterior shape model\n",
      "T21\tOtherScientificTerm 841 859\tmaximum likelihood\n",
      "T22\tGeneric 865 874\tframework\n",
      "T23\tTask 894 927\tautomatic tracking of endocardium\n",
      "T24\tOtherScientificTerm 916 927\tendocardium\n",
      "T25\tMaterial 931 970\tultrasound sequences of the human heart\n",
      "T26\tTask 981 990\tdetection\n",
      "T27\tTask 1002 1010\ttracking\n",
      "T28\tGeneric 1058 1068\tapproaches\n",
      "T29\tOtherScientificTerm 1073 1096\tinter-expert variations\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T4 Arg2:T2\n",
      "R3\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R8\tCOREF Arg1:T10 Arg2:T13\n",
      "R9\tPART-OF Arg1:T13 Arg2:T14\n",
      "R10\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R11\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R12\tCONJUNCTION Arg1:T28 Arg2:T29\n",
      "R13\tCOREF Arg1:T4 Arg2:T27\n",
      "R14\tCONJUNCTION Arg1:T26 Arg2:T27\n",
      "R15\tCOREF Arg1:T22 Arg2:T14\n",
      "R16\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R17\tCOREF Arg1:T3 Arg2:T7\n",
      "R18\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R19\tPART-OF Arg1:T24 Arg2:T25\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2004_30_abs.ann\n",
      "T1\tTask 0 19\tBackground modeling\n",
      "T2\tTask 54 68\tvision systems\n",
      "T3\tOtherScientificTerm 140 173\tstatic or quasi-static structures\n",
      "T4\tGeneric 184 189\tscene\n",
      "T5\tOtherScientificTerm 201 228\tpersistent dynamic behavior\n",
      "T6\tTask 273 282\tdetection\n",
      "T7\tGeneric 341 347\tmethod\n",
      "T8\tTask 356 395\tmodeling and subtraction of such scenes\n",
      "T9\tGeneric 389 395\tscenes\n",
      "T10\tTask 409 448\tmodeling of the dynamic characteristics\n",
      "T11\tOtherScientificTerm 450 462\toptical flow\n",
      "T12\tOtherScientificTerm 493 500\tfeature\n",
      "T13\tOtherScientificTerm 506 530\thigher dimensional space\n",
      "T14\tOtherScientificTerm 541 552\tambiguities\n",
      "T15\tTask 560 583\tcomputation of features\n",
      "T16\tOtherScientificTerm 609 633\tdata-dependent bandwidth\n",
      "T17\tTask 638 656\tdensity estimation\n",
      "T18\tMethod 663 670\tkernels\n",
      "T19\tGeneric 750 758\tapproach\n",
      "R1\tPART-OF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T4 Arg2:T9\n",
      "R3\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R6\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R8\tFEATURE-OF Arg1:T13 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R10\tFEATURE-OF Arg1:T14 Arg2:T15\n",
      "R11\tCOREF Arg1:T7 Arg2:T19\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T14\n",
      "R13\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2005_10_abs.ann\n",
      "T1\tMethod 0 20\tProbabilistic models\n",
      "T2\tTask 82 122\tmodeling and recognition of human motion\n",
      "T3\tMethod 178 196\thuman motion model\n",
      "T4\tMethod 202 220\ttriangulated graph\n",
      "T5\tGeneric 250 256\tmodels\n",
      "T6\tOtherScientificTerm 271 280\tpositions\n",
      "T7\tOtherScientificTerm 285 295\tvelocities\n",
      "T8\tOtherScientificTerm 335 345\tappearance\n",
      "T9\tMethod 359 377\theuristic approach\n",
      "T10\tOtherScientificTerm 406 428\ttranslation invariance\n",
      "T11\tGeneric 467 475\tapproach\n",
      "T12\tGeneric 494 500\tmodels\n",
      "T13\tGeneric 511 515\tthem\n",
      "T14\tTask 520 544\thuman motion recognition\n",
      "T15\tGeneric 560 568\tapproach\n",
      "T16\tGeneric 587 591\tcues\n",
      "T17\tOtherScientificTerm 599 608\tpositions\n",
      "T18\tOtherScientificTerm 610 620\tvelocities\n",
      "T19\tOtherScientificTerm 625 635\tappearance\n",
      "T20\tTask 650 679\tlearning and detection phases\n",
      "T21\tOtherScientificTerm 707 723\tglobal variables\n",
      "T22\tGeneric 731 736\tmodel\n",
      "T23\tOtherScientificTerm 758 775\tglobal properties\n",
      "T24\tOtherScientificTerm 784 795\ttranslation\n",
      "T25\tOtherScientificTerm 797 802\tscale\n",
      "T26\tOtherScientificTerm 806 815\tviewpoint\n",
      "T27\tGeneric 821 826\tmodel\n",
      "T28\tMethod 844 863\tunsupervised manner\n",
      "T29\tMaterial 869 885\tun-labelled data\n",
      "T30\tMethod 914 941\thybrid proba-bilistic model\n",
      "T31\tOtherScientificTerm 958 974\tglobal variables\n",
      "T32\tOtherScientificTerm 981 992\ttranslation\n",
      "T33\tOtherScientificTerm 1000 1015\tlocal variables\n",
      "T34\tOtherScientificTerm 1022 1040\trelative positions\n",
      "T35\tOtherScientificTerm 1045 1070\tappearances of body parts\n",
      "T36\tMetric 1087 1105\tfaster convergence\n",
      "T37\tTask 1109 1123\tlearning phase\n",
      "T38\tMetric 1130 1140\trobustness\n",
      "T39\tOtherScientificTerm 1144 1154\tocclusions\n",
      "T40\tMaterial 1174 1190\trecognition rate\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R5\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R7\tCOREF Arg1:T12 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R10\tCOREF Arg1:T12 Arg2:T3\n",
      "R11\tCOREF Arg1:T15 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T15 Arg2:T20\n",
      "R13\tHYPONYM-OF Arg1:T17 Arg2:T16\n",
      "R14\tHYPONYM-OF Arg1:T18 Arg2:T16\n",
      "R15\tHYPONYM-OF Arg1:T19 Arg2:T16\n",
      "R16\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R17\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R18\tCOREF Arg1:T15 Arg2:T22\n",
      "R19\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R20\tHYPONYM-OF Arg1:T24 Arg2:T23\n",
      "R21\tHYPONYM-OF Arg1:T25 Arg2:T23\n",
      "R22\tUSED-FOR Arg1:T21 Arg2:T23\n",
      "R23\tHYPONYM-OF Arg1:T26 Arg2:T23\n",
      "R24\tCONJUNCTION Arg1:T24 Arg2:T25\n",
      "R25\tCONJUNCTION Arg1:T25 Arg2:T26\n",
      "R26\tCOREF Arg1:T27 Arg2:T22\n",
      "R27\tUSED-FOR Arg1:T28 Arg2:T27\n",
      "R28\tUSED-FOR Arg1:T29 Arg2:T28\n",
      "R29\tUSED-FOR Arg1:T31 Arg2:T30\n",
      "R30\tHYPONYM-OF Arg1:T32 Arg2:T31\n",
      "R31\tHYPONYM-OF Arg1:T34 Arg2:T33\n",
      "R32\tHYPONYM-OF Arg1:T35 Arg2:T33\n",
      "R33\tCONJUNCTION Arg1:T34 Arg2:T35\n",
      "R34\tFEATURE-OF Arg1:T36 Arg2:T37\n",
      "R35\tCONJUNCTION Arg1:T36 Arg2:T38\n",
      "R36\tCONJUNCTION Arg1:T38 Arg2:T40\n",
      "R37\tCOREF Arg1:T15 Arg2:T30\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2005_11_abs.ann\n",
      "T1\tMethod 21 37\treal-time system\n",
      "T2\tTask 42 84\tmultiple object tracking in dynamic scenes\n",
      "T3\tGeneric 117 123\tsystem\n",
      "T4\tOtherScientificTerm 152 188\tlong-duration and complete occlusion\n",
      "T5\tOtherScientificTerm 199 214\tprior knowledge\n",
      "T6\tOtherScientificTerm 225 230\tshape\n",
      "T7\tOtherScientificTerm 234 251\tmotion of objects\n",
      "T8\tGeneric 257 263\tsystem\n",
      "T9\tTask 290 298\ttracking\n",
      "T10\tOtherScientificTerm 312 322\tframe rate\n",
      "T11\tOtherScientificTerm 340 350\timage size\n",
      "T12\tMaterial 420 435\tvideo sequences\n",
      "T13\tOtherScientificTerm 487 524\tlong-duration and complete occlusions\n",
      "T14\tOtherScientificTerm 528 547\tchanging background\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T3 Arg2:T8\n",
      "R5\tEVALUATE-FOR Arg1:T9 Arg2:T8\n",
      "R6\tFEATURE-OF Arg1:T5 Arg2:T6\n",
      "R7\tFEATURE-OF Arg1:T5 Arg2:T7\n",
      "R8\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2005_18_abs.ann\n",
      "T1\tMethod 31 48\tembedding methods\n",
      "T2\tTask 53 110\tsegmenting feature points of piece-wise planar structures\n",
      "T3\tOtherScientificTerm 187 199\thomographies\n",
      "T4\tOtherScientificTerm 239 279\thigher-dimensional real or complex space\n",
      "T5\tOtherScientificTerm 294 304\thomography\n",
      "T6\tOtherScientificTerm 329 350\tcomplex bilinear form\n",
      "T7\tOtherScientificTerm 356 375\treal quadratic form\n",
      "T8\tOtherScientificTerm 448 461\thomo-graphies\n",
      "T9\tMethod 473 506\tclosed-form segmentation solution\n",
      "T10\tMethod 560 589\tsubspace-segmentation methods\n",
      "T11\tOtherScientificTerm 659 682\tpiece-wise planar scene\n",
      "T12\tMaterial 688 698\t2-D images\n",
      "T13\tMethod 733 751\t3-D reconstruction\n",
      "T14\tMethod 800 818\t3-D reconstruction\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R3\tCOREF Arg1:T14 Arg2:T13\n",
      "R4\tFEATURE-OF Arg1:T12 Arg2:T11\n",
      "R5\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "R6\tFEATURE-OF Arg1:T7 Arg2:T5\n",
      "R7\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R8\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2005_21_abs.ann\n",
      "T1\tMethod 0 19\tActive shape models\n",
      "T2\tMaterial 69 87\tcomplex image data\n",
      "T3\tMethod 101 126\tmodels of shape variation\n",
      "T4\tMethod 139 156\tsearch algorithms\n",
      "T5\tOtherScientificTerm 166 183\tpri-ori knowledge\n",
      "T6\tOtherScientificTerm 237 246\tlinearity\n",
      "T7\tMethod 250 253\tPCA\n",
      "T8\tOtherScientificTerm 255 270\tnon-linearities\n",
      "T9\tOtherScientificTerm 276 285\trotations\n",
      "T10\tMethod 391 435\tnon-linear extensions of active shape models\n",
      "T11\tMethod 416 435\tactive shape models\n",
      "T12\tOtherScientificTerm 542 558\tuser interaction\n",
      "T13\tTask 608 641\tbuild-ing/choosing optimal models\n",
      "T14\tGeneric 731 740\talgorithm\n",
      "T15\tMethod 754 790\tminimum description length principle\n",
      "T16\tMethod 868 883\tlinear modeling\n",
      "T17\tGeneric 978 983\tmodel\n",
      "T18\tOtherScientificTerm 996 1015\tmodes of variations\n",
      "T19\tGeneric 1030 1036\tmethod\n",
      "T20\tMaterial 1053 1067\tsynthetic data\n",
      "T21\tMaterial 1069 1083\tmedical images\n",
      "T22\tMaterial 1088 1101\thand contours\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R4\tFEATURE-OF Arg1:T6 Arg2:T7\n",
      "R5\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "R6\tCOREF Arg1:T11 Arg2:T1\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R9\tFEATURE-OF Arg1:T18 Arg2:T17\n",
      "R10\tCOREF Arg1:T19 Arg2:T17\n",
      "R11\tCOREF Arg1:T17 Arg2:T14\n",
      "R12\tEVALUATE-FOR Arg1:T20 Arg2:T19\n",
      "R13\tEVALUATE-FOR Arg1:T21 Arg2:T19\n",
      "R14\tEVALUATE-FOR Arg1:T22 Arg2:T19\n",
      "R15\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R16\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2006_10_abs.ann\n",
      "T1\tTask 25 41\tobject detection\n",
      "T2\tOtherScientificTerm 149 192\tprior on the distribution of natural images\n",
      "T3\tMethod 198 221\tsupport vector machines\n",
      "T4\tMethod 223 227\tSVMs\n",
      "T5\tOtherScientificTerm 254 265\toverfitting\n",
      "T6\tMethod 377 386\tdetectors\n",
      "T7\tOtherScientificTerm 479 502\tprior on natural images\n",
      "T8\tOtherScientificTerm 536 546\thyperplane\n",
      "T9\tMaterial 726 740\treal data sets\n",
      "T10\tMethod 765 773\tdetector\n",
      "T11\tMethod 857 878\tlinear and kernel SVM\n",
      "R1\tCOREF Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R4\tEVALUATE-FOR Arg1:T9 Arg2:T10\n",
      "R5\tCOMPARE Arg1:T10 Arg2:T11\n",
      "R6\tCOREF Arg1:T10 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2006_11_abs.ann\n",
      "T1\tMethod 2 20\trecognition scheme\n",
      "T2\tMetric 92 102\tefficiency\n",
      "T3\tMetric 107 114\tquality\n",
      "T4\tMaterial 168 177\tCD-covers\n",
      "T5\tGeneric 185 193\tdatabase\n",
      "T6\tMaterial 203 231\timages of popular music CD's\n",
      "T7\tGeneric 237 243\tscheme\n",
      "T8\tMethod 278 298\tindexing descriptors\n",
      "T9\tOtherScientificTerm 314 327\tlocal regions\n",
      "T10\tOtherScientificTerm 346 364\tbackground clutter\n",
      "T11\tOtherScientificTerm 369 378\tocclusion\n",
      "T12\tMethod 384 408\tlocal region descriptors\n",
      "T13\tOtherScientificTerm 443 458\tvocabulary tree\n",
      "T14\tOtherScientificTerm 464 479\tvocabulary tree\n",
      "T15\tMetric 619 636\tretrieval quality\n",
      "T16\tOtherScientificTerm 694 698\ttree\n",
      "T17\tOtherScientificTerm 720 732\tquantization\n",
      "T18\tOtherScientificTerm 738 750\tquantization\n",
      "T19\tOtherScientificTerm 759 767\tindexing\n",
      "T20\tMetric 840 859\trecognition quality\n",
      "T21\tTask 881 890\tretrieval\n",
      "T22\tMaterial 896 922\tdatabase with ground truth\n",
      "T23\tMethod 949 973\tvocabulary tree approach\n",
      "R1\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R2\tCOREF Arg1:T1 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R6\tCOREF Arg1:T13 Arg2:T14\n",
      "R7\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R8\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "R9\tEVALUATE-FOR Arg1:T20 Arg2:T23\n",
      "R10\tEVALUATE-FOR Arg1:T21 Arg2:T20\n",
      "R11\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "R12\tUSED-FOR Arg1:T7 Arg2:T10\n",
      "R13\tUSED-FOR Arg1:T7 Arg2:T11\n",
      "R14\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2006_18_abs.ann\n",
      "T1\tMethod 6 30\texemplar-based framework\n",
      "T2\tTask 40 56\timage completion\n",
      "T3\tTask 59 76\ttexture synthesis\n",
      "T4\tTask 81 97\timage inpainting\n",
      "T5\tMethod 146 163\tgreedy techniques\n",
      "T6\tGeneric 171 176\ttasks\n",
      "T7\tTask 204 240\tdiscrete global optimization problem\n",
      "T8\tOtherScientificTerm 248 279\twell defined objective function\n",
      "T9\tGeneric 298 305\tproblem\n",
      "T10\tMethod 314 333\toptimization scheme\n",
      "T11\tMethod 342 353\tPriority-BP\n",
      "T12\tGeneric 400 410\textensions\n",
      "T13\tMethod 425 448\tbelief propagation (BP)\n",
      "T14\tMethod 452 485\tpriority-based message scheduling\n",
      "T15\tMethod 494 515\tdynamic label pruning\n",
      "T16\tGeneric 529 539\textensions\n",
      "T17\tOtherScientificTerm 577 613\tintolerable computational cost of BP\n",
      "T18\tMethod 611 613\tBP\n",
      "T19\tGeneric 675 685\textensions\n",
      "T20\tMethod 734 753\tMRF energy function\n",
      "T21\tGeneric 788 794\tmethod\n",
      "T22\tMaterial 832 857\timage completion examples\n",
      "R1\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R2\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R6\tHYPONYM-OF Arg1:T2 Arg2:T6\n",
      "R7\tHYPONYM-OF Arg1:T3 Arg2:T6\n",
      "R8\tHYPONYM-OF Arg1:T4 Arg2:T6\n",
      "R9\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R10\tCOMPARE Arg1:T5 Arg2:T6\n",
      "R11\tCOREF Arg1:T9 Arg2:T7\n",
      "R12\tHYPONYM-OF Arg1:T11 Arg2:T10\n",
      "R13\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R14\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R15\tHYPONYM-OF Arg1:T14 Arg2:T12\n",
      "R16\tHYPONYM-OF Arg1:T15 Arg2:T12\n",
      "R17\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R18\tCOREF Arg1:T16 Arg2:T12\n",
      "R19\tPART-OF Arg1:T12 Arg2:T10\n",
      "R20\tCOREF Arg1:T18 Arg2:T13\n",
      "R21\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R22\tCOREF Arg1:T19 Arg2:T16\n",
      "R23\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R24\tCOREF Arg1:T21 Arg2:T19\n",
      "R25\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "R26\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2006_21_abs.ann\n",
      "T1\tOtherScientificTerm 20 35\tprior knowledge\n",
      "T2\tMethod 73 117\tlow-level driven image processing algorithms\n",
      "T3\tTask 160 188\tnon-rigid image registration\n",
      "T4\tMetric 211 232\tregistration criteria\n",
      "T5\tMetric 307 333\tmaximum mutual information\n",
      "T6\tGeneric 349 358\tcriterion\n",
      "T7\tGeneric 420 422\tit\n",
      "T8\tMetric 440 459\tlow-level criterion\n",
      "T9\tTask 479 491\tregistration\n",
      "T10\tOtherScientificTerm 527 548\tlow-level information\n",
      "T11\tOtherScientificTerm 570 575\tnoise\n",
      "T12\tOtherScientificTerm 577 595\tpartial occlusions\n",
      "T13\tOtherScientificTerm 599 622\tmissing image structure\n",
      "T14\tMethod 658 676\tBayesian framework\n",
      "T15\tOtherScientificTerm 699 736\tstatistically learned prior knowledge\n",
      "T16\tOtherScientificTerm 747 775\tjoint intensity distribution\n",
      "T17\tMethod 781 807\timage registration methods\n",
      "T18\tGeneric 813 818\tprior\n",
      "T19\tMethod 833 856\tkernel density estimate\n",
      "T20\tOtherScientificTerm 873 902\tjoint intensity distributions\n",
      "T21\tMaterial 941 967\tpre-registered image pairs\n",
      "T22\tOtherScientificTerm 1031 1050\tintensity relations\n",
      "T23\tOtherScientificTerm 1067 1083\timage modalities\n",
      "T24\tOtherScientificTerm 1088 1103\tslice locations\n",
      "T25\tMethod 1157 1177\tregistration process\n",
      "T26\tOtherScientificTerm 1196 1225\tmissing low-level information\n",
      "T27\tOtherScientificTerm 1229 1231\tit\n",
      "T28\tOtherScientificTerm 1239 1264\tintensity correspondences\n",
      "T29\tOtherScientificTerm 1307 1330\tintensity distributions\n",
      "R1\tHYPONYM-OF Arg1:T5 Arg2:T4\n",
      "R2\tCOREF Arg1:T6 Arg2:T5\n",
      "R3\tCOREF Arg1:T6 Arg2:T7\n",
      "R4\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "R5\tCOREF Arg1:T3 Arg2:T9\n",
      "R6\tFEATURE-OF Arg1:T16 Arg2:T15\n",
      "R7\tUSED-FOR Arg1:T14 Arg2:T17\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T17\n",
      "R9\tCOREF Arg1:T18 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T19 Arg2:T18\n",
      "R11\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R12\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R13\tCOREF Arg1:T17 Arg2:T25\n",
      "R14\tUSED-FOR Arg1:T25 Arg2:T26\n",
      "R15\tCOREF Arg1:T25 Arg2:T27\n",
      "R16\tUSED-FOR Arg1:T27 Arg2:T28\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2007_10_abs.ann\n",
      "T1\tMethod 12 50\tlinear Fukunaga-Koontz Transform (FKT)\n",
      "T2\tMethod 69 111\tdiscriminative subspaces building approach\n",
      "T3\tMethod 153 156\tFKT\n",
      "T4\tOtherScientificTerm 181 198\tsmall-sample-size\n",
      "T5\tMethod 237 247\tlinear FKT\n",
      "T6\tGeneric 258 260\tit\n",
      "T7\tTask 272 291\tmulti-class problem\n",
      "T8\tOtherScientificTerm 304 341\thigher dimensional (kernel) subspaces\n",
      "T9\tOtherScientificTerm 373 395\tdiscrimination ability\n",
      "T10\tMethod 441 473\tKernel Fukunaga-Koontz Transform\n",
      "T11\tTask 512 541\tface recognition applications\n",
      "T12\tMethod 564 589\tnon-linear generalization\n",
      "T13\tTask 618 642\tdomain specific problems\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T5 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R8\tFEATURE-OF Arg1:T6 Arg2:T9\n",
      "R9\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R10\tEVALUATE-FOR Arg1:T11 Arg2:T10\n",
      "R11\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R12\tCOREF Arg1:T10 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2007_11_abs.ann\n",
      "T1\tMethod 41 69\tLagrangian Particle Dynamics\n",
      "T2\tTask 86 126\tsegmentation of high density crowd flows\n",
      "T3\tTask 131 162\tdetection of flow instabilities\n",
      "T4\tOtherScientificTerm 184 194\tflow field\n",
      "T5\tOtherScientificTerm 210 222\tmoving crowd\n",
      "T6\tMethod 240 266\taperiodic dynamical system\n",
      "T7\tOtherScientificTerm 270 287\tgrid of particles\n",
      "T8\tOtherScientificTerm 307 317\tflow field\n",
      "T9\tMethod 343 371\tnumerical integration scheme\n",
      "T10\tOtherScientificTerm 377 399\tevolution of particles\n",
      "T11\tMethod 436 444\tFlow Map\n",
      "T12\tOtherScientificTerm 452 469\tspatial gradients\n",
      "T13\tMethod 503 534\tCauchy Green Deformation tensor\n",
      "T14\tOtherScientificTerm 651 669\tmaximum eigenvalue\n",
      "T15\tGeneric 677 683\ttensor\n",
      "T16\tOtherScientificTerm 707 749\tFinite Time Lyapunov Exponent (FTLE) field\n",
      "T17\tOtherScientificTerm 769 805\tLagrangian Coherent Structures (LCS)\n",
      "T18\tOtherScientificTerm 842 845\tLCS\n",
      "T19\tOtherScientificTerm 930 961\tboundaries of the flow segments\n",
      "T20\tMethod 967 992\tnormalized cuts framework\n",
      "T21\tMaterial 1232 1244\tGoogle Video\n",
      "T22\tMaterial 1251 1282\tNational Geographic documentary\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R5\tCOREF Arg1:T4 Arg2:T8\n",
      "R6\tCOREF Arg1:T15 Arg2:T13\n",
      "R7\tFEATURE-OF Arg1:T14 Arg2:T15\n",
      "R8\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R9\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R10\tCOREF Arg1:T18 Arg2:T17\n",
      "R11\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R12\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R13\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "R14\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R15\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R16\tUSED-FOR Arg1:T9 Arg2:T7\n",
      "R17\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R18\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2007_18_abs.ann\n",
      "T1\tMethod 28 59\thuman action recognition system\n",
      "T2\tTask 73 110\tembedded computer vision applications\n",
      "T3\tTask 114 130\tsecurity systems\n",
      "T4\tTask 132 158\thuman-computer interaction\n",
      "T5\tTask 163 187\tintelligent environments\n",
      "T6\tGeneric 193 199\tsystem\n",
      "T7\tTask 216 252\tembedded computer vision application\n",
      "T8\tGeneric 290 296\tsystem\n",
      "T9\tMethod 312 358\tlinear Support Vector Machine (SVM) classifier\n",
      "T10\tMethod 365 388\tclassification progress\n",
      "T11\tOtherScientificTerm 430 447\tembedded hardware\n",
      "T12\tOtherScientificTerm 467 492\tcompacted motion features\n",
      "T13\tMaterial 514 520\tvideos\n",
      "T14\tMethod 567 593\tMotion History Image (MHI)\n",
      "T15\tMethod 612 664\tHierarchical Motion History Histogram (HMHH) feature\n",
      "T16\tOtherScientificTerm 682 700\tmotion information\n",
      "T17\tMethod 702 706\tHMHH\n",
      "T18\tOtherScientificTerm 725 748\trich motion information\n",
      "T19\tMethod 816 819\tMHI\n",
      "T20\tMethod 824 828\tHMHH\n",
      "T21\tOtherScientificTerm 852 880\tlow dimension feature vector\n",
      "T22\tMethod 899 914\tSVM classifiers\n",
      "T23\tGeneric 951 957\tsystem\n",
      "T24\tTask 998 1009\trecognition\n",
      "R1\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R2\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T6 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T2 Arg2:T5\n",
      "R8\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R9\tCOREF Arg1:T7 Arg2:T2\n",
      "R10\tCOREF Arg1:T8 Arg2:T6\n",
      "R11\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R12\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R13\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R14\tCOREF Arg1:T17 Arg2:T15\n",
      "R15\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R16\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R17\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R18\tCOREF Arg1:T23 Arg2:T8\n",
      "R19\tEVALUATE-FOR Arg1:T24 Arg2:T23\n",
      "R20\tCOREF Arg1:T9 Arg2:T10\n",
      "R21\tCOREF Arg1:T22 Arg2:T10\n",
      "R22\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R23\tUSED-FOR Arg1:T19 Arg2:T21\n",
      "R24\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2007_21_abs.ann\n",
      "T1\tTask 33 65\tclassification of outdoor scenes\n",
      "T2\tMethod 116 140\tone-class classification\n",
      "T3\tMethod 145 178\tpatch-based clustering algorithms\n",
      "T4\tMethod 185 206\tone-class classifiers\n",
      "T5\tOtherScientificTerm 241 277\tuniform color and texture properties\n",
      "T6\tMethod 283 304\tclustering of patches\n",
      "T7\tOtherScientificTerm 411 435\tcodebook of region types\n",
      "T8\tGeneric 445 451\tmodels\n",
      "T9\tMethod 472 492\tscene representation\n",
      "T10\tOtherScientificTerm 659 680\tspatial relationships\n",
      "T11\tTask 735 755\tscene classification\n",
      "T12\tMethod 770 790\tBayesian classifiers\n",
      "T13\tMethod 816 842\tregion selection algorithm\n",
      "T14\tMaterial 1050 1066\tLabelMe data set\n",
      "T15\tGeneric 1092 1098\tmodels\n",
      "T16\tMethod 1127 1165\tbaseline global feature-based approach\n",
      "R1\tCONJUNCTION Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R5\tCOMPARE Arg1:T15 Arg2:T16\n",
      "R6\tEVALUATE-FOR Arg1:T14 Arg2:T15\n",
      "R7\tCOREF Arg1:T15 Arg2:T13\n",
      "R8\tEVALUATE-FOR Arg1:T14 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2008_100_abs.ann\n",
      "T1\tMethod 0 24\tStructured-light methods\n",
      "T2\tMaterial 43 72\tgeometric correspondence data\n",
      "T3\tTask 127 151\trobust 3D reconstruction\n",
      "T4\tMethod 179 210\tPhotogeometric Structured Light\n",
      "T5\tMethod 230 253\tstructured light method\n",
      "T6\tMethod 277 296\tphotometric methods\n",
      "T7\tMethod 298 320\tPhotometric processing\n",
      "T8\tOtherScientificTerm 375 399\trecovered surface detail\n",
      "T9\tOtherScientificTerm 420 442\tstructured-light setup\n",
      "T10\tGeneric 488 497\tframework\n",
      "T11\tMethod 505 532\tphotogeometric optimization\n",
      "T12\tMethod 636 655\tmulti-view 3D model\n",
      "T13\tMaterial 681 711\tphotometric and geometric data\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T7 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R6\tCOREF Arg1:T10 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R8\tPART-OF Arg1:T5 Arg2:T4\n",
      "R9\tPART-OF Arg1:T6 Arg2:T4\n",
      "R10\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2008_103_abs.ann\n",
      "T1\tMethod 28 89\tpartially-blurred-image classification and analysis framework\n",
      "T2\tTask 94 124\tautomatically detecting images\n",
      "T3\tMaterial 118 124\timages\n",
      "T4\tOtherScientificTerm 136 151\tblurred regions\n",
      "T5\tGeneric 193 200\tregions\n",
      "T6\tTask 228 250\tblur kernel estimation\n",
      "T7\tTask 255 271\timage deblurring\n",
      "T8\tOtherScientificTerm 292 305\tblur features\n",
      "T9\tOtherScientificTerm 317 328\timage color\n",
      "T10\tOtherScientificTerm 330 338\tgradient\n",
      "T11\tOtherScientificTerm 344 364\tspectrum information\n",
      "T12\tMethod 374 400\tfeature parameter training\n",
      "T13\tMaterial 422 436\tblurred images\n",
      "T14\tMethod 442 456\tblur detection\n",
      "T15\tOtherScientificTerm 469 482\timage patches\n",
      "T16\tMethod 491 530\tregion-wise training and classification\n",
      "T17\tGeneric 591 597\tmethod\n",
      "T18\tMaterial 634 644\timage data\n",
      "T19\tTask 707 731\tcomputer vision problems\n",
      "T20\tTask 741 756\tmotion analysis\n",
      "T21\tTask 761 778\timage restoration\n",
      "T22\tOtherScientificTerm 790 806\tblur information\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tPART-OF Arg1:T4 Arg2:T3\n",
      "R3\tCOREF Arg1:T5 Arg2:T4\n",
      "R4\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T8\n",
      "R8\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R9\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R11\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T14\n",
      "R13\tCOREF Arg1:T17 Arg2:T14\n",
      "R14\tHYPONYM-OF Arg1:T20 Arg2:T19\n",
      "R15\tHYPONYM-OF Arg1:T21 Arg2:T19\n",
      "R16\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R17\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R18\tUSED-FOR Arg1:T17 Arg2:T19\n",
      "R19\tUSED-FOR Arg1:T22 Arg2:T17\n",
      "R20\tCOREF Arg1:T1 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2008_256_abs.ann\n",
      "T1\tMethod 9 21\tobject model\n",
      "T2\tMetric 28 59\tblack-box measure of similarity\n",
      "T3\tGeneric 72 77\tmodel\n",
      "T4\tTask 113 135\tvisual object tracking\n",
      "T5\tTask 141 171\tnumerical optimization problem\n",
      "T6\tMethod 255 273\tlocal optimization\n",
      "T7\tOtherScientificTerm 295 331\tlocal mode of the similarity measure\n",
      "T8\tOtherScientificTerm 337 387\tparameter space of translation, rotation and scale\n",
      "T9\tMethod 458 472\tlocal tracking\n",
      "T10\tMethod 517 538\tprediction techniques\n",
      "T11\tMethod 548 561\tKalman filter\n",
      "T12\tTask 696 712\tobject detection\n",
      "T13\tTask 718 745\tglobal optimization problem\n",
      "T14\tGeneric 756 758\tit\n",
      "T15\tMethod 763 797\tAdaptive Simulated Annealing (ASA)\n",
      "T16\tGeneric 801 807\tmethod\n",
      "T17\tMethod 876 893\texhaustive search\n",
      "T18\tMethod 900 920\tMonte Carlo approach\n",
      "T19\tMethod 922 925\tASA\n",
      "T20\tOtherScientificTerm 953 968\tparameter space\n",
      "T21\tMethod 985 1011\tlocal deterministic search\n",
      "T22\tMethod 1022 1038\tcluster analysis\n",
      "T23\tOtherScientificTerm 1046 1069\tsampled parameter space\n",
      "T24\tMethod 1107 1120\tlocal tracker\n",
      "T25\tMethod 1126 1180\tnumerical hybrid local and global mode-seeking tracker\n",
      "T26\tMaterial 1209 1224\tairborne videos\n",
      "T27\tOtherScientificTerm 1230 1245\theavy occlusion\n",
      "T28\tOtherScientificTerm 1256 1270\tcamera motions\n",
      "T29\tGeneric 1276 1284\tapproach\n",
      "T30\tGeneric 1297 1322\tstate-of-the-art trackers\n",
      "T31\tMaterial 1330 1354\tVIVID benchmark datasets\n",
      "R1\tCOREF Arg1:T3 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R6\tCOREF Arg1:T13 Arg2:T14\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R8\tCOREF Arg1:T16 Arg2:T15\n",
      "R9\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R10\tCOREF Arg1:T15 Arg2:T19\n",
      "R11\tHYPONYM-OF Arg1:T19 Arg2:T18\n",
      "R12\tCOMPARE Arg1:T19 Arg2:T21\n",
      "R13\tCOREF Arg1:T25 Arg2:T29\n",
      "R14\tCOMPARE Arg1:T30 Arg2:T29\n",
      "R15\tEVALUATE-FOR Arg1:T31 Arg2:T29\n",
      "R16\tEVALUATE-FOR Arg1:T31 Arg2:T30\n",
      "R17\tEVALUATE-FOR Arg1:T26 Arg2:T25\n",
      "R18\tFEATURE-OF Arg1:T27 Arg2:T26\n",
      "R19\tFEATURE-OF Arg1:T28 Arg2:T26\n",
      "R20\tCONJUNCTION Arg1:T27 Arg2:T28\n",
      "R21\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R22\tUSED-FOR Arg1:T22 Arg2:T24\n",
      "R23\tPART-OF Arg1:T11 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2008_257_abs.ann\n",
      "T1\tMethod 0 16\tGraphical models\n",
      "T2\tMethod 25 48\tBayesian Networks (BNs)\n",
      "T3\tTask 91 115\tcomputer vision problems\n",
      "T4\tMethod 141 143\tBN\n",
      "T5\tOtherScientificTerm 165 184\tBN model parameters\n",
      "T6\tMaterial 231 259\trepresentative training data\n",
      "T7\tTask 310 331\tcomputer vision tasks\n",
      "T8\tOtherScientificTerm 377 404\tqualitative prior knowledge\n",
      "T9\tGeneric 415 420\tmodel\n",
      "T10\tGeneric 427 436\tknowledge\n",
      "T11\tOtherScientificTerm 455 469\tdomain experts\n",
      "T12\tOtherScientificTerm 512 545\tphysical or geometric constraints\n",
      "T13\tOtherScientificTerm 598 616\tquantitative prior\n",
      "T14\tOtherScientificTerm 622 639\tqualitative prior\n",
      "T15\tGeneric 696 700\tthem\n",
      "T16\tTask 710 732\tmodel learning process\n",
      "T17\tMethod 764 784\tclosed-form solution\n",
      "T18\tMaterial 815 836\tlimited training data\n",
      "T19\tOtherScientificTerm 855 876\tqualitative knowledge\n",
      "T20\tMethod 881 902\tBN parameter learning\n",
      "T21\tGeneric 920 926\tmethod\n",
      "T22\tGeneric 939 941\tit\n",
      "T23\tMethod 951 992\tMaximum Likelihood (ML) estimation method\n",
      "T24\tMaterial 999 1010\tsparse data\n",
      "T25\tMethod 1024 1063\tExpectation Maximization (EM) algorithm\n",
      "T26\tMaterial 1070 1085\tincomplete data\n",
      "T27\tTask 1144 1159\tcomputer vision\n",
      "T28\tGeneric 1170 1172\tit\n",
      "T29\tMethod 1184 1192\tBN model\n",
      "T30\tTask 1197 1232\tfacial Action Unit (AU) recognition\n",
      "T31\tMaterial 1238 1253\treal image data\n",
      "T32\tOtherScientificTerm 1306 1337\tgeneric qualitative constraints\n",
      "T33\tMaterial 1371 1384\ttraining data\n",
      "T34\tGeneric 1390 1396\tmethod\n",
      "T35\tOtherScientificTerm 1438 1457\tBN model parameters\n",
      "R1\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T4 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tCOREF Arg1:T10 Arg2:T8\n",
      "R7\tFEATURE-OF Arg1:T8 Arg2:T9\n",
      "R8\tCOREF Arg1:T14 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R10\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R11\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R12\tCOREF Arg1:T15 Arg2:T14\n",
      "R13\tPART-OF Arg1:T15 Arg2:T16\n",
      "R14\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R15\tCOMPARE Arg1:T22 Arg2:T23\n",
      "R16\tUSED-FOR Arg1:T24 Arg2:T22\n",
      "R17\tUSED-FOR Arg1:T24 Arg2:T23\n",
      "R18\tUSED-FOR Arg1:T26 Arg2:T25\n",
      "R19\tCOMPARE Arg1:T22 Arg2:T25\n",
      "R20\tUSED-FOR Arg1:T28 Arg2:T29\n",
      "R21\tUSED-FOR Arg1:T29 Arg2:T30\n",
      "R22\tCONJUNCTION Arg1:T32 Arg2:T33\n",
      "R23\tUSED-FOR Arg1:T33 Arg2:T34\n",
      "R24\tUSED-FOR Arg1:T32 Arg2:T34\n",
      "R25\tUSED-FOR Arg1:T34 Arg2:T35\n",
      "R26\tCOREF Arg1:T4 Arg2:T29\n",
      "R27\tCOREF Arg1:T27 Arg2:T3\n",
      "R28\tCOREF Arg1:T7 Arg2:T3\n",
      "R29\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R30\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R31\tUSED-FOR Arg1:T18 Arg2:T20\n",
      "R32\tUSED-FOR Arg1:T20 Arg2:T17\n",
      "R33\tCOREF Arg1:T21 Arg2:T22\n",
      "R34\tCOREF Arg1:T17 Arg2:T21\n",
      "R35\tUSED-FOR Arg1:T26 Arg2:T22\n",
      "R36\tCOREF Arg1:T22 Arg2:T28\n",
      "R37\tUSED-FOR Arg1:T28 Arg2:T27\n",
      "R38\tCOREF Arg1:T34 Arg2:T28\n",
      "R39\tUSED-FOR Arg1:T31 Arg2:T30\n",
      "R40\tCOREF Arg1:T9 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2008_258_abs.ann\n",
      "T1\tTask 35 78\tunsupervised seg-mentation of whole objects\n",
      "T2\tTask 105 131\tpartial scene segmentation\n",
      "T3\tOtherScientificTerm 152 171\tsoft, binary mattes\n",
      "T4\tGeneric 179 185\tmattes\n",
      "T5\tOtherScientificTerm 210 248\thypothesized object boundary fragments\n",
      "T6\tGeneric 394 414\tcontemporary methods\n",
      "T7\tTask 419 448\tunsupervised object discovery\n",
      "T8\tOtherScientificTerm 598 626\tdelineation of scene objects\n",
      "T9\tGeneric 641 649\tapproach\n",
      "T10\tMethod 679 698\tspectral clustering\n",
      "T11\tMethod 700 713\timage matting\n",
      "T12\tMethod 719 737\tboundary detection\n",
      "T13\tGeneric 739 741\tIt\n",
      "T14\tMaterial 796 813\tdataset of scenes\n",
      "T15\tTask 850 879\tunsupervised object discovery\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tCOREF Arg1:T3 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R7\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R8\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T9\n",
      "R11\tCOREF Arg1:T15 Arg2:T7\n",
      "R12\tCOREF Arg1:T1 Arg2:T7\n",
      "R13\tCOREF Arg1:T13 Arg2:T9\n",
      "R14\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R15\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2008_259_abs.ann\n",
      "T1\tMethod 28 47\tgeometric framework\n",
      "T2\tTask 52 121\tlinear or nonlinear discriminant subspace learning and classification\n",
      "T3\tGeneric 130 139\tframework\n",
      "T4\tOtherScientificTerm 145 166\tstructures of classes\n",
      "T5\tOtherScientificTerm 191 215\tsemi-Riemannian manifold\n",
      "T6\tOtherScientificTerm 241 252\tsubmanifold\n",
      "T7\tOtherScientificTerm 268 297\tambient semi-Riemannian space\n",
      "T8\tOtherScientificTerm 303 319\tclass structures\n",
      "T9\tMetric 377 419\tlocal metrics of the semi-Riemannian space\n",
      "T10\tMetric 421 444\tSemi-Riemannian metrics\n",
      "T11\tMethod 476 507\tsmoothing of discrete functions\n",
      "T12\tOtherScientificTerm 516 552\tnullity of the semi-Riemannian space\n",
      "T13\tMethod 567 601\tgeometrization of class structures\n",
      "T14\tOtherScientificTerm 614 630\tclass structures\n",
      "T15\tOtherScientificTerm 638 651\tfeature space\n",
      "T16\tOtherScientificTerm 684 722\tquadratic quantities of metric tensors\n",
      "T17\tOtherScientificTerm 730 751\tsemi-Riemannian space\n",
      "T18\tMethod 758 799\tsupervised discriminant subspace learning\n",
      "T19\tMethod 811 858\tunsupervised semi-Riemannian mani-fold learning\n",
      "T20\tGeneric 882 891\tframework\n",
      "T21\tGeneric 901 910\talgorithm\n",
      "T22\tMethod 922 966\tSemi-Riemannian Discriminant Analysis (SRDA)\n",
      "T23\tTask 985 1014\tsubspace-based classification\n",
      "T24\tMethod 1035 1039\tSRDA\n",
      "T25\tTask 1053 1084\tface recognition (singular case\n",
      "T26\tTask 1090 1150\thandwritten capital letter classification (nonsingular case)\n",
      "T27\tGeneric 1168 1178\talgorithms\n",
      "T28\tGeneric 1215 1219\tSRDA\n",
      "T29\tTask 1234 1245\trecognition\n",
      "T30\tTask 1250 1264\tclassification\n",
      "T31\tMethod 1280 1304\tsemi-Riemannian geometry\n",
      "T32\tTask 1333 1352\tpattern recognition\n",
      "T33\tTask 1357 1373\tmachine learning\n",
      "R1\tCOREF Arg1:T3 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R4\tPART-OF Arg1:T6 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R6\tCOREF Arg1:T10 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R9\tFEATURE-OF Arg1:T15 Arg2:T14\n",
      "R10\tFEATURE-OF Arg1:T17 Arg2:T16\n",
      "R11\tCOREF Arg1:T22 Arg2:T21\n",
      "R12\tUSED-FOR Arg1:T21 Arg2:T23\n",
      "R13\tCOREF Arg1:T1 Arg2:T20\n",
      "R14\tCOREF Arg1:T24 Arg2:T22\n",
      "R15\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R16\tEVALUATE-FOR Arg1:T25 Arg2:T24\n",
      "R17\tEVALUATE-FOR Arg1:T26 Arg2:T24\n",
      "R18\tCONJUNCTION Arg1:T25 Arg2:T26\n",
      "R19\tCOMPARE Arg1:T24 Arg2:T27\n",
      "R20\tCOREF Arg1:T22 Arg2:T28\n",
      "R21\tEVALUATE-FOR Arg1:T25 Arg2:T27\n",
      "R22\tEVALUATE-FOR Arg1:T26 Arg2:T27\n",
      "R23\tUSED-FOR Arg1:T28 Arg2:T29\n",
      "R24\tUSED-FOR Arg1:T28 Arg2:T30\n",
      "R25\tCONJUNCTION Arg1:T29 Arg2:T30\n",
      "R26\tCONJUNCTION Arg1:T32 Arg2:T33\n",
      "R27\tUSED-FOR Arg1:T31 Arg2:T32\n",
      "R28\tUSED-FOR Arg1:T31 Arg2:T33\n",
      "R29\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2009_10_abs.ann\n",
      "T1\tMethod 19 42\tprobabilistic framework\n",
      "T2\tTask 56 93\tvisual models of 3D object categories\n",
      "T3\tOtherScientificTerm 107 129\tappearance information\n",
      "T4\tOtherScientificTerm 134 155\tgeometric constraints\n",
      "T5\tOtherScientificTerm 239 267\t3D viewpoint transformations\n",
      "T6\tOtherScientificTerm 298 320\tsalient image features\n",
      "T7\tMethod 324 344\tgenerative framework\n",
      "T8\tGeneric 368 373\tmodel\n",
      "T9\tOtherScientificTerm 438 460\tdiscretized viewpoints\n",
      "T10\tMethod 495 523\tmixture of viewpoints models\n",
      "T11\tGeneric 530 535\tmodel\n",
      "T12\tOtherScientificTerm 599 609\tviewpoints\n",
      "T13\tMaterial 643 648\timage\n",
      "T14\tTask 650 659\tdetection\n",
      "T15\tTask 664 678\tclassification\n",
      "T16\tOtherScientificTerm 711 719\tposition\n",
      "T17\tOtherScientificTerm 724 733\tviewpoint\n",
      "T18\tMetric 761 779\trecognition scores\n",
      "T19\tGeneric 810 818\tapproach\n",
      "T20\tMethod 851 886\tgenerative proba-bilistic framework\n",
      "T21\tTask 891 915\t3D object categorization\n",
      "T22\tGeneric 929 938\talgorithm\n",
      "T23\tTask 946 960\tdetection task\n",
      "T24\tTask 969 998\tviewpoint classification task\n",
      "T25\tMaterial 1064 1088\tPASCAL VOC 2006 datasets\n",
      "T26\tTask 1128 1172\tdetection and viewpoint classification tasks\n",
      "T27\tGeneric 1198 1206\tdatasets\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R6\tUSED-FOR Arg1:T17 Arg2:T15\n",
      "R7\tUSED-FOR Arg1:T16 Arg2:T14\n",
      "R8\tUSED-FOR Arg1:T17 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R10\tCOREF Arg1:T19 Arg2:T11\n",
      "R11\tCOREF Arg1:T22 Arg2:T19\n",
      "R12\tEVALUATE-FOR Arg1:T25 Arg2:T22\n",
      "R13\tHYPONYM-OF Arg1:T25 Arg2:T27\n",
      "R14\tCOMPARE Arg1:T11 Arg2:T10\n",
      "R15\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R16\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R17\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R18\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R19\tCOREF Arg1:T20 Arg2:T19\n",
      "R20\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R21\tUSED-FOR Arg1:T22 Arg2:T24\n",
      "R22\tCONJUNCTION Arg1:T23 Arg2:T24\n",
      "R23\tEVALUATE-FOR Arg1:T27 Arg2:T26\n",
      "R24\tHYPONYM-OF Arg1:T23 Arg2:T26\n",
      "R25\tHYPONYM-OF Arg1:T24 Arg2:T26\n",
      "R26\tCOREF Arg1:T11 Arg2:T8\n",
      "R27\tCOREF Arg1:T8 Arg2:T1\n",
      "R28\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2009_11_abs.ann\n",
      "T1\tOtherScientificTerm 23 50\tpan-tilt-zoom (PTZ) cameras\n",
      "T2\tOtherScientificTerm 77 91\tpanoramic area\n",
      "T3\tOtherScientificTerm 105 128\thigh resolution imagery\n",
      "T4\tTask 144 174\tautomated surveillance systems\n",
      "T5\tOtherScientificTerm 189 200\tPTZ cameras\n",
      "T6\tGeneric 251 261\talgorithms\n",
      "T7\tOtherScientificTerm 274 331\tprior knowledge of intrinsic parameters of the PTZ camera\n",
      "T8\tOtherScientificTerm 345 365\trelative positioning\n",
      "T9\tOtherScientificTerm 370 381\torientation\n",
      "T10\tOtherScientificTerm 397 408\tPTZ cameras\n",
      "T11\tMethod 458 475\tmapping algorithm\n",
      "T12\tOtherScientificTerm 493 513\trelative positioning\n",
      "T13\tOtherScientificTerm 518 529\torientation\n",
      "T14\tOtherScientificTerm 542 553\tPTZ cameras\n",
      "T15\tMethod 565 589\tunified polynomial model\n",
      "T16\tOtherScientificTerm 663 673\tPTZ camera\n",
      "T17\tOtherScientificTerm 678 696\trelative positions\n",
      "T18\tGeneric 749 758\talgorithm\n",
      "T19\tMetric 790 814\tcomputational complexity\n",
      "T20\tMetric 828 839\tflexibility\n",
      "T21\tMetric 874 888\tpixel accuracy\n",
      "T22\tMetric 958 972\tpixel accuracy\n",
      "T23\tMethod 995 1025\tconsistent labeling approaches\n",
      "T24\tTask 1068 1098\tautomated surveillance systems\n",
      "T25\tOtherScientificTerm 1157 1168\tPTZ cameras\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T9\n",
      "R4\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R5\tFEATURE-OF Arg1:T8 Arg2:T10\n",
      "R6\tFEATURE-OF Arg1:T9 Arg2:T10\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R10\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R11\tFEATURE-OF Arg1:T13 Arg2:T14\n",
      "R12\tFEATURE-OF Arg1:T12 Arg2:T14\n",
      "R13\tEVALUATE-FOR Arg1:T19 Arg2:T18\n",
      "R14\tEVALUATE-FOR Arg1:T20 Arg2:T18\n",
      "R15\tEVALUATE-FOR Arg1:T21 Arg2:T18\n",
      "R16\tCOREF Arg1:T22 Arg2:T21\n",
      "R17\tUSED-FOR Arg1:T23 Arg2:T22\n",
      "R18\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R19\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R20\tCOREF Arg1:T4 Arg2:T24\n",
      "R21\tCOREF Arg1:T11 Arg2:T18\n",
      "R22\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2009_18_abs.ann\n",
      "T1\tGeneric 17 23\tmethod\n",
      "T2\tTask 28 53\tdetecting interest points\n",
      "T3\tOtherScientificTerm 60 81\thistogram information\n",
      "T4\tMethod 99 123\tinterest point detectors\n",
      "T5\tMetric 139 180\tpixel-wise differences in image intensity\n",
      "T6\tGeneric 186 195\tdetectors\n",
      "T7\tMethod 208 239\thistogram-based representations\n",
      "T8\tGeneric 345 354\tdetectors\n",
      "T9\tOtherScientificTerm 375 397\tlarge-scale structures\n",
      "T10\tOtherScientificTerm 402 431\tdistinctive textured patterns\n",
      "T11\tOtherScientificTerm 466 474\trotation\n",
      "T12\tOtherScientificTerm 476 498\tillumination variation\n",
      "T13\tOtherScientificTerm 504 508\tblur\n",
      "T14\tMethod 558 598\thistogram-based interest point detectors\n",
      "T15\tTask 642 666\tmatching textured scenes\n",
      "T16\tOtherScientificTerm 673 702\tblur and illumination changes\n",
      "T17\tMetric 716 729\trepeatability\n",
      "T18\tMetric 734 749\tdistinctiveness\n",
      "T19\tGeneric 771 777\tmethod\n",
      "T20\tTask 781 816\tspace-time interest point detection\n",
      "T21\tTask 821 842\taction classification\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T6 Arg2:T1\n",
      "R4\tPART-OF Arg1:T7 Arg2:T6\n",
      "R5\tEVALUATE-FOR Arg1:T5 Arg2:T4\n",
      "R6\tCOREF Arg1:T8 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R8\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T11\n",
      "R11\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R12\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R13\tUSED-FOR Arg1:T8 Arg2:T12\n",
      "R14\tUSED-FOR Arg1:T8 Arg2:T13\n",
      "R15\tCOREF Arg1:T14 Arg2:T8\n",
      "R16\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R17\tCOREF Arg1:T19 Arg2:T14\n",
      "R18\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R19\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R20\tEVALUATE-FOR Arg1:T17 Arg2:T14\n",
      "R21\tEVALUATE-FOR Arg1:T18 Arg2:T14\n",
      "R22\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2009_21_abs.ann\n",
      "T1\tTask 5 33\tcomputer vision applications\n",
      "T2\tTask 43 63\timage classification\n",
      "T3\tTask 68 82\tvideo indexing\n",
      "T4\tTask 96 131\tmulti-label classification problems\n",
      "T5\tMethod 230 265\tmulti-label classification approach\n",
      "T6\tOtherScientificTerm 271 297\thypergraph regu-larization\n",
      "T7\tOtherScientificTerm 367 377\thypergraph\n",
      "T8\tMethod 616 640\tSVM like learning system\n",
      "T9\tOtherScientificTerm 659 684\thypergraph regularization\n",
      "T10\tMethod 693 705\tRank-HLapSVM\n",
      "T11\tTask 733 768\tmulti-label classification problems\n",
      "T12\tTask 801 821\toptimization problem\n",
      "T13\tMethod 855 885\tdual coordinate descent method\n",
      "T14\tGeneric 930 943\treal datasets\n",
      "T15\tMaterial 954 963\tImageCLEF\n",
      "T16\tMaterial 968 978\tMe-diaMill\n",
      "T17\tGeneric 1040 1049\talgorithm\n",
      "R1\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R5\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "R6\tPART-OF Arg1:T9 Arg2:T8\n",
      "R7\tHYPONYM-OF Arg1:T10 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T11\n",
      "R9\tCOREF Arg1:T11 Arg2:T4\n",
      "R10\tCOREF Arg1:T5 Arg2:T8\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R12\tCOREF Arg1:T8 Arg2:T17\n",
      "R13\tHYPONYM-OF Arg1:T15 Arg2:T14\n",
      "R14\tHYPONYM-OF Arg1:T16 Arg2:T14\n",
      "R15\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R16\tEVALUATE-FOR Arg1:T14 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2010_10_abs.ann\n",
      "T1\tGeneric 17 25\tapproach\n",
      "T2\tMethod 63 73\tclassifier\n",
      "T3\tTask 86 99\tclass problem\n",
      "T4\tMaterial 147 152\timage\n",
      "T5\tOtherScientificTerm 169 182\torien-tations\n",
      "T6\tGeneric 229 236\tproblem\n",
      "T7\tMethod 252 263\tclassifiers\n",
      "T8\tGeneric 343 351\tapproach\n",
      "T9\tMethod 360 376\testimation stage\n",
      "T10\tMethod 383 403\tclassification stage\n",
      "T11\tMethod 409 418\testimator\n",
      "T12\tOtherScientificTerm 454 466\tobject poses\n",
      "T13\tMethod 498 508\tclassifier\n",
      "T14\tMetric 547 562\ttime complexity\n",
      "T15\tGeneric 570 579\talgorithm\n",
      "T16\tTask 586 600\tclassification\n",
      "T17\tMethod 626 636\tclassifier\n",
      "T18\tMethod 673 708\tboosted combination of Random Ferns\n",
      "T19\tOtherScientificTerm 714 759\tlocal histograms of oriented gradients (HOGs)\n",
      "T20\tMethod 787 806\tpre-processing step\n",
      "T21\tMethod 824 843\tsupervised learning\n",
      "T22\tOtherScientificTerm 863 877\tgradient space\n",
      "T23\tGeneric 888 896\tapproach\n",
      "T24\tGeneric 1019 1027\tdatabase\n",
      "T25\tMaterial 1036 1069\tmotorbikes under planar rotations\n",
      "T26\tGeneric 1092 1102\tconditions\n",
      "T27\tOtherScientificTerm 1111 1132\tcluttered backgrounds\n",
      "T28\tOtherScientificTerm 1134 1166\tchanging illumination conditions\n",
      "T29\tOtherScientificTerm 1171 1189\tpartial occlusions\n",
      "R1\tCOREF Arg1:T8 Arg2:T1\n",
      "R2\tCOREF Arg1:T15 Arg2:T8\n",
      "R3\tCOREF Arg1:T23 Arg2:T8\n",
      "R4\tCOREF Arg1:T11 Arg2:T9\n",
      "R5\tCOREF Arg1:T13 Arg2:T10\n",
      "R6\tCOREF Arg1:T17 Arg2:T10\n",
      "R7\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R8\tFEATURE-OF Arg1:T26 Arg2:T24\n",
      "R9\tHYPONYM-OF Arg1:T27 Arg2:T26\n",
      "R10\tHYPONYM-OF Arg1:T28 Arg2:T26\n",
      "R11\tHYPONYM-OF Arg1:T29 Arg2:T26\n",
      "R12\tCONJUNCTION Arg1:T27 Arg2:T28\n",
      "R13\tCONJUNCTION Arg1:T28 Arg2:T29\n",
      "R14\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R15\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R16\tCOREF Arg1:T6 Arg2:T3\n",
      "R17\tPART-OF Arg1:T9 Arg2:T8\n",
      "R18\tPART-OF Arg1:T10 Arg2:T8\n",
      "R19\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R20\tEVALUATE-FOR Arg1:T14 Arg2:T15\n",
      "R21\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R22\tFEATURE-OF Arg1:T19 Arg2:T18\n",
      "R23\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R24\tUSED-FOR Arg1:T21 Arg2:T23\n",
      "R25\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R26\tFEATURE-OF Arg1:T25 Arg2:T24\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2010_11_abs.ann\n",
      "T1\tTask 5 47\tclassifying high-dimensional sequence data\n",
      "T2\tMethod 76 80\tHMMs\n",
      "T3\tMethod 82 86\tCRFs\n",
      "T4\tOtherScientificTerm 140 151\toverfitting\n",
      "T5\tMethod 167 191\tdimensionality reduction\n",
      "T6\tMethod 218 248\tlow-dimensional representation\n",
      "T7\tTask 258 272\tclassification\n",
      "T8\tGeneric 303 319\tExisting methods\n",
      "T9\tTask 324 359\tsupervised dimensionality reduction\n",
      "T10\tOtherScientificTerm 417 445\tneighborhood graph structure\n",
      "T11\tOtherScientificTerm 492 510\tknown distribution\n",
      "T12\tMethod 512 553\tSufficient dimension reduction techniques\n",
      "T13\tMethod 568 598\tlow dimensional representation\n",
      "T14\tMethod 730 782\tsequence kernel dimension reduction approach (S-KDR)\n",
      "T15\tGeneric 788 796\tapproach\n",
      "T16\tOtherScientificTerm 869 911\tSpatial, temporal and periodic information\n",
      "T17\tOtherScientificTerm 963 971\tmanifold\n",
      "T18\tGeneric 991 999\tend-task\n",
      "T19\tGeneric 1041 1049\tapproach\n",
      "T20\tTask 1081 1134\tdiscrimination of human gesture and motion categories\n",
      "T21\tMaterial 1152 1180\tdatabase of dynamic textures\n",
      "R1\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R8\tCOREF Arg1:T14 Arg2:T15\n",
      "R9\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R10\tEVALUATE-FOR Arg1:T20 Arg2:T19\n",
      "R11\tEVALUATE-FOR Arg1:T21 Arg2:T19\n",
      "R12\tCOREF Arg1:T15 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2010_18_abs.ann\n",
      "T1\tMethod 0 23\tGraph-cuts optimization\n",
      "T2\tTask 40 68\tvision and graphics problems\n",
      "T3\tMethod 130 153\tgraph-cuts optimization\n",
      "T4\tOtherScientificTerm 180 199\tmulti-core machines\n",
      "T5\tMethod 227 243\tserial algorithm\n",
      "T6\tMethod 285 297\tBK algorithm\n",
      "T7\tOtherScientificTerm 391 415\tsynchronization overhead\n",
      "T8\tOtherScientificTerm 448 459\tparallelism\n",
      "T9\tMethod 495 522\tadaptive bottom-up approach\n",
      "T10\tMethod 542 554\tBK algorithm\n",
      "T11\tOtherScientificTerm 589 594\tgraph\n",
      "T12\tOtherScientificTerm 612 648\tregularly-shaped dis-joint subgraphs\n",
      "T13\tGeneric 661 665\tthem\n",
      "T14\tOtherScientificTerm 712 721\tsubgraphs\n",
      "T15\tOtherScientificTerm 755 769\tglobal optimum\n",
      "T16\tGeneric 779 788\talgorithm\n",
      "T17\tOtherScientificTerm 853 862\tsubgraphs\n",
      "T18\tOtherScientificTerm 876 894\tbalanced workloads\n",
      "T19\tOtherScientificTerm 938 946\toverhead\n",
      "T20\tGeneric 1030 1042\tapplications\n",
      "T21\tTask 1051 1076\t2D/3D image segmentations\n",
      "T22\tTask 1081 1099\t3D surface fitting\n",
      "T23\tGeneric 1137 1145\tapproach\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R5\tCOREF Arg1:T10 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R7\tCOREF Arg1:T13 Arg2:T12\n",
      "R8\tCOREF Arg1:T14 Arg2:T13\n",
      "R9\tCOREF Arg1:T16 Arg2:T9\n",
      "R10\tCOREF Arg1:T23 Arg2:T16\n",
      "R11\tHYPONYM-OF Arg1:T21 Arg2:T20\n",
      "R12\tHYPONYM-OF Arg1:T22 Arg2:T20\n",
      "R13\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "R14\tEVALUATE-FOR Arg1:T20 Arg2:T23\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2010_21_abs.ann\n",
      "T1\tMethod 0 31\tConditional Random Field models\n",
      "T2\tTask 66 100\tlow-level computer vision problems\n",
      "T3\tTask 102 111\tInference\n",
      "T4\tGeneric 121 127\tmodels\n",
      "T5\tTask 147 181\tcombinatorial optimization problem\n",
      "T6\tGeneric 188 195\tmethods\n",
      "T7\tMethod 204 214\tgraph cuts\n",
      "T8\tMethod 216 234\tbelief propagation\n",
      "T9\tOtherScientificTerm 293 309\tmodel parameters\n",
      "T10\tGeneric 381 391\tparameters\n",
      "T11\tOtherScientificTerm 415 433\tpartition function\n",
      "T12\tMethod 492 519\tstructured learning methods\n",
      "T13\tGeneric 530 537\tproblem\n",
      "T14\tTask 548 571\tlarge margin estimation\n",
      "T15\tMethod 573 592\tIterative solutions\n",
      "T16\tTask 635 662\tconvex optimization problem\n",
      "T17\tTask 699 716\tinference problem\n",
      "T18\tGeneric 776 794\tstructured methods\n",
      "T19\tMethod 834 873\tlarge margin piece-wise learning method\n",
      "T20\tTask 928 948\toptimization problem\n",
      "T21\tTask 981 995\tconvex problem\n",
      "T22\tGeneric 1077 1083\tmethod\n",
      "R1\tCOREF Arg1:T1 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tPART-OF Arg1:T5 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R5\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R8\tCOREF Arg1:T10 Arg2:T9\n",
      "R9\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R11\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R12\tCOREF Arg1:T16 Arg2:T5\n",
      "R13\tCOREF Arg1:T12 Arg2:T18\n",
      "R14\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R15\tCOREF Arg1:T19 Arg2:T22\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2010_30_abs.ann\n",
      "T1\tGeneric 15 21\tmethod\n",
      "T2\tTask 40 79\tevaluation of object detection cascades\n",
      "T3\tMethod 99 127\tdivide-and-conquer procedure\n",
      "T4\tMethod 135 161\tspace of candidate regions\n",
      "T5\tMethod 179 199\texhaustive procedure\n",
      "T6\tTask 242 260\tcascade evaluation\n",
      "T7\tGeneric 275 281\tmethod\n",
      "T8\tOtherScientificTerm 316 336\tclassifier functions\n",
      "T9\tTask 362 368\tsearch\n",
      "T10\tMethod 428 460\tsubwindow search (ESS) procedure\n",
      "T11\tGeneric 511 517\tmethod\n",
      "T12\tGeneric 545 551\tmethod\n",
      "T13\tTask 594 612\tcascade evaluation\n",
      "T14\tTask 654 687\tbranch-and-bound object detection\n",
      "T15\tOtherScientificTerm 693 720\tnonlinear quality functions\n",
      "T16\tMethod 736 771\tkernel-ized support vector machines\n",
      "T17\tMaterial 792 815\tPASCAL VOC 2006 dataset\n",
      "T18\tGeneric 861 867\tmethod\n",
      "T19\tMethod 889 907\tcascade evaluation\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tCOREF Arg1:T2 Arg2:T6\n",
      "R5\tCOREF Arg1:T7 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R7\tCOMPARE Arg1:T5 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R9\tCOREF Arg1:T11 Arg2:T7\n",
      "R10\tPART-OF Arg1:T10 Arg2:T11\n",
      "R11\tCOREF Arg1:T12 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R13\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R14\tCOREF Arg1:T18 Arg2:T12\n",
      "R15\tEVALUATE-FOR Arg1:T17 Arg2:T18\n",
      "R16\tEVALUATE-FOR Arg1:T17 Arg2:T19\n",
      "R17\tCOMPARE Arg1:T19 Arg2:T18\n",
      "R18\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R19\tHYPONYM-OF Arg1:T16 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2011_10_abs.ann\n",
      "T1\tOtherScientificTerm 0 11\tReflections\n",
      "T2\tOtherScientificTerm 0 30\tReflections in image sequences\n",
      "T3\tMaterial 15 30\timage sequences\n",
      "T4\tMethod 115 142\timage processing techniques\n",
      "T5\tTask 224 241\tmotion estimation\n",
      "T6\tTask 246 264\tobject recognition\n",
      "T7\tGeneric 298 307\ttechnique\n",
      "T8\tTask 312 352\tdetecting reflections in image sequences\n",
      "T9\tOtherScientificTerm 366 385\tmotion trajectories\n",
      "T10\tOtherScientificTerm 389 403\tfeature points\n",
      "T11\tGeneric 405 407\tIt\n",
      "T12\tOtherScientificTerm 415 425\treflection\n",
      "T13\tGeneric 513 521\tdetector\n",
      "T14\tGeneric 555 564\tdetectors\n",
      "T15\tOtherScientificTerm 579 585\tpriors\n",
      "T16\tOtherScientificTerm 596 627\tsparse and dense detection maps\n",
      "T17\tMetric 654 668\tdetection rate\n",
      "T18\tOtherScientificTerm 687 706\tpathological motion\n",
      "T19\tOtherScientificTerm 711 720\tocclusion\n",
      "R1\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T9 Arg2:T7\n",
      "R3\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "R4\tCOREF Arg1:T11 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R6\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R7\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R8\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R9\tCOREF Arg1:T11 Arg2:T13\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2011_11_abs.ann\n",
      "T1\tGeneric 19 27\tapproach\n",
      "T2\tOtherScientificTerm 65 76\tPTZ cameras\n",
      "T3\tTask 105 155\tcamera handoff in wide-area surveillance scenarios\n",
      "T4\tGeneric 172 182\tapproaches\n",
      "T5\tOtherScientificTerm 193 248\tgeometric, appearance, or correlation-based information\n",
      "T6\tOtherScientificTerm 290 304\tstatic cameras\n",
      "T7\tOtherScientificTerm 370 388\twide-area settings\n",
      "T8\tOtherScientificTerm 394 405\tPTZ cameras\n",
      "T9\tGeneric 414 422\tapproach\n",
      "T10\tOtherScientificTerm 428 440\tslave camera\n",
      "T11\tGeneric 631 641\tapproaches\n",
      "T12\tOtherScientificTerm 679 693\tmodel transfer\n",
      "T13\tMethod 738 782\tMultiple Instance Learning (MIL) formulation\n",
      "T14\tOtherScientificTerm 812 873\tlogistic softmax function of covariance-based region features\n",
      "T15\tMethod 883 907\tMAP estimation framework\n",
      "T16\tGeneric 928 936\tapproach\n",
      "T17\tOtherScientificTerm 942 971\tmultiple PTZ camera sequences\n",
      "T18\tOtherScientificTerm 983 1012\toutdoor surveillance settings\n",
      "T19\tGeneric 1040 1067\tstate-of-the-art approaches\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tCOREF Arg1:T1 Arg2:T9\n",
      "R4\tCOMPARE Arg1:T16 Arg2:T19\n",
      "R5\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R6\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R7\tCOREF Arg1:T9 Arg2:T16\n",
      "R8\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R9\tUSED-FOR Arg1:T16 Arg2:T18\n",
      "R10\tCOREF Arg1:T4 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2011_18_abs.ann\n",
      "T1\tGeneric 13 19\tmethod\n",
      "T2\tTask 39 123\trelative pose of two calibrated or uncalibrated non-overlapping surveillance cameras\n",
      "T3\tTask 193 222\tmissing point correspondences\n",
      "T4\tMethod 243 256\tSfM pipelines\n",
      "T5\tGeneric 289 297\tparadigm\n",
      "T6\tOtherScientificTerm 312 329\tnon-linear nature\n",
      "T7\tGeneric 337 344\tproblem\n",
      "T8\tGeneric 362 373\tassumptions\n",
      "T9\tOtherScientificTerm 380 402\tsurveillance scenarios\n",
      "T10\tOtherScientificTerm 467 481\tgravity vector\n",
      "T11\tGeneric 492 503\tassumptions\n",
      "T12\tGeneric 516 523\tproblem\n",
      "T13\tTask 529 557\tQuadratic Eigenvalue Problem\n",
      "T14\tOtherScientificTerm 594 613\tnonlinear monomials\n",
      "T15\tMethod 631 657\tquasi closed-form solution\n",
      "T16\tTask 701 718\tbundle adjustment\n",
      "T17\tMethod 750 770\tclosed form solution\n",
      "T18\tGeneric 796 803\tproblem\n",
      "T19\tTask 815 833\tvideo surveillance\n",
      "T20\tGeneric 905 913\tapproach\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R2\tCOREF Arg1:T5 Arg2:T4\n",
      "R3\tCOREF Arg1:T7 Arg2:T3\n",
      "R4\tFEATURE-OF Arg1:T6 Arg2:T7\n",
      "R5\tCOREF Arg1:T11 Arg2:T8\n",
      "R6\tCOREF Arg1:T12 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R11\tCOREF Arg1:T18 Arg2:T12\n",
      "R12\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R13\tFEATURE-OF Arg1:T19 Arg2:T18\n",
      "R14\tCOREF Arg1:T17 Arg2:T15\n",
      "R15\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R16\tCOREF Arg1:T20 Arg2:T1\n",
      "R17\tCOREF Arg1:T20 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2011_292_abs.ann\n",
      "T1\tMaterial 0 5\tVideo\n",
      "T2\tOtherScientificTerm 29 40\tvisual cues\n",
      "T3\tOtherScientificTerm 49 55\tmotion\n",
      "T4\tOtherScientificTerm 60 70\tappearance\n",
      "T5\tOtherScientificTerm 100 132\tlong-range temporal interactions\n",
      "T6\tGeneric 171 183\tinteractions\n",
      "T7\tMethod 212 251\tintermediate-level video representation\n",
      "T8\tTask 267 278\trecognition\n",
      "T9\tOtherScientificTerm 322 355\tspatio-temporal over-segmentation\n",
      "T10\tOtherScientificTerm 393 410\tobject boundaries\n",
      "T11\tMethod 559 603\tspatio-temporal video segmentation algorithm\n",
      "T12\tOtherScientificTerm 634 656\tlong-range motion cues\n",
      "T13\tOtherScientificTerm 704 728\tclusters of point tracks\n",
      "T14\tMethod 775 805\ttrack clustering cost function\n",
      "T15\tOtherScientificTerm 820 839\tocclusion reasoning\n",
      "T16\tOtherScientificTerm 856 882\tdepth ordering constraints\n",
      "T17\tOtherScientificTerm 895 912\tmotion similarity\n",
      "T18\tGeneric 956 964\tapproach\n",
      "T19\tMaterial 989 1021\tvideo sequences of office scenes\n",
      "T20\tMaterial 1042 1048\tmovies\n",
      "R1\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R3\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R4\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R5\tHYPONYM-OF Arg1:T4 Arg2:T2\n",
      "R6\tCOREF Arg1:T6 Arg2:T5\n",
      "R7\tPART-OF Arg1:T15 Arg2:T14\n",
      "R8\tPART-OF Arg1:T17 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R11\tEVALUATE-FOR Arg1:T19 Arg2:T18\n",
      "R12\tFEATURE-OF Arg1:T16 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2011_293_abs.ann\n",
      "T1\tTask 52 76\tobject recognition tasks\n",
      "T2\tMaterial 109 128\tuncontrolled images\n",
      "T3\tOtherScientificTerm 142 152\tilluminant\n",
      "T4\tGeneric 179 186\tmethods\n",
      "T5\tTask 191 206\tcolor constancy\n",
      "T6\tMethod 219 249\tsurface re-flectance estimates\n",
      "T7\tMaterial 260 279\tuncalibrated images\n",
      "T8\tOtherScientificTerm 327 343\tbackground scene\n",
      "T9\tTask 353 391\trecognition and retrieval applications\n",
      "T10\tTask 607 622\tcolor constancy\n",
      "T11\tTask 641 675\tmulti-view color constancy problem\n",
      "T12\tGeneric 691 697\tmethod\n",
      "T13\tTask 709 753\testimates of underlying surface re-flectance\n",
      "T14\tOtherScientificTerm 789 807\tsurface properties\n",
      "T15\tOtherScientificTerm 816 827\tilluminants\n",
      "T16\tGeneric 860 866\tmethod\n",
      "T17\tOtherScientificTerm 879 900\timage correspondences\n",
      "T18\tMethod 921 941\talignment techniques\n",
      "T19\tOtherScientificTerm 973 1003\tmatching local region features\n",
      "T20\tOtherScientificTerm 1027 1049\tmulti-view constraints\n",
      "T21\tTask 1076 1150\testimates of both scene illuminants and object color (surface reflectance)\n",
      "T22\tMethod 1170 1197\tbaseline single-view method\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R5\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R6\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R7\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R8\tCOMPARE Arg1:T22 Arg2:T20\n",
      "R9\tCOREF Arg1:T5 Arg2:T10\n",
      "R10\tCOREF Arg1:T16 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2011_300_abs.ann\n",
      "T1\tGeneric 14 23\talgorithm\n",
      "T2\tTask 28 70\tcalibrated camera relative pose estimation\n",
      "T3\tOtherScientificTerm 179 196\trelative rotation\n",
      "T4\tOtherScientificTerm 241 261\trelative translation\n",
      "T5\tGeneric 310 319\tframework\n",
      "T6\tGeneric 392 401\talgorithm\n",
      "T7\tMaterial 408 431\tsynthetic and real data\n",
      "T8\tGeneric 457 466\talgorithm\n",
      "T9\tMethod 482 513\thypothesize-and-test frameworks\n",
      "T10\tMethod 522 528\tRANSAC\n",
      "T11\tGeneric 534 542\tapproach\n",
      "T12\tOtherScientificTerm 559 588\turban and indoor environments\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T6 Arg2:T5\n",
      "R3\tCOREF Arg1:T5 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R5\tCOREF Arg1:T8 Arg2:T6\n",
      "R6\tHYPONYM-OF Arg1:T10 Arg2:T9\n",
      "R7\tCOREF Arg1:T11 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R9\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2011_303_abs.ann\n",
      "T1\tOtherScientificTerm 4 25\tco-occurrence pattern\n",
      "T2\tOtherScientificTerm 44 68\tbinary or local features\n",
      "T3\tTask 150 187\tobject, scene, and action recognition\n",
      "T4\tOtherScientificTerm 213 235\tco-occurrence patterns\n",
      "T5\tOtherScientificTerm 278 335\tconjunction (AND) and disjunction (OR) of binary features\n",
      "T6\tTask 364 413\tidentifying discriminative co-occurrence patterns\n",
      "T7\tOtherScientificTerm 376 413\tdiscriminative co-occurrence patterns\n",
      "T8\tMethod 459 477\tdata mining method\n",
      "T9\tOtherScientificTerm 506 535\toptimal co-occurrence pattern\n",
      "T10\tOtherScientificTerm 541 564\tminimum empirical error\n",
      "T11\tMaterial 578 600\tnoisy training dataset\n",
      "T12\tGeneric 607 623\tmining procedure\n",
      "T13\tOtherScientificTerm 627 646\tAND and OR patterns\n",
      "T14\tMethod 672 680\tboosting\n",
      "T15\tMetric 701 723\tgeneralization ability\n",
      "T16\tMethod 746 769\tboosting decision trees\n",
      "T17\tMethod 774 798\tboosting decision stumps\n",
      "T18\tTask 829 870\tobject, scene, and action cat-egorization\n",
      "T19\tOtherScientificTerm 913 951\tdis-criminative co-occurrence patterns\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R2\tCOREF Arg1:T4 Arg2:T1\n",
      "R3\tCOREF Arg1:T5 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T8\n",
      "R5\tCOREF Arg1:T13 Arg2:T5\n",
      "R6\tPART-OF Arg1:T13 Arg2:T14\n",
      "R7\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R8\tCOMPARE Arg1:T14 Arg2:T16\n",
      "R9\tCOMPARE Arg1:T14 Arg2:T17\n",
      "R10\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R11\tCOREF Arg1:T3 Arg2:T18\n",
      "R12\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "R13\tCOREF Arg1:T19 Arg2:T7\n",
      "R14\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R15\tEVALUATE-FOR Arg1:T15 Arg2:T17\n",
      "R16\tCOREF Arg1:T8 Arg2:T12\n",
      "R17\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R18\tPART-OF Arg1:T2 Arg2:T1\n",
      "R19\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R20\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2012_10_abs.ann\n",
      "T1\tTask 0 39\tAutomated facial expression recognition\n",
      "T2\tGeneric 100 114\tExisting works\n",
      "T3\tOtherScientificTerm 161 179\ttemporal evolution\n",
      "T4\tOtherScientificTerm 187 228\tintensity of the observed facial displays\n",
      "T5\tGeneric 230 234\tThey\n",
      "T6\tMaterial 262 325\tmultidimensional (multi-class) continuous facial behaviour data\n",
      "T7\tMethod 327 345\tbinary classifiers\n",
      "T8\tOtherScientificTerm 419 475\tintrinsic topology of multidimensional continuous facial\n",
      "T9\tOtherScientificTerm 511 528\tordinal man-ifold\n",
      "T10\tGeneric 535 543\ttopology\n",
      "T11\tMethod 574 632\tHidden Conditional Ordinal Random Field (H-CORF) framework\n",
      "T12\tTask 637 663\tdynamic ordinal regression\n",
      "T13\tOtherScientificTerm 680 697\tH-CORF parameters\n",
      "T14\tOtherScientificTerm 712 728\tordinal manifold\n",
      "T15\tGeneric 744 749\tmodel\n",
      "T16\tTask 758 790\tsimultaneous dynamic recognition\n",
      "T17\tTask 795 837\tintensity estimation of facial expressions\n",
      "T18\tMethod 890 909\tthe proposed method\n",
      "T19\tMaterial 973 1003\tspontaneous facial affect data\n",
      "R1\tCONJUNCTION Arg1:T4 Arg2:T3\n",
      "R2\tCOREF Arg1:T5 Arg2:T2\n",
      "R3\tCOREF Arg1:T18 Arg2:T15\n",
      "R4\tCOREF Arg1:T10 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R6\tPART-OF Arg1:T10 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T17\n",
      "R10\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R11\tEVALUATE-FOR Arg1:T19 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2012_11_abs.ann\n",
      "T1\tMethod 13 44\tunified variational formulation\n",
      "T2\tTask 49 89\tjoint motion estimation and segmentation\n",
      "T3\tMethod 95 122\texplicit occlusion handling\n",
      "T4\tMethod 142 186\tmulti-label representation of the flow field\n",
      "T5\tTask 222 261\tparametric representation of the motion\n",
      "T6\tMethod 272 290\tconvex formulation\n",
      "T7\tMethod 298 321\tmulti-label Potts model\n",
      "T8\tMetric 357 392\tasymmetric map-uniqueness criterion\n",
      "T9\tGeneric 420 431\tformulation\n",
      "T10\tOtherScientificTerm 444 462\tconvex constraints\n",
      "T11\tMethod 464 491\tExplicit occlusion handling\n",
      "T12\tOtherScientificTerm 535 549\tregularization\n",
      "T13\tOtherScientificTerm 554 564\tocclusions\n",
      "T14\tOtherScientificTerm 583 600\tobject boundaries\n",
      "T15\tMethod 661 682\tprimal-dual algorithm\n",
      "T16\tOtherScientificTerm 721 736\tmotion segments\n",
      "T17\tTask 767 796\tclassical motion segmentation\n",
      "T18\tTask 801 813\toptical flow\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T6 Arg2:T9\n",
      "R4\tPART-OF Arg1:T8 Arg2:T9\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R7\tCOREF Arg1:T3 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2012_18_abs.ann\n",
      "T1\tGeneric 19 28\ttechnique\n",
      "T2\tMethod 36 66\tbispectral photo-metric stereo\n",
      "T3\tOtherScientificTerm 95 107\tfluorescence\n",
      "T4\tTask 112 132\tshape reconstruction\n",
      "T5\tOtherScientificTerm 134 146\tFluorescence\n",
      "T6\tOtherScientificTerm 201 213\tnatural gems\n",
      "T7\tOtherScientificTerm 229 245\tfluorescent dyes\n",
      "T8\tOtherScientificTerm 304 316\tfluorescence\n",
      "T9\tOtherScientificTerm 354 375\tfluorescent materials\n",
      "T10\tMetric 466 476\tcomplexity\n",
      "T11\tMethod 484 500\temission process\n",
      "T12\tOtherScientificTerm 502 515\tfluo-rescence\n",
      "T13\tGeneric 547 557\talgorithms\n",
      "T14\tTask 561 576\tcomputer vision\n",
      "T15\tTask 581 597\timage processing\n",
      "T16\tOtherScientificTerm 645 655\tsimilarity\n",
      "T17\tOtherScientificTerm 664 676\tfluorescence\n",
      "T18\tOtherScientificTerm 687 705\tdiffuse reflection\n",
      "T19\tOtherScientificTerm 715 727\tfluorescence\n",
      "T20\tOtherScientificTerm 804 847\tfluorescence's wavelength-shifting property\n",
      "T21\tOtherScientificTerm 875 880\tshape\n",
      "T22\tMethod 906 925\tphotomet-ric stereo\n",
      "T23\tMaterial 929 949\temission-only images\n",
      "T24\tOtherScientificTerm 973 992\tspecular reflection\n",
      "T25\tMethod 1035 1060\tfluorescence-based method\n",
      "T26\tGeneric 1075 1082\tmethods\n",
      "T27\tOtherScientificTerm 1092 1102\treflection\n",
      "R1\tCOREF Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "R4\tEVALUATE-FOR Arg1:T10 Arg2:T11\n",
      "R5\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R8\tCOREF Arg1:T22 Arg2:T2\n",
      "R9\tUSED-FOR Arg1:T23 Arg2:T22\n",
      "R10\tCOMPARE Arg1:T26 Arg2:T25\n",
      "R11\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R12\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2013_10_abs.ann\n",
      "T1\tGeneric 19 28\talgorithm\n",
      "T2\tTask 54 100\t3D geometric structure of outdoor video scenes\n",
      "T3\tMethod 113 147\tspatio-temporal video segmentation\n",
      "T4\tOtherScientificTerm 164 177\tdynamic scene\n",
      "T5\tOtherScientificTerm 203 220\tgeometric classes\n",
      "T6\tMethod 251 269\tregion-classifiers\n",
      "T7\tOtherScientificTerm 290 320\tappearance and motion features\n",
      "T8\tOtherScientificTerm 409 438\tsegmentation hierarchy levels\n",
      "T9\tOtherScientificTerm 477 497\tgranularity a priori\n",
      "T10\tGeneric 527 534\tdataset\n",
      "T11\tOtherScientificTerm 538 564\tgeometric context of video\n",
      "T12\tGeneric 581 587\tmethod\n",
      "T13\tOtherScientificTerm 625 649\tannotated outdoor videos\n",
      "T14\tGeneric 704 711\tdataset\n",
      "T15\tMethod 726 760\tsemi-supervised learning framework\n",
      "T16\tMaterial 783 795\tlabeled data\n",
      "T17\tOtherScientificTerm 801 828\thigh confidence predictions\n",
      "T18\tOtherScientificTerm 843 857\tunlabeled data\n",
      "T19\tGeneric 863 869\tsystem\n",
      "T20\tOtherScientificTerm 905 931\tgeometric context of video\n",
      "T21\tMetric 946 954\taccuracy\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tPART-OF Arg1:T13 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R7\tEVALUATE-FOR Arg1:T10 Arg2:T12\n",
      "R8\tCOREF Arg1:T12 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R10\tUSED-FOR Arg1:T17 Arg2:T15\n",
      "R11\tEVALUATE-FOR Arg1:T21 Arg2:T19\n",
      "R12\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R13\tPART-OF Arg1:T5 Arg2:T4\n",
      "R14\tCOREF Arg1:T12 Arg2:T19\n",
      "R15\tFEATURE-OF Arg1:T11 Arg2:T10\n",
      "R16\tCOREF Arg1:T10 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2014_10_abs.ann\n",
      "T1\tMethod 14 48\timage set classification algorithm\n",
      "T2\tMethod 58 81\tunsupervised clustering\n",
      "T3\tMaterial 85 126\tlabeled training and unla-beled test data\n",
      "T4\tOtherScientificTerm 161 179\tstopping criterion\n",
      "T5\tOtherScientificTerm 185 209\tprobability distribution\n",
      "T6\tOtherScientificTerm 240 248\tclusters\n",
      "T7\tMetric 274 302\tset based similarity measure\n",
      "T8\tMethod 331 377\titerative sparse spectral clustering algorithm\n",
      "T9\tOtherScientificTerm 400 416\tproximity matrix\n",
      "T10\tOtherScientificTerm 467 491\tlocal subspace structure\n",
      "T11\tOtherScientificTerm 493 509\tInitial clusters\n",
      "T12\tOtherScientificTerm 522 543\tglobal data structure\n",
      "T13\tOtherScientificTerm 548 562\tfiner clusters\n",
      "T14\tOtherScientificTerm 595 619\tsubtle class differences\n",
      "T15\tOtherScientificTerm 639 651\tglobal scale\n",
      "T16\tMaterial 653 663\tImage sets\n",
      "T17\tMethod 704 727\tGrass-mannian manifolds\n",
      "T18\tOtherScientificTerm 763 778\tEuclidean space\n",
      "T19\tMethod 797 826\tspectral clustering algorithm\n",
      "T20\tMethod 857 875\teigenvector solver\n",
      "T21\tMetric 903 921\tcomputational cost\n",
      "T22\tMethod 925 944\tspectral clustering\n",
      "T23\tMetric 981 999\tclustering quality\n",
      "T24\tMetric 1010 1032\tclassification results\n",
      "T25\tMaterial 1063 1071\tdatasets\n",
      "T26\tGeneric 1143 1152\talgorithm\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R4\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R5\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R6\tUSED-FOR Arg1:T19 Arg2:T18\n",
      "R7\tEVALUATE-FOR Arg1:T21 Arg2:T22\n",
      "R8\tEVALUATE-FOR Arg1:T23 Arg2:T22\n",
      "R9\tUSED-FOR Arg1:T20 Arg2:T22\n",
      "R10\tCOREF Arg1:T26 Arg2:T1\n",
      "R11\tCOREF Arg1:T19 Arg2:T8\n",
      "R12\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R13\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R14\tEVALUATE-FOR Arg1:T24 Arg2:T22\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2014_11_abs.ann\n",
      "T1\tTask 38 58\tpoint cloud matching\n",
      "T2\tTask 64 86\tshape matching problem\n",
      "T3\tOtherScientificTerm 121 133\tpoint clouds\n",
      "T4\tMethod 141 161\tshape representation\n",
      "T5\tMethod 173 224\tSchrÃ¶dinger distance transform (SDT) representation\n",
      "T6\tOtherScientificTerm 256 283\tstatic SchrÃ¶dinger equation\n",
      "T7\tOtherScientificTerm 313 344\tstatic Hamilton-Jacobi equation\n",
      "T8\tMethod 366 384\tSDT representation\n",
      "T9\tOtherScientificTerm 391 410\tanalytic expression\n",
      "T10\tOtherScientificTerm 429 459\ttheoretical physics literature\n",
      "T11\tOtherScientificTerm 487 499\tunit L2 norm\n",
      "T12\tGeneric 507 509\tit\n",
      "T13\tOtherScientificTerm 512 531\tsquare-root density\n",
      "T14\tOtherScientificTerm 571 590\tunit Hilbert sphere\n",
      "T15\tOtherScientificTerm 598 616\tintrinsic geometry\n",
      "T16\tMetric 637 654\tFisher-Rao metric\n",
      "T17\tGeneric 658 672\tnatural metric\n",
      "T18\tOtherScientificTerm 681 699\tspace of densities\n",
      "T19\tOtherScientificTerm 709 729\tanalytic expressions\n",
      "T20\tOtherScientificTerm 738 755\tgeodesic distance\n",
      "T21\tGeneric 779 785\tsphere\n",
      "T22\tMethod 824 844\tRiemannian framework\n",
      "T23\tTask 867 887\tpoint cloud matching\n",
      "T24\tMethod 909 927\tmatching algorithm\n",
      "T25\tTask 937 955\tpoint set matching\n",
      "T26\tOtherScientificTerm 962 997\trigid and non-rigid transformations\n",
      "T27\tGeneric 1006 1015\tframework\n",
      "T28\tGeneric 1034 1049\ttransformations\n",
      "T29\tMethod 1065 1098\tnonlinear optimization techniques\n",
      "T30\tMethod 1144 1153\talgorithm\n",
      "T31\tMethod 1154 1165\tdubbed SDTM\n",
      "T32\tMaterial 1185 1217\tsynthetic and real data examples\n",
      "T33\tGeneric 1254 1281\tstate-of-the-art techniques\n",
      "T34\tGeneric 1313 1322\talgorithm\n",
      "T35\tMethod 1352 1385\tpoint set registration algorithms\n",
      "T36\tMetric 1394 1414\tquantitative metrics\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tHYPONYM-OF Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R4\tCOREF Arg1:T8 Arg2:T5\n",
      "R5\tHYPONYM-OF Arg1:T8 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R7\tCOREF Arg1:T14 Arg2:T21\n",
      "R8\tCOREF Arg1:T1 Arg2:T23\n",
      "R9\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R10\tCOREF Arg1:T22 Arg2:T27\n",
      "R11\tCOREF Arg1:T26 Arg2:T28\n",
      "R12\tUSED-FOR Arg1:T29 Arg2:T28\n",
      "R13\tUSED-FOR Arg1:T26 Arg2:T25\n",
      "R14\tUSED-FOR Arg1:T27 Arg2:T25\n",
      "R15\tCOREF Arg1:T31 Arg2:T30\n",
      "R16\tCOMPARE Arg1:T30 Arg2:T33\n",
      "R17\tEVALUATE-FOR Arg1:T36 Arg2:T35\n",
      "R18\tCOREF Arg1:T8 Arg2:T12\n",
      "R19\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R20\tPART-OF Arg1:T11 Arg2:T8\n",
      "R21\tCOREF Arg1:T16 Arg2:T17\n",
      "R22\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R23\tCOMPARE Arg1:T34 Arg2:T35\n",
      "R24\tCOREF Arg1:T34 Arg2:T30\n",
      "R25\tEVALUATE-FOR Arg1:T36 Arg2:T34\n",
      "R26\tFEATURE-OF Arg1:T15 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2014_18_abs.ann\n",
      "T1\tMaterial 37 71\tobject category detection datasets\n",
      "T2\tTask 84 113\tper-object 3D reconstructions\n",
      "T3\tMethod 148 188\tground truth figure-ground segmentations\n",
      "T4\tMethod 208 228\tkeypoint annotations\n",
      "T5\tGeneric 243 252\talgorithm\n",
      "T6\tOtherScientificTerm 269 285\tcamera viewpoint\n",
      "T7\tOtherScientificTerm 292 319\trigid structure-from-motion\n",
      "T8\tOtherScientificTerm 339 352\tobject shapes\n",
      "T9\tOtherScientificTerm 372 393\tvisual hull proposals\n",
      "T10\tOtherScientificTerm 404 451\tloose within-class shape similarity assumptions\n",
      "T11\tMethod 457 485\tvisual hull sampling process\n",
      "T12\tOtherScientificTerm 520 535\tprojection cone\n",
      "T13\tGeneric 662 668\tmethod\n",
      "T14\tTask 699 728\tper-object 3D reconstructions\n",
      "T15\tMaterial 769 803\tobject-category detection datasets\n",
      "T16\tMaterial 805 815\tPASCAL VOC\n",
      "T17\tMethod 859 911\tgeometry-oriented model-based recognition approaches\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R8\tHYPONYM-OF Arg1:T16 Arg2:T15\n",
      "R9\tCOREF Arg1:T13 Arg2:T5\n",
      "R10\tCOREF Arg1:T2 Arg2:T14\n",
      "R11\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R12\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R13\tUSED-FOR Arg1:T4 Arg2:T2\n",
      "R14\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R15\tCOREF Arg1:T15 Arg2:T1\n",
      "R16\tCOREF Arg1:T11 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2014_21_abs.ann\n",
      "T1\tGeneric 33 52\tautonomous pipeline\n",
      "T2\tMethod 64 114\tpersonalized parametric model (pose-driven avatar)\n",
      "T3\tOtherScientificTerm 123 142\tsingle depth sensor\n",
      "T4\tGeneric 148 154\tmethod\n",
      "T5\tMethod 298 325\ttemplate fitting techniques\n",
      "T6\tOtherScientificTerm 341 355\thuman template\n",
      "T7\tOtherScientificTerm 400 430\tglobal consistency constraints\n",
      "T8\tMethod 458 475\twatertight models\n",
      "T9\tMethod 517 533\tparametric model\n",
      "T10\tMethod 562 574\tSCAPE method\n",
      "T11\tMethod 585 601\tparametric model\n",
      "T12\tGeneric 612 614\tit\n",
      "T13\tOtherScientificTerm 633 651\tanim-itable avatar\n",
      "T14\tMethod 687 704\tdynamic 3D models\n",
      "T15\tMaterial 710 734\tsingle-view depth videos\n",
      "T16\tGeneric 794 800\tsystem\n",
      "T17\tMethod 812 826\tdynamic models\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T4 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R7\tCOREF Arg1:T9 Arg2:T11\n",
      "R8\tCOREF Arg1:T11 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R11\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R13\tCOREF Arg1:T4 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2015_300_abs.ann\n",
      "T1\tTask 26 57\testimating location information\n",
      "T2\tMaterial 64 69\timage\n",
      "T3\tMethod 92 125\tautomated representation learning\n",
      "T4\tMethod 139 174\thierarchical sparse coding approach\n",
      "T5\tOtherScientificTerm 187 195\tfeatures\n",
      "T6\tGeneric 262 264\tit\n",
      "T7\tOtherScientificTerm 272 287\tgeometric prior\n",
      "T8\tOtherScientificTerm 329 351\timage appearance space\n",
      "T9\tOtherScientificTerm 376 399\tlocation grouping space\n",
      "T10\tOtherScientificTerm 420 451\tparallel transport on manifolds\n",
      "T11\tGeneric 473 481\tapproach\n",
      "T12\tOtherScientificTerm 517 546\theterogeneous data modalities\n",
      "T13\tOtherScientificTerm 555 563\tgeo-tags\n",
      "T14\tOtherScientificTerm 568 574\tvideos\n",
      "T15\tTask 665 687\ttransferring knowledge\n",
      "T16\tTask 734 750\tgrouping of data\n",
      "T17\tMethod 789 797\tapproach\n",
      "T18\tGeneric 818 826\tdatasets\n",
      "T19\tMaterial 835 841\tim2gps\n",
      "T20\tMaterial 843 856\tSan Francisco\n",
      "T21\tMaterial 861 874\tMediaEval2010\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T6 Arg2:T4\n",
      "R4\tCOREF Arg1:T11 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R7\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R8\tHYPONYM-OF Arg1:T13 Arg2:T12\n",
      "R9\tHYPONYM-OF Arg1:T14 Arg2:T12\n",
      "R10\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R12\tCOREF Arg1:T17 Arg2:T11\n",
      "R13\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R14\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R15\tHYPONYM-OF Arg1:T19 Arg2:T18\n",
      "R16\tHYPONYM-OF Arg1:T20 Arg2:T18\n",
      "R17\tHYPONYM-OF Arg1:T21 Arg2:T18\n",
      "R18\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2015_303_abs.ann\n",
      "T1\tOtherScientificTerm 38 62\tgeneric action proposals\n",
      "T2\tMaterial 66 86\tunconstrained videos\n",
      "T3\tOtherScientificTerm 93 108\taction proposal\n",
      "T4\tOtherScientificTerm 126 167\ttemporal series of spatial bounding boxes\n",
      "T5\tOtherScientificTerm 177 203\tspatio-temporal video tube\n",
      "T6\tOtherScientificTerm 246 258\thuman action\n",
      "T7\tOtherScientificTerm 334 360\tappearance and motion cues\n",
      "T8\tMetric 389 400\tac-tionness\n",
      "T9\tMaterial 408 419\tvideo tubes\n",
      "T10\tMetric 471 488\tactionness scores\n",
      "T11\tTask 494 520\taction proposal generation\n",
      "T12\tTask 540 568\tmaximum set coverage problem\n",
      "T13\tMethod 577 590\tgreedy search\n",
      "T14\tOtherScientificTerm 623 639\taction proposals\n",
      "T15\tMetric 670 686\tactionness score\n",
      "T16\tMethod 711 737\taction proposal approaches\n",
      "T17\tOtherScientificTerm 743 759\taction proposals\n",
      "T18\tMethod 775 793\tvideo segmentation\n",
      "T19\tGeneric 876 884\tdatasets\n",
      "T20\tMaterial 886 891\tMSRII\n",
      "T21\tMaterial 896 903\tUCF 101\n",
      "T22\tOtherScientificTerm 946 962\taction proposals\n",
      "T23\tTask 997 1024\taction detection and search\n",
      "R1\tHYPONYM-OF Arg1:T5 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tEVALUATE-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R7\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R8\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R9\tHYPONYM-OF Arg1:T20 Arg2:T19\n",
      "R10\tHYPONYM-OF Arg1:T21 Arg2:T19\n",
      "R11\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R12\tEVALUATE-FOR Arg1:T19 Arg2:T22\n",
      "R13\tEVALUATE-FOR Arg1:T23 Arg2:T22\n",
      "R14\tCOREF Arg1:T22 Arg2:T17\n",
      "R15\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2016_15_abs.ann\n",
      "T1\tGeneric 22 28\tmethod\n",
      "T2\tOtherScientificTerm 42 78\tjoint embed-dings of images and text\n",
      "T3\tMethod 87 112\ttwo-branch neural network\n",
      "T4\tOtherScientificTerm 118 155\tmultiple layers of linear projections\n",
      "T5\tOtherScientificTerm 168 182\tnonlinearities\n",
      "T6\tGeneric 188 195\tnetwork\n",
      "T7\tOtherScientificTerm 215 237\tlarge-margin objective\n",
      "T8\tOtherScientificTerm 252 282\tcross-view ranking constraints\n",
      "T9\tOtherScientificTerm 288 347\twithin-view neighborhood structure preservation constraints\n",
      "T10\tOtherScientificTerm 360 386\tmetric learning literature\n",
      "T11\tGeneric 424 432\tapproach\n",
      "T12\tMetric 467 475\taccuracy\n",
      "T13\tTask 480 521\timage-to-text and text-to-image retrieval\n",
      "T14\tGeneric 527 533\tmethod\n",
      "T15\tMaterial 579 623\tFlickr30K and MSCOCO image-sentence datasets\n",
      "T16\tTask 661 681\tphrase lo-calization\n",
      "T17\tMaterial 689 715\tFlickr30K Entities dataset\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tPART-OF Arg1:T4 Arg2:T3\n",
      "R4\tPART-OF Arg1:T5 Arg2:T3\n",
      "R5\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R6\tCOREF Arg1:T6 Arg2:T3\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R8\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R9\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "R10\tFEATURE-OF Arg1:T9 Arg2:T7\n",
      "R11\tCOREF Arg1:T1 Arg2:T11\n",
      "R12\tEVALUATE-FOR Arg1:T12 Arg2:T11\n",
      "R13\tEVALUATE-FOR Arg1:T13 Arg2:T11\n",
      "R14\tCOREF Arg1:T14 Arg2:T11\n",
      "R15\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R16\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R17\tEVALUATE-FOR Arg1:T16 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2016_405_abs.ann\n",
      "T1\tMaterial 30 43\tanimated GIFs\n",
      "T2\tMaterial 47 59\tsocial media\n",
      "T3\tMaterial 103 117\trich meta-data\n",
      "T4\tTask 142 168\tanimated GIF understanding\n",
      "T5\tGeneric 189 196\tdataset\n",
      "T6\tMaterial 198 215\tTumblr GIF (TGIF)\n",
      "T7\tMaterial 227 240\tanimated GIFs\n",
      "T8\tMaterial 262 291\tnatural language descriptions\n",
      "T9\tMethod 305 318\tcrowdsourcing\n",
      "T10\tTask 377 411\timage sequence description systems\n",
      "T11\tMaterial 443 472\tnatural language descriptions\n",
      "T12\tMaterial 477 490\tanimated GIFs\n",
      "T13\tMaterial 494 505\tvideo clips\n",
      "T14\tMethod 572 588\tquality controls\n",
      "T15\tMaterial 601 621\tfree-form text input\n",
      "T16\tMaterial 696 710\tvisual content\n",
      "T17\tMaterial 715 744\tnatural language descriptions\n",
      "T18\tGeneric 752 759\tdataset\n",
      "T19\tGeneric 768 770\tit\n",
      "T20\tTask 798 828\tvisual content captioning task\n",
      "T21\tOtherScientificTerm 851 871\tstatistical analyses\n",
      "T22\tGeneric 887 894\tdataset\n",
      "T23\tMaterial 907 943\timage and video description datasets\n",
      "T24\tTask 986 1015\tanimated GIF description task\n",
      "T25\tGeneric 1029 1054\trepresentative techniques\n",
      "T26\tMethod 1056 1072\tnearest neighbor\n",
      "T27\tMethod 1074 1105\tstatistical machine translation\n",
      "T28\tMethod 1112 1137\trecurrent neural networks\n",
      "T29\tMaterial 1188 1220\tanimated GIF description dataset\n",
      "T30\tTask 1240 1267\tautomatic movie description\n",
      "R1\tCOREF Arg1:T6 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R4\tPART-OF Arg1:T17 Arg2:T18\n",
      "R5\tPART-OF Arg1:T16 Arg2:T18\n",
      "R6\tCOREF Arg1:T18 Arg2:T5\n",
      "R7\tCOREF Arg1:T22 Arg2:T18\n",
      "R8\tCOREF Arg1:T29 Arg2:T22\n",
      "R9\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R10\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R11\tCONJUNCTION Arg1:T8 Arg2:T7\n",
      "R12\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R13\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R14\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R15\tCOREF Arg1:T18 Arg2:T19\n",
      "R16\tEVALUATE-FOR Arg1:T19 Arg2:T20\n",
      "R17\tCOMPARE Arg1:T22 Arg2:T23\n",
      "R18\tCONJUNCTION Arg1:T26 Arg2:T27\n",
      "R19\tCONJUNCTION Arg1:T27 Arg2:T28\n",
      "R20\tHYPONYM-OF Arg1:T26 Arg2:T25\n",
      "R21\tHYPONYM-OF Arg1:T27 Arg2:T25\n",
      "R22\tHYPONYM-OF Arg1:T28 Arg2:T25\n",
      "R23\tUSED-FOR Arg1:T25 Arg2:T24\n",
      "R24\tUSED-FOR Arg1:T29 Arg2:T30\n",
      "R25\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2016_406_abs.ann\n",
      "T1\tTask 0 14\tImage matching\n",
      "T2\tTask 43 58\tComputer Vision\n",
      "T3\tTask 78 100\tfeature-based matching\n",
      "T4\tMethod 102 106\tSIFT\n",
      "T5\tOtherScientificTerm 189 209\tultra-wide baselines\n",
      "T6\tMaterial 229 242\taerial images\n",
      "T7\tOtherScientificTerm 258 280\tlarge camera rotations\n",
      "T8\tOtherScientificTerm 286 306\tappearance variation\n",
      "T9\tMethod 332 336\tSIFT\n",
      "T10\tMethod 341 347\tRANSAC\n",
      "T11\tMethod 376 417\tdata-driven, deep learning-based approach\n",
      "T12\tOtherScientificTerm 433 453\tlocal correspondence\n",
      "T13\tGeneric 469 476\tproblem\n",
      "T14\tTask 482 501\tclassification task\n",
      "T15\tOtherScientificTerm 537 558\tlocal correspondences\n",
      "T16\tMethod 607 626\tattention mechanism\n",
      "T17\tGeneric 727 733\tmodels\n",
      "T18\tMaterial 739 770\tdataset of urban aerial imagery\n",
      "T19\tGeneric 864 871\tproblem\n",
      "T20\tMethod 878 889\thuman study\n",
      "T21\tMaterial 895 934\tannotations from Amazon Mechanical Turk\n",
      "T22\tGeneric 960 966\tmodels\n",
      "T23\tGeneric 982 998\tstate-of-the-art\n",
      "T24\tTask 1002 1030\tultra-wide baseline matching\n",
      "T25\tMetric 1044 1058\thuman accuracy\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R3\tCOREF Arg1:T22 Arg2:T17\n",
      "R4\tCOMPARE Arg1:T22 Arg2:T25\n",
      "R5\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R6\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R7\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R9\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R10\tCOREF Arg1:T4 Arg2:T9\n",
      "R11\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R12\tCOMPARE Arg1:T22 Arg2:T23\n",
      "R13\tEVALUATE-FOR Arg1:T24 Arg2:T23\n",
      "R14\tEVALUATE-FOR Arg1:T24 Arg2:T22\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2016_413_abs.ann\n",
      "T1\tMethod 0 27\tLearned confidence measures\n",
      "T2\tTask 59 74\toutlier removal\n",
      "T3\tTask 79 98\tquality improvement\n",
      "T4\tTask 102 115\tstereo vision\n",
      "T5\tGeneric 206 210\ttask\n",
      "T6\tOtherScientificTerm 225 243\tmanual interaction\n",
      "T7\tOtherScientificTerm 245 267\tactive sensing devices\n",
      "T8\tOtherScientificTerm 275 291\tsynthetic scenes\n",
      "T9\tGeneric 310 317\tproblem\n",
      "T10\tMaterial 422 435\tstereo images\n",
      "T11\tGeneric 466 474\tapproach\n",
      "T12\tOtherScientificTerm 495 506\tview points\n",
      "T13\tOtherScientificTerm 568 587\tmultiple depth maps\n",
      "T14\tMethod 612 628\tstereo algorithm\n",
      "T15\tGeneric 779 787\tapproach\n",
      "T16\tMethod 825 852\tlearned confidence measures\n",
      "T17\tMaterial 860 877\tKITTI2012 dataset\n",
      "T18\tGeneric 897 901\tthem\n",
      "T19\tMaterial 922 959\tautomatically generated training data\n",
      "T20\tMaterial 992 1015\tlaser ground truth data\n",
      "R1\tPART-OF Arg1:T3 Arg2:T4\n",
      "R2\tPART-OF Arg1:T2 Arg2:T4\n",
      "R3\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R6\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R7\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R9\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T5\n",
      "R11\tCOREF Arg1:T9 Arg2:T5\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R13\tCOREF Arg1:T14 Arg2:T11\n",
      "R14\tCOREF Arg1:T15 Arg2:T11\n",
      "R15\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R16\tEVALUATE-FOR Arg1:T17 Arg2:T16\n",
      "R17\tCOMPARE Arg1:T20 Arg2:T19\n",
      "R18\tCOREF Arg1:T18 Arg2:T16\n",
      "R19\tUSED-FOR Arg1:T19 Arg2:T18\n",
      "R20\tCOREF Arg1:T16 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2016_416_abs.ann\n",
      "T1\tTask 30 78\tfine-grained sketch-based image retrieval (SBIR)\n",
      "T2\tOtherScientificTerm 86 110\tfree-hand human sketches\n",
      "T3\tTask 142 176\tinstance-level retrieval of images\n",
      "T4\tOtherScientificTerm 228 246\tvisual comparisons\n",
      "T5\tOtherScientificTerm 317 344\tfree-hand (finger) sketches\n",
      "T6\tTask 373 394\tfine-grained matching\n",
      "T7\tMaterial 430 474\tannotated cross-domain sketch-photo datasets\n",
      "T8\tMethod 543 570\tmachine learning techniques\n",
      "T9\tTask 715 755\tsketch-based image retrieval application\n",
      "T10\tOtherScientificTerm 845 885\tfine-grained triplet ranking annotations\n",
      "T11\tMethod 905 931\tdeep triplet-ranking model\n",
      "T12\tTask 936 955\tinstance-level SBIR\n",
      "T13\tMethod 969 986\tdata augmentation\n",
      "T14\tMethod 991 1019\tstaged pre-training strategy\n",
      "T15\tMaterial 1046 1085\tinsufficient fine-grained training data\n",
      "T16\tOtherScientificTerm 1184 1200\tdata sufficiency\n",
      "T17\tOtherScientificTerm 1205 1227\tover-fitting avoidance\n",
      "T18\tMethod 1242 1255\tdeep networks\n",
      "T19\tTask 1260 1299\tfine-grained cross-domain ranking tasks\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R4\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R5\tUSED-FOR Arg1:T13 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T14 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T15\n",
      "R8\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R9\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E06-1004.ann\n",
      "T1\tTask 84 121\tStatistical Machine Translation (SMT)\n",
      "T2\tMethod 242 256\tSMT algorithms\n",
      "T3\tMetric 332 356\tcomputational complexity\n",
      "T4\tGeneric 385 393\tproblems\n",
      "T5\tTask 398 401\tSMT\n",
      "T6\tMetric 462 486\tcomputational complexity\n",
      "T7\tGeneric 497 505\tproblems\n",
      "T8\tMethod 528 542\tIBM Models 1-2\n",
      "T9\tGeneric 589 601\tcomputations\n",
      "T10\tGeneric 642 648\tmodels\n",
      "T11\tMethod 705 729\tpolynomial time solution\n",
      "T12\tGeneric 749 762\thard problems\n",
      "T13\tMethod 857 887\tpolynomial time approximations\n",
      "T14\tGeneric 899 911\tcomputations\n",
      "T15\tMetric 966 976\tcomplexity\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R2\tCOREF Arg1:T7 Arg2:T4\n",
      "R3\tEVALUATE-FOR Arg1:T6 Arg2:T7\n",
      "R4\tCOMPARE Arg1:T8 Arg2:T10\n",
      "R5\tCOREF Arg1:T12 Arg2:T7\n",
      "R6\tCOREF Arg1:T5 Arg2:T1\n",
      "R7\tCOREF Arg1:T14 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R9\tEVALUATE-FOR Arg1:T3 Arg2:T4\n",
      "R10\tPART-OF Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E06-1018.ann\n",
      "T1\tGeneric 23 31\tsolution\n",
      "T2\tTask 35 89\tautomatic and  unsupervised word sense induction (WSI)\n",
      "T3\tGeneric 106 108\tIt\n",
      "T4\tMethod 145 182\tone sense per collocation observation\n",
      "T5\tGeneric 235 237\tit\n",
      "T6\tMethod 248 281\tclustering of word co-occurrences\n",
      "T7\tGeneric 290 298\tapproach\n",
      "T8\tGeneric 318 328\tapproaches\n",
      "T9\tTask 333 336\tWSI\n",
      "T10\tGeneric 346 348\tit\n",
      "T11\tMethod 377 414\tone sense per collocation observation\n",
      "T12\tOtherScientificTerm 425 443\ttriplets of  words\n",
      "T13\tMethod 487 514\ttwo-step clustering process\n",
      "T14\tOtherScientificTerm 523 546\tsentence co-occurrences\n",
      "T15\tOtherScientificTerm 552 560\tfeatures\n",
      "T16\tMetric 626 671\tautomatic and  unsupervised evaluation method\n",
      "T17\tMethod 725 761\tword sense disambiguation algorithms\n",
      "T18\tMethod 885 917\tautomatic parameter optimization\n",
      "T19\tMethod 927 940\tWSI algorithm\n",
      "R1\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T5 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R5\tCOMPARE Arg1:T7 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R8\tCOREF Arg1:T10 Arg2:T7\n",
      "R9\tCOREF Arg1:T7 Arg2:T5\n",
      "R10\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R11\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R12\tCOREF Arg1:T11 Arg2:T4\n",
      "R13\tHYPONYM-OF Arg1:T3 Arg2:T4\n",
      "R14\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R15\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R16\tCOREF Arg1:T2 Arg2:T9\n",
      "R17\tEVALUATE-FOR Arg1:T16 Arg2:T17\n",
      "R18\tCOREF Arg1:T19 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E06-1022.ann\n",
      "T1\tTask 24 93\taddressee identification  in  four-participants face-to-face meetings\n",
      "T2\tMethod 102 118\tBayesian Network\n",
      "T3\tMethod 125 148\tNaive Bayes classifiers\n",
      "T4\tOtherScientificTerm 188 217\taddressee  of a  dialogue act\n",
      "T5\tOtherScientificTerm 246 250\tgaze\n",
      "T6\tOtherScientificTerm 255 264\tutterance\n",
      "T7\tOtherScientificTerm 271 302\tconversational context features\n",
      "T8\tOtherScientificTerm 350 365\tmeeting context\n",
      "T9\tMethod 376 387\tclassifiers\n",
      "T10\tMethod 414 425\tclassifiers\n",
      "T11\tOtherScientificTerm 450 472\tconversational context\n",
      "T12\tOtherScientificTerm 479 497\tutterance features\n",
      "T13\tOtherScientificTerm 518 544\tspeaker's gaze information\n",
      "T14\tMethod 553 564\tclassifiers\n",
      "T15\tOtherScientificTerm 609 624\tmeeting context\n",
      "R1\tCONJUNCTION Arg1:T3 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R3\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R4\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R5\tCONJUNCTION Arg1:T13 Arg2:T12\n",
      "R6\tCOREF Arg1:T14 Arg2:T10\n",
      "R7\tHYPONYM-OF Arg1:T2 Arg2:T10\n",
      "R8\tHYPONYM-OF Arg1:T3 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T10\n",
      "R12\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R13\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R14\tUSED-FOR Arg1:T7 Arg2:T4\n",
      "R15\tCOREF Arg1:T10 Arg2:T9\n",
      "R16\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R17\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E06-1031.ann\n",
      "T1\tMetric 24 43\tevaluation measures\n",
      "T2\tTask 50 69\tmachine translation\n",
      "T3\tMetric 252 270\tevaluation measure\n",
      "T4\tOtherScientificTerm 297 313\tblock reordering\n",
      "T5\tOtherScientificTerm 322 336\tedit operation\n",
      "T6\tGeneric 345 352\tmeasure\n",
      "T7\tOtherScientificTerm 384 398\tquadratic time\n",
      "T8\tMetric 438 457\tevaluation measures\n",
      "T9\tOtherScientificTerm 499 532\tword-dependent substitution costs\n",
      "T10\tGeneric 564 571\tmeasure\n",
      "T11\tOtherScientificTerm 579 593\thuman judgment\n",
      "T12\tMaterial 650 664\tlanguage pairs\n",
      "T13\tGeneric 708 710\tit\n",
      "T14\tGeneric 754 764\tapproaches\n",
      "T15\tMetric 769 795\tsentence-level correlation\n",
      "T16\tOtherScientificTerm 830 863\tword dependent substitution costs\n",
      "T17\tMetric 929 958\tautomatic evaluation measures\n",
      "T18\tOtherScientificTerm 965 979\thuman judgment\n",
      "R1\tEVALUATE-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R4\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R5\tCOREF Arg1:T6 Arg2:T3\n",
      "R6\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R7\tCOMPARE Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T10 Arg2:T8\n",
      "R9\tCOREF Arg1:T8 Arg2:T6\n",
      "R10\tCOREF Arg1:T13 Arg2:T10\n",
      "R11\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R12\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R13\tCOREF Arg1:T17 Arg2:T13\n",
      "R14\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R15\tEVALUATE-FOR Arg1:T15 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E06-1035.ann\n",
      "T1\tTask 60 90\tpredicting  segment boundaries\n",
      "T2\tMaterial 96 122\tspoken multiparty dialogue\n",
      "T3\tGeneric 175 185\tapproaches\n",
      "T4\tTask 215 248\tpredicting top-level topic shifts\n",
      "T5\tTask 269 300\tidentifying subtopic boundaries\n",
      "T6\tOtherScientificTerm 358 368\tASR output\n",
      "T7\tOtherScientificTerm 385 404\thuman transcription\n",
      "T8\tOtherScientificTerm 438 446\tfeatures\n",
      "T9\tTask 460 515\tpredicting top-level and predicting subtopic boundaries\n",
      "T10\tGeneric 534 539\ttasks\n",
      "T11\tTask 549 580\tpredicting  subtopic boundaries\n",
      "T12\tMethod 589 620\tlexical cohesion-based approach\n",
      "T13\tTask 670 701\tpredicting top-level boundaries\n",
      "T14\tMethod 710 735\tmachine learning approach\n",
      "T15\tOtherScientificTerm 752 796\tlexical-cohesion and conversational features\n",
      "T16\tOtherScientificTerm 822 841\tconversational cues\n",
      "T17\tOtherScientificTerm 854 865\tcue phrases\n",
      "T18\tOtherScientificTerm 872 890\toverlapping speech\n",
      "T19\tGeneric 905 915\tindicators\n",
      "T20\tGeneric 924 949\ttop-level prediction task\n",
      "T21\tOtherScientificTerm 974 994\ttranscription errors\n",
      "T22\tOtherScientificTerm 1011 1021\tASR output\n",
      "T23\tGeneric 1049 1055\tmodels\n",
      "T24\tOtherScientificTerm 1070 1114\tlexical-cohesion and conversational features\n",
      "T25\tGeneric 1183 1188\ttasks\n",
      "R1\tCOMPARE Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R3\tFEATURE-OF Arg1:T21 Arg2:T22\n",
      "R4\tFEATURE-OF Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R6\tHYPONYM-OF Arg1:T5 Arg2:T9\n",
      "R7\tPART-OF Arg1:T13 Arg2:T9\n",
      "R8\tCONJUNCTION Arg1:T15 Arg2:T14\n",
      "R9\tHYPONYM-OF Arg1:T17 Arg2:T16\n",
      "R10\tHYPONYM-OF Arg1:T18 Arg2:T16\n",
      "R11\tCONJUNCTION Arg1:T18 Arg2:T17\n",
      "R12\tCOREF Arg1:T19 Arg2:T16\n",
      "R13\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R14\tCOREF Arg1:T20 Arg2:T13\n",
      "R15\tCONJUNCTION Arg1:T23 Arg2:T24\n",
      "R16\tCOREF Arg1:T10 Arg2:T9\n",
      "R17\tCOREF Arg1:T25 Arg2:T10\n",
      "R18\tCOREF Arg1:T23 Arg2:T14\n",
      "R19\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R20\tPART-OF Arg1:T11 Arg2:T9\n",
      "R21\tCOREF Arg1:T11 Arg2:T5\n",
      "R22\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R23\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E06-1045.ann\n",
      "T1\tTask 34 55\tdata-driven selection\n",
      "T2\tMaterial 59 83\temphatic facial displays\n",
      "T3\tTask 92 121\tembodied conversational agent\n",
      "T4\tTask 129 144\tdialogue system\n",
      "T5\tMaterial 150 169\tcorpus of sentences\n",
      "T6\tMethod 200 215\tdialogue system\n",
      "T7\tMaterial 239 254\tfacial displays\n",
      "T8\tGeneric 297 301\tdata\n",
      "T9\tGeneric 347 353\tmodels\n",
      "T10\tMaterial 369 384\tfacial displays\n",
      "T11\tGeneric 391 396\tmodel\n",
      "T12\tGeneric 500 506\tmodels\n",
      "T13\tMethod 539 555\tcross-validation\n",
      "T14\tGeneric 570 576\tcorpus\n",
      "T15\tMethod 643 659\tcross-validation\n",
      "T16\tMethod 717 733\tcross-validation\n",
      "R1\tPART-OF Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R4\tCOREF Arg1:T7 Arg2:T2\n",
      "R5\tEVALUATE-FOR Arg1:T13 Arg2:T12\n",
      "R6\tCOREF Arg1:T15 Arg2:T13\n",
      "R7\tCOREF Arg1:T16 Arg2:T15\n",
      "R8\tCOREF Arg1:T10 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R10\tCOREF Arg1:T11 Arg2:T9\n",
      "R11\tCOREF Arg1:T12 Arg2:T11\n",
      "R12\tCOREF Arg1:T8 Arg2:T5\n",
      "R13\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R14\tCOREF Arg1:T14 Arg2:T8\n",
      "R15\tCOREF Arg1:T4 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E83-1021.ann\n",
      "T1\tTask 50 71\tconceptual operations\n",
      "T2\tMaterial 110 131\tnatural language (NL)\n",
      "T3\tMethod 145 194\tStructured Inheritance Network (SI-Nets) paradigm\n",
      "T4\tGeneric 201 211\toperations\n",
      "T5\tOtherScientificTerm 245 260\tformal language\n",
      "T6\tGeneric 309 319\toperations\n",
      "T7\tMethod 340 347\tSI-Nets\n",
      "T8\tGeneric 365 375\toperations\n",
      "T9\tMethod 380 387\tSI-Nets\n",
      "T10\tOtherScientificTerm 425 448\tepistemological objects\n",
      "T11\tMethod 543 560\tconceptual system\n",
      "T12\tMaterial 566 568\tNL\n",
      "T13\tMethod 620 626\tKL-ONE\n",
      "T14\tOtherScientificTerm 650 671\tepistemological level\n",
      "T15\tGeneric 688 709\texperimental language\n",
      "T16\tMethod 712 719\tKL-Conc\n",
      "T17\tOtherScientificTerm 738 754\tconceptual level\n",
      "T18\tMethod 757 764\tKL-Conc\n",
      "T19\tMethod 836 843\tSI-Nets\n",
      "R1\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R2\tFEATURE-OF Arg1:T14 Arg2:T13\n",
      "R3\tFEATURE-OF Arg1:T17 Arg2:T16\n",
      "R4\tCOREF Arg1:T6 Arg2:T4\n",
      "R5\tCOREF Arg1:T7 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R7\tCOREF Arg1:T9 Arg2:T7\n",
      "R8\tCOREF Arg1:T8 Arg2:T6\n",
      "R9\tCOREF Arg1:T12 Arg2:T2\n",
      "R10\tCOREF Arg1:T18 Arg2:T16\n",
      "R11\tCOREF Arg1:T19 Arg2:T9\n",
      "R12\tCOMPARE Arg1:T13 Arg2:T16\n",
      "R13\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R14\tCOREF Arg1:T4 Arg2:T1\n",
      "R15\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R16\tCOREF Arg1:T16 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E83-1029.ann\n",
      "T1\tGeneric 17 23\tsystem\n",
      "T2\tTask 62 101\tscenes descriptions in natural language\n",
      "T3\tGeneric 145 155\tcomponents\n",
      "T4\tGeneric 163 169\tsystem\n",
      "T5\tMethod 190 208\tsyntactic analyzer\n",
      "T6\tMethod 223 250\tProcedural Systemic Grammar\n",
      "T7\tMethod 258 275\tsemantic analyzer\n",
      "T8\tMethod 293 321\tConceptual Dependency Theory\n",
      "T9\tOtherScientificTerm 333 343\tdictionary\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tPART-OF Arg1:T3 Arg2:T4\n",
      "R6\tPART-OF Arg1:T5 Arg2:T3\n",
      "R7\tPART-OF Arg1:T7 Arg2:T3\n",
      "R8\tPART-OF Arg1:T9 Arg2:T3\n",
      "R9\tCONJUNCTION Arg1:T5 Arg2:T7\n",
      "R10\tCONJUNCTION Arg1:T7 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E85-1004.ann\n",
      "T1\tMethod 112 131\tanalytical inverses\n",
      "T2\tOtherScientificTerm 138 164\tcompositional syntax rules\n",
      "T3\tMethod 197 231\tDefinite Clause Grammar techniques\n",
      "T4\tTask 259 301\tparser  returning  Montague analysis trees\n",
      "T5\tMethod 307 318\tparser MDCC\n",
      "T6\tMethod 354 391\taugmented Friedman - Warren algorithm\n",
      "T7\tOtherScientificTerm 405 421\tpost referencing\n",
      "T8\tOtherScientificTerm 459 492\tintenslonal logic translator LILT\n",
      "T9\tOtherScientificTerm 516 536\tderivational history\n",
      "T10\tOtherScientificTerm 556 575\treduced IL formulae\n",
      "T11\tMethod 601 615\tMontague's PTQ\n",
      "T12\tMethod 626 645\tbasic DCG mechanism\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "R4\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R6\tCOREF Arg1:T12 Arg2:T3\n",
      "R7\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R8\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E85-1037.ann\n",
      "T1\tMethod 2 18\tSystemic grammar\n",
      "T2\tTask 39 57\tAI text generation\n",
      "T3\tGeneric 86 101\timplementations\n",
      "T4\tGeneric 164 172\tapproach\n",
      "T5\tTask 186 201\ttext generation\n",
      "T6\tMethod 210 239\tAI problem solving techniques\n",
      "T7\tMethod 283 299\tsystemic grammar\n",
      "T8\tGeneric 308 316\tapproach\n",
      "T9\tMethod 370 386\tsystemic grammar\n",
      "T10\tMethod 393 408\tproblem solving\n",
      "T11\tTask 504 519\ttext generation\n",
      "T12\tMethod 540 557\tlinguistic theory\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R4\tCOREF Arg1:T3 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R6\tCOREF Arg1:T5 Arg2:T2\n",
      "R7\tCOREF Arg1:T6 Arg2:T4\n",
      "R8\tCOREF Arg1:T8 Arg2:T4\n",
      "R9\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R10\tCOREF Arg1:T11 Arg2:T5\n",
      "R11\tCOREF Arg1:T10 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E85-1041.ann\n",
      "T1\tGeneric 35 40\tmodel\n",
      "T2\tOtherScientificTerm 59 93\tstructure of communicative context\n",
      "T3\tMaterial 99 119\tdialogue interaction\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E87-1037.ann\n",
      "T1\tMethod 20 42\tgrammatical formalisms\n",
      "T2\tMethod 102 139\tcontext-free phrase-structure grammar\n",
      "T3\tOtherScientificTerm 162 165\tLFG\n",
      "T4\tOtherScientificTerm 172 179\tPATR-II\n",
      "T5\tGeneric 216 226\tformalisms\n",
      "T6\tMethod 250 273\tchart-parsing framework\n",
      "T7\tGeneric 310 320\tformalisms\n",
      "T8\tMethod 368 392\toptimal control strategy\n",
      "T9\tMethod 456 480\trule-invocation strategy\n",
      "T10\tOtherScientificTerm 594 599\trules\n",
      "T11\tMethod 697 723\trule-invocation strategies\n",
      "T12\tMethod 733 759\tcontext-free chart parsing\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tPART-OF Arg1:T11 Arg2:T12\n",
      "R3\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R4\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R5\tHYPONYM-OF Arg1:T4 Arg2:T1\n",
      "R6\tCOREF Arg1:T5 Arg2:T1\n",
      "R7\tCOREF Arg1:T7 Arg2:T5\n",
      "R8\tCOREF Arg1:T11 Arg2:T9\n",
      "R9\tCOREF Arg1:T12 Arg2:T6\n",
      "R10\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E87-1043.ann\n",
      "T1\tOtherScientificTerm 6 16\tverb forms\n",
      "T2\tGeneric 60 71\tinformation\n",
      "T3\tOtherScientificTerm 161 180\tdeictic information\n",
      "T4\tOtherScientificTerm 305 326\taspectual information\n",
      "T5\tTask 413 444\tanalysis of  verb form meanings\n",
      "T6\tGeneric 518 526\tanalysis\n",
      "T7\tOtherScientificTerm 531 556\tmodel-theoretic semantics\n",
      "R1\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T4 Arg2:T2\n",
      "R3\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E89-1006.ann\n",
      "T1\tGeneric 3 11\tproposal\n",
      "T2\tOtherScientificTerm 26 39\tFrench tenses\n",
      "T3\tMethod 62 93\tDiscourse Representation Theory\n",
      "T4\tGeneric 112 114\tit\n",
      "T5\tTask 159 162\tIMS\n",
      "T6\tGeneric 165 167\tIt\n",
      "T7\tOtherScientificTerm 185 201\ttheory of tenses\n",
      "T8\tGeneric 248 257\toperators\n",
      "T9\tOtherScientificTerm 275 298\tmeaning  of the  tenses\n",
      "T10\tOtherScientificTerm 526 541\tevent structure\n",
      "T11\tMethod 580 604\tsystem of relevant times\n",
      "T12\tOtherScientificTerm 622 638\tpreceeding  text\n",
      "T13\tOtherScientificTerm 652 671\ttemporal adverbials\n",
      "T14\tGeneric 721 727\tsystem\n",
      "T15\tOtherScientificTerm 753 768\treference times\n",
      "T16\tOtherScientificTerm 775 801\ttemporal perspective times\n",
      "T17\tOtherScientificTerm 809 820\tspeech time\n",
      "T18\tOtherScientificTerm 831 844\tlocation time\n",
      "T19\tMethod 962 986\tsystem of relevant times\n",
      "T20\tMethod 1008 1038\tsystem of temporal coordinates\n",
      "T21\tOtherScientificTerm 1173 1196\tmeaning  of the  tenses\n",
      "T22\tMethod 1215 1235\tresolution component\n",
      "T23\tMethod 1264 1282\tsyntactic analysis\n",
      "R1\tCOMPARE Arg1:T22 Arg2:T23\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R5\tCOREF Arg1:T14 Arg2:T11\n",
      "R6\tPART-OF Arg1:T15 Arg2:T14\n",
      "R7\tPART-OF Arg1:T16 Arg2:T14\n",
      "R8\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R9\tPART-OF Arg1:T17 Arg2:T14\n",
      "R10\tPART-OF Arg1:T18 Arg2:T14\n",
      "R11\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R12\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R13\tCOREF Arg1:T19 Arg2:T14\n",
      "R14\tCOREF Arg1:T20 Arg2:T19\n",
      "R15\tCOREF Arg1:T4 Arg2:T1\n",
      "R16\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R17\tCOREF Arg1:T4 Arg2:T6\n",
      "R18\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R19\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R20\tUSED-FOR Arg1:T13 Arg2:T11\n",
      "R21\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E89-1016.ann\n",
      "T1\tGeneric 61 71\tapproaches\n",
      "T2\tTask 101 139\tevaluation of Natural Language systems\n",
      "T3\tMethod 115 139\tNatural Language systems\n",
      "T4\tGeneric 169 179\tapproaches\n",
      "T5\tGeneric 209 216\tsystems\n",
      "T6\tGeneric 263 267\ttask\n",
      "T7\tTask 280 294\tdata retrieval\n",
      "T8\tGeneric 347 357\tapproaches\n",
      "T9\tMethod 435 457\tWizard of Oz technique\n",
      "T10\tOtherScientificTerm 472 487\tNL requirements\n",
      "T11\tGeneric 512 516\ttask\n",
      "T12\tMaterial 549 563\ttask dialogues\n",
      "T13\tGeneric 587 596\ttechnique\n",
      "T14\tMethod 613 646\tprototype Natural Language system\n",
      "T15\tGeneric 712 716\ttask\n",
      "T16\tGeneric 771 775\ttask\n",
      "T17\tTask 780 795\tdatabase access\n",
      "T18\tOtherScientificTerm 807 827\tcontextual reference\n",
      "T19\tMethod 942 966\tNatural Language systems\n",
      "R1\tCOREF Arg1:T8 Arg2:T4\n",
      "R2\tCOREF Arg1:T5 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R4\tEVALUATE-FOR Arg1:T4 Arg2:T5\n",
      "R5\tCOREF Arg1:T11 Arg2:T6\n",
      "R6\tCOREF Arg1:T13 Arg2:T9\n",
      "R7\tCOREF Arg1:T15 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R10\tCOREF Arg1:T19 Arg2:T14\n",
      "R11\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R12\tPART-OF Arg1:T7 Arg2:T6\n",
      "R13\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R14\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R15\tCOREF Arg1:T16 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E89-1040.ann\n",
      "T1\tTask 38 57\tmachine translation\n",
      "T2\tGeneric 123 132\tformalism\n",
      "T3\tTask 217 228\ttranslation\n",
      "T4\tMethod 286 305\tanaphoric component\n",
      "T5\tMethod 315 329\tMimo formalism\n",
      "T6\tTask 361 397\ttranslation  of  anaphoric relations\n",
      "T7\tOtherScientificTerm 479 502\tstrict compositionality\n",
      "T8\tOtherScientificTerm 509 513\tMimo\n",
      "T9\tTask 521 557\ttranslation  of  anaphoric relations\n",
      "T10\tMethod 582 601\tanaphoric component\n",
      "T11\tOtherScientificTerm 622 642\tlinguistic phenomena\n",
      "T12\tOtherScientificTerm 653 664\twh-movement\n",
      "T13\tOtherScientificTerm 667 724\tthe  passive  and the  binding of reflexives and pronouns\n",
      "T14\tOtherScientificTerm 844 855\twh-movement\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R3\tCOREF Arg1:T5 Arg2:T2\n",
      "R4\tCOREF Arg1:T8 Arg2:T5\n",
      "R5\tCOREF Arg1:T10 Arg2:T4\n",
      "R6\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R7\tCOREF Arg1:T14 Arg2:T12\n",
      "R8\tPART-OF Arg1:T4 Arg2:T5\n",
      "R9\tCOREF Arg1:T9 Arg2:T6\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R11\tHYPONYM-OF Arg1:T13 Arg2:T11\n",
      "R12\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E91-1012.ann\n",
      "T1\tMethod 40 50\tLR-parsers\n",
      "T2\tMethod 86 103\tcorrectness proof\n",
      "T3\tGeneric 106 108\tIt\n",
      "T4\tMethod 150 174\trecursive descent parser\n",
      "T5\tMethod 182 197\tnon-LR grammars\n",
      "T6\tMetric 203 218\ttime-complexity\n",
      "T7\tMethod 227 233\tparser\n",
      "T8\tMethod 282 288\tparser\n",
      "T9\tMethod 310 324\tmemo-functions\n",
      "T10\tMethod 394 408\tMemo-functions\n",
      "T11\tOtherScientificTerm 490 502\tparse forest\n",
      "T12\tMethod 510 524\tLR(0) grammars\n",
      "T13\tGeneric 531 540\talgorithm\n",
      "T14\tOtherScientificTerm 568 592\trecursive ascent parsers\n",
      "T15\tMethod 655 675\tExtended CF grammars\n",
      "T16\tMethod 679 687\tgrammars\n",
      "T17\tOtherScientificTerm 695 714\tregular expressions\n",
      "T18\tMethod 789 798\tLR-parser\n",
      "T19\tMethod 812 823\tCF grammars\n",
      "R1\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R2\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R3\tCONJUNCTION Arg1:T2 Arg2:T1\n",
      "R4\tCOREF Arg1:T8 Arg2:T7\n",
      "R5\tCOREF Arg1:T10 Arg2:T9\n",
      "R6\tCOREF Arg1:T16 Arg2:T15\n",
      "R7\tFEATURE-OF Arg1:T17 Arg2:T16\n",
      "R8\tUSED-FOR Arg1:T18 Arg2:T15\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R10\tCOREF Arg1:T13 Arg2:T8\n",
      "R11\tCOREF Arg1:T18 Arg2:T13\n",
      "R12\tCOREF Arg1:T1 Arg2:T7\n",
      "R13\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R14\tCOREF Arg1:T1 Arg2:T3\n",
      "R15\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R16\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R17\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R18\tEVALUATE-FOR Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E91-1043.ann\n",
      "T1\tMethod 35 66\tmodel of grammatical processing\n",
      "T2\tMethod 86 104\tuniform processing\n",
      "T3\tMaterial 111 128\tknowledge sources\n",
      "T4\tGeneric 158 163\tmodel\n",
      "T5\tTask 176 183\tparsing\n",
      "T6\tTask 190 200\tgeneration\n",
      "T7\tGeneric 230 235\ttasks\n",
      "T8\tMethod 259 290\tparametrized deduction  process\n",
      "T9\tTask 357 384\tnatural language processing\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tCONJUNCTION Arg1:T3 Arg2:T2\n",
      "R5\tCOREF Arg1:T4 Arg2:T1\n",
      "R6\tHYPONYM-OF Arg1:T6 Arg2:T7\n",
      "R7\tHYPONYM-OF Arg1:T5 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E91-1050.ann\n",
      "T1\tMethod 2 13\tUnification\n",
      "T2\tGeneric 40 46\tmethod\n",
      "T3\tTask 63 98\trelations  between  representations\n",
      "T4\tOtherScientificTerm 116 134\tfeature structures\n",
      "T5\tGeneric 191 199\tapproach\n",
      "T6\tMethod 217 238\tdeclarative formalism\n",
      "T7\tOtherScientificTerm 267 324\tdirect  mappings  of one  feature structure  into another\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T6 Arg2:T5\n",
      "R3\tCOMPARE Arg1:T5 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R5\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E93-1004.ann\n",
      "T1\tMethod 31 48\tmodal language LT\n",
      "T2\tOtherScientificTerm 63 85\tconstraints  on  trees\n",
      "T3\tMethod 95 113\textension  LT (LF)\n",
      "T4\tOtherScientificTerm 129 185\tconstraints  on  trees decorated with feature structures\n",
      "T5\tGeneric 226 235\tlanguages\n",
      "T6\tMethod 274 296\tgrammatical frameworks\n",
      "T7\tMethod 381 385\tGPSG\n",
      "T8\tMethod 407 414\tLT (LF)\n",
      "T9\tMethod 443 458\tmodal languages\n",
      "T10\tMethod 504 525\tconstraint formalisms\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tCOREF Arg1:T9 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R7\tHYPONYM-OF Arg1:T3 Arg2:T5\n",
      "R8\tCOREF Arg1:T8 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E93-1023.ann\n",
      "T1\tOtherScientificTerm 105 114\tambiguity\n",
      "T2\tTask 122 132\tgeneration\n",
      "T3\tOtherScientificTerm 233 242\tambiguity\n",
      "T4\tMethod 250 276\tMORphological PArser MORPA\n",
      "T5\tMethod 298 339\tprobabilistic context-free grammar (PCFG)\n",
      "T6\tGeneric 347 349\tit\n",
      "T7\tMethod 362 411\t\"conventional\" context-free morphological grammar\n",
      "T8\tOtherScientificTerm 428 455\tungrammatical segmentations\n",
      "T9\tMethod 465 499\tprobability-based scoring function\n",
      "T10\tTask 553 558\tparse\n",
      "T11\tMethod 682 686\tPCFG\n",
      "T12\tTask 712 733\tmorphological parsing\n",
      "T13\tMethod 737 742\tMORPA\n",
      "T14\tMethod 768 774\tparser\n",
      "T15\tTask 800 832\ttext-to-speech conversion system\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tCONJUNCTION Arg1:T9 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R4\tCOREF Arg1:T6 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R8\tCOREF Arg1:T11 Arg2:T5\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R10\tCOREF Arg1:T13 Arg2:T4\n",
      "R11\tHYPONYM-OF Arg1:T13 Arg2:T14\n",
      "R12\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R13\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R14\tUSED-FOR Arg1:T9 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E93-1025.ann\n",
      "T1\tTask 13 45\tanalysis of  ellipsis resolution\n",
      "T2\tMethod 78 105\tdiscourse copying algorithm\n",
      "T3\tGeneric 162 171\ttreatment\n",
      "T4\tTask 215 245\tidentity-of-relations analyses\n",
      "T5\tGeneric 321 330\ttreatment\n",
      "T6\tOtherScientificTerm 383 391\tfull NPs\n",
      "T7\tOtherScientificTerm 402 422\treferential elements\n",
      "T8\tTask 469 481\trole linking\n",
      "T9\tOtherScientificTerm 547 555\tellipsis\n",
      "T10\tGeneric 588 596\tanalysis\n",
      "T11\tTask 624 651\tdiscourse copying phenomena\n",
      "R1\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R2\tCOREF Arg1:T5 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R4\tCOREF Arg1:T10 Arg2:T1\n",
      "R5\tCOREF Arg1:T3 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E93-1043.ann\n",
      "T1\tMethod 18 41\tmorphological component\n",
      "T2\tOtherScientificTerm 112 125\tderived words\n",
      "T3\tGeneric 145 151\tsystem\n",
      "T4\tOtherScientificTerm 174 194\ttwo-level morphology\n",
      "T5\tMethod 233 259\tfeature-based word grammar\n",
      "T6\tOtherScientificTerm 276 296\thierarchical lexicon\n",
      "T7\tOtherScientificTerm 300 319\tPolymorphemic stems\n",
      "T8\tOtherScientificTerm 373 401\tcompositional interpretation\n",
      "T9\tGeneric 417 423\tsystem\n",
      "T10\tOtherScientificTerm 480 493\tderived words\n",
      "T11\tOtherScientificTerm 557 576\twords formed ad-hoc\n",
      "T12\tGeneric 611 617\tsystem\n",
      "T13\tMethod 636 646\tCommonLisp\n",
      "T14\tMaterial 685 702\tGerman derivation\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "R4\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R6\tCOREF Arg1:T3 Arg2:T1\n",
      "R7\tCOREF Arg1:T10 Arg2:T2\n",
      "R8\tCOREF Arg1:T9 Arg2:T3\n",
      "R9\tCOREF Arg1:T12 Arg2:T9\n",
      "R10\tEVALUATE-FOR Arg1:T14 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E93-1066.ann\n",
      "T1\tTask 32 78\tfull scale two-level morphological description\n",
      "T2\tMaterial 121 144\tTurkish word structures\n",
      "T3\tGeneric 151 162\tdescription\n",
      "T4\tMethod 195 215\tPC-KIMMO environment\n",
      "T5\tMaterial 253 270\troot word lexicon\n",
      "T6\tOtherScientificTerm 354 390\tphonological and morphological rules\n",
      "T7\tMaterial 416 423\tTurkish\n",
      "T8\tMaterial 432 454\tagglutinative language\n",
      "T9\tOtherScientificTerm 462 477\tword structures\n",
      "T10\tOtherScientificTerm 490 554\tproductive affixations of derivational and inflectional suffixes\n",
      "T11\tMaterial 574 581\tTurkish\n",
      "T12\tOtherScientificTerm 588 600\tfinite-state\n",
      "T13\tOtherScientificTerm 650 659\tMorphemes\n",
      "T14\tOtherScientificTerm 742 758\tverbal structure\n",
      "T15\tOtherScientificTerm 790 810\tadverbial constructs\n",
      "T16\tTask 818 871\tsurface realizations  of  morphological constructions\n",
      "T17\tOtherScientificTerm 918 932\tphonetic rules\n",
      "T18\tOtherScientificTerm 943 956\tvowel harmony\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T3\n",
      "R5\tHYPONYM-OF Arg1:T7 Arg2:T8\n",
      "R6\tCOREF Arg1:T11 Arg2:T7\n",
      "R7\tPART-OF Arg1:T10 Arg2:T9\n",
      "R8\tHYPONYM-OF Arg1:T18 Arg2:T17\n",
      "R9\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R10\tFEATURE-OF Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E95-1021.ann\n",
      "T1\tGeneric 40 50\tapproaches\n",
      "T2\tTask 55 77\tpart-of-speech tagging\n",
      "T3\tTask 81 128\tstatistical and constraint-based disambiguation\n",
      "T4\tMaterial 138 144\tFrench\n",
      "T5\tGeneric 260 277\tconstraint system\n",
      "T6\tMethod 359 376\tstatistical model\n",
      "T7\tGeneric 399 406\tsystems\n",
      "T8\tMetric 437 445\taccuracy\n",
      "T9\tMethod 455 473\tstatistical method\n",
      "T10\tMethod 510 517\ttaggers\n",
      "T11\tMaterial 524 531\tEnglish\n",
      "T12\tMethod 543 566\tconstraint-based tagger\n",
      "R1\tCOMPARE Arg1:T5 Arg2:T6\n",
      "R2\tCOMPARE Arg1:T9 Arg2:T10\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T3 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R6\tCOREF Arg1:T9 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T12 Arg2:T5\n",
      "R9\tCOREF Arg1:T7 Arg2:T1\n",
      "R10\tHYPONYM-OF Arg1:T5 Arg2:T1\n",
      "R11\tHYPONYM-OF Arg1:T6 Arg2:T1\n",
      "R12\tEVALUATE-FOR Arg1:T8 Arg2:T9\n",
      "R13\tEVALUATE-FOR Arg1:T8 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E95-1033.ann\n",
      "T1\tOtherScientificTerm 34 72\tsentence-level and text-level anaphora\n",
      "T2\tMethod 101 131\tdependency-based grammar model\n",
      "T3\tGeneric 134 142\tCriteria\n",
      "T4\tTask 148 196\tanaphora resolution  within  sentence boundaries\n",
      "T5\tMethod 228 247\tGB's binding theory\n",
      "T6\tGeneric 256 261\tthose\n",
      "T7\tOtherScientificTerm 267 286\ttext-level anaphora\n",
      "T8\tMethod 325 355\tGrosz-Sidner-style focus model\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T6 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R4\tPART-OF Arg1:T8 Arg2:T6\n",
      "R5\tHYPONYM-OF Arg1:T7 Arg2:T1\n",
      "R6\tHYPONYM-OF Arg1:T4 Arg2:T1\n",
      "R7\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R8\tUSED-FOR Arg1:T5 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E95-1036.ann\n",
      "T1\tTask 37 54\ttemporal anaphora\n",
      "T2\tOtherScientificTerm 86 112\tquantification over events\n",
      "T3\tMethod 140 171\tDiscourse Representation Theory\n",
      "T4\tMaterial 209 229\tquantified sentences\n",
      "T5\tOtherScientificTerm 249 268\ttemporal connective\n",
      "T6\tOtherScientificTerm 316 335\ttemporal connective\n",
      "T7\tOtherScientificTerm 345 363\tsubordinate clause\n",
      "T8\tGeneric 391 398\tproblem\n",
      "T9\tOtherScientificTerm 472 490\tproportion problem\n",
      "T10\tGeneric 504 512\tsolution\n",
      "T11\tMethod 521 552\tGeneralized Quantifier approach\n",
      "T12\tOtherScientificTerm 620 634\treference time\n",
      "T13\tGeneric 682 690\tsolution\n",
      "T14\tGeneric 700 707\tproblem\n",
      "T15\tMethod 735 738\tDRT\n",
      "T16\tGeneric 776 784\tsolution\n",
      "T17\tTask 801 828\ttemporal anaphora phenomena\n",
      "T18\tMaterial 834 854\tquantified sentences\n",
      "R1\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R2\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tPART-OF Arg1:T2 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T8\n",
      "R6\tCOREF Arg1:T8 Arg2:T1\n",
      "R7\tCOREF Arg1:T14 Arg2:T8\n",
      "R8\tCOREF Arg1:T11 Arg2:T10\n",
      "R9\tCOREF Arg1:T16 Arg2:T13\n",
      "R10\tUSED-FOR Arg1:T18 Arg2:T16\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R12\tCOREF Arg1:T3 Arg2:T15\n",
      "R13\tPART-OF Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E99-1014.ann\n",
      "T1\tGeneric 24 32\tapproach\n",
      "T2\tTask 37 49\tfull parsing\n",
      "T3\tTask 65 87\tInformation Extraction\n",
      "T4\tOtherScientificTerm 129 134\trules\n",
      "T5\tOtherScientificTerm 184 206\tunambiguous structures\n",
      "T6\tOtherScientificTerm 254 274\targumental relations\n",
      "T7\tOtherScientificTerm 301 320\tmodifier attachment\n",
      "T8\tOtherScientificTerm 344 361\tglobal parse tree\n",
      "T9\tGeneric 377 385\tapproach\n",
      "T10\tGeneric 452 454\tIt\n",
      "T11\tMethod 479 488\tIE module\n",
      "T12\tMethod 494 558\tFACILE, a EU project for multilingual text classification and IE\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tPART-OF Arg1:T11 Arg2:T12\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T10 Arg2:T9\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R6\tCOREF Arg1:T9 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E99-1015.ann\n",
      "T1\tTask 27 56\tautomatic abstracting systems\n",
      "T2\tMaterial 87 105\ttraining resources\n",
      "T3\tMethod 169 186\tannotation scheme\n",
      "T4\tMaterial 192 211\tscientific articles\n",
      "T5\tGeneric 247 255\tresource\n",
      "T6\tGeneric 307 313\tscheme\n",
      "T7\tMethod 329 364\trhetorical moves  of  argumentation\n",
      "T8\tGeneric 407 413\tscheme\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T6 Arg2:T3\n",
      "R5\tCOREF Arg1:T8 Arg2:T6\n",
      "R6\tCOREF Arg1:T5 Arg2:T2\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E99-1023.ann\n",
      "T1\tTask 1 41\tDividing  sentences  in  chunks of words\n",
      "T2\tTask 79 86\tparsing\n",
      "T3\tTask 90 112\tinformation extraction\n",
      "T4\tTask 119 140\tinformation retrieval\n",
      "T5\tMethod 202 221\tdata representation\n",
      "T6\tTask 228 236\tchunking\n",
      "T7\tGeneric 252 254\tit\n",
      "T8\tTask 261 273\ttagging task\n",
      "T9\tMethod 323 343\tdata representations\n",
      "T10\tTask 364 395\trecognizing  noun phrase chunks\n",
      "T11\tMethod 421 440\tdata representation\n",
      "T12\tTask 475 483\tchunking\n",
      "T13\tMethod 539 558\tdata representation\n",
      "T14\tMethod 566 595\tmemory-based learning chunker\n",
      "T15\tTask 637 645\tchunking\n",
      "T16\tMaterial 671 679\tdata set\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R2\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R3\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R5\tEVALUATE-FOR Arg1:T16 Arg2:T14\n",
      "R6\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R7\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R8\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R9\tCOREF Arg1:T6 Arg2:T1\n",
      "R10\tCOREF Arg1:T7 Arg2:T6\n",
      "R11\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R12\tCOREF Arg1:T6 Arg2:T12\n",
      "R13\tCOREF Arg1:T12 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E99-1029.ann\n",
      "T1\tMethod 33 56\tTree Adjoining Grammars\n",
      "T2\tGeneric 66 70\tthey\n",
      "T3\tOtherScientificTerm 80 114\textended domain of locality (EDOL)\n",
      "T4\tMethod 178 207\tfeature structure unification\n",
      "T5\tTask 217 224\tparsing\n",
      "T6\tMethod 257 288\tlexicalized grammars of English\n",
      "T7\tMethod 292 298\tLEXSYS\n",
      "T8\tMethod 305 309\tXTAG\n",
      "T9\tMethod 334 342\tgrammars\n",
      "T10\tOtherScientificTerm 353 357\tEDOL\n",
      "R1\tFEATURE-OF Arg1:T1 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tCOMPARE Arg1:T7 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R5\tHYPONYM-OF Arg1:T7 Arg2:T6\n",
      "R6\tHYPONYM-OF Arg1:T8 Arg2:T6\n",
      "R7\tCOREF Arg1:T9 Arg2:T6\n",
      "R8\tCOREF Arg1:T10 Arg2:T3\n",
      "R9\tCOREF Arg1:T2 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E99-1034.ann\n",
      "T1\tOtherScientificTerm 51 77\tco-occurrence similarities\n",
      "T2\tGeneric 111 122\tquery terms\n",
      "T3\tTask 145 154\tretrieval\n",
      "T4\tGeneric 161 166\tthose\n",
      "T5\tGeneric 227 239\tuseful terms\n",
      "T6\tGeneric 294 305\tquery terms\n",
      "T7\tGeneric 337 349\tsimilarities\n",
      "T8\tOtherScientificTerm 366 408\tfirst-order and second-order co-occurrence\n",
      "T9\tOtherScientificTerm 443 460\tTerm similarities\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tCOMPARE Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R5\tCOREF Arg1:T9 Arg2:T7\n",
      "R6\tCOMPARE Arg1:T4 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E99-1038.ann\n",
      "T1\tGeneric 15 34\toperable definition\n",
      "T2\tOtherScientificTerm 73 97\tcognito-pragmatic nature\n",
      "T3\tGeneric 114 116\tit\n",
      "T4\tOtherScientificTerm 135 144\tdiscourse\n",
      "T5\tMethod 188 247\ta file card model of  discourse model  and  knowledge store\n",
      "T6\tMethod 210 225\tdiscourse model\n",
      "T7\tOtherScientificTerm 232 247\tknowledge store\n",
      "T8\tOtherScientificTerm 328 349\tdetermination process\n",
      "T9\tMethod 356 378\tprogrammable algorithm\n",
      "T10\tMethod 381 384\tFDA\n",
      "T11\tOtherScientificTerm 420 451\tsocial and cognitive psychology\n",
      "T12\tOtherScientificTerm 513 516\tFDA\n",
      "T13\tOtherScientificTerm 524 549\tdiscourse-level construct\n",
      "T14\tMethod 557 581\tspeech synthesis systems\n",
      "T15\tMethod 600 625\tconcept-to-speech systems\n",
      "R1\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T10 Arg2:T9\n",
      "R4\tCOREF Arg1:T12 Arg2:T10\n",
      "R5\tHYPONYM-OF Arg1:T15 Arg2:T14\n",
      "R6\tPART-OF Arg1:T13 Arg2:T14\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_1998_39_abs.ann\n",
      "T1\tMethod 0 36\tImage sequence processing techniques\n",
      "T2\tTask 55 97\texchange , growth, and transport processes\n",
      "T3\tMaterial 129 150\tenvironmental physics\n",
      "T4\tMaterial 155 162\tbiology\n",
      "T5\tGeneric 170 182\tapplications\n",
      "T6\tMetric 196 204\taccuracy\n",
      "T7\tTask 213 243\testimation of the motion field\n",
      "T8\tMethod 289 308\tdynamical processes\n",
      "T9\tOtherScientificTerm 334 377\tfirst-order derivatives of the motion field\n",
      "T10\tOtherScientificTerm 384 423\tdynamical changes of the moving objects\n",
      "T11\tTask 455 498\toptimization of low-level motion estimators\n",
      "T12\tMethod 515 528\ttensor method\n",
      "T13\tMethod 560 578\tderivative filters\n",
      "T14\tOtherScientificTerm 605 637\tdisplacement vector fields (DVF)\n",
      "T15\tMetric 646 654\taccuracy\n",
      "T16\tMetric 680 692\tpixels/frame\n",
      "T17\tMaterial 697 714\treal-world images\n",
      "T18\tMetric 720 728\taccuracy\n",
      "T19\tMethod 736 749\ttensor method\n",
      "T20\tMaterial 767 795\tcomputer-generated sequences\n",
      "T21\tMaterial 802 827\tcalibrated image sequence\n",
      "T22\tMetric 854 862\taccuracy\n",
      "T23\tTask 867 884\tmotion estimation\n",
      "T24\tOtherScientificTerm 931 942\tCCD sensors\n",
      "T25\tOtherScientificTerm 959 981\tspatial nonuni-formity\n",
      "T26\tOtherScientificTerm 989 1001\tresponsivity\n",
      "T27\tMethod 1017 1038\ttwo-point calibration\n",
      "T28\tGeneric 1108 1118\ttechniques\n",
      "T29\tTask 1126 1150\tanalysis of plant growth\n",
      "T30\tTask 1155 1206\tocean surface microturbulence in IR image sequences\n",
      "T31\tTask 1215 1233\tsediment transport\n",
      "R1\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tEVALUATE-FOR Arg1:T6 Arg2:T7\n",
      "R4\tHYPONYM-OF Arg1:T5 Arg2:T2\n",
      "R5\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R7\tCOREF Arg1:T19 Arg2:T12\n",
      "R8\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R9\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "R10\tEVALUATE-FOR Arg1:T22 Arg2:T23\n",
      "R11\tCOREF Arg1:T28 Arg2:T1\n",
      "R12\tUSED-FOR Arg1:T28 Arg2:T29\n",
      "R13\tUSED-FOR Arg1:T28 Arg2:T30\n",
      "R14\tUSED-FOR Arg1:T28 Arg2:T31\n",
      "R15\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R16\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R17\tEVALUATE-FOR Arg1:T16 Arg2:T14\n",
      "R18\tEVALUATE-FOR Arg1:T20 Arg2:T19\n",
      "R19\tEVALUATE-FOR Arg1:T21 Arg2:T19\n",
      "R20\tUSED-FOR Arg1:T24 Arg2:T23\n",
      "R21\tFEATURE-OF Arg1:T25 Arg2:T26\n",
      "R22\tFEATURE-OF Arg1:T26 Arg2:T24\n",
      "R23\tCONJUNCTION Arg1:T29 Arg2:T30\n",
      "R24\tCONJUNCTION Arg1:T30 Arg2:T31\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2006_13_abs.ann\n",
      "T1\tTask 50 62\tillumination\n",
      "T2\tTask 67 82\tpose invariance\n",
      "T3\tTask 127 143\tface recognition\n",
      "T4\tMaterial 232 247\tvideo sequences\n",
      "T5\tOtherScientificTerm 334 342\tlighting\n",
      "T6\tOtherScientificTerm 344 348\tpose\n",
      "T7\tOtherScientificTerm 353 372\tuser motion pattern\n",
      "T8\tMaterial 401 412\tface images\n",
      "T9\tMetric 424 434\tresolution\n",
      "T10\tMethod 502 519\tphotometric model\n",
      "T11\tTask 523 538\timage formation\n",
      "T12\tMethod 562 579\tstatistical model\n",
      "T13\tTask 583 616\tgeneric face appearance variation\n",
      "T14\tOtherScientificTerm 667 695\textreme illumination changes\n",
      "T15\tOtherScientificTerm 713 723\tsmoothness\n",
      "T16\tOtherScientificTerm 727 775\tgeodesically local appearance manifold structure\n",
      "T17\tMethod 782 813\trobust same-identity likelihood\n",
      "T18\tOtherScientificTerm 839 856\tunseen head poses\n",
      "T19\tMethod 893 936\tvideo sequence \" reillumination \" algorithm\n",
      "T20\tMetric 948 958\trobustness\n",
      "T21\tOtherScientificTerm 962 982\tface motion patterns\n",
      "T22\tMaterial 986 991\tvideo\n",
      "T23\tMethod 1007 1041\tfully automatic recognition system\n",
      "T24\tGeneric 1064 1070\tmethod\n",
      "T25\tMaterial 1132 1147\tvideo sequences\n",
      "T26\tOtherScientificTerm 1161 1173\tillumination\n",
      "T27\tOtherScientificTerm 1175 1179\tpose\n",
      "T28\tOtherScientificTerm 1184 1205\thead motion variation\n",
      "T29\tGeneric 1227 1235\tdata set\n",
      "T30\tGeneric 1240 1246\tsystem\n",
      "T31\tMetric 1290 1306\trecognition rate\n",
      "T32\tMaterial 1332 1341\tdatabases\n",
      "T33\tMethod 1390 1409\tcommercial software\n",
      "T34\tGeneric 1414 1421\tmethods\n",
      "R1\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R2\tPART-OF Arg1:T2 Arg2:T3\n",
      "R3\tPART-OF Arg1:T1 Arg2:T3\n",
      "R4\tFEATURE-OF Arg1:T9 Arg2:T8\n",
      "R5\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R6\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R9\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R10\tFEATURE-OF Arg1:T15 Arg2:T16\n",
      "R11\tCONJUNCTION Arg1:T26 Arg2:T27\n",
      "R12\tCONJUNCTION Arg1:T27 Arg2:T28\n",
      "R13\tUSED-FOR Arg1:T24 Arg2:T23\n",
      "R14\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R15\tCONJUNCTION Arg1:T10 Arg2:T12\n",
      "R16\tFEATURE-OF Arg1:T26 Arg2:T25\n",
      "R17\tFEATURE-OF Arg1:T27 Arg2:T25\n",
      "R18\tFEATURE-OF Arg1:T28 Arg2:T25\n",
      "R19\tEVALUATE-FOR Arg1:T25 Arg2:T23\n",
      "R20\tCOREF Arg1:T23 Arg2:T30\n",
      "R21\tCOREF Arg1:T25 Arg2:T29\n",
      "R22\tEVALUATE-FOR Arg1:T29 Arg2:T30\n",
      "R23\tEVALUATE-FOR Arg1:T31 Arg2:T30\n",
      "R24\tCOMPARE Arg1:T30 Arg2:T33\n",
      "R25\tCOMPARE Arg1:T30 Arg2:T34\n",
      "R26\tCONJUNCTION Arg1:T33 Arg2:T34\n",
      "R27\tPART-OF Arg1:T21 Arg2:T22\n",
      "R28\tFEATURE-OF Arg1:T21 Arg2:T20\n",
      "R29\tEVALUATE-FOR Arg1:T20 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2012_29_abs.ann\n",
      "T1\tTask 36 75\toptimal alignment of non-rigid surfaces\n",
      "T2\tOtherScientificTerm 81 110\tmulti-view video observations\n",
      "T3\tMethod 123 159\ttemporally consistent representation\n",
      "T4\tMethod 174 200\tnon-rigid surface tracking\n",
      "T5\tMethod 210 234\tframe-to-frame alignment\n",
      "T6\tMethod 324 358\tnon-sequential tracking approaches\n",
      "T7\tMetric 420 441\tdissimilarity measure\n",
      "T8\tOtherScientificTerm 552 565\treduced drift\n",
      "T9\tMetric 580 590\trobustness\n",
      "T10\tOtherScientificTerm 600 622\tnon-rigid deformations\n",
      "T11\tOtherScientificTerm 684 692\tbranches\n",
      "T12\tOtherScientificTerm 700 704\ttree\n",
      "T13\tOtherScientificTerm 727 745\terror accumulation\n",
      "T14\tTask 758 782\tOptimisation of the tree\n",
      "T15\tMethod 787 810\tnon-sequential tracking\n",
      "T16\tMetric 842 862\ttemporal consistency\n",
      "T17\tMethod 921 933\tcluster tree\n",
      "T18\tTask 943 980\tsequential tracking in local segments\n",
      "T19\tOtherScientificTerm 966 980\tlocal segments\n",
      "T20\tOtherScientificTerm 1012 1043\tglobal non-sequential traversal\n",
      "T21\tGeneric 1056 1064\tsegments\n",
      "T22\tOtherScientificTerm 1104 1118\ttree structure\n",
      "T23\tOtherScientificTerm 1288 1306\tnon-rigid surfaces\n",
      "T24\tOtherScientificTerm 1317 1321\tface\n",
      "T25\tOtherScientificTerm 1323 1328\tcloth\n",
      "T26\tOtherScientificTerm 1333 1339\tpeople\n",
      "T27\tMethod 1375 1387\tcluster tree\n",
      "T28\tMetric 1404 1424\ttemporal consistency\n",
      "T29\tMethod 1443 1492\tsequential and non-sequential tracking approaches\n",
      "T30\tMetric 1529 1557\tsynthetic facial performance\n",
      "T31\tMethod 1591 1603\tcluster tree\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R5\tFEATURE-OF Arg1:T9 Arg2:T10\n",
      "R6\tCOREF Arg1:T15 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R8\tEVALUATE-FOR Arg1:T16 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R10\tUSED-FOR Arg1:T17 Arg2:T20\n",
      "R11\tCOREF Arg1:T19 Arg2:T21\n",
      "R12\tCOREF Arg1:T17 Arg2:T27\n",
      "R13\tEVALUATE-FOR Arg1:T28 Arg2:T27\n",
      "R14\tCOMPARE Arg1:T27 Arg2:T29\n",
      "R15\tCOREF Arg1:T27 Arg2:T31\n",
      "R16\tEVALUATE-FOR Arg1:T30 Arg2:T31\n",
      "R17\tHYPONYM-OF Arg1:T24 Arg2:T23\n",
      "R18\tHYPONYM-OF Arg1:T25 Arg2:T23\n",
      "R19\tHYPONYM-OF Arg1:T26 Arg2:T23\n",
      "R20\tCONJUNCTION Arg1:T24 Arg2:T25\n",
      "R21\tCONJUNCTION Arg1:T25 Arg2:T26\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2012_30_abs.ann\n",
      "T1\tTask 36 86\treconstructing the motion of a 3D articulated tree\n",
      "T2\tOtherScientificTerm 92 116\t2D point correspondences\n",
      "T3\tOtherScientificTerm 133 147\ttemporal prior\n",
      "T4\tOtherScientificTerm 159 172\tsmooth motion\n",
      "T5\tOtherScientificTerm 201 217\ttrajectory basis\n",
      "T6\tTask 230 256\thard combinatorial problem\n",
      "T7\tMetric 262 277\ttime complexity\n",
      "T8\tMethod 325 352\tBranch and bound strategies\n",
      "T9\tGeneric 392 402\tcomplexity\n",
      "T10\tOtherScientificTerm 422 439\tglobal optimality\n",
      "T11\tGeneric 450 454\tthey\n",
      "T12\tMethod 505 522\texhaustive search\n",
      "T13\tMethod 594 619\tcompact high-pass filters\n",
      "T14\tMethod 634 662\tdynamic programming approach\n",
      "T15\tOtherScientificTerm 755 774\tfilter interactions\n",
      "T16\tMethod 789 806\taffine projection\n",
      "T17\tTask 815 829\treconstruction\n",
      "T18\tMethod 838 856\testimating cameras\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R3\tCOREF Arg1:T9 Arg2:T7\n",
      "R4\tCOREF Arg1:T8 Arg2:T11\n",
      "R5\tCOMPARE Arg1:T11 Arg2:T12\n",
      "R6\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R7\tFEATURE-OF Arg1:T10 Arg2:T8\n",
      "R8\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R9\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R10\tCOREF Arg1:T1 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2012_37_abs.ann\n",
      "T1\tMethod 47 69\tdiscriminative patches\n",
      "T2\tTask 97 141\tunsupervised mid-level visual representation\n",
      "T3\tGeneric 377 384\tpatches\n",
      "T4\tGeneric 501 505\tthis\n",
      "T5\tTask 512 558\tunsupervised discriminative clustering problem\n",
      "T6\tMaterial 580 593\timage patches\n",
      "T7\tMethod 605 624\titerative procedure\n",
      "T8\tMethod 650 660\tclustering\n",
      "T9\tMethod 665 700\ttraining discriminative classifiers\n",
      "T10\tMethod 725 741\tcross-validation\n",
      "T11\tOtherScientificTerm 766 777\toverfitting\n",
      "T12\tMethod 838 860\tdiscriminative patches\n",
      "T13\tTask 867 911\tunsupervised mid-level visual representation\n",
      "T14\tGeneric 929 931\tit\n",
      "T15\tMethod 1000 1023\tdiscrim-inative patches\n",
      "T16\tTask 1046 1063\tsupervised regime\n",
      "T17\tTask 1073 1093\tscene classification\n",
      "T18\tGeneric 1101 1105\tthey\n",
      "T19\tMaterial 1154 1175\tMIT Indoor-67 dataset\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tCOREF Arg1:T3 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R8\tCOREF Arg1:T12 Arg2:T1\n",
      "R9\tCOREF Arg1:T13 Arg2:T2\n",
      "R10\tCOREF Arg1:T15 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R12\tHYPONYM-OF Arg1:T17 Arg2:T16\n",
      "R13\tCOREF Arg1:T18 Arg2:T15\n",
      "R14\tEVALUATE-FOR Arg1:T19 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2012_40_abs.ann\n",
      "T1\tMethod 28 41\tKAZE features\n",
      "T2\tMethod 51 108\tmultiscale 2D feature detection and description algorithm\n",
      "T3\tOtherScientificTerm 112 134\tnonlinear scale spaces\n",
      "T4\tOtherScientificTerm 244 264\tGaussian scale space\n",
      "T5\tOtherScientificTerm 287 304\tGaussian blurring\n",
      "T6\tOtherScientificTerm 334 355\tboundaries of objects\n",
      "T7\tMetric 421 462\tlocalization accuracy and distinctiveness\n",
      "T8\tMethod 500 511\t2D features\n",
      "T9\tOtherScientificTerm 517 538\tnonlinear scale space\n",
      "T10\tMethod 551 580\tnonlinear diffusion filtering\n",
      "T11\tMaterial 640 650\timage data\n",
      "T12\tOtherScientificTerm 681 698\tobject boundaries\n",
      "T13\tMetric 719 760\tlocalization accuracy and distinctiviness\n",
      "T14\tOtherScientificTerm 766 787\tnonlinear scale space\n",
      "T15\tMethod 813 857\tAdditive Operator Splitting (AOS) techniques\n",
      "T16\tMethod 862 893\tvariable con-ductance diffusion\n",
      "T17\tMaterial 933 951\tbenchmark datasets\n",
      "T18\tTask 968 1011\tmatching application on deformable surfaces\n",
      "T19\tGeneric 1029 1037\tfeatures\n",
      "T20\tMethod 1082 1086\tSURF\n",
      "T21\tOtherScientificTerm 1118 1139\tnonlinear scale space\n",
      "T22\tMethod 1159 1163\tSIFT\n",
      "T23\tGeneric 1169 1176\tresults\n",
      "T24\tTask 1222 1231\tdetection\n",
      "T25\tTask 1236 1247\tdescription\n",
      "T26\tGeneric 1265 1289\tstate-of-the-art methods\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R3\tFEATURE-OF Arg1:T9 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R5\tCOREF Arg1:T7 Arg2:T13\n",
      "R6\tCOREF Arg1:T8 Arg2:T19\n",
      "R7\tCOREF Arg1:T1 Arg2:T8\n",
      "R8\tCOMPARE Arg1:T19 Arg2:T20\n",
      "R9\tCOMPARE Arg1:T19 Arg2:T22\n",
      "R10\tCOREF Arg1:T19 Arg2:T23\n",
      "R11\tEVALUATE-FOR Arg1:T24 Arg2:T23\n",
      "R12\tEVALUATE-FOR Arg1:T25 Arg2:T23\n",
      "R13\tCONJUNCTION Arg1:T24 Arg2:T25\n",
      "R14\tCOMPARE Arg1:T23 Arg2:T26\n",
      "R15\tEVALUATE-FOR Arg1:T24 Arg2:T26\n",
      "R16\tEVALUATE-FOR Arg1:T25 Arg2:T26\n",
      "R17\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R18\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R19\tUSED-FOR Arg1:T16 Arg2:T14\n",
      "R20\tCOREF Arg1:T14 Arg2:T21\n",
      "R21\tCOREF Arg1:T9 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2014_47_abs.ann\n",
      "T1\tTask 15 56\tpredicting image or video interestingness\n",
      "T2\tMethod 68 101\tlow-level feature representations\n",
      "T3\tOtherScientificTerm 148 175\tsubjective visual attribute\n",
      "T4\tOtherScientificTerm 192 214\tinteresting-ness value\n",
      "T5\tMethod 247 263\tprediction model\n",
      "T6\tMethod 360 379\tcrowdsourcing tools\n",
      "T7\tOtherScientificTerm 391 411\tpairwise comparisons\n",
      "T8\tMethod 425 440\tmajority voting\n",
      "T9\tOtherScientificTerm 454 480\tannotation outliers/errors\n",
      "T10\tGeneric 526 529\tway\n",
      "T11\tOtherScientificTerm 542 561\tannotation outliers\n",
      "T12\tTask 581 612\tinterestingness prediction task\n",
      "T13\tMethod 618 641\tunified robust learning\n",
      "T14\tTask 645 657\trank problem\n",
      "T15\tTask 677 694\toutlier detection\n",
      "T16\tTask 699 731\tinterestingness prediction tasks\n",
      "T17\tMaterial 771 821\timage and video interestingness benchmark datasets\n",
      "T18\tGeneric 847 855\tapproach\n",
      "T19\tGeneric 882 911\tstate-of-the-art alternatives\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R6\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R8\tCOMPARE Arg1:T18 Arg2:T19\n",
      "R9\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T10 Arg2:T15\n",
      "R11\tUSED-FOR Arg1:T10 Arg2:T16\n",
      "R12\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R13\tCOREF Arg1:T10 Arg2:T18\n",
      "R14\tEVALUATE-FOR Arg1:T17 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2014_50_abs.ann\n",
      "T1\tGeneric 23 31\tapproach\n",
      "T2\tTask 48 112\tintrinsic texture properties (albedo, shading, normal) of scenes\n",
      "T3\tTask 118 143\tmultiple view acquisition\n",
      "T4\tOtherScientificTerm 150 181\tunknown illumination conditions\n",
      "T5\tOtherScientificTerm 211 229\tintrinsic textures\n",
      "T6\tOtherScientificTerm 241 274\tpixel-resolution surface textures\n",
      "T7\tOtherScientificTerm 292 323\tintrinsic appearance parameters\n",
      "T8\tMethod 352 376\tvideo relighting methods\n",
      "T9\tGeneric 382 390\tapproach\n",
      "T10\tOtherScientificTerm 418 432\tuniform albedo\n",
      "T11\tGeneric 446 448\tit\n",
      "T12\tMaterial 463 485\trichly textured scenes\n",
      "T13\tMethod 500 523\tintrinsic image methods\n",
      "T14\tTask 549 588\tinitial, low-frequency shading estimate\n",
      "T15\tOtherScientificTerm 600 630\tglobal lighting reconstruction\n",
      "T16\tOtherScientificTerm 648 681\ttexture and coarse scene geometry\n",
      "T17\tOtherScientificTerm 706 742\tinherent global ambiguity in shading\n",
      "T18\tGeneric 748 754\tmethod\n",
      "T19\tTask 769 808\trelight-ing of free-viewpoint rendering\n",
      "T20\tOtherScientificTerm 814 841\tmultiple view video capture\n",
      "T21\tTask 861 871\trelighting\n",
      "T22\tOtherScientificTerm 877 912\treproduction of fine surface detail\n",
      "R1\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T6 Arg2:T5\n",
      "R5\tCOMPARE Arg1:T9 Arg2:T8\n",
      "R6\tCOREF Arg1:T9 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R10\tFEATURE-OF Arg1:T16 Arg2:T15\n",
      "R11\tUSED-FOR Arg1:T14 Arg2:T17\n",
      "R12\tCOREF Arg1:T13 Arg2:T18\n",
      "R13\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R14\tFEATURE-OF Arg1:T22 Arg2:T21\n",
      "R15\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R16\tCOREF Arg1:T21 Arg2:T19\n",
      "R17\tCOREF Arg1:T1 Arg2:T9\n",
      "R18\tCOREF Arg1:T9 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2016_100_abs.ann\n",
      "T1\tGeneric 29 37\tapproach\n",
      "T2\tMethod 53 74\tvisual representation\n",
      "T3\tMaterial 84 120\traw spatiotemporal signals in videos\n",
      "T4\tGeneric 126 140\trepresentation\n",
      "T5\tOtherScientificTerm 160 192\tsupervision from semantic labels\n",
      "T6\tGeneric 211 217\tmethod\n",
      "T7\tTask 224 265\tunsupervised sequential verification task\n",
      "T8\tOtherScientificTerm 346 360\ttemporal order\n",
      "T9\tGeneric 379 383\ttask\n",
      "T10\tOtherScientificTerm 391 406\tsemantic labels\n",
      "T11\tMethod 428 449\tvisual representation\n",
      "T12\tMethod 458 492\tConvolutional Neural Network (CNN)\n",
      "T13\tGeneric 498 512\trepresentation\n",
      "T14\tOtherScientificTerm 522 547\tcomplementary information\n",
      "T15\tMaterial 569 594\tsupervised image datasets\n",
      "T16\tMaterial 600 608\tImageNet\n",
      "T17\tGeneric 644 650\tmethod\n",
      "T18\tOtherScientificTerm 708 718\thuman pose\n",
      "T19\tMethod 733 745\tpre-training\n",
      "T20\tTask 750 768\taction recognition\n",
      "T21\tMethod 771 781\tour method\n",
      "T22\tMethod 811 841\tlearning without external data\n",
      "T23\tGeneric 845 863\tbenchmark datasets\n",
      "T24\tMaterial 869 875\tUCF101\n",
      "T25\tMaterial 880 886\tHMDB51\n",
      "T26\tOtherScientificTerm 922 932\thuman pose\n",
      "T27\tTask 954 969\tpose estimation\n",
      "T28\tMaterial 977 999\tFLIC and MPII datasets\n",
      "T29\tGeneric 1037 1047\tapproaches\n",
      "T30\tOtherScientificTerm 1073 1084\tsupervision\n",
      "T31\tOtherScientificTerm 1086 1096\tOur method\n",
      "T32\tMethod 1118 1144\tsupervised representations\n",
      "T33\tMetric 1179 1187\taccuracy\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T2 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R5\tCOREF Arg1:T1 Arg2:T6\n",
      "R6\tCOREF Arg1:T7 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R9\tCOREF Arg1:T13 Arg2:T11\n",
      "R10\tPART-OF Arg1:T14 Arg2:T13\n",
      "R11\tHYPONYM-OF Arg1:T16 Arg2:T15\n",
      "R12\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R13\tCOREF Arg1:T6 Arg2:T17\n",
      "R14\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R15\tCOREF Arg1:T17 Arg2:T21\n",
      "R16\tCOMPARE Arg1:T21 Arg2:T22\n",
      "R17\tHYPONYM-OF Arg1:T24 Arg2:T23\n",
      "R18\tHYPONYM-OF Arg1:T25 Arg2:T23\n",
      "R19\tCONJUNCTION Arg1:T24 Arg2:T25\n",
      "R20\tEVALUATE-FOR Arg1:T23 Arg2:T22\n",
      "R21\tEVALUATE-FOR Arg1:T23 Arg2:T21\n",
      "R22\tUSED-FOR Arg1:T21 Arg2:T19\n",
      "R23\tEVALUATE-FOR Arg1:T28 Arg2:T27\n",
      "R24\tCOREF Arg1:T31 Arg2:T21\n",
      "R25\tCONJUNCTION Arg1:T32 Arg2:T31\n",
      "R26\tEVALUATE-FOR Arg1:T33 Arg2:T31\n",
      "R27\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R28\tUSED-FOR Arg1:T30 Arg2:T29\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2016_107_abs.ann\n",
      "T1\tMethod 0 8\tDiagrams\n",
      "T2\tOtherScientificTerm 43 59\tcomplex concepts\n",
      "T3\tOtherScientificTerm 62 75\trelationships\n",
      "T4\tOtherScientificTerm 80 86\tevents\n",
      "T5\tMaterial 158 172\tnatural images\n",
      "T6\tTask 174 202\tUnderstanding natural images\n",
      "T7\tMaterial 188 202\tnatural images\n",
      "T8\tTask 235 250\tcomputer vision\n",
      "T9\tTask 258 279\tdiagram understanding\n",
      "T10\tTask 350 386\tdiagram interpretation and reasoning\n",
      "T11\tGeneric 404 408\ttask\n",
      "T12\tOtherScientificTerm 428 450\tstructure of a diagram\n",
      "T13\tMethod 527 553\tDiagram Parse Graphs (DPG)\n",
      "T14\tOtherScientificTerm 589 610\tstructure of diagrams\n",
      "T15\tTask 622 651\tsyntactic parsing of diagrams\n",
      "T16\tMethod 673 677\tDPGs\n",
      "T17\tTask 701 750\tsemantic interpretation and reasoning of diagrams\n",
      "T18\tTask 769 795\tdiagram question answering\n",
      "T19\tMethod 810 827\tLSTM-based method\n",
      "T20\tTask 832 861\tsyntactic parsing of diagrams\n",
      "T21\tMethod 878 903\tDPG-based attention model\n",
      "T22\tTask 908 934\tdiagram question answering\n",
      "T23\tGeneric 953 960\tdataset\n",
      "T24\tMaterial 964 972\tdiagrams\n",
      "T25\tGeneric 1134 1140\tmodels\n",
      "T26\tTask 1145 1197\tsyntactic parsing and question answering in diagrams\n",
      "T27\tMethod 1204 1208\tDPGs\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R4\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R5\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R6\tCOREF Arg1:T7 Arg2:T5\n",
      "R7\tCOMPARE Arg1:T6 Arg2:T9\n",
      "R8\tPART-OF Arg1:T6 Arg2:T8\n",
      "R9\tCOREF Arg1:T10 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R12\tCOREF Arg1:T16 Arg2:T13\n",
      "R13\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R14\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R15\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R16\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R17\tCOREF Arg1:T22 Arg2:T18\n",
      "R18\tCOREF Arg1:T20 Arg2:T15\n",
      "R19\tFEATURE-OF Arg1:T24 Arg2:T23\n",
      "R20\tUSED-FOR Arg1:T25 Arg2:T26\n",
      "R21\tUSED-FOR Arg1:T27 Arg2:T25\n",
      "R22\tHYPONYM-OF Arg1:T20 Arg2:T26\n",
      "R23\tHYPONYM-OF Arg1:T22 Arg2:T26\n",
      "R24\tHYPONYM-OF Arg1:T19 Arg2:T25\n",
      "R25\tHYPONYM-OF Arg1:T21 Arg2:T25\n",
      "R26\tCOREF Arg1:T27 Arg2:T16\n",
      "R27\tHYPONYM-OF Arg1:T9 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2016_110_abs.ann\n",
      "T1\tTask 19 34\tcomputer vision\n",
      "T2\tMethod 54 74\thigh-capacity models\n",
      "T3\tMaterial 86 100\tlarge datasets\n",
      "T4\tMaterial 126 140\tlarge datasets\n",
      "T5\tOtherScientificTerm 146 164\tpixel-level labels\n",
      "T6\tGeneric 264 272\tapproach\n",
      "T7\tOtherScientificTerm 293 327\tpixel-accurate semantic label maps\n",
      "T8\tMaterial 332 338\timages\n",
      "T9\tOtherScientificTerm 354 375\tmodern computer games\n",
      "R1\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R4\tCOREF Arg1:T4 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tPART-OF Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2016_204_abs.ann\n",
      "T1\tTask 23 43\tMahalanobis distance\n",
      "T2\tOtherScientificTerm 60 64\tloss\n",
      "T3\tOtherScientificTerm 80 92\tweighted sum\n",
      "T4\tMetric 100 109\tprecision\n",
      "T5\tOtherScientificTerm 123 128\tranks\n",
      "T6\tOtherScientificTerm 171 189\tweighted rank loss\n",
      "T7\tTask 234 249\tcomputer vision\n",
      "T8\tTask 258 282\tperson re-identification\n",
      "T9\tMethod 303 330\tmetric learning formulation\n",
      "T10\tMethod 338 390\tWeighted Approximate Rank Component Analysis (WARCA)\n",
      "T11\tMethod 418 455\tstochastic gradient descent algorithm\n",
      "T12\tGeneric 474 490\tlearning problem\n",
      "T13\tMethod 520 549\tnon-linear extension of WARCA\n",
      "T14\tMethod 544 549\tWARCA\n",
      "T15\tMethod 563 575\tkernel trick\n",
      "T16\tOtherScientificTerm 577 599\tKernel space embedding\n",
      "T17\tOtherScientificTerm 614 643\ttraining and prediction costs\n",
      "T18\tOtherScientificTerm 653 667\tdata dimension\n",
      "T19\tMethod 691 720\tinarbitrary distance measures\n",
      "T20\tOtherScientificTerm 752 760\tfeatures\n",
      "T21\tOtherScientificTerm 804 828\tmatrix rank degeneration\n",
      "T22\tOtherScientificTerm 831 850\tnon-isolated minima\n",
      "T23\tTask 858 886\tlow-rank matrix optimization\n",
      "T24\tMethod 908 919\tregularizer\n",
      "T25\tOtherScientificTerm 953 968\tor-thonormality\n",
      "T26\tOtherScientificTerm 976 990\tlearned matrix\n",
      "T27\tGeneric 1030 1036\tmethod\n",
      "T28\tMaterial 1054 1087\tperson re-identification datasets\n",
      "T29\tMaterial 1108 1125\tscale Market-1501\n",
      "T30\tMaterial 1130 1145\tCUHK03 datasets\n",
      "T31\tGeneric 1223 1227\tthem\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T6 Arg2:T2\n",
      "R3\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R6\tHYPONYM-OF Arg1:T10 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R8\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "R9\tFEATURE-OF Arg1:T22 Arg2:T23\n",
      "R10\tFEATURE-OF Arg1:T21 Arg2:T23\n",
      "R11\tFEATURE-OF Arg1:T25 Arg2:T26\n",
      "R12\tUSED-FOR Arg1:T24 Arg2:T25\n",
      "R13\tEVALUATE-FOR Arg1:T28 Arg2:T27\n",
      "R14\tCONJUNCTION Arg1:T30 Arg2:T29\n",
      "R15\tHYPONYM-OF Arg1:T29 Arg2:T28\n",
      "R16\tHYPONYM-OF Arg1:T30 Arg2:T28\n",
      "R17\tCOREF Arg1:T31 Arg2:T28\n",
      "R18\tFEATURE-OF Arg1:T3 Arg2:T4\n",
      "R19\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R20\tCOREF Arg1:T27 Arg2:T13\n",
      "R21\tUSED-FOR Arg1:T16 Arg2:T19\n",
      "R22\tUSED-FOR Arg1:T24 Arg2:T23\n",
      "R23\tCOREF Arg1:T14 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2016_205_abs.ann\n",
      "T1\tGeneric 20 30\tapproaches\n",
      "T2\tTask 60 96\tmonocular nonrigid 3D reconstruction\n",
      "T3\tMethod 98 120\tTemplate-based methods\n",
      "T4\tMethod 125 167\tNon-rigid Structure from Motion techniques\n",
      "T5\tGeneric 185 189\tones\n",
      "T6\tOtherScientificTerm 223 247\tpoorly-textured surfaces\n",
      "T7\tGeneric 249 253\tthey\n",
      "T8\tMethod 283 297\t3D shape model\n",
      "T9\tTask 307 321\treconstruction\n",
      "T10\tGeneric 347 351\tones\n",
      "T11\tOtherScientificTerm 374 388\tshape template\n",
      "T12\tMaterial 446 460\tvideo sequence\n",
      "T13\tOtherScientificTerm 496 520\tpoorly-textured surfaces\n",
      "T14\tMethod 552 574\ttemplate-free approach\n",
      "T15\tOtherScientificTerm 595 630\tpoorly-textured, deformable surface\n",
      "T16\tMethod 657 673\tsurface isometry\n",
      "T17\tTask 688 705\t3D reconstruction\n",
      "T18\tTask 713 779\tjoint problem of non-rigid image registration and depth estimation\n",
      "T19\tGeneric 818 826\tapproach\n",
      "T20\tTask 853 871\t3D reconstructions\n",
      "T21\tGeneric 877 904\tstate-of-the-art techniques\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T4 Arg2:T1\n",
      "R4\tCOREF Arg1:T3 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R6\tCOREF Arg1:T5 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R8\tCOREF Arg1:T4 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R11\tCOREF Arg1:T14 Arg2:T19\n",
      "R12\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R13\tCOMPARE Arg1:T19 Arg2:T21\n",
      "R14\tEVALUATE-FOR Arg1:T20 Arg2:T19\n",
      "R15\tEVALUATE-FOR Arg1:T20 Arg2:T21\n",
      "R16\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R17\tCOREF Arg1:T17 Arg2:T20\n",
      "R18\tCOREF Arg1:T2 Arg2:T17\n",
      "R19\tCOREF Arg1:T2 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2016_212_abs.ann\n",
      "T1\tTask 0 24\tPerson re-identification\n",
      "T2\tOtherScientificTerm 71 75\tpose\n",
      "T3\tOtherScientificTerm 77 89\tillumination\n",
      "T4\tOtherScientificTerm 91 100\tocclusion\n",
      "T5\tOtherScientificTerm 105 116\tcamera view\n",
      "T6\tMaterial 149 164\tpedestrian data\n",
      "T7\tMethod 183 206\thighly-curved manifolds\n",
      "T8\tOtherScientificTerm 214 227\tfeature space\n",
      "T9\tMethod 249 284\tconvolutional neural networks (CNN)\n",
      "T10\tOtherScientificTerm 301 319\tfeature extraction\n",
      "T11\tOtherScientificTerm 389 406\tgeodesic distance\n",
      "T12\tMethod 460 482\tdeep embedding methods\n",
      "T13\tOtherScientificTerm 491 509\tEuclidean distance\n",
      "T14\tMethod 560 585\tmanifold learning methods\n",
      "T15\tOtherScientificTerm 605 623\tEuclidean distance\n",
      "T16\tOtherScientificTerm 631 642\tlocal range\n",
      "T17\tOtherScientificTerm 663 685\tgraphical relationship\n",
      "T18\tOtherScientificTerm 726 743\tgeodesic distance\n",
      "T19\tOtherScientificTerm 843 854\tlocal range\n",
      "T20\tOtherScientificTerm 884 897\tCNN embedding\n",
      "T21\tGeneric 919 923\tdata\n",
      "T22\tOtherScientificTerm 934 956\tintra-class variations\n",
      "T23\tMethod 992 1030\tmoderate positive sample mining method\n",
      "T24\tMethod 1040 1050\trobust CNN\n",
      "T25\tTask 1055 1079\tperson re-identification\n",
      "T26\tGeneric 1154 1162\tlearning\n",
      "T27\tOtherScientificTerm 1168 1192\tmetric weight constraint\n",
      "T28\tOtherScientificTerm 1206 1220\tlearned metric\n",
      "T29\tOtherScientificTerm 1234 1256\tgeneralization ability\n",
      "T30\tOtherScientificTerm 1327 1346\trobust deep metrics\n",
      "T31\tTask 1351 1375\tperson re-identification\n",
      "T32\tMethod 1397 1407\tdeep model\n",
      "T33\tGeneric 1438 1462\tstate-of-the-art methods\n",
      "T34\tTask 1488 1512\tperson re-identification\n",
      "T35\tMethod 1601 1612\tdeep models\n",
      "T36\tTask 1617 1641\tperson re-identification\n",
      "R1\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R3\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R5\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R6\tFEATURE-OF Arg1:T16 Arg2:T15\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T18\n",
      "R8\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R9\tCONJUNCTION Arg1:T15 Arg2:T17\n",
      "R10\tUSED-FOR Arg1:T23 Arg2:T24\n",
      "R11\tUSED-FOR Arg1:T24 Arg2:T25\n",
      "R12\tUSED-FOR Arg1:T27 Arg2:T26\n",
      "R13\tFEATURE-OF Arg1:T29 Arg2:T28\n",
      "R14\tUSED-FOR Arg1:T30 Arg2:T31\n",
      "R15\tCOMPARE Arg1:T32 Arg2:T33\n",
      "R16\tUSED-FOR Arg1:T32 Arg2:T34\n",
      "R17\tUSED-FOR Arg1:T33 Arg2:T34\n",
      "R18\tUSED-FOR Arg1:T35 Arg2:T36\n",
      "R19\tCOREF Arg1:T36 Arg2:T34\n",
      "R20\tCOREF Arg1:T34 Arg2:T25\n",
      "R21\tCOREF Arg1:T25 Arg2:T1\n",
      "R22\tFEATURE-OF Arg1:T22 Arg2:T21\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2016_215_abs.ann\n",
      "T1\tMethod 0 19\tJoint image filters\n",
      "T2\tMaterial 37 51\tguidance image\n",
      "T3\tMaterial 108 122\tguidance image\n",
      "T4\tTask 147 164\tsuppressing noise\n",
      "T5\tTask 168 196\tenhancing spatial resolution\n",
      "T6\tGeneric 198 214\tExisting methods\n",
      "T7\tMethod 240 268\texplicit filter construction\n",
      "T8\tMethod 272 305\thand-designed objective functions\n",
      "T9\tGeneric 367 371\tthem\n",
      "T10\tGeneric 377 395\tcoherent framework\n",
      "T11\tMethod 425 448\tlearning-based approach\n",
      "T12\tMethod 464 476\tjoint filter\n",
      "T13\tMethod 486 516\tConvolution-al Neural Networks\n",
      "T14\tGeneric 542 549\tmethods\n",
      "T15\tMaterial 573 587\tguidance image\n",
      "T16\tGeneric 593 599\tmethod\n",
      "T17\tTask 616 643\ttransfer salient structures\n",
      "T18\tGeneric 717 722\tmodel\n",
      "T19\tGeneric 752 756\tdata\n",
      "T20\tMaterial 764 784\tRGB and depth images\n",
      "T21\tGeneric 813 823\tmodalities\n",
      "T22\tMaterial 831 865\tFlash/Non-Flash and RGB/NIR images\n",
      "T23\tMethod 913 925\tjoint filter\n",
      "T24\tGeneric 961 985\tstate-of-the-art methods\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R3\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R4\tCOREF Arg1:T6 Arg2:T9\n",
      "R5\tCOREF Arg1:T14 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R7\tCOMPARE Arg1:T14 Arg2:T16\n",
      "R8\tCOREF Arg1:T18 Arg2:T16\n",
      "R9\tHYPONYM-OF Arg1:T20 Arg2:T19\n",
      "R10\tUSED-FOR Arg1:T19 Arg2:T18\n",
      "R11\tHYPONYM-OF Arg1:T22 Arg2:T21\n",
      "R12\tUSED-FOR Arg1:T18 Arg2:T21\n",
      "R13\tCOMPARE Arg1:T23 Arg2:T24\n",
      "R14\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R15\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R16\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R17\tCOREF Arg1:T1 Arg2:T12\n",
      "R18\tUSED-FOR Arg1:T13 Arg2:T11\n",
      "R19\tCOREF Arg1:T11 Arg2:T16\n",
      "R20\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R21\tCOREF Arg1:T12 Arg2:T23\n",
      "R22\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R23\tUSED-FOR Arg1:T1 Arg2:T5\n",
      "R24\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2016_99_abs.ann\n",
      "T1\tTask 0 24\tHuman action recognition\n",
      "T2\tMaterial 30 61\twell-segmented 3D skeleton data\n",
      "T3\tTask 131 154\tOnline action detection\n",
      "T4\tOtherScientificTerm 223 234\taction type\n",
      "T5\tOtherScientificTerm 253 269\taction positions\n",
      "T6\tMaterial 290 306\tuntrimmed stream\n",
      "T7\tTask 347 370\tonline action detection\n",
      "T8\tMaterial 380 403\tstreaming skeleton data\n",
      "T9\tMethod 418 496\tmulti-task end-to-end Joint Classification-Regression Recurrent Neural Network\n",
      "T10\tOtherScientificTerm 519 530\taction type\n",
      "T11\tOtherScientificTerm 535 569\ttemporal localiza-tion information\n",
      "T12\tOtherScientificTerm 586 644\tjoint classification and regression optimization objective\n",
      "T13\tGeneric 651 658\tnetwork\n",
      "T14\tMethod 797 842\tdeep Long Short-Term Memory (LSTM) subnetwork\n",
      "T15\tGeneric 857 862\tmodel\n",
      "T16\tOtherScientificTerm 898 926\tlong-range temporal dynamics\n",
      "T17\tMethod 963 984\tsliding window design\n",
      "T18\tOtherScientificTerm 1007 1031\tcomputational efficiency\n",
      "T19\tTask 1061 1084\tregression optimization\n",
      "T20\tGeneric 1179 1184\tmodel\n",
      "T21\tMaterial 1203 1226\tstreaming video dataset\n",
      "T22\tGeneric 1273 1280\tdataset\n",
      "T23\tMaterial 1296 1307\tG3D dataset\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T3\n",
      "R6\tCOREF Arg1:T7 Arg2:T3\n",
      "R7\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R9\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R10\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R11\tCOREF Arg1:T13 Arg2:T9\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R13\tCOREF Arg1:T15 Arg2:T13\n",
      "R14\tFEATURE-OF Arg1:T16 Arg2:T15\n",
      "R15\tCOREF Arg1:T20 Arg2:T15\n",
      "R16\tEVALUATE-FOR Arg1:T21 Arg2:T20\n",
      "R17\tCOREF Arg1:T22 Arg2:T21\n",
      "R18\tCONJUNCTION Arg1:T22 Arg2:T23\n",
      "R19\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1001.ann\n",
      "T1\tMaterial 2 20\tOral communication\n",
      "T2\tTask 139 165\tstorage media and networks\n",
      "T3\tMaterial 202 214\tconversation\n",
      "T4\tMethod 350 382\tinformation retrieval techniques\n",
      "T5\tMethod 391 414\thistogram  of  keywords\n",
      "T6\tMethod 424 447\tdocument representation\n",
      "T7\tMaterial 454 472\toral communication\n",
      "T8\tOtherScientificTerm 605 613\tactivity\n",
      "T9\tOtherScientificTerm 622 632\tdiscussing\n",
      "T10\tOtherScientificTerm 634 642\tplanning\n",
      "T11\tOtherScientificTerm 644 653\tinforming\n",
      "T12\tOtherScientificTerm 655 668\tstory-telling\n",
      "T13\tTask 716 735\tautomatic detection\n",
      "T14\tGeneric 746 756\tactivities\n",
      "T15\tGeneric 890 900\tactivities\n",
      "T16\tMaterial 1003 1025\tdatabase  of  TV shows\n",
      "T17\tMaterial 1030 1038\tEmotions\n",
      "T18\tOtherScientificTerm 1073 1107\tdominance distribution of speakers\n",
      "R1\tCOREF Arg1:T7 Arg2:T1\n",
      "R2\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "R3\tHYPONYM-OF Arg1:T10 Arg2:T8\n",
      "R4\tHYPONYM-OF Arg1:T11 Arg2:T8\n",
      "R5\tHYPONYM-OF Arg1:T12 Arg2:T8\n",
      "R6\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R7\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R8\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R9\tCOREF Arg1:T14 Arg2:T8\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R11\tCOREF Arg1:T15 Arg2:T14\n",
      "R12\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R13\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1017.ann\n",
      "T1\tMethod 45 90\tmixed-initiative speech dialogue interactions\n",
      "T2\tMethod 136 152\tdialogue systems\n",
      "T3\tMethod 226 268\tdistributed message-passing infrastructure\n",
      "T4\tMethod 275 291\tdialogue systems\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tCOREF Arg1:T4 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1040.ann\n",
      "T1\tGeneric 42 49\toutputs\n",
      "T2\tMethod 56 91\tinformation extraction (IE) systems\n",
      "T3\tOtherScientificTerm 96 120\tnamed entity annotations\n",
      "T4\tOtherScientificTerm 127 145\tscenario templates\n",
      "T5\tMaterial 183 199\ttext collections\n",
      "T6\tMethod 217 229\ttext browser\n",
      "T7\tGeneric 280 296\tprototype system\n",
      "T8\tMaterial 355 382\tpharmaceutical news archive\n",
      "T9\tMetric 470 497\tqualitative user evaluation\n",
      "T10\tGeneric 506 512\tsystem\n",
      "T11\tMethod 655 680\tIE-enhanced text browsers\n",
      "R1\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R2\tHYPONYM-OF Arg1:T4 Arg2:T1\n",
      "R3\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R6\tCOREF Arg1:T10 Arg2:T7\n",
      "R7\tEVALUATE-FOR Arg1:T9 Arg2:T10\n",
      "R8\tCOREF Arg1:T11 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T1 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1041.ann\n",
      "T1\tMethod 55 99\tKorean-to-English machine translation system\n",
      "T2\tMethod 102 165\tCCLINC (Common Coalition Language System at Lincoln Laboratory)\n",
      "T3\tMethod 174 217\tCCLINC Korean-to-English translation system\n",
      "T4\tGeneric 236 248\tcore modules\n",
      "T5\tMethod 253 298\tlanguage understanding and generation modules\n",
      "T6\tMethod 315 354\tlanguage neutral meaning representation\n",
      "T7\tOtherScientificTerm 366 380\tsemantic frame\n",
      "T8\tGeneric 408 414\tsystem\n",
      "T9\tTask 446 465\tparsing  of  Korean\n",
      "T10\tMaterial 459 465\tKorean\n",
      "T11\tMaterial 471 490\tverb final language\n",
      "T12\tOtherScientificTerm 498 516\tovert case markers\n",
      "T13\tTask 611 622\ttranslation\n",
      "T14\tMethod 629 654\tword sense disambiguation\n",
      "T15\tTask 670 691\tword order generation\n",
      "T16\tMethod 787 836\tknowledge-based automated acquisition of grammars\n",
      "T17\tMaterial 864 889\tKorean newspaper articles\n",
      "T18\tMaterial 894 934\tmissiles and chemical biological warfare\n",
      "T19\tGeneric 940 946\tsystem\n",
      "R1\tPART-OF Arg1:T4 Arg2:T3\n",
      "R2\tFEATURE-OF Arg1:T12 Arg2:T11\n",
      "R3\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R4\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R5\tCOREF Arg1:T3 Arg2:T2\n",
      "R6\tCOREF Arg1:T5 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R8\tHYPONYM-OF Arg1:T7 Arg2:T6\n",
      "R9\tHYPONYM-OF Arg1:T10 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R11\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R12\tCOREF Arg1:T19 Arg2:T3\n",
      "R13\tUSED-FOR Arg1:T17 Arg2:T19\n",
      "R14\tCOREF Arg1:T8 Arg2:T3\n",
      "R15\tFEATURE-OF Arg1:T18 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1042.ann\n",
      "T1\tMethod 67 98\tautomated evaluation techniques\n",
      "T2\tTask 129 167\tevaluation of  human language learners\n",
      "T3\tMethod 191 223\tmachine translation (MT) systems\n",
      "T4\tGeneric 250 271\tevaluation techniques\n",
      "T5\tTask 314 345\thuman language learning process\n",
      "T6\tTask 354 373\ttranslation process\n",
      "T7\tTask 401 428\tmachine translation systems\n",
      "T8\tTask 538 555\tlanguage learning\n",
      "T9\tGeneric 581 590\tassessors\n",
      "T10\tMaterial 623 649\tnon-native language essays\n",
      "T11\tGeneric 731 740\tassessors\n",
      "T12\tOtherScientificTerm 863 889\tmachine translation output\n",
      "T13\tMaterial 945 969\ttranslated newswire text\n",
      "T14\tOtherScientificTerm 1000 1025\texpert human translations\n",
      "T15\tOtherScientificTerm 1042 1069\tmachine translation outputs\n",
      "T16\tOtherScientificTerm 1186 1210\texpert human translation\n",
      "T17\tOtherScientificTerm 1218 1237\tmachine translation\n",
      "R1\tCOREF Arg1:T4 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R4\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R5\tCONJUNCTION Arg1:T15 Arg2:T14\n",
      "R6\tCOREF Arg1:T7 Arg2:T3\n",
      "R7\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R8\tUSED-FOR Arg1:T4 Arg2:T7\n",
      "R9\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R10\tCOREF Arg1:T9 Arg2:T4\n",
      "R11\tCOREF Arg1:T11 Arg2:T9\n",
      "R12\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R13\tEVALUATE-FOR Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1049.ann\n",
      "T1\tTask 2 31\tListen-Communicate-Show (LCS)\n",
      "T2\tTask 56 91\thuman interaction with data sources\n",
      "T3\tMethod 111 147\tspoken language understanding system\n",
      "T4\tMethod 155 180\tintelligent mobile agents\n",
      "T5\tMaterial 216 235\tinformation sources\n",
      "T6\tGeneric 297 305\tapproach\n",
      "T7\tTask 314 324\tLCS-Marine\n",
      "T8\tTask 335 345\tLCS-Marine\n",
      "T9\tMethod 479 504\tmobile, intelligent agent\n",
      "T10\tGeneric 587 593\tsystem\n",
      "T11\tMaterial 827 838\tnew domains\n",
      "R1\tPART-OF Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T8 Arg2:T7\n",
      "R4\tCOREF Arg1:T10 Arg2:T8\n",
      "R5\tCOREF Arg1:T6 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1055.ann\n",
      "T1\tMethod 23 62\tAutomatic Speech Recognition technology\n",
      "T2\tTask 105 119\tdialog systems\n",
      "T3\tTask 158 176\tspeech recognition\n",
      "T4\tTask 218 232\tdialog systems\n",
      "T5\tGeneric 281 285\tthey\n",
      "T6\tOtherScientificTerm 360 375\tsystem response\n",
      "T7\tTask 425 462\tnatural language generation community\n",
      "T8\tTask 499 513\tdialog systems\n",
      "T9\tTask 542 552\tgeneration\n",
      "T10\tTask 573 587\tdialog systems\n",
      "T11\tMethod 616 665\thand-crafting  knowledge-based generation systems\n",
      "T12\tMethod 697 724\tmachine learning techniques\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tPART-OF Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R4\tCOREF Arg1:T8 Arg2:T4\n",
      "R5\tCOREF Arg1:T4 Arg2:T2\n",
      "R6\tCOREF Arg1:T10 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R8\tCOREF Arg1:T5 Arg2:T4\n",
      "R9\tCOMPARE Arg1:T7 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1058.ann\n",
      "T1\tMethod 61 82\tlanguage models (LMs)\n",
      "T2\tMethod 107 128\tinterpolation methods\n",
      "T3\tMethod 138 173\tlog-linear and linear interpolation\n",
      "T4\tMetric 374 401\tword or semantic error rate\n",
      "T5\tMethod 502 504\tLM\n",
      "T6\tMethod 544 560\tdynamic combiner\n",
      "T7\tOtherScientificTerm 568 582\thard decisions\n",
      "T8\tMethod 674 708\tdynamic language model combination\n",
      "T9\tGeneric 762 768\tmethod\n",
      "T10\tMethod 819 833\tneural network\n",
      "T11\tMethod 841 854\tdecision tree\n",
      "T12\tGeneric 862 868\tmethod\n",
      "T13\tMethod 889 892\tLMs\n",
      "T14\tMetric 900 919\tconfidence measures\n",
      "T15\tMethod 977 979\tLM\n",
      "R1\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R2\tCOREF Arg1:T8 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R5\tCONJUNCTION Arg1:T11 Arg2:T10\n",
      "R6\tCOREF Arg1:T12 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R8\tCOREF Arg1:T15 Arg2:T13\n",
      "R9\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1070.ann\n",
      "T1\tGeneric 33 41\tapproach\n",
      "T2\tMethod 53 66\tn-gram models\n",
      "T3\tMethod 73 95\terror-correction rules\n",
      "T4\tTask 102 121\tThai key prediction\n",
      "T5\tTask 128 164\tThai-English language identification\n",
      "T6\tMethod 193 217\trule-reduction algorithm\n",
      "T7\tOtherScientificTerm 229 247\tmutual information\n",
      "T8\tOtherScientificTerm 264 286\terror-correction rules\n",
      "T9\tGeneric 294 303\talgorithm\n",
      "T10\tMetric 328 336\taccuracy\n",
      "T11\tTask 347 370\tlanguage identification\n",
      "T12\tTask 377 391\tkey prediction\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T5\n",
      "R6\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R7\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R8\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T9 Arg2:T12\n",
      "R11\tCOREF Arg1:T1 Arg2:T9\n",
      "R12\tEVALUATE-FOR Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-1005.ann\n",
      "T1\tOtherScientificTerm 28 74\tinformation redundancy  in  multilingual input\n",
      "T2\tTask 98 117\tmachine translation\n",
      "T3\tTask 152 174\tmultilingual summaries\n",
      "T4\tTask 203 231\tmulti-document summarization\n",
      "T5\tMaterial 271 277\tArabic\n",
      "T6\tMaterial 313 320\tEnglish\n",
      "T7\tOtherScientificTerm 403 426\tlexical-syntactic forms\n",
      "T8\tMethod 485 512\tmachine translation systems\n",
      "T9\tMaterial 605 612\tEnglish\n",
      "T10\tTask 650 670\tmachine translations\n",
      "T11\tMaterial 686 702\tArabic documents\n",
      "R1\tCOREF Arg1:T10 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-1012.ann\n",
      "T1\tMethod 24 64\tmaximum entropy word alignment algorithm\n",
      "T2\tMaterial 71 85\tArabic-English\n",
      "T3\tMaterial 97 121\tsupervised training data\n",
      "T4\tMaterial 171 188\ttraining material\n",
      "T5\tTask 207 226\tmachine translation\n",
      "T6\tMethod 251 286\tsupervised and unsupervised methods\n",
      "T7\tMethod 325 344\tprobabilistic model\n",
      "T8\tTask 359 368\talignment\n",
      "T9\tTask 391 405\tlink decisions\n",
      "T10\tMethod 451 476\tword alignment techniques\n",
      "T11\tOtherScientificTerm 522 547\tmachine translation tests\n",
      "T12\tGeneric 570 579\talgorithm\n",
      "T13\tOtherScientificTerm 600 616\thuman annotation\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R7\tCOREF Arg1:T12 Arg2:T1\n",
      "R8\tCOMPARE Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-1041.ann\n",
      "T1\tMethod 27 55\tunsupervised learning method\n",
      "T2\tOtherScientificTerm 69 91\tsingle-snippet answers\n",
      "T3\tMethod 123 149\tquestion answering systems\n",
      "T4\tMethod 168 186\tWeb search engines\n",
      "T5\tGeneric 193 199\tmethod\n",
      "T6\tMaterial 210 248\ton-line encyclopedias and dictionaries\n",
      "T7\tMaterial 308 349\tpositive and negative definition examples\n",
      "T8\tMethod 385 388\tsvm\n",
      "T9\tGeneric 460 466\tmethod\n",
      "T10\tGeneric 483 485\tit\n",
      "T11\tGeneric 502 513\talternative\n",
      "T12\tGeneric 531 537\tsystem\n",
      "T13\tMaterial 559 572\tnews articles\n",
      "T14\tMaterial 578 582\ttrec\n",
      "T15\tGeneric 594 596\tit\n",
      "T16\tMethod 608 621\tsearch engine\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R3\tCOREF Arg1:T9 Arg2:T5\n",
      "R4\tCOREF Arg1:T1 Arg2:T5\n",
      "R5\tCOREF Arg1:T10 Arg2:T9\n",
      "R6\tCOMPARE Arg1:T10 Arg2:T11\n",
      "R7\tCOREF Arg1:T16 Arg2:T4\n",
      "R8\tCOREF Arg1:T15 Arg2:T9\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R10\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R11\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R12\tCOREF Arg1:T12 Arg2:T3\n",
      "R13\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R14\tPART-OF Arg1:T13 Arg2:T14\n",
      "R15\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-1064.ann\n",
      "T1\tGeneric 19 25\tmethod\n",
      "T2\tOtherScientificTerm 53 67\tNLP structures\n",
      "T3\tMethod 77 97\treranking approaches\n",
      "T4\tMethod 118 146\tconditional log-linear model\n",
      "T5\tOtherScientificTerm 155 171\thidden variables\n",
      "T6\tOtherScientificTerm 226 239\tword clusters\n",
      "T7\tOtherScientificTerm 245 256\tword senses\n",
      "T8\tGeneric 263 268\tmodel\n",
      "T9\tMetric 330 363\tdiscriminative training criterion\n",
      "T10\tGeneric 401 406\tmodel\n",
      "T11\tOtherScientificTerm 455 482\thidden-variable assignments\n",
      "T12\tGeneric 498 508\tsummations\n",
      "T13\tMethod 556 575\tdynamic programming\n",
      "T14\tGeneric 608 613\tmodel\n",
      "T15\tTask 618 633\tparse reranking\n",
      "T16\tGeneric 640 645\tmodel\n",
      "T17\tMetric 656 665\tF-measure\n",
      "T18\tMethod 701 712\tbase parser\n",
      "T19\tMethod 749 772\tCollins (2000) reranker\n",
      "T20\tTask 816 823\tparsing\n",
      "T21\tGeneric 830 840\ttechniques\n",
      "T22\tOtherScientificTerm 876 890\tNLP structures\n",
      "T23\tOtherScientificTerm 904 915\tparse trees\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tCOMPARE Arg1:T18 Arg2:T19\n",
      "R3\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tCOREF Arg1:T8 Arg2:T4\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R7\tCOREF Arg1:T10 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R9\tCOREF Arg1:T14 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R11\tEVALUATE-FOR Arg1:T17 Arg2:T16\n",
      "R12\tCOREF Arg1:T16 Arg2:T14\n",
      "R13\tCOMPARE Arg1:T16 Arg2:T18\n",
      "R14\tCOREF Arg1:T21 Arg2:T16\n",
      "R15\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R16\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R17\tCONJUNCTION Arg1:T23 Arg2:T22\n",
      "R18\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R19\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R20\tUSED-FOR Arg1:T21 Arg2:T23\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-1095.ann\n",
      "T1\tMethod 24 75\tphrase-based statistical machine translation method\n",
      "T2\tMaterial 89 111\tnon-contiguous phrases\n",
      "T3\tGeneric 143 149\tmethod\n",
      "T4\tGeneric 170 177\tphrases\n",
      "T5\tMaterial 187 207\tword-aligned corpora\n",
      "T6\tMethod 225 254\tstatistical translation model\n",
      "T7\tGeneric 291 298\tphrases\n",
      "T8\tMethod 316 331\ttraining method\n",
      "T9\tMetric 346 383\tmaximization of  translation accuracy\n",
      "T10\tMetric 409 431\tNIST evaluation metric\n",
      "T11\tOtherScientificTerm 436 448\tTranslations\n",
      "T12\tMethod 478 497\tbeam-search decoder\n",
      "T13\tGeneric 571 577\tmethod\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R4\tCOREF Arg1:T4 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R6\tEVALUATE-FOR Arg1:T5 Arg2:T3\n",
      "R7\tCOREF Arg1:T7 Arg2:T4\n",
      "R8\tEVALUATE-FOR Arg1:T10 Arg2:T6\n",
      "R9\tCOREF Arg1:T13 Arg2:T1\n",
      "R10\tCOREF Arg1:T6 Arg2:T1\n",
      "R11\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-1101.ann\n",
      "T1\tOtherScientificTerm 33 55\tcomputational problems\n",
      "T2\tMethod 74 106\tprobabilistic translation models\n",
      "T3\tTask 162 181\tmachine translation\n",
      "T4\tGeneric 192 198\tmodels\n",
      "T5\tMethod 227 262\tprobabilistic context-free grammars\n",
      "T6\tOtherScientificTerm 367 395\texponential time lower-bound\n",
      "R1\tFEATURE-OF Arg1:T1 Arg2:T2\n",
      "R2\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R4\tCOREF Arg1:T4 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-1115.ann\n",
      "T1\tTask 29 64\tquestion-focused sentence retrieval\n",
      "T2\tMaterial 80 93\tnews articles\n",
      "T3\tMaterial 107 126\tmulti-event stories\n",
      "T4\tTask 462 488\tsentence retrieval problem\n",
      "T5\tMethod 503 533\tstochastic, graph-based method\n",
      "T6\tTask 641 662\tgeneric summarization\n",
      "T7\tGeneric 721 727\tmethod\n",
      "T8\tGeneric 750 752\tit\n",
      "T9\tGeneric 783 791\tbaseline\n",
      "T10\tOtherScientificTerm 874 899\tIDF-weighted word overlap\n",
      "T11\tGeneric 927 933\tmethod\n",
      "T12\tMetric 947 957\tTRDR score\n",
      "T13\tGeneric 1006 1014\tbaseline\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R6\tCOREF Arg1:T7 Arg2:T5\n",
      "R7\tCOREF Arg1:T11 Arg2:T7\n",
      "R8\tCOREF Arg1:T13 Arg2:T9\n",
      "R9\tEVALUATE-FOR Arg1:T12 Arg2:T11\n",
      "R10\tEVALUATE-FOR Arg1:T12 Arg2:T13\n",
      "R11\tCOREF Arg1:T8 Arg2:T7\n",
      "R12\tCOMPARE Arg1:T9 Arg2:T8\n",
      "R13\tCOMPARE Arg1:T11 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-1117.ann\n",
      "T1\tTask 39 59\tautomatic evaluation\n",
      "T2\tTask 39 113\tautomatic evaluation  of  machine translation  and  document summarization\n",
      "T3\tTask 65 84\tmachine translation\n",
      "T4\tTask 91 113\tdocument summarization\n",
      "T5\tGeneric 138 146\tapproach\n",
      "T6\tGeneric 165 172\tmeasure\n",
      "T7\tMetric 181 188\tPOURPRE\n",
      "T8\tTask 197 253\tautomatically evaluating answers to definition questions\n",
      "T9\tMaterial 587 620\tTREC 2003 and TREC 2004 QA tracks\n",
      "T10\tOtherScientificTerm 637 645\trankings\n",
      "T11\tGeneric 663 669\tmetric\n",
      "T12\tOtherScientificTerm 693 710\tofficial rankings\n",
      "T13\tMetric 724 731\tPOURPRE\n",
      "T14\tGeneric 776 783\tmetrics\n",
      "R1\tEVALUATE-FOR Arg1:T1 Arg2:T3\n",
      "R2\tEVALUATE-FOR Arg1:T1 Arg2:T4\n",
      "R3\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T7 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R6\tCOREF Arg1:T13 Arg2:T7\n",
      "R7\tCOREF Arg1:T11 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R9\tEVALUATE-FOR Arg1:T9 Arg2:T11\n",
      "R10\tCOREF Arg1:T11 Arg2:T13\n",
      "R11\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R12\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R13\tEVALUATE-FOR Arg1:T9 Arg2:T13\n",
      "R14\tEVALUATE-FOR Arg1:T9 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-2007.ann\n",
      "T1\tGeneric 15 21\tmethod\n",
      "T2\tOtherScientificTerm 38 80\tsystematic  patterns  in  translation data\n",
      "T3\tMaterial 89 117\tpart-of-speech tag sequences\n",
      "T4\tGeneric 141 149\tanalysis\n",
      "T5\tMethod 158 173\tdiagnostic tool\n",
      "T6\tMethod 205 232\tmachine translation systems\n",
      "T7\tGeneric 260 271\tapplication\n",
      "T8\tOtherScientificTerm 312 352\tpatterns  in  machine translation output\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R2\tCOREF Arg1:T1 Arg2:T4\n",
      "R3\tPART-OF Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R5\tCOREF Arg1:T7 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H89-1027.ann\n",
      "T1\tMethod 48 103\tphonetically-based spoken language understanding system\n",
      "T2\tMethod 113 119\tSUMMIT\n",
      "T3\tMethod 180 195\theuristic rules\n",
      "T4\tMethod 233 254\tknowledge engineering\n",
      "T5\tGeneric 261 269\tapproach\n",
      "T6\tOtherScientificTerm 295 311\tspeech knowledge\n",
      "T7\tMethod 358 376\tmathematical tools\n",
      "T8\tGeneric 385 391\tsystem\n",
      "T9\tOtherScientificTerm 394 402\tfeatures\n",
      "T10\tMethod 409 428\tdecision strategies\n",
      "T11\tMaterial 495 506\tspeech data\n",
      "T12\tGeneric 534 540\tsystem\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R3\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R5\tCOREF Arg1:T5 Arg2:T2\n",
      "R6\tCOREF Arg1:T8 Arg2:T5\n",
      "R7\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R8\tCOREF Arg1:T12 Arg2:T8\n",
      "R9\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H89-2019.ann\n",
      "T1\tMethod 48 116\tdomain-independent means of evaluating Spoken Language Systems (SLS)\n",
      "T2\tGeneric 134 142\tsoftware\n",
      "T3\tMethod 186 196\tComparator\n",
      "T4\tGeneric 214 228\tspecifications\n",
      "T5\tOtherScientificTerm 235 253\tanswer expressions\n",
      "T6\tMethod 262 289\tCommon Answer Specification\n",
      "T7\tMethod 297 300\tCAS\n",
      "T8\tMethod 309 319\tComparator\n",
      "T9\tMethod 362 365\tSLS\n",
      "T10\tMethod 439 466\tCommon Answer Specification\n",
      "T11\tOtherScientificTerm 484 514\tsyntax  of  answer expressions\n",
      "T12\tMethod 667 677\tComparator\n",
      "T13\tOtherScientificTerm 708 711\tCAS\n",
      "T14\tMethod 758 777\tComparator software\n",
      "T15\tMethod 815 827\tCAS approach\n",
      "R1\tCOREF Arg1:T3 Arg2:T2\n",
      "R2\tCOREF Arg1:T7 Arg2:T6\n",
      "R3\tCOREF Arg1:T8 Arg2:T3\n",
      "R4\tCOREF Arg1:T9 Arg2:T1\n",
      "R5\tCOREF Arg1:T10 Arg2:T7\n",
      "R6\tCOREF Arg1:T12 Arg2:T8\n",
      "R7\tCOREF Arg1:T13 Arg2:T10\n",
      "R8\tCOREF Arg1:T15 Arg2:T13\n",
      "R9\tCOREF Arg1:T14 Arg2:T8\n",
      "R10\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R11\tCOREF Arg1:T6 Arg2:T4\n",
      "R12\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R13\tCONJUNCTION Arg1:T2 Arg2:T4\n",
      "R14\tPART-OF Arg1:T2 Arg2:T1\n",
      "R15\tPART-OF Arg1:T4 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H89-2066.ann\n",
      "T1\tMethod 44 66\tspoken language system\n",
      "T2\tMaterial 109 120\tvoice input\n",
      "T3\tTask 127 154\tinteractive problem solving\n",
      "T4\tMaterial 181 198\tcontinuous speech\n",
      "T5\tTask 287 305\tspeech recognition\n",
      "T6\tTask 312 339\tnatural language processing\n",
      "T7\tTask 353 373\tspeech understanding\n",
      "T8\tGeneric 380 386\tsystem\n",
      "T9\tMethod 503 556\trobust and high-performance speech recognition system\n",
      "T10\tMethod 567 589\tsegment-based approach\n",
      "T11\tTask 595 615\tphonetic recognition\n",
      "T12\tMethod 623 641\trecognition system\n",
      "T13\tTask 679 706\tnatural language processing\n",
      "T14\tTask 720 749\tspoken language understanding\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R4\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R6\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R7\tCOREF Arg1:T8 Arg2:T1\n",
      "R8\tCOREF Arg1:T9 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R10\tCOREF Arg1:T12 Arg2:T9\n",
      "R11\tCONJUNCTION Arg1:T13 Arg2:T12\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R13\tCOREF Arg1:T14 Arg2:T7\n",
      "R14\tCOREF Arg1:T13 Arg2:T6\n",
      "R15\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R16\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H90-1011.ann\n",
      "T1\tGeneric 35 43\tapproach\n",
      "T2\tTask 48 55\tparsing\n",
      "T3\tTask 91 116\tunification-based parsing\n",
      "T4\tTask 126 171\tclassification-based knowledge representation\n",
      "T5\tMethod 178 218\tunification-based grammatical frameworks\n",
      "T6\tOtherScientificTerm 267 289\tlinguistic information\n",
      "T7\tGeneric 292 296\tthey\n",
      "T8\tMethod 364 408\tKL-ONE-like knowledge representation systems\n",
      "T9\tMethod 455 501\tclassification-based representation techniques\n",
      "T10\tOtherScientificTerm 522 563\tunification-based linguistic descriptions\n",
      "T11\tOtherScientificTerm 608 642\tsemantic and syntactic information\n",
      "T12\tGeneric 658 664\tsystem\n",
      "T13\tMethod 790 797\tparsing\n",
      "T14\tMethod 861 888\tKL-ONE style representation\n",
      "T15\tTask 895 902\tparsing\n",
      "T16\tTask 909 932\tsemantic interpretation\n",
      "T17\tMethod 961 977\tPSI-KLONE system\n",
      "T18\tTask 994 1001\tparsing\n",
      "T19\tMethod 1026 1043\tinference process\n",
      "T20\tMethod 1052 1086\tincremental description refinement\n",
      "R1\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R2\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R5\tCONJUNCTION Arg1:T4 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R7\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R8\tCOREF Arg1:T7 Arg2:T5\n",
      "R9\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R10\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R12\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R13\tUSED-FOR Arg1:T17 Arg2:T14\n",
      "R14\tCOREF Arg1:T18 Arg2:T15\n",
      "R15\tHYPONYM-OF Arg1:T20 Arg2:T19\n",
      "R16\tCOREF Arg1:T14 Arg2:T8\n",
      "R17\tCOREF Arg1:T15 Arg2:T13\n",
      "R18\tCOREF Arg1:T12 Arg2:T1\n",
      "R19\tUSED-FOR Arg1:T20 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H90-1016.ann\n",
      "T1\tGeneric 19 26\tmethods\n",
      "T2\tGeneric 31 39\thardware\n",
      "T3\tMethod 102 135\tintegrated Spoken Language System\n",
      "T4\tGeneric 151 161\talgorithms\n",
      "T5\tOtherScientificTerm 221 247\tN-Best sentence hypotheses\n",
      "T6\tOtherScientificTerm 261 286\tgrammar coverage problems\n",
      "T7\tMethod 298 351\tfully-connected first-order statistical class grammar\n",
      "T8\tMethod 360 383\tspeech-search algorithm\n",
      "T9\tOtherScientificTerm 406 411\tboard\n",
      "T10\tOtherScientificTerm 428 443\tIntel i860 chip\n",
      "T11\tOtherScientificTerm 493 498\tSUN 4\n",
      "T12\tOtherScientificTerm 505 520\tstraight C code\n",
      "T13\tOtherScientificTerm 529 534\tboard\n",
      "T14\tOtherScientificTerm 561 568\tVME bus\n",
      "T15\tOtherScientificTerm 578 582\tSUN4\n",
      "T16\tGeneric 605 611\tsystem\n",
      "T17\tMethod 630 653\tnatural language system\n",
      "T18\tOtherScientificTerm 660 680\tapplication back end\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R2\tPART-OF Arg1:T14 Arg2:T15\n",
      "R3\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R7\tCOMPARE Arg1:T10 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R10\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R11\tCOREF Arg1:T16 Arg2:T3\n",
      "R12\tCOREF Arg1:T8 Arg2:T4\n",
      "R13\tCOREF Arg1:T4 Arg2:T1\n",
      "R14\tPART-OF Arg1:T10 Arg2:T9\n",
      "R15\tCOREF Arg1:T9 Arg2:T13\n",
      "R16\tUSED-FOR Arg1:T13 Arg2:T16\n",
      "R17\tPART-OF Arg1:T17 Arg2:T13\n",
      "R18\tPART-OF Arg1:T18 Arg2:T13\n",
      "R19\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H90-1060.ann\n",
      "T1\tTask 47 93\tlarge vocabulary continuous speech recognition\n",
      "T2\tTask 135 200\tspeaker-independent (SI) training  of  hidden Markov models (HMM)\n",
      "T3\tMaterial 234 240\tspeech\n",
      "T4\tOtherScientificTerm 413 472\taveraging the  statistics  of  independently trained models\n",
      "T5\tOtherScientificTerm 496 527\tpooling of all the  speech data\n",
      "T6\tTask 610 624\tSI recognition\n",
      "T7\tMetric 648 663\tword error rate\n",
      "T8\tMaterial 714 746\tDARPA Resource Management corpus\n",
      "T9\tTask 905 928\tspeaker adaptation (SA)\n",
      "T10\tMaterial 945 954\tSI corpus\n",
      "T11\tMethod 1024 1054\tprobabilistic spectral mapping\n",
      "T12\tMethod 1156 1171\treference model\n",
      "T13\tTask 1315 1325\tadaptation\n",
      "T14\tMetric 1334 1344\terror rate\n",
      "T15\tTask 1408 1410\tSI\n",
      "R1\tEVALUATE-FOR Arg1:T10 Arg2:T9\n",
      "R2\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R3\tEVALUATE-FOR Arg1:T8 Arg2:T6\n",
      "R4\tCOREF Arg1:T13 Arg2:T9\n",
      "R5\tCOREF Arg1:T15 Arg2:T6\n",
      "R6\tCOMPARE Arg1:T4 Arg2:T5\n",
      "R7\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H91-1010.ann\n",
      "T1\tMethod 45 63\tLincoln CSR system\n",
      "T2\tMethod 90 108\tsemiphone modeling\n",
      "T3\tMethod 152 166\tduration model\n",
      "T4\tMetric 185 195\terror rate\n",
      "T5\tMethod 219 249\ttriphone and semiphone systems\n",
      "T6\tMethod 259 276\ttraining strategy\n",
      "T7\tMethod 408 434\trapid adaptation technique\n",
      "T8\tMethod 450 460\trecognizer\n",
      "T9\tMethod 488 519\tbigram back-off language models\n",
      "T10\tGeneric 526 532\tsystem\n",
      "T11\tTask 564 571\tRM task\n",
      "T12\tTask 581 594\tATIS CSR task\n",
      "T13\tTask 701 722\tRM and ATIS CSR tasks\n",
      "R1\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R3\tHYPONYM-OF Arg1:T2 Arg2:T5\n",
      "R4\tHYPONYM-OF Arg1:T11 Arg2:T13\n",
      "R5\tHYPONYM-OF Arg1:T12 Arg2:T13\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R8\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R9\tEVALUATE-FOR Arg1:T4 Arg2:T5\n",
      "R10\tCOREF Arg1:T1 Arg2:T10\n",
      "R11\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H91-1067.ann\n",
      "T1\tGeneric 37 44\tprogram\n",
      "T2\tMaterial 59 77\ttagged text corpus\n",
      "T3\tOtherScientificTerm 116 140\tsubcategorization frames\n",
      "T4\tMetric 302 322\tFalse positive rates\n",
      "T5\tOtherScientificTerm 356 380\tsubcategorization frames\n",
      "T6\tMaterial 500 528\tsubcategorization dictionary\n",
      "R1\tEVALUATE-FOR Arg1:T2 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H91-1077.ann\n",
      "T1\tGeneric 3 9\tmethod\n",
      "T2\tTask 14 30\tsense resolution\n",
      "T3\tMaterial 62 69\tWordNet\n",
      "T4\tMaterial 75 100\ton-line  lexical database\n",
      "T5\tOtherScientificTerm 121 139\tsemantic relations\n",
      "T6\tOtherScientificTerm 143 151\tsynonymy\n",
      "T7\tOtherScientificTerm 155 163\tantonymy\n",
      "T8\tOtherScientificTerm 167 175\thyponymy\n",
      "T9\tOtherScientificTerm 179 187\tmeronymy\n",
      "T10\tOtherScientificTerm 191 223\tcausal and troponymic entailment\n",
      "T11\tMaterial 277 284\tWordNet\n",
      "T12\tOtherScientificTerm 319 345\tsemantically related words\n",
      "T13\tTask 382 398\tsense resolution\n",
      "T14\tTask 408 423\ttext processing\n",
      "T15\tGeneric 502 512\tprocedures\n",
      "T16\tOtherScientificTerm 580 598\talternative senses\n",
      "T17\tOtherScientificTerm 608 623\tpolysemous word\n",
      "T18\tOtherScientificTerm 739 754\tpolysemous word\n",
      "T19\tOtherScientificTerm 978 993\tpolysemous word\n",
      "T20\tMaterial 1106 1113\tWordNet\n",
      "T21\tOtherScientificTerm 1150 1167\tsemantic distance\n",
      "T22\tGeneric 1372 1381\tprocedure\n",
      "T23\tTask 1432 1453\tinformation retrieval\n",
      "T24\tTask 1457 1479\tmechanical translation\n",
      "T25\tTask 1483 1511\tintelligent tutoring systems\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R2\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R3\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R6\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R7\tHYPONYM-OF Arg1:T7 Arg2:T5\n",
      "R8\tHYPONYM-OF Arg1:T8 Arg2:T5\n",
      "R9\tHYPONYM-OF Arg1:T9 Arg2:T5\n",
      "R10\tHYPONYM-OF Arg1:T10 Arg2:T5\n",
      "R11\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R12\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R13\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R14\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R15\tCOREF Arg1:T11 Arg2:T3\n",
      "R16\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R17\tCOREF Arg1:T20 Arg2:T11\n",
      "R18\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R19\tUSED-FOR Arg1:T22 Arg2:T24\n",
      "R20\tUSED-FOR Arg1:T22 Arg2:T25\n",
      "R21\tCONJUNCTION Arg1:T23 Arg2:T24\n",
      "R22\tCONJUNCTION Arg1:T24 Arg2:T25\n",
      "R23\tHYPONYM-OF Arg1:T22 Arg2:T15\n",
      "R24\tPART-OF Arg1:T5 Arg2:T3\n",
      "R25\tHYPONYM-OF Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H92-1003.ann\n",
      "T1\tMaterial 46 68\tspoken language corpus\n",
      "T2\tTask 79 122\tATIS (Air Travel Information System) domain\n",
      "T3\tGeneric 131 146\tdata collection\n",
      "T4\tMethod 319 354\tmulti-site data collection paradigm\n",
      "T5\tGeneric 413 423\tcollection\n",
      "T6\tMaterial 469 487\tspontaneous speech\n",
      "T7\tTask 519 595\tmulti-site common evaluation of speech, natural language and spoken language\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T5 Arg2:T3\n",
      "R4\tEVALUATE-FOR Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H92-1010.ann\n",
      "T1\tTask 88 105\tspeech processing\n",
      "T2\tTask 143 170\tHuman-Machine Communication\n",
      "T3\tTask 185 212\tNatural Language Processing\n",
      "T4\tTask 217 256\tNon Verbal and Multimodal Communication\n",
      "R1\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R3\tHYPONYM-OF Arg1:T4 Arg2:T2\n",
      "R4\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H92-1017.ann\n",
      "T1\tGeneric 42 73\tdomain-independent capabilities\n",
      "T2\tMethod 98 142\tParamax spoken language understanding system\n",
      "T3\tTask 147 170\tnon-monotonic reasoning\n",
      "T4\tTask 175 204\timplicit reference resolution\n",
      "T5\tTask 213 238\tdatabase query paraphrase\n",
      "T6\tMaterial 286 320\tFebruary 1992 ATIS benchmark tests\n",
      "T7\tMethod 526 573\tn-best speech/language integration architecture\n",
      "T8\tMetric 589 603\tOCR   accuracy\n",
      "R1\tPART-OF Arg1:T1 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T4 Arg2:T1\n",
      "R4\tHYPONYM-OF Arg1:T5 Arg2:T1\n",
      "R5\tEVALUATE-FOR Arg1:T8 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H92-1026.ann\n",
      "T1\tMethod 18 68\tgenerative probabilistic model of natural language\n",
      "T2\tMethod 87 90\tHBG\n",
      "T3\tOtherScientificTerm 128 150\tlinguistic information\n",
      "T4\tTask 164 173\tambiguity\n",
      "T5\tMethod 179 182\tHBG\n",
      "T6\tOtherScientificTerm 198 254\tlexical, syntactic, semantic, and structural information\n",
      "T7\tOtherScientificTerm 266 276\tparse tree\n",
      "T8\tTask 288 310\tdisambiguation process\n",
      "T9\tMaterial 338 367\tcorpus of bracketed sentences\n",
      "T10\tMaterial 381 389\tTreebank\n",
      "T11\tMethod 414 436\tdecision tree building\n",
      "T12\tOtherScientificTerm 478 488\tparse tree\n",
      "T13\tOtherScientificTerm 523 528\tparse\n",
      "T14\tTask 606 624\tgrammar  tailoring\n",
      "T15\tMethod 640 664\tlinguistic introspection\n",
      "T16\tOtherScientificTerm 705 710\tparse\n",
      "T17\tOtherScientificTerm 718 736\thead-to-head tests\n",
      "T18\tMethod 771 807\trobust  probabilistic parsing models\n",
      "T19\tMethod 826 831\tP-CFG\n",
      "T20\tMethod 839 848\tHBG model\n",
      "T21\tMethod 877 882\tP-CFG\n",
      "T22\tMetric 902 924\tparsing accuracy  rate\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tCOMPARE Arg1:T20 Arg2:T21\n",
      "R4\tCOREF Arg1:T2 Arg2:T1\n",
      "R5\tCOREF Arg1:T5 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T8\n",
      "R7\tCOREF Arg1:T10 Arg2:T9\n",
      "R8\tCONJUNCTION Arg1:T9 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R10\tCOREF Arg1:T19 Arg2:T21\n",
      "R11\tCOREF Arg1:T20 Arg2:T5\n",
      "R12\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R13\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R14\tUSED-FOR Arg1:T9 Arg2:T12\n",
      "R15\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R16\tEVALUATE-FOR Arg1:T22 Arg2:T20\n",
      "R17\tHYPONYM-OF Arg1:T19 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H92-1036.ann\n",
      "T1\tMethod 15 46\tmaximum a posteriori estimation\n",
      "T2\tMethod 52 99\tcontinuous density hidden Markov models (CDHMM)\n",
      "T3\tMethod 118 145\tMLE reestimation algorithms\n",
      "T4\tMethod 161 187\tforward-backward algorithm\n",
      "T5\tMethod 198 225\tsegmental k-means algorithm\n",
      "T6\tOtherScientificTerm 247 268\treestimation formulas\n",
      "T7\tMethod 285 332\tHMM with Gaussian mixture observation densities\n",
      "T8\tMethod 369 386\tBayesian learning\n",
      "T9\tTask 441 473\tspeech recognition  applications\n",
      "T10\tTask 483 502\tparameter smoothing\n",
      "T11\tTask 507 525\tspeaker adaptation\n",
      "T12\tTask 530 552\tspeaker group modeling\n",
      "T13\tTask 559 578\tcorrective training\n",
      "T14\tGeneric 619 631\tapplications\n",
      "T15\tMethod 679 702\tMAP estimation approach\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R2\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R3\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R4\tCONJUNCTION Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R7\tHYPONYM-OF Arg1:T10 Arg2:T9\n",
      "R8\tHYPONYM-OF Arg1:T11 Arg2:T9\n",
      "R9\tHYPONYM-OF Arg1:T12 Arg2:T9\n",
      "R10\tHYPONYM-OF Arg1:T13 Arg2:T9\n",
      "R11\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R12\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R13\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R14\tCOREF Arg1:T14 Arg2:T9\n",
      "R15\tCOREF Arg1:T15 Arg2:T1\n",
      "R16\tEVALUATE-FOR Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H92-1045.ann\n",
      "T1\tOtherScientificTerm 36 52\tpolysemous words\n",
      "T2\tMethod 166 199\tword-sense disambiguation systems\n",
      "T3\tGeneric 203 206\tone\n",
      "T4\tMaterial 219 237\tbilingual material\n",
      "T5\tMaterial 245 262\tCanadian Hansards\n",
      "T6\tGeneric 274 279\tother\n",
      "T7\tMaterial 292 312\tmonolingual material\n",
      "T8\tMaterial 317 334\tRoget's Thesaurus\n",
      "T9\tMaterial 341 363\tGrolier's Encyclopedia\n",
      "T10\tOtherScientificTerm 432 441\tdiscourse\n",
      "T11\tOtherScientificTerm 466 481\tpolysemous word\n",
      "T12\tOtherScientificTerm 534 556\twell-written discourse\n",
      "T13\tOtherScientificTerm 752 761\tdiscourse\n",
      "T14\tOtherScientificTerm 842 852\tconstraint\n",
      "T15\tMethod 892 927\tword-sense disambiguation algorithm\n",
      "T16\tGeneric 944 946\tit\n",
      "T17\tMethod 984 1009\tdisambiguation algorithms\n",
      "T18\tOtherScientificTerm 1041 1061\tdiscourse constraint\n",
      "R1\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T6 Arg2:T2\n",
      "R3\tEVALUATE-FOR Arg1:T4 Arg2:T3\n",
      "R4\tCOREF Arg1:T5 Arg2:T4\n",
      "R5\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R6\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R7\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R8\tCONJUNCTION Arg1:T3 Arg2:T6\n",
      "R9\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R10\tEVALUATE-FOR Arg1:T16 Arg2:T17\n",
      "R11\tCOREF Arg1:T15 Arg2:T2\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\H93-1076.ann\n",
      "T1\tGeneric 5 11\tthemes\n",
      "T2\tTask 29 61\tspeech and text image processing\n",
      "T3\tMethod 122 144\trecognition technology\n",
      "T4\tTask 150 180\tdocument-oriented applications\n",
      "T5\tGeneric 183 186\tOne\n",
      "T6\tGeneric 209 216\tsystems\n",
      "T7\tMethod 264 279\ttext processors\n",
      "T8\tMaterial 306 334\taudio and scanned image data\n",
      "T9\tGeneric 355 360\ttheme\n",
      "T10\tMethod 376 409\tspeech and text-image recognition\n",
      "T11\tOtherScientificTerm 467 496\tdocuments with signal content\n",
      "T12\tGeneric 526 534\tresearch\n",
      "T13\tGeneric 578 584\tthemes\n",
      "T14\tMethod 589 606\ttext-image editor\n",
      "T15\tMethod 615 626\twordspotter\n",
      "T16\tTask 633 659\tvoice editing and indexing\n",
      "T17\tMethod 673 691\tdecoding framework\n",
      "T18\tTask 698 732\tscanned-document content retrieval\n",
      "T19\tTask 821 867\tsignal-based document processing functionality\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R3\tHYPONYM-OF Arg1:T5 Arg2:T1\n",
      "R4\tCOREF Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R6\tHYPONYM-OF Arg1:T9 Arg2:T1\n",
      "R7\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R8\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R9\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R10\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R11\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R12\tPART-OF Arg1:T1 Arg2:T2\n",
      "R13\tCOREF Arg1:T13 Arg2:T1\n",
      "R14\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R15\tHYPONYM-OF Arg1:T14 Arg2:T12\n",
      "R16\tHYPONYM-OF Arg1:T15 Arg2:T12\n",
      "R17\tHYPONYM-OF Arg1:T17 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H94-1064.ann\n",
      "T1\tTask 51 119\tmultilingual, speaker-independent, large vocabulary speech dictation\n",
      "T2\tMethod 141 157\tLIMSI recognizer\n",
      "T3\tMaterial 187 206\tARPA NOV93 CSR test\n",
      "T4\tMaterial 255 275\tWSJ and BREF corpora\n",
      "T5\tGeneric 334 341\tcorpora\n",
      "T6\tTask 344 360\tword recognition\n",
      "T7\tGeneric 445 455\trecognizer\n",
      "T8\tMethod 470 492\tcontinuous density HMM\n",
      "T9\tMethod 500 516\tGaussian mixture\n",
      "T10\tTask 523 540\tacoustic modeling\n",
      "T11\tMethod 547 564\tn-gram statistics\n",
      "T12\tMaterial 584 599\tnewspaper texts\n",
      "T13\tTask 606 623\tlanguage modeling\n",
      "T14\tGeneric 630 640\trecognizer\n",
      "T15\tMethod 649 687\ttime-synchronous graph-search strategy\n",
      "T16\tMethod 766 797\tbigram back-off language models\n",
      "T17\tOtherScientificTerm 847 857\tword graph\n",
      "T18\tMethod 879 885\tbigram\n",
      "T19\tMethod 904 926\ttrigram language model\n",
      "T20\tTask 930 947\tAcoustic modeling\n",
      "T21\tOtherScientificTerm 955 978\tcepstrum-based features\n",
      "T22\tMethod 982 1034\tcontext-dependent phone models (intra and interword)\n",
      "T23\tMethod 1038 1059\tphone duration models\n",
      "T24\tMethod 1067 1087\tsex-dependent models\n",
      "R1\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R2\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R3\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R4\tEVALUATE-FOR Arg1:T3 Arg2:T2\n",
      "R5\tEVALUATE-FOR Arg1:T4 Arg2:T2\n",
      "R6\tCOREF Arg1:T7 Arg2:T2\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R9\tEVALUATE-FOR Arg1:T12 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T11 Arg2:T7\n",
      "R11\tCONJUNCTION Arg1:T8 Arg2:T11\n",
      "R12\tCOREF Arg1:T14 Arg2:T7\n",
      "R13\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R14\tCONJUNCTION Arg1:T16 Arg2:T15\n",
      "R15\tUSED-FOR Arg1:T16 Arg2:T14\n",
      "R16\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R17\tCOREF Arg1:T20 Arg2:T10\n",
      "R18\tCONJUNCTION Arg1:T19 Arg2:T17\n",
      "R19\tUSED-FOR Arg1:T22 Arg2:T20\n",
      "R20\tUSED-FOR Arg1:T23 Arg2:T20\n",
      "R21\tUSED-FOR Arg1:T24 Arg2:T20\n",
      "R22\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "R23\tCONJUNCTION Arg1:T22 Arg2:T23\n",
      "R24\tCONJUNCTION Arg1:T23 Arg2:T24\n",
      "R25\tHYPONYM-OF Arg1:T3 Arg2:T5\n",
      "R26\tHYPONYM-OF Arg1:T4 Arg2:T5\n",
      "R27\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R28\tEVALUATE-FOR Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H94-1102.ann\n",
      "T1\tMethod 93 139\tcontinuous speech recognition (CSR) techniques\n",
      "T2\tTask 169 198\tSpoken Language Systems (SLS)\n",
      "T3\tTask 241 285\tmilitary and civilian computer-based systems\n",
      "T4\tTask 367 411\tspeech recognition and understanding systems\n",
      "T5\tMethod 454 480\tspoken language technology\n",
      "T6\tTask 488 517\tmilitary and civilian systems\n",
      "T7\tMethod 568 571\tCSR\n",
      "T8\tTask 577 612\tmobile military command and control\n",
      "T9\tMethod 668 686\tacoustic modelling\n",
      "T10\tMethod 689 701\trapid search\n",
      "T11\tMethod 708 746\trecognition-time adaptation techniques\n",
      "T12\tMethod 760 780\tlarge-vocabulary CSR\n",
      "T13\tGeneric 805 815\ttechniques\n",
      "T14\tMaterial 828 861\tARPA large-vocabulary CSR corpora\n",
      "T15\tTask 870 896\tmilitary application tasks\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R5\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R6\tCOREF Arg1:T6 Arg2:T3\n",
      "R7\tCOREF Arg1:T5 Arg2:T2\n",
      "R8\tCOREF Arg1:T7 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R10\tUSED-FOR Arg1:T9 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R12\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R13\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R14\tHYPONYM-OF Arg1:T9 Arg2:T13\n",
      "R15\tHYPONYM-OF Arg1:T10 Arg2:T13\n",
      "R16\tHYPONYM-OF Arg1:T11 Arg2:T13\n",
      "R17\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R18\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R19\tUSED-FOR Arg1:T9 Arg2:T15\n",
      "R20\tUSED-FOR Arg1:T10 Arg2:T15\n",
      "R21\tUSED-FOR Arg1:T11 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-2013.ann\n",
      "T1\tGeneric 15 19\ttool\n",
      "T2\tMethod 30 35\tILIMP\n",
      "T3\tMaterial 62 82\traw text  in  French\n",
      "T4\tGeneric 269 273\ttool\n",
      "T5\tTask 325 352\tanaphoric occurrences of il\n",
      "T6\tMethod 369 395\tanaphora resolution system\n",
      "T7\tMetric 544 558\tprecision rate\n",
      "T8\tMethod 565 570\tILIMP\n",
      "T9\tGeneric 630 635\ttasks\n",
      "T10\tGeneric 648 654\tmethod\n",
      "T11\tMethod 671 676\tILIMP\n",
      "T12\tMethod 724 729\tILIMP\n",
      "T13\tMethod 736 770\tmodular  syntactic analysis system\n",
      "R1\tEVALUATE-FOR Arg1:T7 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R3\tCOREF Arg1:T2 Arg2:T1\n",
      "R4\tCOREF Arg1:T1 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T12 Arg2:T11\n",
      "R9\tCOREF Arg1:T11 Arg2:T8\n",
      "R10\tCOREF Arg1:T8 Arg2:T4\n",
      "R11\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-2014.ann\n",
      "T1\tMetric 3 32\tAutomatic  evaluation metrics\n",
      "T2\tTask 39 71\tMachine Translation (MT) systems\n",
      "T3\tMetric 84 88\tBLEU\n",
      "T4\tMetric 94 98\tNIST\n",
      "T5\tGeneric 133 137\tthey\n",
      "T6\tTask 164 193\tassessment of  language pairs\n",
      "T7\tOtherScientificTerm 179 193\tlanguage pairs\n",
      "T8\tOtherScientificTerm 201 216\tEnglish-Chinese\n",
      "T9\tOtherScientificTerm 222 238\tEnglish-Japanese\n",
      "T10\tTask 258 283\tword segmentation problem\n",
      "T11\tMetric 355 359\tBLEU\n",
      "T12\tMethod 365 377\tword n-grams\n",
      "T13\tOtherScientificTerm 407 423\tcharacter  level\n",
      "T14\tMetric 437 441\tBLEU\n",
      "T15\tOtherScientificTerm 451 467\tcharacter  level\n",
      "T16\tTask 484 509\tword segmentation problem\n",
      "T17\tGeneric 513 515\tit\n",
      "T18\tMethod 554 572\tcommercial systems\n",
      "T19\tMethod 625 647\tstatistical MT systems\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R2\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R3\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R4\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R5\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R6\tCOREF Arg1:T14 Arg2:T11\n",
      "R7\tCOREF Arg1:T11 Arg2:T3\n",
      "R8\tCOMPARE Arg1:T18 Arg2:T19\n",
      "R9\tCOREF Arg1:T17 Arg2:T14\n",
      "R10\tCOREF Arg1:T16 Arg2:T10\n",
      "R11\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R12\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R13\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R14\tEVALUATE-FOR Arg1:T17 Arg2:T18\n",
      "R15\tEVALUATE-FOR Arg1:T17 Arg2:T19\n",
      "R16\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R17\tEVALUATE-FOR Arg1:T1 Arg2:T2\n",
      "R18\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R19\tHYPONYM-OF Arg1:T4 Arg2:T1\n",
      "R20\tCOREF Arg1:T1 Arg2:T5\n",
      "R21\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-2021.ann\n",
      "T1\tMethod 122 150\tChinese-to-English SMT model\n",
      "T2\tTask 165 190\tword sense disambiguation\n",
      "T3\tMethod 222 248\tWSD evaluation methodology\n",
      "T4\tMaterial 275 313\tSenseval-3 Chinese lexical sample task\n",
      "T5\tMethod 370 419\tdedicated  word sense disambiguation (WSD) models\n",
      "T6\tMaterial 447 476\tSenseval  series of workshops\n",
      "T7\tMetric 528 539\tBLEU scores\n",
      "T8\tTask 545 582\tstatistical machine translation (SMT)\n",
      "T9\tMethod 599 609\tSMT models\n",
      "T10\tTask 645 656\ttranslation\n",
      "T11\tMetric 733 747\tWSD   accuracy\n",
      "T12\tMethod 753 763\tSMT models\n",
      "T13\tGeneric 808 812\tthat\n",
      "T14\tMethod 820 841\tdedicated  WSD models\n",
      "T15\tMetric 892 906\tWSD   accuracy\n",
      "T16\tMethod 928 938\tSMT models\n",
      "T17\tGeneric 971 975\tthat\n",
      "T18\tMethod 987 1008\tdedicated  WSD models\n",
      "T19\tMethod 1118 1128\tSMT models\n",
      "T20\tMethod 1169 1190\tdedicated  WSD models\n",
      "T21\tMethod 1204 1207\tSMT\n",
      "T22\tMethod 1265 1275\tWSD models\n",
      "R1\tEVALUATE-FOR Arg1:T2 Arg2:T1\n",
      "R2\tEVALUATE-FOR Arg1:T7 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R4\tCOREF Arg1:T21 Arg2:T19\n",
      "R5\tCOREF Arg1:T19 Arg2:T16\n",
      "R6\tCOREF Arg1:T16 Arg2:T12\n",
      "R7\tEVALUATE-FOR Arg1:T4 Arg2:T1\n",
      "R8\tEVALUATE-FOR Arg1:T3 Arg2:T1\n",
      "R9\tEVALUATE-FOR Arg1:T11 Arg2:T12\n",
      "R10\tCOREF Arg1:T12 Arg2:T9\n",
      "R11\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R12\tCOREF Arg1:T14 Arg2:T18\n",
      "R13\tCOREF Arg1:T20 Arg2:T18\n",
      "R14\tCOMPARE Arg1:T19 Arg2:T20\n",
      "R15\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "R16\tEVALUATE-FOR Arg1:T6 Arg2:T5\n",
      "R17\tCOREF Arg1:T14 Arg2:T5\n",
      "R18\tCOREF Arg1:T22 Arg2:T20\n",
      "R19\tCOMPARE Arg1:T17 Arg2:T15\n",
      "R20\tCOMPARE Arg1:T13 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-2043.ann\n",
      "T1\tMethod 8 35\tnatural language processing\n",
      "T2\tTask 55 67\ttrend survey\n",
      "T3\tTask 55 116\ttrend survey on  Japanese natural language processing studies\n",
      "T4\tMaterial 72 116\tJapanese natural language processing studies\n",
      "T5\tMaterial 412 424\tJapanese NLP\n",
      "T6\tTask 466 479\ttrend surveys\n",
      "T7\tMethod 487 490\tNLP\n",
      "R1\tCOREF Arg1:T6 Arg2:T2\n",
      "R2\tCOREF Arg1:T7 Arg2:T1\n",
      "R3\tCOREF Arg1:T5 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-2044.ann\n",
      "T1\tMaterial 9 25\tChinese language\n",
      "T2\tTask 105 154\tambiguity resolution  of  right-side dependencies\n",
      "T3\tTask 174 192\tdependency parsing\n",
      "T4\tMethod 254 285\tshift-reduce dependency parsers\n",
      "T5\tMetric 310 322\tconnectivity\n",
      "T6\tOtherScientificTerm 330 345\tdependency tree\n",
      "T7\tOtherScientificTerm 387 410\tright-side dependencies\n",
      "T8\tMethod 436 476\ttwo-phase shift-reduce dependency parser\n",
      "T9\tMethod 488 500\tSVM learning\n",
      "T10\tOtherScientificTerm 508 528\tleft-side dependents\n",
      "T11\tOtherScientificTerm 535 564\tright-side nominal dependents\n",
      "T12\tOtherScientificTerm 596 624\tright-side verbal dependents\n",
      "T13\tGeneric 692 698\tmethod\n",
      "T14\tMethod 721 752\tshift-reduce dependency parsers\n",
      "T15\tMaterial 763 777\tChine language\n",
      "T16\tMetric 804 823\tdependency accuracy\n",
      "R1\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R2\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R3\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R4\tCONJUNCTION Arg1:T12 Arg2:T11\n",
      "R5\tCOREF Arg1:T14 Arg2:T4\n",
      "R6\tEVALUATE-FOR Arg1:T16 Arg2:T14\n",
      "R7\tCOREF Arg1:T13 Arg2:T8\n",
      "R8\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R9\tEVALUATE-FOR Arg1:T15 Arg2:T13\n",
      "R10\tCOREF Arg1:T15 Arg2:T1\n",
      "R11\tEVALUATE-FOR Arg1:T16 Arg2:T13\n",
      "R12\tEVALUATE-FOR Arg1:T5 Arg2:T6\n",
      "R13\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-2048.ann\n",
      "T1\tMethod 2 39\tStatistical machine translation (SMT)\n",
      "T2\tTask 79 106\tnatural language processing\n",
      "T3\tMethod 230 233\tSMT\n",
      "T4\tMethod 265 295\trule-based translation systems\n",
      "T5\tTask 392 411\ttranslation systems\n",
      "T6\tOtherScientificTerm 417 436\tnew  language pairs\n",
      "T7\tOtherScientificTerm 441 453\tnew  domains\n",
      "T8\tMethod 511 542\tstatistical machine translation\n",
      "T9\tMethod 670 680\tSMT system\n",
      "T10\tMethod 787 790\tSMT\n",
      "T11\tMethod 829 833\tSTTK\n",
      "T12\tMethod 840 880\tstatistical machine translation tool kit\n",
      "T13\tTask 932 950\ttranslation system\n",
      "T14\tMethod 955 959\tSTTK\n",
      "T15\tMethod 1080 1090\tSMT system\n",
      "T16\tGeneric 1094 1096\tIt\n",
      "T17\tMethod 1138 1194\trule-based and example based machine translation modules\n",
      "T18\tTask 1208 1247\tmulti engine machine translation system\n",
      "T19\tGeneric 1277 1285\ttool kit\n",
      "R1\tCOMPARE Arg1:T3 Arg2:T4\n",
      "R2\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T3 Arg2:T1\n",
      "R4\tCOREF Arg1:T8 Arg2:T3\n",
      "R5\tCOREF Arg1:T9 Arg2:T8\n",
      "R6\tCOREF Arg1:T10 Arg2:T8\n",
      "R7\tHYPONYM-OF Arg1:T11 Arg2:T12\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R9\tCOREF Arg1:T13 Arg2:T5\n",
      "R10\tCOREF Arg1:T14 Arg2:T11\n",
      "R11\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R12\tCOREF Arg1:T16 Arg2:T14\n",
      "R13\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R14\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R15\tUSED-FOR Arg1:T16 Arg2:T18\n",
      "R16\tCOREF Arg1:T19 Arg2:T14\n",
      "R17\tHYPONYM-OF Arg1:T4 Arg2:T17\n",
      "R18\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R19\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R20\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-3022.ann\n",
      "T1\tMethod 24 48\tword segmentation system\n",
      "T2\tGeneric 102 110\tapproach\n",
      "T3\tTask 115 128\tword breaking\n",
      "T4\tTask 135 153\tOOV identification\n",
      "T5\tGeneric 297 303\tsystem\n",
      "T6\tOtherScientificTerm 344 364\tsegmentation bakeoff\n",
      "T7\tOtherScientificTerm 370 377\tPK-open\n",
      "T8\tOtherScientificTerm 381 390\tPK-closed\n",
      "T9\tOtherScientificTerm 394 401\tAS-open\n",
      "T10\tOtherScientificTerm 405 414\tAS-closed\n",
      "T11\tOtherScientificTerm 418 425\tHK-open\n",
      "T12\tOtherScientificTerm 429 438\tHK-closed\n",
      "T13\tOtherScientificTerm 442 450\tMSR-open\n",
      "T14\tOtherScientificTerm 457 468\tMSR- closed\n",
      "T15\tOtherScientificTerm 525 533\tMSR-open\n",
      "T16\tOtherScientificTerm 537 546\tMSR-close\n",
      "T17\tOtherScientificTerm 553 560\tPK-open\n",
      "T18\tGeneric 627 633\tsystem\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R3\tCOREF Arg1:T5 Arg2:T1\n",
      "R4\tHYPONYM-OF Arg1:T7 Arg2:T6\n",
      "R5\tHYPONYM-OF Arg1:T8 Arg2:T6\n",
      "R6\tHYPONYM-OF Arg1:T9 Arg2:T6\n",
      "R7\tHYPONYM-OF Arg1:T10 Arg2:T6\n",
      "R8\tHYPONYM-OF Arg1:T11 Arg2:T6\n",
      "R9\tCOREF Arg1:T16 Arg2:T14\n",
      "R10\tCOREF Arg1:T17 Arg2:T7\n",
      "R11\tCOREF Arg1:T18 Arg2:T5\n",
      "R12\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R13\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R14\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R15\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R16\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R17\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R18\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R19\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R20\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "R21\tHYPONYM-OF Arg1:T12 Arg2:T6\n",
      "R22\tHYPONYM-OF Arg1:T13 Arg2:T6\n",
      "R23\tHYPONYM-OF Arg1:T14 Arg2:T6\n",
      "R24\tCOREF Arg1:T13 Arg2:T15\n",
      "R25\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R26\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-4008.ann\n",
      "T1\tMaterial 2 30\tTaiwan Child Language Corpus\n",
      "T2\tGeneric 203 209\tcorpus\n",
      "T3\tMaterial 223 268\tChild Language Data Exchange System (CHILDES)\n",
      "T4\tGeneric 288 294\tcorpus\n",
      "T5\tTask 354 369\tdata collection\n",
      "T6\tTask 373 386\ttranscription\n",
      "T7\tTask 390 407\tword segmentation\n",
      "T8\tTask 415 440\tpart-of-speech annotation\n",
      "T9\tGeneric 451 457\tcorpus\n",
      "T10\tGeneric 481 487\tcorpus\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R3\tCOREF Arg1:T2 Arg2:T1\n",
      "R4\tCOREF Arg1:T4 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R8\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R9\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R10\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R11\tCOREF Arg1:T9 Arg2:T4\n",
      "R12\tCOREF Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-4010.ann\n",
      "T1\tMaterial 57 80\tEnglish-Chinese bitexts\n",
      "T2\tGeneric 135 139\tthem\n",
      "T3\tMethod 187 203\tnumbering system\n",
      "T4\tOtherScientificTerm 213 233\tlegal text hierarchy\n",
      "T5\tMaterial 319 335\tbilingual corpus\n",
      "T6\tGeneric 503 505\tIt\n",
      "T7\tTask 535 556\tempirical MT research\n",
      "T8\tMaterial 636 659\tEnglish-Chinese bitexts\n",
      "R1\tCOREF Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T6 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R4\tCOREF Arg1:T8 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-5003.ann\n",
      "T1\tTask 14 49\tmachine translation (MT) evaluation\n",
      "T2\tTask 86 136\tsentence-level semantic equivalence classification\n",
      "T3\tMetric 198 219\tMT evaluation methods\n",
      "T4\tMetric 221 225\tBLEU\n",
      "T5\tMetric 227 231\tNIST\n",
      "T6\tMetric 233 236\tWER\n",
      "T7\tMetric 241 244\tPER\n",
      "T8\tMethod 260 271\tclassifiers\n",
      "T9\tTask 285 305\tsemantic equivalence\n",
      "T10\tTask 312 322\tentailment\n",
      "T11\tMethod 353 374\tclassification method\n",
      "T12\tMetric 386 389\tPER\n",
      "T13\tOtherScientificTerm 408 434\tpart of speech information\n",
      "T14\tTask 472 500\tword matches and non-matches\n",
      "T15\tMethod 545 569\tMT evaluation techniques\n",
      "T16\tOtherScientificTerm 599 607\tfeatures\n",
      "T17\tTask 614 639\tparaphrase classification\n",
      "T18\tTask 665 675\tentailment\n",
      "T19\tGeneric 684 693\ttechnique\n",
      "T20\tTask 731 756\tparaphrase classification\n",
      "T21\tMetric 731 765\tparaphrase classification accuracy\n",
      "T22\tGeneric 790 796\tmodels\n",
      "R1\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R3\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R6\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R7\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R8\tHYPONYM-OF Arg1:T7 Arg2:T3\n",
      "R9\tHYPONYM-OF Arg1:T6 Arg2:T3\n",
      "R10\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R11\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R12\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R13\tUSED-FOR Arg1:T3 Arg2:T8\n",
      "R14\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R15\tCOREF Arg1:T11 Arg2:T8\n",
      "R16\tCOREF Arg1:T12 Arg2:T7\n",
      "R17\tCOREF Arg1:T15 Arg2:T3\n",
      "R18\tUSED-FOR Arg1:T15 Arg2:T17\n",
      "R19\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R20\tUSED-FOR Arg1:T15 Arg2:T18\n",
      "R21\tCOREF Arg1:T19 Arg2:T11\n",
      "R22\tCOMPARE Arg1:T19 Arg2:T22\n",
      "R23\tCOREF Arg1:T20 Arg2:T17\n",
      "R24\tEVALUATE-FOR Arg1:T21 Arg2:T19\n",
      "R25\tEVALUATE-FOR Arg1:T21 Arg2:T22\n",
      "R26\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R27\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-5004.ann\n",
      "T1\tTask 27 63\tcompositional classes of paraphrases\n",
      "T2\tMethod 86 110\tclass-oriented framework\n",
      "T3\tMaterial 128 147\tparaphrase examples\n",
      "T4\tMaterial 160 182\tsentential paraphrases\n",
      "T5\tMethod 250 280\tautomatic candidate generation\n",
      "T6\tMethod 287 303\tmanual judgement\n",
      "T7\tMaterial 349 366\tparaphrase corpus\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R6\tCOREF Arg1:T4 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-5008.ann\n",
      "T1\tGeneric 14 20\tmethod\n",
      "T2\tOtherScientificTerm 51 61\tparaphrase\n",
      "T3\tMetric 135 174\tmachine translation evaluation measures\n",
      "T4\tMetric 182 186\tBLEU\n",
      "T5\tMetric 193 197\tNIST\n",
      "T6\tOtherScientificTerm 233 244\tparaphrases\n",
      "T7\tMetric 290 304\tgrammaticality\n",
      "T8\tMetric 355 377\tequivalence in meaning\n",
      "T9\tOtherScientificTerm 403 414\tparaphrases\n",
      "T10\tMethod 427 446\tmeaning equivalence\n",
      "T11\tMethod 452 462\tentailment\n",
      "T12\tMetric 491 534\tinternal  lexical and syntactical variation\n",
      "T13\tOtherScientificTerm 549 560\tparaphrases\n",
      "T14\tOtherScientificTerm 594 612\thand-produced sets\n",
      "T15\tOtherScientificTerm 621 631\tparaphrase\n",
      "T16\tGeneric 655 661\tmethod\n",
      "T17\tTask 717 730\tMT evaluation\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R3\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R4\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R6\tCONJUNCTION Arg1:T8 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R9\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R10\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R11\tCOREF Arg1:T16 Arg2:T1\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R13\tCONJUNCTION Arg1:T12 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-5009.ann\n",
      "T1\tGeneric 25 42\tevaluation method\n",
      "T2\tMethod 57 78\tlatent variable model\n",
      "T3\tOtherScientificTerm 85 96\tparaphrases\n",
      "T4\tOtherScientificTerm 185 200\tlatent variable\n",
      "T5\tGeneric 210 215\tmodel\n",
      "T6\tOtherScientificTerm 295 305\tparaphrase\n",
      "T7\tGeneric 426 432\tmethod\n",
      "T8\tMetric 588 596\taccuracy\n",
      "T9\tGeneric 615 621\tmethod\n",
      "T10\tOtherScientificTerm 640 657\ttopic information\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T5 Arg2:T2\n",
      "R3\tEVALUATE-FOR Arg1:T1 Arg2:T3\n",
      "R4\tCOREF Arg1:T7 Arg2:T1\n",
      "R5\tCOREF Arg1:T9 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R7\tEVALUATE-FOR Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-6010.ann\n",
      "T1\tTask 44 79\tquantifying noun groups  in  German\n",
      "T2\tMaterial 73 79\tGerman\n",
      "T3\tOtherScientificTerm 304 325\tgrammar sensu stricto\n",
      "T4\tMaterial 337 345\ttreebank\n",
      "T5\tOtherScientificTerm 387 411\tfine-grained  annotation\n",
      "T6\tMaterial 421 430\ttree-bank\n",
      "T7\tMethod 468 486\tstochastic parsers\n",
      "T8\tMaterial 504 513\ttree-bank\n",
      "T9\tMethod 523 531\tgrammars\n",
      "T10\tMaterial 551 559\ttreebank\n",
      "T11\tMaterial 585 593\ttreebank\n",
      "T12\tTask 636 673\ttheoretical linguistic investigations\n",
      "T13\tMethod 791 796\tSILVA\n",
      "T14\tMethod 802 831\tparsing  and  extraction tool\n",
      "T15\tMaterial 838 857\tGerman text corpora\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R4\tHYPONYM-OF Arg1:T13 Arg2:T14\n",
      "R5\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R6\tCOREF Arg1:T11 Arg2:T10\n",
      "R7\tCOREF Arg1:T10 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R9\tCOREF Arg1:T6 Arg2:T8\n",
      "R10\tCOREF Arg1:T6 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-6011.ann\n",
      "T1\tMethod 25 42\tannotating scheme\n",
      "T2\tMaterial 58 68\thonorifics\n",
      "T3\tOtherScientificTerm 71 87\trespectful words\n",
      "T4\tMaterial 91 101\tHonorifics\n",
      "T5\tMaterial 128 136\tJapanese\n",
      "T6\tOtherScientificTerm 230 253\treferential information\n",
      "T7\tOtherScientificTerm 279 292\tzero pronouns\n",
      "T8\tOtherScientificTerm 309 336\tmachine translation outputs\n",
      "T9\tMaterial 352 362\thonorifics\n",
      "T10\tMaterial 428 438\thonorifics\n",
      "T11\tOtherScientificTerm 453 458\tranks\n",
      "T12\tOtherScientificTerm 513 518\tranks\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tCOREF Arg1:T4 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R7\tCOREF Arg1:T9 Arg2:T4\n",
      "R8\tCOREF Arg1:T10 Arg2:T9\n",
      "R9\tCOREF Arg1:T12 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I08-1027.ann\n",
      "T1\tTask 2 45\tAutomatic estimation  of  word significance\n",
      "T2\tOtherScientificTerm 28 45\tword significance\n",
      "T3\tTask 61 100\tspeech-based Information Retrieval (IR)\n",
      "T4\tOtherScientificTerm 127 139\tsignificance\n",
      "T5\tTask 164 166\tIR\n",
      "T6\tTask 170 204\tautomatic speech recognition (ASR)\n",
      "T7\tMetric 247 278\tweighted word error rate (WWER)\n",
      "T8\tTask 337 339\tIR\n",
      "T9\tMetric 354 375\tword error rate (WER)\n",
      "T10\tMethod 417 434\tdecoding strategy\n",
      "T11\tMetric 452 456\tWWER\n",
      "T12\tMethod 470 498\tMinimum Bayes-Risk framework\n",
      "T13\tTask 553 556\tASR\n",
      "T14\tTask 563 565\tIR\n",
      "T15\tMethod 616 643\tautomatic estimation method\n",
      "T16\tOtherScientificTerm 650 677\tword significance (weights)\n",
      "T17\tTask 706 708\tIR\n",
      "T18\tMetric 758 777\tevaluation measures\n",
      "T19\tTask 783 786\tASR\n",
      "T20\tTask 793 795\tIR\n",
      "T21\tGeneric 835 841\tmethod\n",
      "T22\tTask 848 889\tspeech-based information retrieval system\n",
      "T23\tTask 912 921\tIR system\n",
      "T24\tGeneric 942 948\tmethod\n",
      "R1\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R2\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R3\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R4\tCOREF Arg1:T4 Arg2:T2\n",
      "R5\tCOREF Arg1:T8 Arg2:T5\n",
      "R6\tCOMPARE Arg1:T9 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R8\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "R9\tEVALUATE-FOR Arg1:T18 Arg2:T20\n",
      "R10\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R11\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R12\tHYPONYM-OF Arg1:T22 Arg2:T23\n",
      "R13\tCOREF Arg1:T24 Arg2:T21\n",
      "R14\tCOREF Arg1:T21 Arg2:T15\n",
      "R15\tCOREF Arg1:T16 Arg2:T4\n",
      "R16\tCOREF Arg1:T17 Arg2:T14\n",
      "R17\tCOREF Arg1:T14 Arg2:T8\n",
      "R18\tCOREF Arg1:T19 Arg2:T13\n",
      "R19\tCOREF Arg1:T11 Arg2:T7\n",
      "R20\tCOREF Arg1:T6 Arg2:T13\n",
      "R21\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R22\tCOREF Arg1:T20 Arg2:T17\n",
      "R23\tCOREF Arg1:T23 Arg2:T20\n",
      "R24\tCOREF Arg1:T22 Arg2:T3\n",
      "R25\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I08-1043.ann\n",
      "T1\tMethod 24 67\tmethod to automatically acquire paraphrases\n",
      "T2\tMaterial 76 93\tbilingual corpora\n",
      "T3\tOtherScientificTerm 116 146\tbilingual dependency relations\n",
      "T4\tOtherScientificTerm 174 202\tmonolingual dependency parse\n",
      "T5\tMethod 247 279\tstatistical alignment techniques\n",
      "T6\tMethod 293 312\tparaphrasing method\n",
      "T7\tOtherScientificTerm 398 440\tbilingual context  of  dependency relation\n",
      "T8\tOtherScientificTerm 491 502\tparaphrases\n",
      "T9\tGeneric 558 564\tmethod\n",
      "T10\tOtherScientificTerm 577 610\tgeneralized translation knowledge\n",
      "T11\tOtherScientificTerm 633 644\tparaphrases\n",
      "T12\tGeneric 662 668\tmethod\n",
      "T13\tOtherScientificTerm 685 718\tgeneralized translation knowledge\n",
      "T14\tTask 725 751\tKorean-English translation\n",
      "T15\tMaterial 780 837\tparallel corpora  of a  Korean and English language pairs\n",
      "T16\tMethod 858 877\tparaphrasing method\n",
      "T17\tOtherScientificTerm 901 912\tparaphrases\n",
      "T18\tMetric 925 934\tprecision\n",
      "T19\tMaterial 971 977\tKorean\n",
      "T20\tMaterial 984 991\tEnglish\n",
      "T21\tOtherScientificTerm 1003 1024\ttranslation knowledge\n",
      "T22\tMaterial 1046 1063\tbilingual corpora\n",
      "T23\tOtherScientificTerm 1110 1121\tparaphrases\n",
      "T24\tMetric 1139 1156\tcompression ratio\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T3\n",
      "R3\tCOREF Arg1:T6 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R7\tCOREF Arg1:T12 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R10\tCOREF Arg1:T16 Arg2:T6\n",
      "R11\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "R12\tCOREF Arg1:T22 Arg2:T2\n",
      "R13\tCOREF Arg1:T23 Arg2:T17\n",
      "R14\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R15\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R16\tCOREF Arg1:T15 Arg2:T22\n",
      "R17\tEVALUATE-FOR Arg1:T18 Arg2:T16\n",
      "R18\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R19\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R20\tUSED-FOR Arg1:T23 Arg2:T21\n",
      "R21\tEVALUATE-FOR Arg1:T24 Arg2:T21\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_1997_706_abs.ann\n",
      "T1\tMethod 0 27\tUtterance Verification (UV)\n",
      "T2\tMethod 57 98\tAutomatic Speech Recognition (ASR) System\n",
      "T3\tOtherScientificTerm 134 152\tspontaneous speech\n",
      "T4\tOtherScientificTerm 154 183\tout-of-vocabulary (OOV) words\n",
      "T5\tOtherScientificTerm 188 203\tacoustic noises\n",
      "T6\tMethod 248 260\tUV procedure\n",
      "T7\tMethod 289 305\tConfidence tests\n",
      "T8\tOtherScientificTerm 321 346\tdecoded string hypotheses\n",
      "T9\tOtherScientificTerm 406 415\tOOV words\n",
      "T10\tOtherScientificTerm 420 426\tnoises\n",
      "T11\tMethod 437 447\tASR system\n",
      "T12\tTask 493 506\tWord Spotting\n",
      "T13\tTask 511 538\tNoise Spotting capabilities\n",
      "T14\tMethod 547 559\tUV procedure\n",
      "T15\tMethod 588 604\tconfidence tests\n",
      "T16\tGeneric 606 609\ttwo\n",
      "T17\tMetric 619 636\tacoustic measures\n",
      "T18\tGeneric 641 644\tone\n",
      "T19\tOtherScientificTerm 656 678\tlinguistic information\n",
      "T20\tOtherScientificTerm 693 715\thierarchical structure\n",
      "T21\tTask 750 771\ttelephone application\n",
      "T22\tTask 777 808\tnatural number recognition task\n",
      "T23\tMetric 834 852\trecognition errors\n",
      "T24\tMetric 873 887\trejection rate\n",
      "T25\tMetric 933 949\tfalse acceptance\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T6 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R4\tCONJUNCTION Arg1:T10 Arg2:T9\n",
      "R5\tCOREF Arg1:T11 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R8\tCOREF Arg1:T14 Arg2:T6\n",
      "R9\tFEATURE-OF Arg1:T22 Arg2:T21\n",
      "R10\tEVALUATE-FOR Arg1:T23 Arg2:T22\n",
      "R11\tHYPONYM-OF Arg1:T16 Arg2:T15\n",
      "R12\tHYPONYM-OF Arg1:T18 Arg2:T15\n",
      "R13\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R14\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R15\tUSED-FOR Arg1:T19 Arg2:T18\n",
      "R16\tUSED-FOR Arg1:T15 Arg2:T20\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_1997_707_abs.ann\n",
      "T1\tOtherScientificTerm 0 30\tNonstationary chaotic behavior\n",
      "T2\tOtherScientificTerm 41 49\toxymoron\n",
      "T3\tGeneric 66 73\tmethods\n",
      "T4\tOtherScientificTerm 88 107\tnonstationary chaos\n",
      "T5\tGeneric 128 136\texamples\n",
      "T6\tMaterial 147 165\tbiological signals\n",
      "T7\tMaterial 167 178\tocean waves\n",
      "T8\tMaterial 183 195\ttraffic flow\n",
      "T9\tOtherScientificTerm 275 295\tnonstationary events\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R3\tHYPONYM-OF Arg1:T7 Arg2:T5\n",
      "R4\tHYPONYM-OF Arg1:T8 Arg2:T5\n",
      "R5\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R6\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_1997_714_abs.ann\n",
      "T1\tMethod 0 23\tLPC based speech coders\n",
      "T2\tOtherScientificTerm 37 46\tbit rates\n",
      "T3\tOtherScientificTerm 95 122\tbuzzy or metallic artefacts\n",
      "T4\tMaterial 130 146\tsynthetic speech\n",
      "T5\tOtherScientificTerm 224 241\texcitation source\n",
      "T6\tOtherScientificTerm 287 300\tlow bit rates\n",
      "T7\tMethod 322 333\tLPC vocoder\n",
      "T8\tOtherScientificTerm 364 378\tLPC excitation\n",
      "T9\tOtherScientificTerm 388 403\tfrequency bands\n",
      "T10\tOtherScientificTerm 412 437\tvariable cutoff frequency\n",
      "T11\tMaterial 490 512\tvoiced parts of speech\n",
      "T12\tMaterial 547 562\tunvoiced speech\n",
      "T13\tGeneric 580 585\tcoder\n",
      "T14\tMaterial 612 632\tmixed voicing speech\n",
      "T15\tMaterial 637 669\tspeech containing acoustic noise\n",
      "T16\tMaterial 701 729\tsoft natural sounding speech\n",
      "T17\tMethod 760 783\tparameter determination\n",
      "T18\tMethod 788 811\tquantisation techniques\n",
      "T19\tGeneric 843 848\tcoder\n",
      "T20\tOtherScientificTerm 857 870\tlow bit rates\n",
      "R1\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R2\tFEATURE-OF Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R5\tCOREF Arg1:T13 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T16\n",
      "R9\tCOREF Arg1:T13 Arg2:T19\n",
      "R10\tFEATURE-OF Arg1:T20 Arg2:T19\n",
      "R11\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R12\tUSED-FOR Arg1:T17 Arg2:T19\n",
      "R13\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_2011_587_abs.ann\n",
      "T1\tGeneric 34 43\talgorithm\n",
      "T2\tTask 65 93\ton-line interference effects\n",
      "T3\tTask 111 152\tGlobal Navigation Satellite System (GNSS)\n",
      "T4\tTask 157 189\tInertial Navigation System (INS)\n",
      "T5\tTask 195 212\tGNSS/INS coupling\n",
      "T6\tMethod 240 268\tExtended Kalman Filter (EKF)\n",
      "T7\tTask 285 317\taccurate and robust localization\n",
      "T8\tOtherScientificTerm 329 341\tinterference\n",
      "T9\tOtherScientificTerm 352 374\tGNSS measurement noise\n",
      "T10\tMetric 419 439\tpositioning accuracy\n",
      "T11\tOtherScientificTerm 549 559\tcovariance\n",
      "T12\tOtherScientificTerm 567 578\tEKF outputs\n",
      "T13\tMethod 598 619\tleast square estimate\n",
      "T14\tOtherScientificTerm 637 651\tvariance jumps\n",
      "T15\tGeneric 664 674\testimation\n",
      "T16\tMethod 688 701\tBayesian test\n",
      "T17\tOtherScientificTerm 756 767\tGNSS signal\n",
      "T18\tTask 918 937\tnavigation solution\n",
      "T19\tGeneric 1007 1015\tapproach\n",
      "T20\tMaterial 1019 1033\tsimulated data\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R5\tFEATURE-OF Arg1:T12 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R7\tCOREF Arg1:T15 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R9\tEVALUATE-FOR Arg1:T20 Arg2:T19\n",
      "R10\tHYPONYM-OF Arg1:T3 Arg2:T5\n",
      "R11\tHYPONYM-OF Arg1:T4 Arg2:T5\n",
      "R12\tCOREF Arg1:T19 Arg2:T16\n",
      "R13\tCOREF Arg1:T16 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_2011_588_abs.ann\n",
      "T1\tMaterial 42 60\tmeasurable signals\n",
      "T2\tMethod 66 86\tfrequency components\n",
      "T3\tOtherScientificTerm 102 132\trotational speed of the engine\n",
      "T4\tOtherScientificTerm 153 163\tvibrations\n",
      "T5\tOtherScientificTerm 165 196\telectrical system voltage level\n",
      "T6\tOtherScientificTerm 202 215\tambient sound\n",
      "T7\tGeneric 223 230\tsignals\n",
      "T8\tTask 273 312\tspeed and related states of the vehicle\n",
      "T9\tMethod 410 430\tfrequency components\n",
      "T10\tOtherScientificTerm 439 444\tspeed\n",
      "T11\tOtherScientificTerm 459 464\tgears\n",
      "T12\tOtherScientificTerm 551 569\tgear scale factors\n",
      "T13\tGeneric 575 588\ttraining data\n",
      "T14\tOtherScientificTerm 608 626\tspeed measurements\n",
      "T15\tTask 675 693\testimation problem\n",
      "T16\tTask 713 750\tmaximum likelihood estimation problem\n",
      "T17\tMethod 755 765\theuristics\n",
      "T18\tTask 803 840\tnumerical evaluation of the estimator\n",
      "T19\tGeneric 831 840\testimator\n",
      "T20\tMethod 916 933\testimation method\n",
      "T21\tMaterial 949 958\treal data\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tHYPONYM-OF Arg1:T4 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T5 Arg2:T1\n",
      "R4\tHYPONYM-OF Arg1:T6 Arg2:T1\n",
      "R5\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R6\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R7\tCOREF Arg1:T1 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R11\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R12\tCOREF Arg1:T19 Arg2:T20\n",
      "R13\tEVALUATE-FOR Arg1:T21 Arg2:T20\n",
      "R14\tFEATURE-OF Arg1:T10 Arg2:T11\n",
      "R15\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R16\tFEATURE-OF Arg1:T2 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_2011_598_abs.ann\n",
      "T1\tMetric 41 59\tmeasures of speech\n",
      "T2\tTask 76 102\tintelligibility prediction\n",
      "T3\tMaterial 106 124\tsynthesized speech\n",
      "T4\tOtherScientificTerm 128 152\tdiverse noisy situations\n",
      "T5\tMetric 173 198\tintel-ligibility measures\n",
      "T6\tMetric 204 215\tDau measure\n",
      "T7\tMetric 221 239\tglimpse proportion\n",
      "T8\tMetric 248 282\tSpeech Intelligibility Index (SII)\n",
      "T9\tMetric 289 304\tquality measure\n",
      "T10\tMetric 311 357\tPerceptual Evaluation of Speech Quality (PESQ)\n",
      "T11\tTask 367 399\tgeneration of synthesized speech\n",
      "T12\tMethod 427 460\tHMM-based speech synthesis system\n",
      "T13\tOtherScientificTerm 466 482\tnoisy conditions\n",
      "T14\tOtherScientificTerm 498 513\tadditive noises\n",
      "T15\tGeneric 519 527\tmeasures\n",
      "T16\tMetric 547 580\tsubjective intelligibility scores\n",
      "T17\tMetric 631 634\tDau\n",
      "T18\tMetric 643 659\tglimpse measures\n",
      "T19\tMethod 675 704\tpredictors of intelligibility\n",
      "T20\tMetric 711 723\tcorrelations\n",
      "T21\tOtherScientificTerm 742 759\tsubjective scores\n",
      "T22\tGeneric 765 773\tmeasures\n",
      "T23\tTask 793 823\tpredictions of intelligibility\n",
      "T24\tMaterial 828 844\tsynthetic speech\n",
      "T25\tMaterial 881 895\tnatural speech\n",
      "T26\tMetric 915 926\tSII measure\n",
      "T27\tMaterial 972 990\tsynthesized speech\n",
      "T28\tMethod 997 1014\tideal binary mask\n",
      "T29\tMetric 1040 1055\tGlimpse measure\n",
      "T30\tTask 1079 1106\tintelligibility predictions\n",
      "R1\tHYPONYM-OF Arg1:T10 Arg2:T9\n",
      "R2\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R3\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R4\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R5\tHYPONYM-OF Arg1:T7 Arg2:T5\n",
      "R6\tHYPONYM-OF Arg1:T8 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R8\tPART-OF Arg1:T14 Arg2:T13\n",
      "R9\tHYPONYM-OF Arg1:T5 Arg2:T1\n",
      "R10\tHYPONYM-OF Arg1:T9 Arg2:T1\n",
      "R11\tCOREF Arg1:T1 Arg2:T15\n",
      "R12\tCOMPARE Arg1:T15 Arg2:T16\n",
      "R13\tCOREF Arg1:T6 Arg2:T17\n",
      "R14\tCOREF Arg1:T7 Arg2:T18\n",
      "R15\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R16\tCOREF Arg1:T15 Arg2:T22\n",
      "R17\tUSED-FOR Arg1:T24 Arg2:T23\n",
      "R18\tCOREF Arg1:T2 Arg2:T23\n",
      "R19\tCOMPARE Arg1:T24 Arg2:T25\n",
      "R20\tHYPONYM-OF Arg1:T26 Arg2:T22\n",
      "R21\tEVALUATE-FOR Arg1:T22 Arg2:T23\n",
      "R22\tUSED-FOR Arg1:T29 Arg2:T30\n",
      "R23\tCOREF Arg1:T23 Arg2:T30\n",
      "R24\tUSED-FOR Arg1:T28 Arg2:T27\n",
      "R25\tCOREF Arg1:T29 Arg2:T18\n",
      "R26\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R27\tEVALUATE-FOR Arg1:T1 Arg2:T2\n",
      "R28\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "R29\tEVALUATE-FOR Arg1:T20 Arg2:T18\n",
      "R30\tEVALUATE-FOR Arg1:T20 Arg2:T17\n",
      "R31\tHYPONYM-OF Arg1:T18 Arg2:T19\n",
      "R32\tHYPONYM-OF Arg1:T17 Arg2:T19\n",
      "R33\tCOMPARE Arg1:T18 Arg2:T21\n",
      "R34\tCOMPARE Arg1:T17 Arg2:T21\n",
      "R35\tCONJUNCTION Arg1:T5 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_2016_11_abs.ann\n",
      "T1\tTask 15 96\tblind separation of underdetermined instantaneous mixtures of independent signals\n",
      "T2\tGeneric 120 126\tmethod\n",
      "T3\tOtherScientificTerm 138 153\tnonstationarity\n",
      "T4\tOtherScientificTerm 161 177\toriginal signals\n",
      "T5\tGeneric 183 190\tsignals\n",
      "T6\tGeneric 346 353\tsignals\n",
      "T7\tMethod 395 427\tfirst-order autoregressive model\n",
      "T8\tGeneric 434 439\tmodel\n",
      "T9\tTask 477 520\tblind separation of natural speech signals.\n",
      "T10\tMethod 523 540\tseparation method\n",
      "T11\tOtherScientificTerm 623 646\tCramÃ©r-Rao lower bound)\n",
      "T12\tGeneric 682 695\tassumed model\n",
      "T13\tOtherScientificTerm 712 734\tnatural speech signals\n",
      "T14\tGeneric 741 747\tmethod\n",
      "T15\tMetric 765 784\tseparation accuracy\n",
      "T16\tGeneric 818 825\tmethods\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tCOREF Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R4\tCOREF Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R6\tCOREF Arg1:T8 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R8\tCOMPARE Arg1:T14 Arg2:T16\n",
      "R9\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R10\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R11\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T13\n",
      "R13\tCOREF Arg1:T14 Arg2:T10\n",
      "R14\tCOREF Arg1:T8 Arg2:T12\n",
      "R15\tFEATURE-OF Arg1:T11 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_2016_14_abs.ann\n",
      "T1\tTask 4 29\tmobile speech application\n",
      "T2\tMetric 31 62\tspeaker DOA estimation accuracy\n",
      "T3\tMetric 64 87\tinterference robustness\n",
      "T4\tMetric 92 113\tcompact physical size\n",
      "T5\tMethod 171 199\tacoustic vector sensor (AVS)\n",
      "T6\tMethod 215 239\tDOA estimation algorithm\n",
      "T7\tOtherScientificTerm 328 358\tnon-speech interferences (NSI)\n",
      "T8\tMethod 382 421\trobust speaker DOA estimation algorithm\n",
      "T9\tGeneric 423 425\tIt\n",
      "T10\tMethod 454 483\tinter-sensor data ratio model\n",
      "T11\tMethod 490 493\tAVS\n",
      "T12\tMethod 497 522\tbispectrum domain (BISDR)\n",
      "T13\tGeneric 541 561\tfavorable properties\n",
      "T14\tMethod 565 575\tbispectrum\n",
      "T15\tOtherScientificTerm 585 615\tzero value of Gaussian process\n",
      "T16\tOtherScientificTerm 630 660\tdistribution of speech and NSI\n",
      "T17\tOtherScientificTerm 657 660\tNSI\n",
      "T18\tMethod 687 702\tbispectrum mask\n",
      "T19\tOtherScientificTerm 738 754\tspeaker DOA cues\n",
      "T20\tMethod 769 774\tBISDR\n",
      "T21\tOtherScientificTerm 790 793\tNSI\n",
      "T22\tOtherScientificTerm 806 821\tspeech sparsity\n",
      "T23\tOtherScientificTerm 832 852\tbispectrum amplitude\n",
      "T24\tGeneric 952 961\talgorithm\n",
      "T25\tOtherScientificTerm 976 990\tNSI conditions\n",
      "T26\tMetric 1001 1004\tSIR\n",
      "R1\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R2\tFEATURE-OF Arg1:T3 Arg2:T1\n",
      "R3\tFEATURE-OF Arg1:T4 Arg2:T1\n",
      "R4\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R5\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R6\tCOREF Arg1:T9 Arg2:T8\n",
      "R7\tCOREF Arg1:T5 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R9\tCOREF Arg1:T17 Arg2:T7\n",
      "R10\tCOREF Arg1:T20 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R12\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R13\tCOREF Arg1:T21 Arg2:T7\n",
      "R14\tCOREF Arg1:T21 Arg2:T25\n",
      "R15\tUSED-FOR Arg1:T24 Arg2:T25\n",
      "R16\tCOREF Arg1:T9 Arg2:T24\n",
      "R17\tCOREF Arg1:T6 Arg2:T8\n",
      "R18\tHYPONYM-OF Arg1:T15 Arg2:T13\n",
      "R19\tHYPONYM-OF Arg1:T16 Arg2:T13\n",
      "R20\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R21\tUSED-FOR Arg1:T9 Arg2:T13\n",
      "R22\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_2016_3_abs.ann\n",
      "T1\tTask 0 33\tSpeech-based depression detection\n",
      "T2\tMetric 198 208\trobustness\n",
      "T3\tOtherScientificTerm 212 223\tspeech cues\n",
      "T4\tOtherScientificTerm 271 276\tnoise\n",
      "T5\tOtherScientificTerm 281 294\treverberation\n",
      "T6\tTask 298 319\tdepression prediction\n",
      "T7\tMethod 338 381\tmel-frequency cepstral coefficients (MFCCs)\n",
      "T8\tGeneric 390 398\tfeatures\n",
      "T9\tMetric 412 428\tnoise robustness\n",
      "T10\tMethod 430 477\tdamped oscillator cepstral coefficients (DOCCs)\n",
      "T11\tMaterial 503 551\tAudioVisual Emotion Recognition Challenge (AVEC)\n",
      "T12\tOtherScientificTerm 567 581\tadditive noise\n",
      "T13\tOtherScientificTerm 586 599\treverberation\n",
      "T14\tMetric 653 671\tevaluation metrics\n",
      "T15\tMethod 751 764\tMFCC features\n",
      "T16\tOtherScientificTerm 820 825\tnoise\n",
      "T17\tOtherScientificTerm 830 843\treverberation\n",
      "T18\tMethod 845 858\tDOCC features\n",
      "T19\tOtherScientificTerm 898 932\thigher-order cepstral coefficients\n",
      "T20\tMethod 965 991\tartificial neural networks\n",
      "T21\tMethod 1011 1036\tsupport vector regression\n",
      "T22\tMaterial 1046 1064\tspontaneous speech\n",
      "T23\tMaterial 1105 1116\tread speech\n",
      "T24\tOtherScientificTerm 1129 1173\tcross-corpus (and cross-language) experiment\n",
      "T25\tMetric 1189 1223\tnoise and reverberation robustness\n",
      "T26\tMethod 1228 1233\tDOCCs\n",
      "T27\tMethod 1243 1248\tMFCCs\n",
      "T28\tTask 1289 1327\treal-world robust depression detection\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R3\tFEATURE-OF Arg1:T5 Arg2:T6\n",
      "R4\tFEATURE-OF Arg1:T4 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R7\tCOREF Arg1:T10 Arg2:T8\n",
      "R8\tCOREF Arg1:T15 Arg2:T7\n",
      "R9\tCOMPARE Arg1:T18 Arg2:T15\n",
      "R10\tCOREF Arg1:T18 Arg2:T10\n",
      "R11\tCOMPARE Arg1:T20 Arg2:T21\n",
      "R12\tCOMPARE Arg1:T22 Arg2:T23\n",
      "R13\tCOMPARE Arg1:T26 Arg2:T27\n",
      "R14\tCOREF Arg1:T26 Arg2:T18\n",
      "R15\tCOREF Arg1:T27 Arg2:T15\n",
      "R16\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R17\tEVALUATE-FOR Arg1:T25 Arg2:T26\n",
      "R18\tEVALUATE-FOR Arg1:T25 Arg2:T27\n",
      "R19\tEVALUATE-FOR Arg1:T24 Arg2:T26\n",
      "R20\tEVALUATE-FOR Arg1:T24 Arg2:T27\n",
      "R21\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R22\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R23\tCONJUNCTION Arg1:T8 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_2016_4_abs.ann\n",
      "T1\tOtherScientificTerm 0 34\tHigh frequency oscillations (HFOs)\n",
      "T2\tOtherScientificTerm 64 99\tepileptic brain tissue and activity\n",
      "T3\tOtherScientificTerm 101 105\tHFOs\n",
      "T4\tTask 172 199\tanalysis of discrete events\n",
      "T5\tMaterial 203 250\thigh-temporal resolution, intracranial EEG data\n",
      "T6\tTask 282 306\tdimensionality reduction\n",
      "T7\tTask 315 354\tassessing feasibility of classification\n",
      "T8\tTask 340 354\tclassification\n",
      "T9\tTask 356 380\tDimensionality reduction\n",
      "T10\tMaterial 412 420\tmanifold\n",
      "T11\tOtherScientificTerm 458 472\tfeatures space\n",
      "T12\tTask 492 504\tHFO analysis\n",
      "T13\tOtherScientificTerm 520 535\tlinear manifold\n",
      "T14\tMethod 659 673\tlinear methods\n",
      "T15\tOtherScientificTerm 720 728\tmanifold\n",
      "T16\tOtherScientificTerm 780 786\tbounds\n",
      "T17\tOtherScientificTerm 794 820\tBayes classification error\n",
      "T18\tOtherScientificTerm 872 876\tHFOs\n",
      "T19\tGeneric 878 883\tthose\n",
      "T20\tGeneric 914 919\tthose\n",
      "T21\tTask 1004 1032\tclinical use of HFO features\n",
      "T22\tOtherScientificTerm 1020 1032\tHFO features\n",
      "T23\tOtherScientificTerm 1067 1082\tdiscrete events\n",
      "T24\tOtherScientificTerm 1103 1120\taction potentials\n",
      "T25\tOtherScientificTerm 1124 1143\tmulti-unit activity\n",
      "R1\tCOREF Arg1:T1 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tHYPONYM-OF Arg1:T19 Arg2:T18\n",
      "R4\tHYPONYM-OF Arg1:T20 Arg2:T18\n",
      "R5\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R7\tCOREF Arg1:T6 Arg2:T9\n",
      "R8\tCOREF Arg1:T3 Arg2:T18\n",
      "R9\tHYPONYM-OF Arg1:T24 Arg2:T23\n",
      "R10\tHYPONYM-OF Arg1:T25 Arg2:T23\n",
      "R11\tCONJUNCTION Arg1:T24 Arg2:T25\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_1999_47_abs.ann\n",
      "T1\tTask 0 22\tBackground maintenance\n",
      "T2\tTask 48 74\tvideo surveillance systems\n",
      "T3\tMethod 87 97\tWallflower\n",
      "T4\tGeneric 101 123\tthree-component system\n",
      "T5\tTask 128 150\tbackground maintenance\n",
      "T6\tMethod 156 177\tpixel-level component\n",
      "T7\tMethod 187 203\tWiener filtering\n",
      "T8\tTask 212 264\tprobabilistic predictions of the expected background\n",
      "T9\tMethod 270 292\tregion-level component\n",
      "T10\tOtherScientificTerm 302 343\thomogeneous regions of foreground objects\n",
      "T11\tMethod 353 374\tframe-level component\n",
      "T12\tGeneric 488 494\tsystem\n",
      "T13\tMethod 508 541\tbackground subtraction algorithms\n",
      "T14\tMethod 543 553\tWallflower\n",
      "T15\tGeneric 586 596\talgorithms\n",
      "T16\tMethod 724 744\tnormative principles\n",
      "T17\tTask 749 771\tbackground maintenance\n",
      "R1\tPART-OF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T5 Arg2:T1\n",
      "R3\tCOREF Arg1:T3 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tPART-OF Arg1:T6 Arg2:T4\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R9\tPART-OF Arg1:T9 Arg2:T4\n",
      "R10\tPART-OF Arg1:T11 Arg2:T4\n",
      "R11\tCONJUNCTION Arg1:T6 Arg2:T9\n",
      "R12\tCONJUNCTION Arg1:T9 Arg2:T11\n",
      "R13\tCOREF Arg1:T3 Arg2:T12\n",
      "R14\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R15\tCOREF Arg1:T14 Arg2:T12\n",
      "R16\tCOREF Arg1:T15 Arg2:T13\n",
      "R17\tCOMPARE Arg1:T14 Arg2:T15\n",
      "R18\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R19\tCOREF Arg1:T5 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2001_47_abs.ann\n",
      "T1\tOtherScientificTerm 28 56\tpriori geometric constraints\n",
      "T2\tMethod 62 94\t3â€“D stereo reconstruction scheme\n",
      "T3\tOtherScientificTerm 129 146\timage information\n",
      "T4\tOtherScientificTerm 193 202\t3â€“D shape\n",
      "T5\tGeneric 208 216\tapproach\n",
      "T6\tMethod 233 276\titerative deformation of a 3â€“D surface mesh\n",
      "T7\tOtherScientificTerm 292 310\tobjective function\n",
      "T8\tMethod 335 354\tanisotropic meshing\n",
      "T9\tMethod 362 384\tnon-quadratic approach\n",
      "T10\tOtherScientificTerm 388 402\tregularization\n",
      "T11\tTask 437 451\treconstruction\n",
      "T12\tOtherScientificTerm 466 480\ttriangulations\n",
      "T13\tOtherScientificTerm 490 498\tvertices\n",
      "T14\tOtherScientificTerm 500 535\tStructural or numerical constraints\n",
      "T15\tMethod 569 591\treconstruction process\n",
      "T16\tMethod 602 633\tconstrained optimization scheme\n",
      "T17\tGeneric 635 639\tThey\n",
      "T18\tTask 652 666\treconstruction\n",
      "T19\tOtherScientificTerm 712 728\tpriori knowledge\n",
      "T20\tOtherScientificTerm 735 747\tobject shape\n",
      "T21\tOtherScientificTerm 776 795\tmodeling properties\n",
      "T22\tOtherScientificTerm 799 820\tdifferential features\n",
      "T23\tGeneric 826 830\tthem\n",
      "T24\tTask 892 910\t3â€“D reconstruction\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R4\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R6\tPART-OF Arg1:T1 Arg2:T2\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R11\tUSED-FOR Arg1:T16 Arg2:T14\n",
      "R12\tCOREF Arg1:T18 Arg2:T11\n",
      "R13\tCOREF Arg1:T14 Arg2:T17\n",
      "R14\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R15\tFEATURE-OF Arg1:T20 Arg2:T19\n",
      "R16\tCOREF Arg1:T23 Arg2:T17\n",
      "R17\tUSED-FOR Arg1:T23 Arg2:T24\n",
      "R18\tCOREF Arg1:T24 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2001_50_abs.ann\n",
      "T1\tMethod 17 56\tmodel-based bundle adjustment algorithm\n",
      "T2\tMethod 72 80\t3D model\n",
      "T3\tMaterial 118 124\timages\n",
      "T4\tOtherScientificTerm 130 145\tunknown motions\n",
      "T5\tOtherScientificTerm 203 223\tisolated 3D features\n",
      "T6\tGeneric 246 255\talgorithm\n",
      "T7\tOtherScientificTerm 263 270\tsurface\n",
      "T8\tGeneric 335 357\tmodel-based approaches\n",
      "T9\tGeneric 363 371\tapproach\n",
      "T10\tOtherScientificTerm 430 441\tmodel space\n",
      "T11\tOtherScientificTerm 447 459\tregular-izer\n",
      "T12\tGeneric 477 479\tit\n",
      "T13\tOtherScientificTerm 487 499\tsearch space\n",
      "T14\tGeneric 599 608\talgorithm\n",
      "T15\tOtherScientificTerm 685 693\tsurfaces\n",
      "T16\tOtherScientificTerm 730 756\tprior 2D-to-3D association\n",
      "T17\tTask 775 788\tface modeling\n",
      "T18\tMetric 817 829\tface metrics\n",
      "T19\tOtherScientificTerm 877 890\tface geometry\n",
      "T20\tOtherScientificTerm 915 927\tsearch space\n",
      "T21\tMethod 941 953\tposed system\n",
      "T22\tMaterial 977 1000\tsynthetic and real data\n",
      "T23\tGeneric 1020 1029\talgorithm\n",
      "T24\tGeneric 1085 1089\tones\n",
      "R1\tPART-OF Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T1 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R6\tCOREF Arg1:T9 Arg2:T6\n",
      "R7\tCOMPARE Arg1:T8 Arg2:T9\n",
      "R8\tCOREF Arg1:T10 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R10\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R11\tCOMPARE Arg1:T11 Arg2:T13\n",
      "R12\tCOREF Arg1:T9 Arg2:T14\n",
      "R13\tCOREF Arg1:T14 Arg2:T23\n",
      "R14\tEVALUATE-FOR Arg1:T22 Arg2:T23\n",
      "R15\tCOREF Arg1:T8 Arg2:T24\n",
      "R16\tCOMPARE Arg1:T23 Arg2:T24\n",
      "R17\tEVALUATE-FOR Arg1:T22 Arg2:T24\n",
      "R18\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R19\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R20\tUSED-FOR Arg1:T18 Arg2:T20\n",
      "R21\tUSED-FOR Arg1:T18 Arg2:T21\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2003_150_abs.ann\n",
      "T1\tMethod 13 50\tsingle-image highlight removal method\n",
      "T2\tOtherScientificTerm 69 99\tillumination-based constraints\n",
      "T3\tTask 105 122\timage in-painting\n",
      "T4\tOtherScientificTerm 131 153\toccluded image regions\n",
      "T5\tOtherScientificTerm 176 186\tinpainting\n",
      "T6\tOtherScientificTerm 188 204\thighlight pixels\n",
      "T7\tTask 253 271\tinpainting process\n",
      "T8\tOtherScientificTerm 273 284\tConstraints\n",
      "T9\tOtherScientificTerm 306 318\tpixel colors\n",
      "T10\tOtherScientificTerm 320 344\thighlight color analysis\n",
      "T11\tOtherScientificTerm 349 378\tillumination color uniformity\n",
      "T12\tGeneric 399 405\tmethod\n",
      "T13\tOtherScientificTerm 417 459\testimation of the underlying diffuse color\n",
      "T14\tOtherScientificTerm 484 508\tillumination constraints\n",
      "T15\tOtherScientificTerm 527 559\trecovery of shading and textures\n",
      "T16\tTask 563 573\tinpainting\n",
      "T17\tMethod 644 650\tmethod\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R2\tCOREF Arg1:T7 Arg2:T3\n",
      "R3\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R5\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T12\n",
      "R7\tCOREF Arg1:T14 Arg2:T8\n",
      "R8\tCOREF Arg1:T16 Arg2:T7\n",
      "R9\tCOREF Arg1:T12 Arg2:T1\n",
      "R10\tPART-OF Arg1:T2 Arg2:T3\n",
      "R11\tCOREF Arg1:T17 Arg2:T12\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R13\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2003_151_abs.ann\n",
      "T1\tGeneric 6 15\talgorithm\n",
      "T2\tTask 32 53\tnovel view generation\n",
      "T3\tTask 57 97\tone-to-one teleconferencing applications\n",
      "T4\tMaterial 109 122\tvideo streams\n",
      "T5\tOtherScientificTerm 139 146\tcameras\n",
      "T6\tOtherScientificTerm 174 190\tcomputer monitor\n",
      "T7\tGeneric 206 215\talgorithm\n",
      "T8\tMaterial 228 234\timages\n",
      "T9\tOtherScientificTerm 242 256\tvirtual camera\n",
      "T10\tOtherScientificTerm 260 278\tarbitrary position\n",
      "T11\tOtherScientificTerm 332 343\teye contact\n",
      "T12\tGeneric 349 358\ttechnique\n",
      "T13\tMethod 384 421\tdynamic-programming, stereo algorithm\n",
      "T14\tTask 436 457\tnovel-view generation\n",
      "T15\tMethod 522 539\tthree-plane graph\n",
      "T16\tMethod 544 576\tdense-stereo dynamic-programming\n",
      "T17\tTask 602 620\tocclusion labeling\n",
      "T18\tOtherScientificTerm 628 656\tcompact geometric derivation\n",
      "T19\tTask 661 681\tnovel-view synthesis\n",
      "T20\tMethod 685 730\tdirect projection of the minimum-cost surface\n",
      "T21\tGeneric 773 782\talgorithm\n",
      "T22\tTask 791 833\ttemporal maintenance of a background model\n",
      "T23\tTask 849 872\trendering of occlusions\n",
      "T24\tOtherScientificTerm 884 912\ttemporal artefacts (flicker)\n",
      "T25\tMethod 920 946\tcost aggregation algorithm\n",
      "T26\tOtherScientificTerm 973 1010\tthree-dimensional matching cost space\n",
      "T27\tMetric 1052 1062\trobustness\n",
      "T28\tGeneric 1074 1083\talgorithm\n",
      "T29\tOtherScientificTerm 1087 1117\tspatial and temporal artefacts\n",
      "T30\tMaterial 1122 1147\tlong stereo video streams\n",
      "T31\tTask 1181 1246\tsynthesis of cyclopean views of extended conversational sequences\n",
      "T32\tOtherScientificTerm 1194 1209\tcyclopean views\n",
      "T33\tMaterial 1213 1246\textended conversational sequences\n",
      "T34\tTask 1271 1280\tsynthesis\n",
      "T35\tOtherScientificTerm 1295 1321\ttranslating virtual camera\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tCOREF Arg1:T1 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R4\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T11\n",
      "R6\tCOREF Arg1:T12 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R11\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R12\tUSED-FOR Arg1:T20 Arg2:T18\n",
      "R13\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R14\tUSED-FOR Arg1:T21 Arg2:T23\n",
      "R15\tUSED-FOR Arg1:T25 Arg2:T26\n",
      "R16\tCONJUNCTION Arg1:T25 Arg2:T21\n",
      "R17\tCOREF Arg1:T12 Arg2:T21\n",
      "R18\tCOREF Arg1:T21 Arg2:T28\n",
      "R19\tEVALUATE-FOR Arg1:T27 Arg2:T28\n",
      "R20\tUSED-FOR Arg1:T21 Arg2:T24\n",
      "R21\tUSED-FOR Arg1:T28 Arg2:T29\n",
      "R22\tUSED-FOR Arg1:T35 Arg2:T34\n",
      "R23\tUSED-FOR Arg1:T29 Arg2:T30\n",
      "R24\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R25\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R26\tCOREF Arg1:T2 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2003_158_abs.ann\n",
      "T1\tGeneric 23 32\talgorithm\n",
      "T2\tTask 37 96\tcomputing optical flow, shape, motion, lighting, and albedo\n",
      "T3\tMaterial 105 119\timage sequence\n",
      "T4\tMaterial 125 157\trigidly-moving Lambertian object\n",
      "T5\tOtherScientificTerm 164 184\tdistant illumination\n",
      "T6\tGeneric 190 197\tproblem\n",
      "T7\tMaterial 253 259\tmotion\n",
      "T8\tMaterial 261 278\tmulti-view stereo\n",
      "T9\tMaterial 284 303\tphoto-metric stereo\n",
      "T10\tGeneric 326 335\talgorithm\n",
      "T11\tOtherScientificTerm 350 390\tspatial and temporal intensity variation\n",
      "T12\tGeneric 394 398\tcues\n",
      "T13\tGeneric 404 410\tformer\n",
      "T14\tOtherScientificTerm 422 426\tflow\n",
      "T15\tGeneric 435 441\tlatter\n",
      "T16\tOtherScientificTerm 453 472\tsurface orientation\n",
      "T17\tGeneric 490 494\tcues\n",
      "T18\tTask 503 566\tdense reconstruction of both textured and texture-less surfaces\n",
      "T19\tGeneric 572 581\talgorithm\n",
      "T20\tMethod 603 672\testimating affine camera parameters, illumination , shape, and albedo\n",
      "T21\tMaterial 728 755\tvideos of hand-held objects\n",
      "R1\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "R2\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R5\tCOREF Arg1:T2 Arg2:T6\n",
      "R6\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R7\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R10\tCOREF Arg1:T11 Arg2:T12\n",
      "R11\tHYPONYM-OF Arg1:T13 Arg2:T12\n",
      "R12\tHYPONYM-OF Arg1:T15 Arg2:T12\n",
      "R13\tCONJUNCTION Arg1:T13 Arg2:T15\n",
      "R14\tCOREF Arg1:T17 Arg2:T12\n",
      "R15\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R16\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R17\tCOREF Arg1:T10 Arg2:T1\n",
      "R18\tCOREF Arg1:T19 Arg2:T10\n",
      "R19\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2003_161_abs.ann\n",
      "T1\tTask 4 37\tperception of transparent objects\n",
      "T2\tMaterial 43 49\timages\n",
      "T3\tOtherScientificTerm 165 184\ttransparent objects\n",
      "T4\tOtherScientificTerm 248 267\ttransparent objects\n",
      "T5\tOtherScientificTerm 302 310\tfeatures\n",
      "T6\tOtherScientificTerm 337 355\ttransparent object\n",
      "T7\tGeneric 380 385\tthose\n",
      "T8\tMethod 445 465\tmodel-based approach\n",
      "T9\tOtherScientificTerm 481 524\tshapes and the poses of transparent objects\n",
      "T10\tOtherScientificTerm 530 542\tknown motion\n",
      "T11\tGeneric 548 555\tobjects\n",
      "T12\tGeneric 579 583\tthey\n",
      "T13\tOtherScientificTerm 603 618\tmultiple layers\n",
      "T14\tOtherScientificTerm 634 652\trefractive indices\n",
      "T15\tGeneric 736 745\talgorithm\n",
      "T16\tGeneric 763 765\tit\n",
      "T17\tMaterial 769 780\treal scenes\n",
      "T18\tOtherScientificTerm 794 813\ttransparent objects\n",
      "T19\tOtherScientificTerm 832 853\tshapes of the objects\n",
      "T20\tMetric 864 872\taccuracy\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOMPARE Arg1:T7 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R5\tCOREF Arg1:T11 Arg2:T12\n",
      "R6\tPART-OF Arg1:T13 Arg2:T12\n",
      "R7\tCOREF Arg1:T8 Arg2:T15\n",
      "R8\tFEATURE-OF Arg1:T14 Arg2:T13\n",
      "R9\tCOREF Arg1:T16 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R11\tPART-OF Arg1:T18 Arg2:T17\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T19\n",
      "R13\tEVALUATE-FOR Arg1:T20 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2005_47_abs.ann\n",
      "T1\tTask 0 32\tFace images of non-frontal views\n",
      "T2\tMetric 97 122\tface recognition accuracy\n",
      "T3\tMetric 174 190\trecognition rate\n",
      "T4\tMethod 207 231\tface recognition systems\n",
      "T5\tMaterial 248 270\tlive CCTV camera input\n",
      "T6\tMethod 300 318\tBayesian framework\n",
      "T7\tOtherScientificTerm 365 374\tviewpoint\n",
      "T8\tOtherScientificTerm 379 391\tillumination\n",
      "T9\tTask 393 420\tface image super-resolution\n",
      "T10\tTask 425 436\trecognition\n",
      "T11\tOtherScientificTerm 440 452\ttensor space\n",
      "T12\tMaterial 462 500\tsingle modal low-resolution face image\n",
      "T13\tOtherScientificTerm 522 569\tmultiple factor interactions of training tensor\n",
      "T14\tTask 593 624\thigh-resolution reconstructions\n",
      "T15\tOtherScientificTerm 642 652\tmodalities\n",
      "T16\tTask 657 673\tface recognition\n",
      "T17\tTask 697 742\tpixel-domain super-resolution and recognition\n",
      "T18\tTask 821 837\tsuper-resolution\n",
      "T19\tTask 842 853\trecognition\n",
      "T20\tOtherScientificTerm 878 922\tmaximum likelihood identity parameter vector\n",
      "T21\tOtherScientificTerm 926 954\thigh-resolution tensor space\n",
      "T22\tTask 959 970\trecognition\n",
      "T23\tTask 993 1042\tmulti-modal super-resolution and face recognition\n",
      "T24\tOtherScientificTerm 1072 1090\timaging modalities\n",
      "T25\tMaterial 1098 1119\tlow-resolution images\n",
      "T26\tMetric 1163 1180\trecognition rates\n",
      "T27\tMethod 1195 1235\ttensorface and eigenface representations\n",
      "R1\tEVALUATE-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R5\tFEATURE-OF Arg1:T15 Arg2:T14\n",
      "R6\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R7\tFEATURE-OF Arg1:T21 Arg2:T20\n",
      "R8\tUSED-FOR Arg1:T20 Arg2:T22\n",
      "R9\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R10\tUSED-FOR Arg1:T25 Arg2:T23\n",
      "R11\tEVALUATE-FOR Arg1:T26 Arg2:T23\n",
      "R12\tEVALUATE-FOR Arg1:T26 Arg2:T27\n",
      "R13\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R14\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R15\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R16\tFEATURE-OF Arg1:T11 Arg2:T10\n",
      "R17\tHYPONYM-OF Arg1:T18 Arg2:T17\n",
      "R18\tHYPONYM-OF Arg1:T19 Arg2:T17\n",
      "R19\tUSED-FOR Arg1:T20 Arg2:T18\n",
      "R20\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R21\tCOREF Arg1:T22 Arg2:T19\n",
      "R22\tCOREF Arg1:T19 Arg2:T16\n",
      "R23\tCOREF Arg1:T16 Arg2:T10\n",
      "R24\tCOREF Arg1:T18 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2005_50_abs.ann\n",
      "T1\tGeneric 8 18\tapproaches\n",
      "T2\tTask 22 49\tobject category recognition\n",
      "T3\tGeneric 58 66\tdatasets\n",
      "T4\tOtherScientificTerm 135 146\tsupervision\n",
      "T5\tGeneric 162 170\tapproach\n",
      "T6\tOtherScientificTerm 189 204\tobject category\n",
      "T7\tMethod 256 276\timage search engines\n",
      "T8\tGeneric 321 326\tmodel\n",
      "T9\tMethod 328 336\tTSI-pLSA\n",
      "T10\tMethod 352 356\tpLSA\n",
      "T11\tOtherScientificTerm 372 384\tvisual words\n",
      "T12\tOtherScientificTerm 397 416\tspatial information\n",
      "T13\tGeneric 466 474\tapproach\n",
      "T14\tOtherScientificTerm 495 518\tintra-class variability\n",
      "T15\tOtherScientificTerm 543 559\tunrelated images\n",
      "T16\tMethod 572 586\tsearch engines\n",
      "T17\tGeneric 604 610\tmodels\n",
      "T18\tGeneric 623 632\ttest sets\n",
      "T19\tGeneric 680 687\tmethods\n",
      "T20\tMaterial 699 721\thand prepared datasets\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tCOREF Arg1:T5 Arg2:T8\n",
      "R5\tCOREF Arg1:T8 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T9 Arg2:T13\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R10\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R11\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R13\tCOREF Arg1:T7 Arg2:T16\n",
      "R14\tCOREF Arg1:T13 Arg2:T17\n",
      "R15\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R16\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R17\tCOMPARE Arg1:T19 Arg2:T17\n",
      "R18\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "R19\tPART-OF Arg1:T12 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2009_47_abs.ann\n",
      "T1\tGeneric 27 36\ttechnique\n",
      "T2\tTask 41 58\trobust estimation\n",
      "T3\tOtherScientificTerm 99 147\tinherent uncertainty of the estimation procedure\n",
      "T4\tMethod 167 204\tefficient robust estimation algorithm\n",
      "T5\tTask 246 275\trandomized model verification\n",
      "T6\tGeneric 285 289\tthis\n",
      "T7\tGeneric 371 381\tstrategies\n",
      "T8\tMethod 395 422\trobust estimation procedure\n",
      "T9\tMethod 474 491\tRANSAC techniques\n",
      "T10\tOtherScientificTerm 512 529\tprior information\n",
      "T11\tOtherScientificTerm 543 559\tsampling process\n",
      "T12\tGeneric 580 589\talgorithm\n",
      "T13\tMethod 651 657\tRANSAC\n",
      "T14\tOtherScientificTerm 692 715\ttheoretical predictions\n",
      "T15\tGeneric 739 748\talgorithm\n",
      "T16\tTask 783 812\tgeometric estimation problems\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T6 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R6\tCOREF Arg1:T4 Arg2:T8\n",
      "R7\tCOMPARE Arg1:T9 Arg2:T8\n",
      "R8\tCOREF Arg1:T12 Arg2:T8\n",
      "R9\tCOREF Arg1:T13 Arg2:T9\n",
      "R10\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R11\tCOREF Arg1:T15 Arg2:T12\n",
      "R12\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2011_47_abs.ann\n",
      "T1\tGeneric 13 19\tmethod\n",
      "T2\tTask 24 44\tdetecting 3D objects\n",
      "T3\tOtherScientificTerm 51 67\tmulti-modalities\n",
      "T4\tGeneric 75 77\tit\n",
      "T5\tGeneric 105 107\tit\n",
      "T6\tOtherScientificTerm 133 138\timage\n",
      "T7\tOtherScientificTerm 145 160\tdense depth map\n",
      "T8\tOtherScientificTerm 172 204\tcomplementary object information\n",
      "T9\tGeneric 206 208\tIt\n",
      "T10\tOtherScientificTerm 269 298\ttime consuming training stage\n",
      "T11\tOtherScientificTerm 315 333\tuntextured objects\n",
      "T12\tGeneric 335 337\tIt\n",
      "T13\tOtherScientificTerm 381 390\ttemplates\n",
      "T14\tOtherScientificTerm 418 428\tmodalities\n",
      "T15\tOtherScientificTerm 465 483\tcommodity hardware\n",
      "T16\tGeneric 493 501\tapproach\n",
      "T17\tGeneric 528 552\tstate-of-the-art methods\n",
      "T18\tOtherScientificTerm 556 573\tsingle modalities\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R7\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "R8\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R9\tCOREF Arg1:T9 Arg2:T5\n",
      "R10\tCOREF Arg1:T9 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R12\tCOREF Arg1:T16 Arg2:T12\n",
      "R13\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R14\tUSED-FOR Arg1:T16 Arg2:T18\n",
      "R15\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2011_50_abs.ann\n",
      "T1\tTask 7 22\tsecurity domain\n",
      "T2\tTask 40 79\tidentifying rare behaviours of interest\n",
      "T3\tOtherScientificTerm 52 79\trare behaviours of interest\n",
      "T4\tMaterial 81 98\tTraining examples\n",
      "T5\tGeneric 109 119\tbehaviours\n",
      "T6\tGeneric 149 153\tthey\n",
      "T7\tMethod 230 257\tweakly supervised algorithm\n",
      "T8\tOtherScientificTerm 274 284\tbehaviours\n",
      "T9\tOtherScientificTerm 362 376\tGlobal context\n",
      "T10\tTask 403 435\tdetection of abnormal behaviours\n",
      "T11\tOtherScientificTerm 469 486\tPragmatic aspects\n",
      "T12\tMethod 516 532\tparameter tuning\n",
      "R1\tCOREF Arg1:T5 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tCOREF Arg1:T4 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R6\tCOREF Arg1:T10 Arg2:T2\n",
      "R7\tPART-OF Arg1:T2 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2013_25_abs.ann\n",
      "T1\tMethod 13 28\tscanning method\n",
      "T2\tOtherScientificTerm 43 90\tdense sub-pixel camera-projector correspondence\n",
      "T3\tOtherScientificTerm 113 136\tphotometric calibration\n",
      "T4\tOtherScientificTerm 172 189\trelative geometry\n",
      "T5\tMetric 191 208\tSubpixel accuracy\n",
      "T6\tOtherScientificTerm 244 258\tzero-crossings\n",
      "T7\tOtherScientificTerm 302 323\tunstructured patterns\n",
      "T8\tOtherScientificTerm 332 373\tgray-level band-pass white noise patterns\n",
      "T9\tMetric 388 398\trobustness\n",
      "T10\tOtherScientificTerm 402 419\tindirect lighting\n",
      "T11\tOtherScientificTerm 424 445\tscene discontinuities\n",
      "T12\tGeneric 496 502\tmethod\n",
      "T13\tOtherScientificTerm 512 526\tscene geometry\n",
      "T14\tMetric 537 555\tsubpixel precision\n",
      "T15\tGeneric 566 568\tit\n",
      "T16\tTask 599 628\tactive reconstruction systems\n",
      "T17\tGeneric 656 680\tstate of the art methods\n",
      "T18\tMethod 689 710\tmi-cro phase shifting\n",
      "T19\tMethod 715 739\tmodulated phase shifting\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tEVALUATE-FOR Arg1:T9 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R4\tCOREF Arg1:T12 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R6\tCOREF Arg1:T15 Arg2:T12\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R8\tFEATURE-OF Arg1:T14 Arg2:T13\n",
      "R9\tHYPONYM-OF Arg1:T18 Arg2:T17\n",
      "R10\tHYPONYM-OF Arg1:T19 Arg2:T17\n",
      "R11\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "R12\tFEATURE-OF Arg1:T11 Arg2:T9\n",
      "R13\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R14\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2013_26_abs.ann\n",
      "T1\tMethod 43 86\tcoarse-to-fine energy minimization strategy\n",
      "T2\tTask 91 119\tsemantic video segmenta-tion\n",
      "T3\tGeneric 125 133\tstrategy\n",
      "T4\tTask 148 196\thierarchical abstraction of the supervoxel graph\n",
      "T5\tOtherScientificTerm 269 278\thierarchy\n",
      "T6\tOtherScientificTerm 335 349\tcoarser graphs\n",
      "T7\tGeneric 355 363\tstrategy\n",
      "T8\tGeneric 380 382\tit\n",
      "T9\tOtherScientificTerm 433 445\tfinest graph\n",
      "T10\tGeneric 447 449\tIt\n",
      "T11\tGeneric 468 470\tit\n",
      "T12\tOtherScientificTerm 499 514\tenergy function\n",
      "T13\tMethod 581 610\tenergy minimization algorithm\n",
      "T14\tMethod 618 628\tgraph cuts\n",
      "T15\tMethod 633 651\tbelief propagation\n",
      "T16\tGeneric 654 656\tIt\n",
      "T17\tTask 692 701\tinference\n",
      "T18\tGeneric 714 722\tdatasets\n",
      "T19\tOtherScientificTerm 747 773\tspatio-temporal continuity\n",
      "T20\tGeneric 827 835\tstrategy\n",
      "T21\tMethod 857 880\thierarchical approaches\n",
      "T22\tMaterial 899 919\timage and video data\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R4\tCOREF Arg1:T3 Arg2:T7\n",
      "R5\tCOREF Arg1:T7 Arg2:T8\n",
      "R6\tCOREF Arg1:T7 Arg2:T10\n",
      "R7\tCOREF Arg1:T10 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R10\tCONJUNCTION Arg1:T11 Arg2:T13\n",
      "R11\tHYPONYM-OF Arg1:T14 Arg2:T13\n",
      "R12\tHYPONYM-OF Arg1:T15 Arg2:T13\n",
      "R13\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R14\tCOREF Arg1:T11 Arg2:T20\n",
      "R15\tCOMPARE Arg1:T20 Arg2:T21\n",
      "R16\tCOREF Arg1:T10 Arg2:T16\n",
      "R17\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R18\tFEATURE-OF Arg1:T19 Arg2:T18\n",
      "R19\tEVALUATE-FOR Arg1:T18 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2013_33_abs.ann\n",
      "T1\tGeneric 23 31\tapproach\n",
      "T2\tTask 35 64\tlocalizing functional objects\n",
      "T3\tMaterial 68 87\tsurveillance videos\n",
      "T4\tOtherScientificTerm 96 112\tdomain knowledge\n",
      "T5\tOtherScientificTerm 119 142\tsemantic object classes\n",
      "T6\tOtherScientificTerm 173 191\tFunctional objects\n",
      "T7\tOtherScientificTerm 204 239\tdiscriminative appearance and shape\n",
      "T8\tGeneric 245 249\tthey\n",
      "T9\tOtherScientificTerm 485 503\tfunctional objects\n",
      "T10\tMethod 693 714\tLa-grangian mechanics\n",
      "T11\tOtherScientificTerm 908 926\tfunctional objects\n",
      "T12\tMethod 1075 1093\tBayesian framework\n",
      "T13\tOtherScientificTerm 1130 1163\tpeople's trajectories and intents\n",
      "T14\tOtherScientificTerm 1165 1192\tconstraint map of the scene\n",
      "T15\tOtherScientificTerm 1198 1229\tlocations of functional objects\n",
      "T16\tMethod 1233 1284\tdata-driven Markov Chain Monte Carlo (MCMC) process\n",
      "T17\tTask 1297 1306\tinference\n",
      "T18\tMaterial 1326 1365\tvideos of public squares and courtyards\n",
      "T19\tTask 1400 1429\tlocalizing functional objects\n",
      "T20\tTask 1434 1466\tpredicting people's trajectories\n",
      "T21\tOtherScientificTerm 1494 1507\tvideo footage\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R4\tCOREF Arg1:T8 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R6\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T15\n",
      "R8\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R9\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R11\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "R12\tEVALUATE-FOR Arg1:T18 Arg2:T20\n",
      "R13\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R14\tCOREF Arg1:T19 Arg2:T2\n",
      "R15\tCOREF Arg1:T1 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2013_36_abs.ann\n",
      "T1\tTask 48 71\tcreation of city models\n",
      "T2\tGeneric 113 119\tmethod\n",
      "T3\tTask 124 175\tsynthesizing complex, photo-realistic facade images\n",
      "T4\tMethod 241 260\tsemantic components\n",
      "T5\tOtherScientificTerm 264 270\ttiling\n",
      "T6\tOtherScientificTerm 298 305\ttilings\n",
      "T7\tOtherScientificTerm 336 351\tfacade textures\n",
      "T8\tOtherScientificTerm 386 410\toccluded parts inpainted\n",
      "T9\tGeneric 414 431\tgenetic algorithm\n",
      "T10\tOtherScientificTerm 449 456\tfacades\n",
      "T11\tOtherScientificTerm 468 483\tinpainted parts\n",
      "T12\tGeneric 611 637\tmultiple standard datasets\n",
      "T13\tGeneric 736 742\tmethod\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R6\tCOREF Arg1:T9 Arg2:T13\n",
      "R7\tEVALUATE-FOR Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2013_47_abs.ann\n",
      "T1\tOtherScientificTerm 0 12\tLight fields\n",
      "T2\tMethod 17 44\timage-based representations\n",
      "T3\tOtherScientificTerm 54 74\tdensely sampled rays\n",
      "T4\tOtherScientificTerm 80 97\tscene description\n",
      "T5\tTask 125 157\tgeometric structures of 3D lines\n",
      "T6\tOtherScientificTerm 161 170\tray space\n",
      "T7\tTask 185 210\tlight field triangulation\n",
      "T8\tTask 215 230\tstereo matching\n",
      "T9\tTask 236 257\ttriangulation problem\n",
      "T10\tOtherScientificTerm 278 287\tray space\n",
      "T11\tOtherScientificTerm 293 333\tcontinuous and non-overlapping simplices\n",
      "T12\tOtherScientificTerm 376 389\ttriangulation\n",
      "T13\tOtherScientificTerm 401 429\tpiecewise-linear interpolant\n",
      "T14\tTask 441 469\tlight field super-resolution\n",
      "T15\tOtherScientificTerm 488 505\tlight field space\n",
      "T16\tOtherScientificTerm 534 550\t3D line segments\n",
      "T17\tOtherScientificTerm 600 618\tbilinear subspaces\n",
      "T18\tOtherScientificTerm 707 725\tbilinear subspaces\n",
      "T19\tOtherScientificTerm 729 745\tline constraints\n",
      "T20\tMethod 761 801\tConstrained Delaunay Triangulation (CDT)\n",
      "T21\tMethod 853 893\tline-assisted graph-cut (LAGC) algorithm\n",
      "T22\tOtherScientificTerm 919 938\t3D line constraints\n",
      "T23\tTask 944 971\tlight field stereo matching\n",
      "T24\tMaterial 988 1011\tsynthetic and real data\n",
      "T25\tMethod 1031 1064\ttriangulation and LAGC algorithms\n",
      "T26\tGeneric 1076 1102\tstate-of-the-art solutions\n",
      "T27\tMetric 1106 1114\taccuracy\n",
      "T28\tMetric 1119 1133\tvisual quality\n",
      "R1\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R3\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T8\n",
      "R5\tCOREF Arg1:T7 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R8\tCOREF Arg1:T9 Arg2:T12\n",
      "R9\tCOMPARE Arg1:T25 Arg2:T26\n",
      "R10\tEVALUATE-FOR Arg1:T27 Arg2:T25\n",
      "R11\tEVALUATE-FOR Arg1:T28 Arg2:T25\n",
      "R12\tEVALUATE-FOR Arg1:T27 Arg2:T26\n",
      "R13\tEVALUATE-FOR Arg1:T28 Arg2:T26\n",
      "R14\tEVALUATE-FOR Arg1:T24 Arg2:T25\n",
      "R15\tEVALUATE-FOR Arg1:T24 Arg2:T26\n",
      "R16\tHYPONYM-OF Arg1:T21 Arg2:T25\n",
      "R17\tHYPONYM-OF Arg1:T20 Arg2:T25\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2013_50_abs.ann\n",
      "T1\tMethod 0 27\tRegression-based techniques\n",
      "T2\tTask 61 94\tpeople counting in crowded scenes\n",
      "T3\tGeneric 119 129\ttechniques\n",
      "T4\tTask 162 177\tdata annotation\n",
      "T5\tTask 182 196\tmodel training\n",
      "T6\tOtherScientificTerm 341 359\tinformative frames\n",
      "T7\tTask 377 387\tannotation\n",
      "T8\tGeneric 451 464\tlabelled data\n",
      "T9\tMaterial 470 494\tabundant unlabelled data\n",
      "T10\tTask 595 610\tdata annotation\n",
      "T11\tMethod 649 704\tunified active and semi-supervised regression framework\n",
      "T12\tMethod 729 746\ttransfer learning\n",
      "T13\tOtherScientificTerm 777 814\tgeometric structure of crowd patterns\n",
      "T14\tMethod 819 836\tmanifold analysis\n",
      "T15\tGeneric 894 902\tapproach\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R3\tCOREF Arg1:T4 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R5\tCOREF Arg1:T11 Arg2:T15\n",
      "R6\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T11\n",
      "R8\tCOREF Arg1:T7 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R10\tCOMPARE Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2015_392_abs.ann\n",
      "T1\tGeneric 32 40\tapproach\n",
      "T2\tTask 53 85\toriented object proposals (OOPs)\n",
      "T3\tMetric 100 115\tdetection error\n",
      "T4\tOtherScientificTerm 134 160\torientations of the object\n",
      "T5\tOtherScientificTerm 208 222\tobject regions\n",
      "T6\tOtherScientificTerm 236 264\tpixelwise object probability\n",
      "T7\tOtherScientificTerm 292 302\tobjectness\n",
      "T8\tTask 351 378\tproposal generation problem\n",
      "T9\tMethod 384 415\tgenerative proba-bilistic model\n",
      "T10\tOtherScientificTerm 426 442\tobject proposals\n",
      "T11\tOtherScientificTerm 456 462\tshapes\n",
      "T12\tOtherScientificTerm 470 475\tsizes\n",
      "T13\tOtherScientificTerm 480 492\torientations\n",
      "T14\tOtherScientificTerm 526 551\tlocal maximum likelihoods\n",
      "T15\tGeneric 561 569\tapproach\n",
      "T16\tGeneric 604 606\tit\n",
      "T17\tMethod 617 632\tobject detector\n",
      "T18\tOtherScientificTerm 661 673\torientations\n",
      "T19\tOtherScientificTerm 690 713\tshapes of the proposals\n",
      "T20\tOtherScientificTerm 788 804\tsampling windows\n",
      "T21\tGeneric 830 832\tit\n",
      "T22\tMethod 840 863\tmassive window sampling\n",
      "T23\tOtherScientificTerm 890 909\tnumber of proposals\n",
      "T24\tMetric 935 941\trecall\n",
      "T25\tMaterial 962 985\tPASCAL VOC 2007 dataset\n",
      "T26\tMethod 1009 1012\tOOP\n",
      "T27\tGeneric 1029 1058\tstate-of-the-art fast methods\n",
      "T28\tOtherScientificTerm 1094 1121\trotation invariant property\n",
      "T29\tMethod 1130 1160\tclass-specific object detector\n",
      "T30\tMethod 1214 1241\tproposal generation methods\n",
      "T31\tMaterial 1252 1277\tobject rotation scenarios\n",
      "T32\tMaterial 1281 1298\tgeneral scenarios\n",
      "T33\tTask 1311 1315\tOOPs\n",
      "R1\tEVALUATE-FOR Arg1:T3 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R4\tFEATURE-OF Arg1:T11 Arg2:T10\n",
      "R5\tCOMPARE Arg1:T26 Arg2:T27\n",
      "R6\tUSED-FOR Arg1:T28 Arg2:T29\n",
      "R7\tCOMPARE Arg1:T29 Arg2:T30\n",
      "R8\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R9\tCOMPARE Arg1:T6 Arg2:T7\n",
      "R10\tCOREF Arg1:T15 Arg2:T9\n",
      "R11\tCOREF Arg1:T21 Arg2:T15\n",
      "R12\tCOREF Arg1:T16 Arg2:T15\n",
      "R13\tEVALUATE-FOR Arg1:T24 Arg2:T21\n",
      "R14\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R15\tCOREF Arg1:T9 Arg2:T1\n",
      "R16\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R17\tUSED-FOR Arg1:T21 Arg2:T23\n",
      "R18\tEVALUATE-FOR Arg1:T25 Arg2:T26\n",
      "R19\tCOREF Arg1:T33 Arg2:T26\n",
      "R20\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R21\tHYPONYM-OF Arg1:T13 Arg2:T11\n",
      "R22\tUSED-FOR Arg1:T14 Arg2:T10\n",
      "R23\tCONJUNCTION Arg1:T31 Arg2:T32\n",
      "R24\tEVALUATE-FOR Arg1:T31 Arg2:T30\n",
      "R25\tEVALUATE-FOR Arg1:T32 Arg2:T30\n",
      "R26\tEVALUATE-FOR Arg1:T31 Arg2:T29\n",
      "R27\tEVALUATE-FOR Arg1:T32 Arg2:T29\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2015_393_abs.ann\n",
      "T1\tTask 37 59\tloss-aware predictions\n",
      "T2\tTask 37 90\tloss-aware predictions in image segmentation settings\n",
      "T3\tTask 63 90\timage segmentation settings\n",
      "T4\tOtherScientificTerm 101 120\tevaluation function\n",
      "T5\tMetric 128 165\tIntersection-over-Union (IoU) measure\n",
      "T6\tMethod 200 226\timage segmentation systems\n",
      "T7\tGeneric 253 272\tdominant approaches\n",
      "T8\tGeneric 278 283\tfirst\n",
      "T9\tOtherScientificTerm 301 326\tExpected-IoU (EIoU) score\n",
      "T10\tOtherScientificTerm 330 379\tExpected-Intersection-over-Expected-Union (EIoEU)\n",
      "T11\tGeneric 389 404\tsecond approach\n",
      "T12\tOtherScientificTerm 425 429\tEIoU\n",
      "T13\tTask 559 584\timage seg-mentation tasks\n",
      "T14\tGeneric 689 696\tmethods\n",
      "T15\tOtherScientificTerm 705 710\tEIoEU\n",
      "T16\tMethod 705 724\tEIoEU approximation\n",
      "T17\tGeneric 807 817\tapproaches\n",
      "T18\tTask 855 879\timage segmentation tasks\n",
      "R1\tEVALUATE-FOR Arg1:T5 Arg2:T6\n",
      "R2\tHYPONYM-OF Arg1:T5 Arg2:T4\n",
      "R3\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R4\tHYPONYM-OF Arg1:T11 Arg2:T7\n",
      "R5\tCOREF Arg1:T12 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T16 Arg2:T14\n",
      "R7\tCOREF Arg1:T14 Arg2:T17\n",
      "R8\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R9\tCOREF Arg1:T13 Arg2:T18\n",
      "R10\tCOREF Arg1:T10 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2015_400_abs.ann\n",
      "T1\tMethod 0 12\tHough voting\n",
      "T2\tOtherScientificTerm 18 48\tgeometric transformation space\n",
      "T3\tTask 70 90\tspatial verification\n",
      "T4\tOtherScientificTerm 117 141\tfeature detection errors\n",
      "T5\tOtherScientificTerm 157 215\tinflexible quan-tization of single feature correspondences\n",
      "T6\tGeneric 258 264\tmethod\n",
      "T7\tMethod 273 295\tadaptive dither voting\n",
      "T8\tTask 301 328\trobust spatial verification\n",
      "T9\tGeneric 416 422\tmethod\n",
      "T10\tOtherScientificTerm 457 490\tmultiple dithered transformations\n",
      "T11\tGeneric 562 568\tmethod\n",
      "T12\tOtherScientificTerm 626 653\ttransformation quantization\n",
      "T13\tOtherScientificTerm 687 705\tregards mismatches\n",
      "T14\tOtherScientificTerm 724 745\tgeometric constraints\n",
      "T15\tOtherScientificTerm 753 770\tdithering process\n",
      "T16\tOtherScientificTerm 803 817\tnon-uniformity\n",
      "T17\tMethod 823 838\tHough histogram\n",
      "T18\tOtherScientificTerm 846 864\tspatial similarity\n",
      "T19\tOtherScientificTerm 875 901\tmultiple matching surfaces\n",
      "T20\tGeneric 980 986\tmethod\n",
      "T21\tGeneric 992 998\tmethod\n",
      "T22\tGeneric 1032 1044\tcounterparts\n",
      "T23\tMetric 1053 1061\taccuracy\n",
      "T24\tMetric 1066 1077\tscalability\n",
      "T25\tTask 1111 1146\tretrieval of small, rotated objects\n",
      "R1\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tCOREF Arg1:T7 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R5\tCOREF Arg1:T8 Arg2:T3\n",
      "R6\tCOREF Arg1:T6 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R8\tCOREF Arg1:T11 Arg2:T9\n",
      "R9\tFEATURE-OF Arg1:T16 Arg2:T17\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T19\n",
      "R11\tCOREF Arg1:T20 Arg2:T11\n",
      "R12\tCOREF Arg1:T21 Arg2:T20\n",
      "R13\tCOMPARE Arg1:T22 Arg2:T21\n",
      "R14\tEVALUATE-FOR Arg1:T23 Arg2:T21\n",
      "R15\tEVALUATE-FOR Arg1:T24 Arg2:T21\n",
      "R16\tEVALUATE-FOR Arg1:T23 Arg2:T22\n",
      "R17\tEVALUATE-FOR Arg1:T24 Arg2:T22\n",
      "R18\tUSED-FOR Arg1:T21 Arg2:T25\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2015_403_abs.ann\n",
      "T1\tOtherScientificTerm 46 57\taging faces\n",
      "T2\tMethod 101 132\tage-group specific dictionaries\n",
      "T3\tOtherScientificTerm 156 172\tdictionary bases\n",
      "T4\tOtherScientificTerm 255 276\taging process pattern\n",
      "T5\tMethod 311 329\tlinear combination\n",
      "T6\tGeneric 339 347\tpatterns\n",
      "T7\tTask 371 397\tpersonalized aging process\n",
      "T8\tMethod 457 484\tdictionary learning process\n",
      "T9\tMethod 504 522\taging dictionaries\n",
      "T10\tOtherScientificTerm 552 587\tpersonalized facial characteristics\n",
      "T11\tOtherScientificTerm 594 598\tmole\n",
      "T12\tTask 627 640\taging process\n",
      "T13\tOtherScientificTerm 837 882\tpersonality-aware coupled reconstruction loss\n",
      "T14\tGeneric 908 920\tdictionaries\n",
      "T15\tGeneric 1040 1048\tsolution\n",
      "T16\tGeneric 1060 1077\tstate-of-the-arts\n",
      "T17\tOtherScientificTerm 1089 1119\tpersonalized aging progression\n",
      "T18\tTask 1157 1184\tcross-age face verification\n",
      "T19\tMethod 1188 1212\tsynthesizing aging faces\n",
      "R1\tCOREF Arg1:T4 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R4\tPART-OF Arg1:T3 Arg2:T2\n",
      "R5\tHYPONYM-OF Arg1:T11 Arg2:T10\n",
      "R6\tCOMPARE Arg1:T15 Arg2:T16\n",
      "R7\tUSED-FOR Arg1:T19 Arg2:T18\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T17\n",
      "R9\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R10\tCOREF Arg1:T7 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R12\tCOREF Arg1:T2 Arg2:T9\n",
      "R13\tCOREF Arg1:T9 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2015_50_abs.ann\n",
      "T1\tTask 0 51\tDetecting fine-grained subtle changes among a scene\n",
      "T2\tMethod 98 122\tchange detection methods\n",
      "T3\tTask 136 177\tdetecting large-scale significant changes\n",
      "T4\tMethod 231 250\tend-to-end approach\n",
      "T5\tGeneric 271 278\tproblem\n",
      "T6\tMethod 294 318\tactive camera relocation\n",
      "T7\tMetric 429 450\tdetection sensitivity\n",
      "T8\tMetric 455 463\taccuracy\n",
      "T9\tOtherScientificTerm 546 559\tilluminations\n",
      "T10\tTask 680 709\tfine-grained change detection\n",
      "T11\tTask 715 741\tjoint optimization problem\n",
      "T12\tGeneric 759 766\tfactors\n",
      "T13\tOtherScientificTerm 774 806\tnormal-aware lighting difference\n",
      "T14\tOtherScientificTerm 808 839\tcamera geometry correction flow\n",
      "T15\tOtherScientificTerm 845 867\treal scene change mask\n",
      "T16\tGeneric 888 895\tfactors\n",
      "T17\tOtherScientificTerm 901 922\tcoarse-to-fine manner\n",
      "T18\tOtherScientificTerm 944 959\tchange decision\n",
      "T19\tMethod 963 980\trank minimization\n",
      "T20\tMaterial 997 1016\treal-world datasets\n",
      "T21\tTask 1030 1080\tfine-grained change detection of misaligned scenes\n",
      "T22\tOtherScientificTerm 1087 1122\tvaried multiple lighting conditions\n",
      "T23\tGeneric 1183 1191\tapproach\n",
      "T24\tMethod 1214 1238\tchange detection methods\n",
      "T25\tOtherScientificTerm 1270 1288\treal scene changes\n",
      "T26\tOtherScientificTerm 1315 1334\tlighting variations\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tCOREF Arg1:T3 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R5\tHYPONYM-OF Arg1:T13 Arg2:T12\n",
      "R6\tHYPONYM-OF Arg1:T14 Arg2:T12\n",
      "R7\tHYPONYM-OF Arg1:T15 Arg2:T12\n",
      "R8\tFEATURE-OF Arg1:T12 Arg2:T11\n",
      "R9\tCOREF Arg1:T12 Arg2:T16\n",
      "R10\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R11\tUSED-FOR Arg1:T19 Arg2:T18\n",
      "R12\tFEATURE-OF Arg1:T22 Arg2:T21\n",
      "R13\tEVALUATE-FOR Arg1:T20 Arg2:T21\n",
      "R14\tCOMPARE Arg1:T23 Arg2:T24\n",
      "R15\tUSED-FOR Arg1:T23 Arg2:T25\n",
      "R16\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R17\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R18\tCOREF Arg1:T4 Arg2:T23\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_1995_30_abs.ann\n",
      "T1\tMethod 27 32\tAnt-Q\n",
      "T2\tMethod 94 104\tQ-learning\n",
      "T3\tTask 160 235\tsymmetric and asym-metric instances of the traveling salesman problem (TSP)\n",
      "T4\tMethod 237 253\tAnt-Q algorithms\n",
      "T5\tMethod 283 298\tant system (AS)\n",
      "T6\tMethod 302 323\tdistributed algorithm\n",
      "T7\tTask 328 354\tcombinatorial optimization\n",
      "T8\tMethod 489 491\tAS\n",
      "T9\tMethod 524 536\tAnt-Q family\n",
      "T10\tGeneric 557 566\tinstances\n",
      "T11\tGeneric 575 581\tfamily\n",
      "T12\tOtherScientificTerm 608 610\tAS\n",
      "T13\tMethod 661 666\tAnt-Q\n",
      "T14\tMethod 708 713\tAnt-Q\n",
      "T15\tTask 717 730\tsymmetric TSP\n",
      "T16\tMethod 778 798\theuristic approaches\n",
      "T17\tMethod 808 823\tneural networks\n",
      "T18\tMethod 827 839\tlocal search\n",
      "T19\tMethod 859 864\tAnt-Q\n",
      "T20\tTask 883 897\tasymmetric TSP\n",
      "T21\tMethod 929 934\tAnt-Q\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R2\tHYPONYM-OF Arg1:T8 Arg2:T9\n",
      "R3\tCOREF Arg1:T9 Arg2:T4\n",
      "R4\tCOREF Arg1:T21 Arg2:T19\n",
      "R5\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R6\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R7\tCOMPARE Arg1:T14 Arg2:T16\n",
      "R8\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R9\tCOREF Arg1:T14 Arg2:T13\n",
      "R10\tCOREF Arg1:T19 Arg2:T14\n",
      "R11\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R12\tUSED-FOR Arg1:T18 Arg2:T16\n",
      "R13\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R14\tHYPONYM-OF Arg1:T5 Arg2:T6\n",
      "R15\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R16\tCOREF Arg1:T8 Arg2:T5\n",
      "R17\tCOREF Arg1:T11 Arg2:T9\n",
      "R18\tPART-OF Arg1:T10 Arg2:T11\n",
      "R19\tCOMPARE Arg1:T10 Arg2:T12\n",
      "R20\tCOREF Arg1:T13 Arg2:T9\n",
      "R21\tHYPONYM-OF Arg1:T15 Arg2:T3\n",
      "R22\tHYPONYM-OF Arg1:T20 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_1995_38_abs.ann\n",
      "T1\tTask 21 50\tlearning in autonomous agents\n",
      "T2\tMethod 75 107\tdomain-speciic models of actions\n",
      "T3\tTask 122 138\tplanning systems\n",
      "T4\tGeneric 166 173\tmethods\n",
      "T5\tMethod 199 212\taction models\n",
      "T6\tOtherScientificTerm 267 280\tdomain expert\n",
      "T7\tMetric 288 295\tmethods\n",
      "T8\tMethod 360 382\taction model formalism\n",
      "T9\tMethod 424 439\tre-active agent\n",
      "T10\tMethod 474 499\tnoise-handling mechanisms\n",
      "T11\tMethod 584 589\tGOLEM\n",
      "T12\tMethod 607 620\taction models\n",
      "T13\tMethod 647 673\tintegrated learning system\n",
      "T14\tTask 711 733\tsimulated construction\n",
      "T15\tTask 738 750\tooce domains\n",
      "R1\tCOREF Arg1:T4 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R4\tCOREF Arg1:T12 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R7\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R8\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R9\tEVALUATE-FOR Arg1:T15 Arg2:T13\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R11\tUSED-FOR Arg1:T10 Arg2:T7\n",
      "R12\tCOREF Arg1:T7 Arg2:T13\n",
      "R13\tCOREF Arg1:T5 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_2006_111_abs.ann\n",
      "T1\tMethod 0 16\tBoosting methods\n",
      "T2\tMethod 98 109\tclassifiers\n",
      "T3\tMethod 206 216\tclassifier\n",
      "T4\tMethod 328 346\tboosting algorithm\n",
      "T5\tMethod 348 354\tarc-gv\n",
      "T6\tOtherScientificTerm 383 403\tmargins distribution\n",
      "T7\tMethod 409 417\tAdaBoost\n",
      "T8\tMethod 607 613\tarc-gv\n",
      "T9\tMetric 648 658\tcomplexity\n",
      "T10\tMethod 666 682\tbase classifiers\n",
      "T11\tMethod 769 783\tmargins theory\n",
      "T12\tMetric 900 926\tbase-classifier complexity\n",
      "R1\tHYPONYM-OF Arg1:T5 Arg2:T4\n",
      "R2\tCOMPARE Arg1:T5 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R4\tHYPONYM-OF Arg1:T10 Arg2:T8\n",
      "R5\tCOREF Arg1:T8 Arg2:T5\n",
      "R6\tEVALUATE-FOR Arg1:T9 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_2006_112_abs.ann\n",
      "T1\tGeneric 22 31\tframework\n",
      "T2\tTask 36 62\tonline multiclass learning\n",
      "T3\tOtherScientificTerm 76 104\tnotion of hypothesis sharing\n",
      "T4\tGeneric 113 122\tframework\n",
      "T5\tGeneric 240 249\tframework\n",
      "T6\tTask 308 333\tmulticlass categorization\n",
      "T7\tMethod 465 486\tmulticlass Perceptron\n",
      "T8\tGeneric 494 503\tframework\n",
      "T9\tMethod 517 548\tunifying mistake bound analysis\n",
      "T10\tMethod 684 707\tonline learning process\n",
      "T11\tGeneric 742 750\tapproach\n",
      "T12\tGeneric 764 766\tit\n",
      "T13\tGeneric 779 786\tmethods\n",
      "T14\tMaterial 795 825\tsynthetic and natural datasets\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T1 Arg2:T4\n",
      "R4\tCOREF Arg1:T4 Arg2:T5\n",
      "R5\tCOREF Arg1:T5 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tCOREF Arg1:T8 Arg2:T11\n",
      "R8\tCOREF Arg1:T11 Arg2:T12\n",
      "R9\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R10\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R11\tEVALUATE-FOR Arg1:T14 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_2006_119_abs.ann\n",
      "T1\tTask 63 79\tboard game of Go\n",
      "T2\tMaterial 85 115\tgame records of expert players\n",
      "T3\tOtherScientificTerm 144 168\tprobability distribution\n",
      "T4\tGeneric 234 246\tdistribution\n",
      "T5\tOtherScientificTerm 276 287\tcomputer Go\n",
      "T6\tOtherScientificTerm 323 344\tstand-alone Go player\n",
      "T7\tGeneric 346 348\tIt\n",
      "T8\tMethod 378 391\tmove selector\n",
      "T9\tMethod 396 407\tmove sorter\n",
      "T10\tMethod 412 428\tgame tree search\n",
      "T11\tTask 438 451\ttraining tool\n",
      "T12\tOtherScientificTerm 456 466\tGo players\n",
      "T13\tGeneric 472 478\tmethod\n",
      "T14\tMethod 510 535\tpattern extraction scheme\n",
      "T15\tMethod 630 657\tBayesian learning algorithm\n",
      "T16\tOtherScientificTerm 765 786\tlocal pattern context\n",
      "T17\tGeneric 792 798\tsystem\n",
      "T18\tMaterial 821 833\texpert games\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T4 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R7\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R8\tCOREF Arg1:T13 Arg2:T7\n",
      "R9\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R10\tPART-OF Arg1:T14 Arg2:T13\n",
      "R11\tPART-OF Arg1:T15 Arg2:T13\n",
      "R12\tCOREF Arg1:T17 Arg2:T13\n",
      "R13\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R14\tUSED-FOR Arg1:T7 Arg2:T11\n",
      "R15\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R16\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_2006_122_abs.ann\n",
      "T1\tMethod 7 41\tmodel-based policy search approach\n",
      "T2\tTask 45 72\treinforcement learning (RL)\n",
      "T3\tOtherScientificTerm 74 82\tpolicies\n",
      "T4\tOtherScientificTerm 131 154\tMarkov decision process\n",
      "T5\tTask 169 208\thigh-dimensional continuous-state tasks\n",
      "T6\tGeneric 261 266\tmodel\n",
      "T7\tGeneric 287 296\talgorithm\n",
      "T8\tOtherScientificTerm 307 313\tpolicy\n",
      "T9\tTask 380 393\tmodel-free RL\n",
      "T10\tOtherScientificTerm 440 456\treal-life trials\n",
      "T11\tMethod 486 502\thybrid algorithm\n",
      "T12\tMethod 525 542\tapproximate model\n",
      "T13\tOtherScientificTerm 571 587\treal-life trials\n",
      "T14\tTask 634 652\tpolicy evaluations\n",
      "T15\tOtherScientificTerm 659 675\treal-life trials\n",
      "T16\tMethod 696 713\tapproximate model\n",
      "T17\tGeneric 779 788\talgorithm\n",
      "T18\tOtherScientificTerm 798 822\tnear-optimal performance\n",
      "T19\tGeneric 944 955\tcrude model\n",
      "T20\tOtherScientificTerm 978 994\treal-life trials\n",
      "T21\tGeneric 1001 1010\talgorithm\n",
      "T22\tOtherScientificTerm 1022 1046\tnear-optimal performance\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R5\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R6\tCOREF Arg1:T17 Arg2:T21\n",
      "R7\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R8\tUSED-FOR Arg1:T19 Arg2:T21\n",
      "R9\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R10\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R11\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R12\tCOREF Arg1:T6 Arg2:T7\n",
      "R13\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_2016_10_abs.ann\n",
      "T1\tTask 20 50\tspecialized regression problem\n",
      "T2\tOtherScientificTerm 61 83\tsampling probabilities\n",
      "T3\tMaterial 88 95\trecords\n",
      "T4\tMaterial 99 108\tdatabases\n",
      "T5\tMaterial 147 154\trecords\n",
      "T6\tOtherScientificTerm 177 194\taggregate queries\n",
      "T7\tMethod 253 285\tprincipled and provable solution\n",
      "T8\tGeneric 295 302\tproblem\n",
      "T9\tGeneric 304 306\tit\n",
      "T10\tTask 371 390\tregression problems\n",
      "T11\tOtherScientificTerm 397 401\tloss\n",
      "T12\tOtherScientificTerm 435 454\tregressed-to values\n",
      "T13\tMethod 468 486\tcost zero solution\n",
      "T14\tOtherScientificTerm 529 552\thard budget constraints\n",
      "T15\tOtherScientificTerm 571 586\treg-ularization\n",
      "T16\tMethod 638 693\tregularized Empirical Risk Minimization (ERM) algorithm\n",
      "T17\tMethod 809 825\tuniform sampling\n",
      "T18\tMethod 839 858\tstratified sampling\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tEVALUATE-FOR Arg1:T6 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R4\tPART-OF Arg1:T3 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R6\tCOREF Arg1:T5 Arg2:T3\n",
      "R7\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R8\tCOREF Arg1:T1 Arg2:T8\n",
      "R9\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R10\tCOREF Arg1:T7 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_2016_11_abs.ann\n",
      "T1\tMethod 4 60\trobust principal component analysis (robust PCA) problem\n",
      "T2\tTask 89 118\tmachine learning applications\n",
      "T3\tOtherScientificTerm 155 166\tdata matrix\n",
      "T4\tOtherScientificTerm 172 185\tlow rank part\n",
      "T5\tOtherScientificTerm 193 208\tsparse residual\n",
      "T6\tGeneric 224 234\tapproaches\n",
      "T7\tOtherScientificTerm 273 303\tlow rank plus sparse structure\n",
      "T8\tOtherScientificTerm 327 343\tside information\n",
      "T9\tGeneric 443 454\tinformation\n",
      "T10\tMethod 460 470\trobust PCA\n",
      "T11\tMethod 517 527\trobust PCA\n",
      "T12\tOtherScientificTerm 533 549\tside information\n",
      "T13\tOtherScientificTerm 562 577\tprior structure\n",
      "T14\tOtherScientificTerm 582 602\tfeatures of entities\n",
      "T15\tTask 621 629\trecovery\n",
      "T16\tTask 644 658\tconvex problem\n",
      "T17\tOtherScientificTerm 674 690\tside information\n",
      "T18\tMethod 694 704\trobust PCA\n",
      "T19\tOtherScientificTerm 723 738\tlow rank matrix\n",
      "T20\tGeneric 781 787\tmethod\n",
      "T21\tOtherScientificTerm 882 899\tlow rank matrices\n",
      "T22\tMethod 939 949\trobust PCA\n",
      "T23\tGeneric 987 993\tmethod\n",
      "T24\tOtherScientificTerm 1051 1059\tfeatures\n",
      "T25\tMethod 1063 1073\trobust PCA\n",
      "T26\tTask 1154 1180\tnoisy image classification\n",
      "T27\tGeneric 1198 1204\tmethod\n",
      "T28\tOtherScientificTerm 1261 1277\tside information\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R3\tCOREF Arg1:T1 Arg2:T10\n",
      "R4\tCOREF Arg1:T10 Arg2:T11\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R7\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R8\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R9\tPART-OF Arg1:T17 Arg2:T18\n",
      "R10\tCOREF Arg1:T11 Arg2:T18\n",
      "R11\tCOREF Arg1:T18 Arg2:T22\n",
      "R12\tCOREF Arg1:T22 Arg2:T25\n",
      "R13\tUSED-FOR Arg1:T28 Arg2:T27\n",
      "R14\tEVALUATE-FOR Arg1:T26 Arg2:T27\n",
      "R15\tUSED-FOR Arg1:T23 Arg2:T21\n",
      "R16\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R17\tCOREF Arg1:T20 Arg2:T23\n",
      "R18\tFEATURE-OF Arg1:T24 Arg2:T25\n",
      "R19\tCOREF Arg1:T23 Arg2:T27\n",
      "R20\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R21\tCOREF Arg1:T8 Arg2:T9\n",
      "R22\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R23\tPART-OF Arg1:T4 Arg2:T3\n",
      "R24\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R25\tPART-OF Arg1:T5 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_2016_18_abs.ann\n",
      "T1\tTask 7 30\tObject Recognition task\n",
      "T2\tTask 70 95\tcategorization of objects\n",
      "T3\tTask 100 122\testimating object pose\n",
      "T4\tGeneric 134 140\tformer\n",
      "T5\tMethod 156 185\tview-invariant representation\n",
      "T6\tGeneric 197 203\tlatter\n",
      "T7\tGeneric 215 229\trepresentation\n",
      "T8\tOtherScientificTerm 251 267\tpose information\n",
      "T9\tMethod 323 342\tdeep archi-tectures\n",
      "T10\tTask 372 399\tobject category recognition\n",
      "T11\tMethod 401 422\tDeep learning methods\n",
      "T12\tGeneric 458 462\ttask\n",
      "T13\tTask 477 499\tobject pose estimation\n",
      "T14\tGeneric 512 522\tapproaches\n",
      "T15\tMethod 590 639\tConvolutional Neural Networks (CNN) architectures\n",
      "T16\tTask 683 701\tobject recognition\n",
      "T17\tTask 706 721\tpose estimation\n",
      "T18\tOtherScientificTerm 754 760\tlayers\n",
      "T19\tMethod 772 782\tCNN models\n",
      "T20\tGeneric 815 819\tthem\n",
      "T21\tMethod 857 894\tlayers of distributed representations\n",
      "T22\tMethod 902 906\tCNNs\n",
      "T23\tOtherScientificTerm 917 940\tobject pose information\n",
      "T24\tGeneric 949 953\tthis\n",
      "T25\tMethod 971 1002\tobject category representations\n",
      "T26\tMaterial 1066 1085\tmulti-view datasets\n",
      "R1\tCOREF Arg1:T4 Arg2:T2\n",
      "R2\tCOREF Arg1:T6 Arg2:T3\n",
      "R3\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R7\tPART-OF Arg1:T2 Arg2:T1\n",
      "R8\tPART-OF Arg1:T3 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R10\tCOREF Arg1:T10 Arg2:T2\n",
      "R11\tCOREF Arg1:T12 Arg2:T10\n",
      "R12\tCOREF Arg1:T13 Arg2:T3\n",
      "R13\tCOREF Arg1:T14 Arg2:T11\n",
      "R14\tCOREF Arg1:T17 Arg2:T13\n",
      "R15\tCOREF Arg1:T19 Arg2:T15\n",
      "R16\tPART-OF Arg1:T21 Arg2:T22\n",
      "R17\tUSED-FOR Arg1:T21 Arg2:T23\n",
      "R18\tCOREF Arg1:T24 Arg2:T21\n",
      "R19\tCOMPARE Arg1:T24 Arg2:T25\n",
      "R20\tCOREF Arg1:T22 Arg2:T19\n",
      "R21\tPART-OF Arg1:T18 Arg2:T19\n",
      "R22\tCOREF Arg1:T20 Arg2:T18\n",
      "R23\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R24\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R25\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R26\tUSED-FOR Arg1:T15 Arg2:T17\n",
      "R27\tCOREF Arg1:T16 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_2016_21_abs.ann\n",
      "T1\tMethod 19 62\tlimited-memory stochastic block BFGS update\n",
      "T2\tTask 67 147\tincorporating enriched curvature information in stochastic approximation methods\n",
      "T3\tGeneric 156 162\tmethod\n",
      "T4\tOtherScientificTerm 184 206\tinverse Hessian matrix\n",
      "T5\tGeneric 229 231\tit\n",
      "T6\tOtherScientificTerm 284 291\tHessian\n",
      "T7\tOtherScientificTerm 301 350\trandomly generated compressed form of the Hessian\n",
      "T8\tMethod 371 391\tsketching strategies\n",
      "T9\tMethod 407 426\tquasi-Newton method\n",
      "T10\tMethod 437 466\tstochastic block BFGS updates\n",
      "T11\tMethod 485 517\tvariance reduction approach SVRG\n",
      "T12\tOtherScientificTerm 529 555\tbatch stochastic gradients\n",
      "T13\tOtherScientificTerm 567 585\tlinear convergence\n",
      "T14\tGeneric 603 609\tmethod\n",
      "T15\tTask 630 670\tlarge-scale logistic regression problems\n",
      "T16\tGeneric 687 693\tmethod\n",
      "T17\tGeneric 747 771\tstate-of-the-art methods\n",
      "R1\tCOREF Arg1:T1 Arg2:T3\n",
      "R2\tCOREF Arg1:T5 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R4\tHYPONYM-OF Arg1:T7 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R6\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T12\n",
      "R10\tCOREF Arg1:T1 Arg2:T16\n",
      "R11\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R12\tEVALUATE-FOR Arg1:T15 Arg2:T17\n",
      "R13\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R14\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R15\tCOREF Arg1:T9 Arg2:T14\n",
      "R16\tFEATURE-OF Arg1:T13 Arg2:T14\n",
      "R17\tHYPONYM-OF Arg1:T8 Arg2:T16\n",
      "R18\tHYPONYM-OF Arg1:T9 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_1995_190_abs.ann\n",
      "T1\tMethod 13 26\tprocess model\n",
      "T2\tTask 31 73\thierarchical perceptual sound organization\n",
      "T3\tOtherScientificTerm 92 109\tperceptual sounds\n",
      "T4\tOtherScientificTerm 122 144\tincoming sound signals\n",
      "T5\tTask 158 187\tperceptual sound organization\n",
      "T6\tTask 193 215\tscene analysis problem\n",
      "T7\tMaterial 223 238\tauditory domain\n",
      "T8\tGeneric 244 249\tmodel\n",
      "T9\tMethod 271 289\tprocessing modules\n",
      "T10\tMethod 296 314\thypothesis network\n",
      "T11\tMethod 412 429\tprocessing module\n",
      "T12\tGeneric 448 454\tmodule\n",
      "T13\tMethod 527 545\thypothesis network\n",
      "T14\tMethod 554 572\thypothesis network\n",
      "T15\tMethod 626 640\tinternal model\n",
      "T16\tMaterial 644 661\tperceptual sounds\n",
      "T17\tMethod 705 710\tmodel\n",
      "T18\tMethod 714 741\tmusic scene analysis system\n",
      "T19\tOtherScientificTerm 765 799\tacoustic signals of ensemble music\n",
      "T20\tMaterial 818 824\trhythm\n",
      "T21\tMaterial 826 832\tchords\n",
      "T22\tMaterial 838 868\tsource-separated musical notes\n",
      "T23\tGeneric 905 911\tmethod\n",
      "T24\tOtherScientificTerm 959 982\tinformation integration\n",
      "T25\tMethod 1000 1014\tinternal model\n",
      "T26\tMaterial 1018 1048\thierarchical perceptual sounds\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tPART-OF Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R4\tHYPONYM-OF Arg1:T2 Arg2:T5\n",
      "R5\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R6\tPART-OF Arg1:T9 Arg2:T8\n",
      "R7\tCOREF Arg1:T11 Arg2:T9\n",
      "R8\tCOREF Arg1:T13 Arg2:T10\n",
      "R9\tCOREF Arg1:T14 Arg2:T13\n",
      "R10\tCOREF Arg1:T17 Arg2:T15\n",
      "R11\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "R12\tUSED-FOR Arg1:T18 Arg2:T20\n",
      "R13\tPART-OF Arg1:T15 Arg2:T14\n",
      "R14\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R15\tPART-OF Arg1:T10 Arg2:T8\n",
      "R16\tCOREF Arg1:T11 Arg2:T12\n",
      "R17\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R18\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R19\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R20\tUSED-FOR Arg1:T18 Arg2:T21\n",
      "R21\tUSED-FOR Arg1:T18 Arg2:T22\n",
      "R22\tCOREF Arg1:T25 Arg2:T15\n",
      "R23\tUSED-FOR Arg1:T25 Arg2:T26\n",
      "R24\tFEATURE-OF Arg1:T24 Arg2:T23\n",
      "R25\tUSED-FOR Arg1:T24 Arg2:T25\n",
      "R26\tCOREF Arg1:T23 Arg2:T8\n",
      "R27\tCOREF Arg1:T8 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2001_12_abs.ann\n",
      "T1\tMethod 98 112\tweb interfaces\n",
      "T2\tOtherScientificTerm 127 138\tdesktop PCs\n",
      "T3\tOtherScientificTerm 236 256\tdeep link structures\n",
      "T4\tGeneric 324 333\talgorithm\n",
      "T5\tMethod 335 342\tMINPATH\n",
      "T6\tTask 372 395\twireless web navigation\n",
      "T7\tMethod 446 453\tMINPATH\n",
      "T8\tGeneric 489 494\tmodel\n",
      "T9\tOtherScientificTerm 498 518\tweb visitor behavior\n",
      "T10\tTask 535 560\tsavings of shortcut links\n",
      "T11\tGeneric 624 641\tpredictive models\n",
      "T12\tMethod 653 680\tNaÂ¨Ä±ve Bayes mixture models\n",
      "T13\tMethod 685 710\tmixtures of Markov models\n",
      "T14\tMethod 747 754\tMINPATH\n",
      "R1\tCOREF Arg1:T5 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R4\tCOREF Arg1:T7 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R6\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R7\tHYPONYM-OF Arg1:T13 Arg2:T11\n",
      "R8\tCOREF Arg1:T14 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R10\tCOREF Arg1:T11 Arg2:T8\n",
      "R11\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R12\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R13\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2001_4_abs.ann\n",
      "T1\tGeneric 6 15\talgorithm\n",
      "T2\tTask 38 75\tdimensional container packing problem\n",
      "T3\tGeneric 112 121\talgorithm\n",
      "T4\tMethod 152 190\tapproach of wall building and layering\n",
      "T5\tGeneric 192 194\tIt\n",
      "T6\tGeneric 288 294\tmethod\n",
      "T7\tMaterial 329 339\tOR-Library\n",
      "T8\tGeneric 384 393\talgorithm\n",
      "T9\tMetric 416 443\taverage packing utilization\n",
      "R1\tEVALUATE-FOR Arg1:T9 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T1 Arg2:T3\n",
      "R4\tCOMPARE Arg1:T3 Arg2:T4\n",
      "R5\tCOREF Arg1:T3 Arg2:T5\n",
      "R6\tCOREF Arg1:T5 Arg2:T6\n",
      "R7\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R8\tCOREF Arg1:T5 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2001_5_abs.ann\n",
      "T1\tMethod 34 48\tprocess models\n",
      "T2\tTask 73 103\tscience and engineering fields\n",
      "T3\tMaterial 183 198\tknowledge bases\n",
      "T4\tOtherScientificTerm 203 213\tontologies\n",
      "T5\tOtherScientificTerm 218 223\trules\n",
      "T6\tTask 270 293\tchecking process models\n",
      "T7\tMethod 279 293\tprocess models\n",
      "T8\tTask 326 366\tchecking and refining planning knowledge\n",
      "T9\tTask 384 409\tautomated plan generation\n",
      "T10\tGeneric 492 514\tcomplementary approach\n",
      "T11\tMethod 550 564\tprocess models\n",
      "T12\tGeneric 570 576\tsystem\n",
      "T13\tMethod 585 590\tKANAL\n",
      "T14\tMethod 625 639\tprocess models\n",
      "T15\tMaterial 677 679\tKB\n",
      "T16\tGeneric 762 764\tIt\n",
      "T17\tMethod 772 795\tinterdepen-dency models\n",
      "T18\tGeneric 824 828\tthem\n",
      "T19\tOtherScientificTerm 837 843\terrors\n",
      "T20\tOtherScientificTerm 856 861\tfixes\n",
      "T21\tMethod 897 902\tKANAL\n",
      "T22\tMethod 946 960\tprocess models\n",
      "R1\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R3\tCOREF Arg1:T10 Arg2:T12\n",
      "R4\tCOREF Arg1:T13 Arg2:T12\n",
      "R5\tCOREF Arg1:T12 Arg2:T16\n",
      "R6\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R7\tCOREF Arg1:T17 Arg2:T18\n",
      "R8\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R9\tUSED-FOR Arg1:T18 Arg2:T20\n",
      "R10\tCOREF Arg1:T16 Arg2:T21\n",
      "R11\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R12\tCOREF Arg1:T1 Arg2:T7\n",
      "R13\tCOREF Arg1:T7 Arg2:T11\n",
      "R14\tCOREF Arg1:T11 Arg2:T22\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2003_15_abs.ann\n",
      "T1\tMethod 5 29\tdescription logics (DLs)\n",
      "T2\tMethod 38 62\tknowledge representation\n",
      "T3\tMethod 188 191\tDLs\n",
      "T4\tMethod 374 400\tnatural description logics\n",
      "T5\tOtherScientificTerm 442 475\ttight NEx-PTlME complexity bounds\n",
      "R1\tCOREF Arg1:T1 Arg2:T3\n",
      "R2\tCONJUNCTION Arg1:T2 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2010_4_abs.ann\n",
      "T1\tTask 3 28\tBayesian machine learning\n",
      "T2\tOtherScientificTerm 30 46\tconjugate priors\n",
      "T3\tOtherScientificTerm 168 183\tconjugate prior\n",
      "T4\tOtherScientificTerm 216 231\tconjugate prior\n",
      "T5\tOtherScientificTerm 247 265\tBregman divergence\n",
      "T6\tOtherScientificTerm 311 327\tconjugate priors\n",
      "T7\tOtherScientificTerm 443 459\tconjugate priors\n",
      "T8\tOtherScientificTerm 541 584\tgeometric understanding of conjugate priors\n",
      "T9\tOtherScientificTerm 568 584\tconjugate priors\n",
      "T10\tGeneric 599 614\thyperparameters\n",
      "T11\tGeneric 637 642\tprior\n",
      "T12\tMethod 662 702\tgenerative and discriminative components\n",
      "T13\tMethod 708 720\thybrid model\n",
      "T14\tTask 725 749\tsemi-supervised learning\n",
      "R1\tPART-OF Arg1:T2 Arg2:T1\n",
      "R2\tPART-OF Arg1:T12 Arg2:T13\n",
      "R3\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R4\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R6\tCOREF Arg1:T9 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2010_5_abs.ann\n",
      "T1\tTask 19 40\tlinear classification\n",
      "T2\tGeneric 61 73\tapplications\n",
      "T3\tTask 82 105\tdocument classification\n",
      "T4\tMethod 178 194\ttraining methods\n",
      "T5\tOtherScientificTerm 251 266\tcomputer memory\n",
      "T6\tGeneric 274 281\tmethods\n",
      "T7\tGeneric 310 314\tdata\n",
      "T8\tOtherScientificTerm 331 346\tmemory capacity\n",
      "T9\tOtherScientificTerm 358 371\trandom access\n",
      "T10\tOtherScientificTerm 379 383\tdisk\n",
      "T11\tMethod 410 438\tblock minimization framework\n",
      "T12\tGeneric 443 447\tdata\n",
      "T13\tOtherScientificTerm 464 475\tmemory size\n",
      "T14\tOtherScientificTerm 525 529\tdisk\n",
      "T15\tMethod 553 569\tlearning methods\n",
      "T16\tGeneric 622 631\tframework\n",
      "T17\tMethod 636 656\tprimal and dual SVMs\n",
      "T18\tGeneric 893 899\tmethod\n",
      "R1\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R2\tCOREF Arg1:T6 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R4\tCOREF Arg1:T11 Arg2:T16\n",
      "R5\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R6\tCOREF Arg1:T18 Arg2:T16\n",
      "R7\tCOMPARE Arg1:T7 Arg2:T8\n",
      "R8\tCOMPARE Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2013_15_abs.ann\n",
      "T1\tMethod 4 25\tInterval Algebra (IA)\n",
      "T2\tMethod 46 78\tRegion Connection Calculus (RCC)\n",
      "T3\tMethod 87 92\tRCC-8\n",
      "T4\tMethod 111 145\tArtificial Intelligence approaches\n",
      "T5\tTask 150 229\trepresenting and reasoning about qualitative temporal and topological relations\n",
      "T6\tOtherScientificTerm 183 229\tqualitative temporal and topological relations\n",
      "T7\tOtherScientificTerm 249 272\tqualitative information\n",
      "T8\tMethod 296 332\tQualitative Constraint Network (QCN)\n",
      "T9\tTask 365 395\tminimal labeling problem (MLP)\n",
      "T10\tGeneric 414 423\talgorithm\n",
      "T11\tMethod 483 486\tQCN\n",
      "T12\tGeneric 492 501\talgorithm\n",
      "T13\tMethod 512 524\tchordal QCNs\n",
      "T14\tOtherScientificTerm 543 562\tpartial consistency\n",
      "T15\tOtherScientificTerm 582 597\tâ—† G-consistency\n",
      "T16\tGeneric 621 630\talgorithm\n",
      "T17\tOtherScientificTerm 688 706\tpatchwork property\n",
      "T18\tMethod 766 769\tQCN\n",
      "T19\tMethod 794 798\tQCNs\n",
      "T20\tMethod 794 814\tQCNs of IA and RCC-8\n",
      "T21\tMethod 802 804\tIA\n",
      "T22\tMethod 809 814\tRCC-8\n",
      "T23\tGeneric 862 870\tapproach\n",
      "R1\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tHYPONYM-OF Arg1:T2 Arg2:T4\n",
      "R4\tHYPONYM-OF Arg1:T1 Arg2:T4\n",
      "R5\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R6\tCOREF Arg1:T6 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R8\tCOREF Arg1:T8 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R10\tHYPONYM-OF Arg1:T15 Arg2:T14\n",
      "R11\tCOREF Arg1:T12 Arg2:T16\n",
      "R12\tCOREF Arg1:T1 Arg2:T21\n",
      "R13\tCOREF Arg1:T3 Arg2:T22\n",
      "R14\tPART-OF Arg1:T13 Arg2:T12\n",
      "R15\tCOREF Arg1:T10 Arg2:T12\n",
      "R16\tPART-OF Arg1:T14 Arg2:T12\n",
      "R17\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R18\tCOREF Arg1:T18 Arg2:T19\n",
      "R19\tCOREF Arg1:T12 Arg2:T23\n",
      "R20\tEVALUATE-FOR Arg1:T20 Arg2:T23\n",
      "R21\tCOREF Arg1:T18 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2013_4_abs.ann\n",
      "T1\tTask 42 70\thigh-level program execution\n",
      "T2\tTask 115 143\thigh-level program execution\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2013_5_abs.ann\n",
      "T1\tMethod 0 22\tConstraint propagation\n",
      "T2\tMethod 55 77\tconstraint programming\n",
      "T3\tMethod 128 177\tSpecial-purpose constraint propagation algorithms\n",
      "T4\tMethod 488 516\tgeneral purpose prop-agators\n",
      "T5\tOtherScientificTerm 532 542\tconstraint\n",
      "T6\tMethod 672 681\tSHORTSTR2\n",
      "T7\tMethod 704 744\tSimple Tabular Reduction algorithm STR2+\n",
      "T8\tMethod 759 768\tSHORTSTR2\n",
      "T9\tMethod 813 821\tSHORTGAC\n",
      "T10\tMethod 826 835\tHAGGISGAC\n",
      "T11\tOtherScientificTerm 898 908\tconstraint\n",
      "T12\tOtherScientificTerm 924 938\tshort supports\n",
      "T13\tOtherScientificTerm 944 961\tshort support set\n",
      "T14\tOtherScientificTerm 1000 1023\tfull-length support set\n",
      "T15\tMethod 1035 1044\tSHORTSTR2\n",
      "T16\tOtherScientificTerm 1076 1087\tconstraints\n",
      "T17\tMethod 1093 1098\tSTR2+\n",
      "T18\tMethod 1147 1156\tSHORTSTR2\n",
      "T19\tGeneric 1187 1196\talgorithm\n",
      "T20\tOtherScientificTerm 1209 1223\tshort supports\n",
      "T21\tOtherScientificTerm 1229 1249\tfull-length supports\n",
      "T22\tOtherScientificTerm 1273 1292\tdrop-in replacement\n",
      "T23\tMethod 1297 1302\tSTR2+\n",
      "R1\tCOMPARE Arg1:T8 Arg2:T9\n",
      "R2\tCOMPARE Arg1:T8 Arg2:T10\n",
      "R3\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R4\tCOREF Arg1:T6 Arg2:T8\n",
      "R5\tCOREF Arg1:T8 Arg2:T15\n",
      "R6\tCOREF Arg1:T15 Arg2:T18\n",
      "R7\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R8\tCONJUNCTION Arg1:T19 Arg2:T18\n",
      "R9\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R10\tUSED-FOR Arg1:T18 Arg2:T20\n",
      "R11\tUSED-FOR Arg1:T21 Arg2:T18\n",
      "R12\tUSED-FOR Arg1:T21 Arg2:T18\n",
      "R13\tUSED-FOR Arg1:T21 Arg2:T19\n",
      "R14\tUSED-FOR Arg1:T21 Arg2:T19\n",
      "R15\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R16\tUSED-FOR Arg1:T18 Arg2:T22\n",
      "R17\tCOREF Arg1:T23 Arg2:T7\n",
      "R18\tCOREF Arg1:T17 Arg2:T23\n",
      "R19\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R20\tPART-OF Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2016_412_abs.ann\n",
      "T1\tTask 44 72\thash-tag recommendation task\n",
      "T2\tMaterial 77 87\tmicroblogs\n",
      "T3\tOtherScientificTerm 260 280\thandcrafted features\n",
      "T4\tMethod 317 353\tconvolutional neural networks (CNNs)\n",
      "T5\tTask 363 396\tnatural language processing tasks\n",
      "T6\tMethod 422 426\tCNNs\n",
      "T7\tTask 442 472\thashtag recommendation problem\n",
      "T8\tOtherScientificTerm 493 506\ttrigger words\n",
      "T9\tGeneric 608 620\tarchitecture\n",
      "T10\tOtherScientificTerm 629 648\tattention mechanism\n",
      "T11\tGeneric 684 688\tdata\n",
      "T12\tGeneric 770 775\tmodel\n",
      "T13\tGeneric 788 812\tstate-of-the-art methods\n",
      "T14\tOtherScientificTerm 831 844\ttrigger words\n",
      "T15\tGeneric 910 916\tmethod\n",
      "T16\tGeneric 926 949\tstate-of-the-art method\n",
      "T17\tMetric 972 980\tF1-score\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tEVALUATE-FOR Arg1:T17 Arg2:T16\n",
      "R3\tCOREF Arg1:T16 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tCOREF Arg1:T6 Arg2:T4\n",
      "R6\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R8\tCOREF Arg1:T9 Arg2:T12\n",
      "R9\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R10\tCOREF Arg1:T7 Arg2:T1\n",
      "R11\tCOREF Arg1:T15 Arg2:T12\n",
      "R12\tCOMPARE Arg1:T15 Arg2:T16\n",
      "R13\tEVALUATE-FOR Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2016_413_abs.ann\n",
      "T1\tTask 8 23\tauction domains\n",
      "T2\tGeneric 264 270\tdomain\n",
      "T3\tMethod 281 303\tcombinatorial auctions\n",
      "T4\tGeneric 327 331\tthey\n",
      "T5\tOtherScientificTerm 340 381\tviolations of individual rationality (IR)\n",
      "T6\tOtherScientificTerm 354 381\tindividual rationality (IR)\n",
      "T7\tTask 460 498\tdesign of core-selecting payment rules\n",
      "T8\tGeneric 508 515\tdomains\n",
      "T9\tGeneric 556 562\tdomain\n",
      "T10\tOtherScientificTerm 588 600\tpayment rule\n",
      "T11\tOtherScientificTerm 685 690\trules\n",
      "T12\tOtherScientificTerm 841 854\tIR violations\n",
      "T13\tOtherScientificTerm 870 890\tcore-selecting rules\n",
      "T14\tOtherScientificTerm 911 913\tIR\n",
      "T15\tGeneric 962 967\trules\n",
      "T16\tMethod 981 1026\tcomputational Bayes-Nash equilibrium analysis\n",
      "T17\tGeneric 1066 1071\trules\n",
      "T18\tMetric 1127 1156\trate of ex-post IR violations\n",
      "T19\tOtherScientificTerm 1171 1191\tcore-selecting rules\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T4\n",
      "R3\tCOREF Arg1:T2 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tCOREF Arg1:T8 Arg2:T9\n",
      "R6\tCOREF Arg1:T5 Arg2:T12\n",
      "R7\tCOREF Arg1:T6 Arg2:T14\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R9\tCOREF Arg1:T13 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R11\tCOREF Arg1:T15 Arg2:T17\n",
      "R12\tCOMPARE Arg1:T17 Arg2:T19\n",
      "R13\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R14\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2016_420_abs.ann\n",
      "T1\tTask 3 24\tcross-domain learning\n",
      "T2\tOtherScientificTerm 71 88\tdomain divergence\n",
      "T3\tGeneric 112 128\tdominant factors\n",
      "T4\tOtherScientificTerm 146 156\tviewpoints\n",
      "T5\tOtherScientificTerm 167 178\tresolutions\n",
      "T6\tOtherScientificTerm 192 205\tilluminations\n",
      "T7\tOtherScientificTerm 223 242\tintermediate domain\n",
      "T8\tTask 312 328\tlearning problem\n",
      "T9\tMethod 358 412\tCoupled Marginalized Denoising Auto-encoders framework\n",
      "T10\tTask 428 448\tcross-domain problem\n",
      "T11\tMethod 478 514\tmarginalized denoising auto-encoders\n",
      "T12\tGeneric 516 519\tone\n",
      "T13\tGeneric 543 548\tother\n",
      "T14\tMethod 618 650\tdenoising auto-encoders learning\n",
      "T15\tMethod 669 684\tfeature mapping\n",
      "T16\tOtherScientificTerm 732 751\tintermediate domain\n",
      "T17\tOtherScientificTerm 789 813\tmaximum margin criterion\n",
      "T18\tOtherScientificTerm 821 845\tintra-class com-pactness\n",
      "T19\tOtherScientificTerm 850 869\tinter-class penalty\n",
      "T20\tOtherScientificTerm 915 938\tdiscriminative features\n",
      "T21\tGeneric 994 999\ttasks\n",
      "T22\tGeneric 1041 1047\tmethod\n",
      "T23\tGeneric 1057 1081\tstate-of-the-art methods\n",
      "R1\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R2\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R4\tPART-OF Arg1:T3 Arg2:T2\n",
      "R5\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R6\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R7\tCOREF Arg1:T8 Arg2:T1\n",
      "R8\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R9\tCOREF Arg1:T10 Arg2:T8\n",
      "R10\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R11\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R12\tHYPONYM-OF Arg1:T13 Arg2:T11\n",
      "R13\tPART-OF Arg1:T15 Arg2:T14\n",
      "R14\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R15\tHYPONYM-OF Arg1:T18 Arg2:T17\n",
      "R16\tHYPONYM-OF Arg1:T19 Arg2:T17\n",
      "R17\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R18\tCOMPARE Arg1:T22 Arg2:T23\n",
      "R19\tCOREF Arg1:T22 Arg2:T9\n",
      "R20\tEVALUATE-FOR Arg1:T21 Arg2:T22\n",
      "R21\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2016_423_abs.ann\n",
      "T1\tTask 0 29\tLearning video representation\n",
      "T2\tOtherScientificTerm 386 395\tsemantics\n",
      "T3\tOtherScientificTerm 402 421\tcontext information\n",
      "T4\tMethod 465 506\tintrinsic representation of a video frame\n",
      "T5\tGeneric 542 550\tapproach\n",
      "T6\tMethod 564 589\tdeep video representation\n",
      "T7\tOtherScientificTerm 608 635\tlocal and holistic contexts\n",
      "T8\tMethod 664 690\ttriplet sampling mechanism\n",
      "T9\tOtherScientificTerm 705 751\tlocal temporal relationship of adjacent frames\n",
      "T10\tMethod 767 787\tdeep representations\n",
      "T11\tOtherScientificTerm 821 849\tgraph structure of the video\n",
      "T12\tOtherScientificTerm 856 862\tpriori\n",
      "T13\tGeneric 939 947\tapproach\n",
      "T14\tMethod 988 1046\tend-to-end deep convolutional neu-ral network architecture\n",
      "T15\tGeneric 1091 1113\tlearned representation\n",
      "T16\tTask 1146 1169\tvideo recognition tasks\n",
      "T17\tTask 1171 1180\tretrieval\n",
      "T18\tTask 1183 1197\tclassification\n",
      "T19\tTask 1203 1222\thighlight detection\n",
      "T20\tGeneric 1241 1262\tvideo representations\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R6\tCOREF Arg1:T5 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R8\tHYPONYM-OF Arg1:T17 Arg2:T16\n",
      "R9\tHYPONYM-OF Arg1:T18 Arg2:T16\n",
      "R10\tHYPONYM-OF Arg1:T19 Arg2:T16\n",
      "R11\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R12\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R13\tCOMPARE Arg1:T15 Arg2:T20\n",
      "R14\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "R15\tEVALUATE-FOR Arg1:T16 Arg2:T20\n",
      "R16\tCOREF Arg1:T6 Arg2:T15\n",
      "R17\tCOREF Arg1:T6 Arg2:T10\n",
      "R18\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCNLP_2005_3_abs.ann\n",
      "T1\tTask 0 26\tAutomatic image annotation\n",
      "T2\tTask 83 107\tsemantic image retrieval\n",
      "T3\tMaterial 112 129\ttext descriptions\n",
      "T4\tTask 156 197\tautomatically labeling the image contents\n",
      "T5\tOtherScientificTerm 224 232\tkeywords\n",
      "T6\tOtherScientificTerm 270 285\timage semantics\n",
      "T7\tMethod 289 325\tMaximum Entropy Model-based approach\n",
      "T8\tTask 341 367\tautomatic image annotation\n",
      "T9\tTask 411 419\ttraining\n",
      "T10\tOtherScientificTerm 429 446\tvisual vocabulary\n",
      "T11\tOtherScientificTerm 461 472\tblob-tokens\n",
      "T12\tOtherScientificTerm 489 502\timage content\n",
      "T13\tGeneric 535 559\tstatistical relationship\n",
      "T14\tOtherScientificTerm 583 594\tblob-tokens\n",
      "T15\tOtherScientificTerm 599 607\tkeywords\n",
      "T16\tMethod 613 634\tMaximum Entropy Model\n",
      "T17\tTask 704 714\tannotation\n",
      "T18\tOtherScientificTerm 767 775\tkeywords\n",
      "T19\tOtherScientificTerm 806 820\tblob-token set\n",
      "T20\tMaterial 885 914\tmedium-sized image collection\n",
      "T21\tMaterial 943 958\tCorel Photo CDs\n",
      "T22\tTask 1007 1017\tannotation\n",
      "T23\tGeneric 1038 1044\tmethod\n",
      "T24\tMethod 1074 1092\tannotation methods\n",
      "T25\tMetric 1108 1122\tmean precision\n",
      "T26\tMethod 1151 1172\tMaximum Entropy Model\n",
      "T27\tTask 1188 1214\tautomatic image annotation\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T19 Arg2:T18\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R6\tUSED-FOR Arg1:T16 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T26 Arg2:T27\n",
      "R8\tEVALUATE-FOR Arg1:T25 Arg2:T24\n",
      "R9\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R10\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R11\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R12\tCOREF Arg1:T1 Arg2:T8\n",
      "R13\tPART-OF Arg1:T11 Arg2:T10\n",
      "R14\tCOMPARE Arg1:T23 Arg2:T24\n",
      "R15\tCOREF Arg1:T8 Arg2:T17\n",
      "R16\tCOREF Arg1:T17 Arg2:T22\n",
      "R17\tUSED-FOR Arg1:T23 Arg2:T22\n",
      "R18\tUSED-FOR Arg1:T24 Arg2:T22\n",
      "R19\tCOREF Arg1:T16 Arg2:T26\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2000_483_abs.ann\n",
      "T1\tMaterial 22 58\tout-of-domain acoustic training data\n",
      "T2\tMethod 72 89\tspeech recognizer\n",
      "T3\tMaterial 170 199\tWallstreet Journal (WSJ) data\n",
      "T4\tMethod 211 221\trecognizer\n",
      "T5\tMaterial 261 277\tPhonebook domain\n",
      "T6\tOtherScientificTerm 296 324\tcommon language (US English)\n",
      "T7\tOtherScientificTerm 376 408\tmicrophone vs. telephone channel\n",
      "T8\tOtherScientificTerm 410 427\tcontinuous speech\n",
      "T9\tOtherScientificTerm 432 446\tisolated words\n",
      "T10\tMethod 548 570\tWSJ-trained recognizer\n",
      "T11\tMaterial 581 596\tadaptation data\n",
      "T12\tMaterial 613 638\tPhonebook training corpus\n",
      "T13\tTask 677 688\trecognition\n",
      "T14\tOtherScientificTerm 732 740\tmismatch\n",
      "T15\tTask 780 791\trecognition\n",
      "T16\tMethod 809 850\tPhonebook-trained baseline acoustic model\n",
      "T17\tMaterial 871 898\tout-of-domain training data\n",
      "T18\tMethod 924 963\tadaptation and normalization techniques\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tEVALUATE-FOR Arg1:T5 Arg2:T4\n",
      "R4\tPART-OF Arg1:T11 Arg2:T12\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R8\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R9\tCOREF Arg1:T13 Arg2:T15\n",
      "R10\tCOREF Arg1:T2 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2000_490_abs.ann\n",
      "T1\tMethod 11 24\tN-gram models\n",
      "T2\tTask 72 101\tstatistical language modeling\n",
      "T3\tMethod 162 177\tlanguage models\n",
      "T4\tMethod 191 217\tartificial neural networks\n",
      "T5\tMethod 231 245\tlanguage model\n",
      "T6\tMethod 284 298\tneural network\n",
      "T7\tMethod 311 325\tlanguage model\n",
      "T8\tMethod 373 392\tstatistical methods\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T5 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tCOREF Arg1:T6 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tCOMPARE Arg1:T6 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2001_21_abs.ann\n",
      "T1\tMethod 0 8\tSmartKom\n",
      "T2\tMethod 14 38\tmultimodal dialog system\n",
      "T3\tMaterial 53 59\tspeech\n",
      "T4\tMaterial 61 68\tgesture\n",
      "T5\tTask 99 131\tSpontaneous speech understanding\n",
      "T6\tTask 153 196\tvideo-based recognition of natural gestures\n",
      "T7\tMethod 235 243\tSmartKom\n",
      "T8\tMethod 261 282\tcomputational methods\n",
      "T9\tTask 300 368\tintegration and mutual disambiguation of multimodal input and output\n",
      "T10\tOtherScientificTerm 374 402\tsemantic and pragmatic level\n",
      "T11\tOtherScientificTerm 404 412\tSmartKom\n",
      "T12\tMethod 429 473\tsituated delegation-oriented dialog paradigm\n",
      "T13\tOtherScientificTerm 515 546\tvirtual communication assistant\n",
      "T14\tOtherScientificTerm 588 605\tgraphical display\n",
      "T15\tMethod 623 644\tSmartKom architecture\n",
      "T16\tOtherScientificTerm 660 685\tXML-based markup language\n",
      "T17\tMaterial 690 708\tmultimodal content\n",
      "T18\tMethod 781 802\tSmartKom demonstrator\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R3\tCOREF Arg1:T7 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R7\tUSED-FOR Arg1:T4 Arg2:T2\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R9\tCOREF Arg1:T7 Arg2:T11\n",
      "R10\tCOREF Arg1:T11 Arg2:T15\n",
      "R11\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R12\tCOREF Arg1:T15 Arg2:T18\n",
      "R13\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R14\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2001_28_abs.ann\n",
      "T1\tMethod 74 101\tspeaker verification system\n",
      "T2\tMethod 206 233\tspeaker verification system\n",
      "T3\tMethod 368 383\tuser evaluation\n",
      "T4\tMaterial 425 436\tspeech data\n",
      "T5\tMethod 611 631\tHidden Markov Models\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2001_31_abs.ann\n",
      "T1\tGeneric 22 28\tmethod\n",
      "T2\tTask 33 72\tblind estimation of reverberation times\n",
      "T3\tOtherScientificTerm 76 98\treverberant enclosures\n",
      "T4\tGeneric 113 122\talgorithm\n",
      "T5\tMethod 137 189\tstatistical model of short-term log-energy sequences\n",
      "T6\tMaterial 194 210\techo-free speech\n",
      "T7\tMethod 283 351\tMaximum Likelihood estimate of the room full-band reverberation time\n",
      "T8\tGeneric 357 374\testimation method\n",
      "T9\tGeneric 442 448\tmethod\n",
      "T10\tTask 482 517\trobust automatic speech recognition\n",
      "T11\tOtherScientificTerm 521 545\treverberant environments\n",
      "T12\tMethod 549 564\tmodel selection\n",
      "T13\tGeneric 575 586\tapplication\n",
      "T14\tOtherScientificTerm 592 610\treverberation time\n",
      "T15\tOtherScientificTerm 639 668\treverberated speech utterance\n",
      "T16\tGeneric 691 701\testimation\n",
      "T17\tMethod 734 748\tacoustic model\n",
      "T18\tGeneric 769 775\tmodels\n",
      "T19\tOtherScientificTerm 795 829\tartificial re-verberant conditions\n",
      "T20\tTask 831 849\tSpeech recognition\n",
      "T21\tOtherScientificTerm 865 908\tsimulated and real reverberant environments\n",
      "T22\tGeneric 936 944\tapproach\n",
      "T23\tMethod 972 1005\tchannel normaliza-tion techniques\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T1 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R6\tCOREF Arg1:T8 Arg2:T7\n",
      "R7\tCOREF Arg1:T8 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R9\tFEATURE-OF Arg1:T11 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T9\n",
      "R11\tCOREF Arg1:T10 Arg2:T13\n",
      "R12\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R13\tFEATURE-OF Arg1:T21 Arg2:T20\n",
      "R14\tCOREF Arg1:T4 Arg2:T22\n",
      "R15\tCOMPARE Arg1:T23 Arg2:T22\n",
      "R16\tEVALUATE-FOR Arg1:T20 Arg2:T22\n",
      "R17\tEVALUATE-FOR Arg1:T20 Arg2:T23\n",
      "R18\tPART-OF Arg1:T17 Arg2:T18\n",
      "R19\tFEATURE-OF Arg1:T19 Arg2:T18\n",
      "R20\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2006_21_abs.ann\n",
      "T1\tMethod 26 59\tlanguage model adaptation methods\n",
      "T2\tOtherScientificTerm 68 77\tword list\n",
      "T3\tMaterial 84 94\traw corpus\n",
      "T4\tGeneric 127 133\tmethod\n",
      "T5\tMaterial 152 162\traw corpus\n",
      "T6\tOtherScientificTerm 185 194\tword list\n",
      "T7\tGeneric 246 251\tmodel\n",
      "T8\tMaterial 261 277\tsegmented corpus\n",
      "T9\tMethod 287 331\tsentence-by-sentence error correction method\n",
      "T10\tGeneric 602 608\tmethod\n",
      "T11\tGeneric 776 783\tmethods\n",
      "T12\tTask 788 816\tpreparing a segmented corpus\n",
      "T13\tMethod 834 849\tlanguage models\n",
      "T14\tMetric 859 888\tspeech recognition accuracies\n",
      "T15\tGeneric 931 937\tmethod\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R3\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R8\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R9\tCOREF Arg1:T1 Arg2:T10\n",
      "R10\tCOREF Arg1:T10 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2006_28_abs.ann\n",
      "T1\tOtherScientificTerm 24 64\tautomatic phonetic transcriptions (APTs)\n",
      "T2\tOtherScientificTerm 77 118\tmanually verified phonetic transcriptions\n",
      "T3\tTask 159 182\tpronunciation variation\n",
      "T4\tTask 258 272\tclassification\n",
      "T5\tTask 366 389\tpronunciation variation\n",
      "T6\tMethod 402 413\tclassifiers\n",
      "T7\tMaterial 421 437\tspeech processes\n",
      "T8\tOtherScientificTerm 457 467\talignments\n",
      "T9\tOtherScientificTerm 474 477\tAPT\n",
      "T10\tOtherScientificTerm 485 488\tMPT\n",
      "T11\tOtherScientificTerm 496 519\tcanonical transcription\n",
      "T12\tMaterial 543 554\tclassifiers\n",
      "T13\tOtherScientificTerm 594 616\tunknown transcriptions\n",
      "T14\tMaterial 627 638\tread speech\n",
      "T15\tMaterial 642 661\ttelephone dialogues\n",
      "T16\tMaterial 684 700\tspeech processes\n",
      "T17\tMethod 880 900\tAPT-based classifier\n",
      "T18\tMetric 916 939\tclassification accuracy\n",
      "T19\tMethod 949 969\tMPT-based classifier\n",
      "T20\tOtherScientificTerm 989 1012\tclassification features\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R3\tCOMPARE Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T3 Arg2:T5\n",
      "R5\tCOREF Arg1:T9 Arg2:T1\n",
      "R6\tCOREF Arg1:T10 Arg2:T2\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T8\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R11\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R12\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R13\tCOREF Arg1:T6 Arg2:T12\n",
      "R14\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R15\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R16\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R17\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R18\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R19\tCOMPARE Arg1:T17 Arg2:T19\n",
      "R20\tUSED-FOR Arg1:T20 Arg2:T17\n",
      "R21\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R22\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2006_31_abs.ann\n",
      "T1\tMethod 82 120\tstatistical machine learning algorithm\n",
      "T2\tOtherScientificTerm 150 192\tsmallest meaning-bearing units of language\n",
      "T3\tOtherScientificTerm 195 204\tmorphemes\n",
      "T4\tGeneric 215 220\tthese\n",
      "T5\tGeneric 271 276\ttasks\n",
      "T6\tTask 286 315\tspeech and text understanding\n",
      "T7\tTask 317 336\tmachine translation\n",
      "T8\tTask 338 359\tinformation retrieval\n",
      "T9\tTask 365 394\tstatistical language modeling\n",
      "T10\tMethod 570 594\tsegmen-tation algorithms\n",
      "T11\tTask 598 633\tlarge vocabulary speech recognition\n",
      "T12\tMethod 640 674\tstatistical n-gram language models\n",
      "T13\tMaterial 766 815\tag-glutinative and morphologically rich languages\n",
      "T14\tMaterial 817 824\tFinnish\n",
      "T15\tMaterial 829 837\tTurk-ish\n",
      "R1\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R4\tHYPONYM-OF Arg1:T14 Arg2:T13\n",
      "R5\tHYPONYM-OF Arg1:T15 Arg2:T13\n",
      "R6\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R7\tHYPONYM-OF Arg1:T7 Arg2:T5\n",
      "R8\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R9\tHYPONYM-OF Arg1:T8 Arg2:T5\n",
      "R10\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R11\tHYPONYM-OF Arg1:T9 Arg2:T5\n",
      "R12\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R13\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R14\tCOREF Arg1:T3 Arg2:T4\n",
      "R15\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R16\tEVALUATE-FOR Arg1:T12 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2007_20_abs.ann\n",
      "T1\tMethod 24 43\tdialogue management\n",
      "T2\tTask 51 80\tinformation navigation system\n",
      "T3\tMaterial 92 115\tdocument knowledge base\n",
      "T4\tOtherScientificTerm 166 190\tN-best candidates of ASR\n",
      "T5\tOtherScientificTerm 195 217\tcontextual information\n",
      "T6\tGeneric 235 241\tsystem\n",
      "T7\tGeneric 259 265\tsystem\n",
      "T8\tTask 294 331\tgenerating responses or confirmations\n",
      "T9\tTask 379 405\tminimization of Bayes risk\n",
      "T10\tMetric 415 421\treward\n",
      "T11\tOtherScientificTerm 426 458\tcorrect information presentation\n",
      "T12\tMetric 463 470\tpenalty\n",
      "T13\tOtherScientificTerm 475 490\tredundant turns\n",
      "T14\tGeneric 515 523\tstrategy\n",
      "T15\tTask 533 593\tspoken dialogue system \" Dialogue Navigator for Kyoto City \"\n",
      "T16\tOtherScientificTerm 611 640\tquestion-answering capability\n",
      "T17\tGeneric 672 681\tframework\n",
      "T18\tMetric 703 728\tsuccess rate of retrieval\n",
      "T19\tMetric 737 760\taverage number of turns\n",
      "T20\tOtherScientificTerm 765 783\tinformation access\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T9\n",
      "R8\tCOREF Arg1:T14 Arg2:T9\n",
      "R9\tCOREF Arg1:T7 Arg2:T6\n",
      "R10\tCOREF Arg1:T6 Arg2:T2\n",
      "R11\tCOREF Arg1:T17 Arg2:T14\n",
      "R12\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R13\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R14\tEVALUATE-FOR Arg1:T19 Arg2:T17\n",
      "R15\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R16\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R17\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R18\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R19\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R20\tFEATURE-OF Arg1:T16 Arg2:T15\n",
      "R21\tCOREF Arg1:T7 Arg2:T15\n",
      "R22\tCONJUNCTION Arg1:T10 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2007_21_abs.ann\n",
      "T1\tMethod 13 17\tHMMs\n",
      "T2\tOtherScientificTerm 23 48\tweak duration constraints\n",
      "T3\tMaterial 92 116\tcorrupted speech signals\n",
      "T4\tGeneric 121 127\tmodels\n",
      "T5\tMaterial 139 151\tclean speech\n",
      "T6\tMethod 166 173\tdecoder\n",
      "T7\tOtherScientificTerm 185 197\tword matches\n",
      "T8\tOtherScientificTerm 203 224\tunrealistic durations\n",
      "T9\tOtherScientificTerm 274 299\tword duration constraints\n",
      "T10\tMethod 303 317\tunrolling HMMs\n",
      "T11\tOtherScientificTerm 328 335\tlattice\n",
      "T12\tOtherScientificTerm 342 369\tword duration probabilities\n",
      "T13\tOtherScientificTerm 397 414\tstate transitions\n",
      "T14\tMethod 429 433\tHMMs\n",
      "T15\tMethod 467 483\tViterbi decoding\n",
      "T16\tTask 500 527\tconnected-digit recognition\n",
      "T17\tOtherScientificTerm 558 578\tduration constraints\n",
      "T18\tMethod 583 590\tdecoder\n",
      "T19\tOtherScientificTerm 601 613\tword matches\n",
      "T20\tMetric 650 666\tword error rates\n",
      "T21\tOtherScientificTerm 717 733\tnoise conditions\n",
      "R1\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R8\tCONJUNCTION Arg1:T15 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R10\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R11\tUSED-FOR Arg1:T16 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2007_28_abs.ann\n",
      "T1\tGeneric 26 44\ttwo-pass algorithm\n",
      "T2\tTask 49 122\tExtra Large (more than 1M words) Vocabulary COntinuous Speech recognition\n",
      "T3\tTask 136 168\tInformation Retrieval (ELVIRCOS)\n",
      "T4\tGeneric 192 200\tapproach\n",
      "T5\tMethod 219 238\trecognition process\n",
      "T6\tGeneric 248 254\tpasses\n",
      "T7\tGeneric 265 275\tfirst pass\n",
      "T8\tOtherScientificTerm 287 299\twords subset\n",
      "T9\tGeneric 308 331\tsecond pass recognition\n",
      "T10\tMethod 341 372\tinformation retrieval procedure\n",
      "T11\tMethod 374 396\tWord graph composition\n",
      "T12\tMaterial 401 418\tcontinuous speech\n",
      "T13\tGeneric 443 451\tapproach\n",
      "T14\tTask 476 511\tlarge vocabulary speech recognition\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tHYPONYM-OF Arg1:T7 Arg2:T6\n",
      "R5\tCOREF Arg1:T6 Arg2:T5\n",
      "R6\tHYPONYM-OF Arg1:T9 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R10\tCOREF Arg1:T14 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2007_31_abs.ann\n",
      "T1\tMethod 40 60\tHMM-based TTS system\n",
      "T2\tMaterial 72 85\tGerman speech\n",
      "T3\tOtherScientificTerm 180 196\tcontext features\n",
      "T4\tGeneric 215 221\tsystem\n",
      "T5\tMaterial 251 273\tfootball announcements\n",
      "T6\tMaterial 316 333\texpressive speech\n",
      "T7\tMethod 356 360\tHMMs\n",
      "T8\tMaterial 388 422\tintelligible neutral German speech\n",
      "T9\tMaterial 529 545\tfootball dataset\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T1 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2007_40_abs.ann\n",
      "T1\tTask 0 24\tInformation distillation\n",
      "T2\tMaterial 102 168\tmassive, possibly multilingual, audio and textual document sources\n",
      "T3\tOtherScientificTerm 220 254\tinformation extraction annotations\n",
      "T4\tTask 266 301\tdocument retrieval for distillation\n",
      "T5\tOtherScientificTerm 350 370\tdistillation queries\n",
      "T6\tOtherScientificTerm 394 413\tannotation elements\n",
      "T7\tTask 433 477\tNIST Automatic Content Extraction (ACE) task\n",
      "T8\tOtherScientificTerm 517 527\tACE events\n",
      "T9\tMethod 573 601\tinformation retrieval engine\n",
      "T10\tMetric 629 638\tprecision\n",
      "T11\tMetric 650 662\trecall rates\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2008_20_abs.ann\n",
      "T1\tTask 16 47\texpressive speech communication\n",
      "T2\tMaterial 537 553\tIEMOCAP database\n",
      "T3\tTask 555 626\tdiscrete (categorical) and continuous (attribute) emotional assessments\n",
      "T4\tOtherScientificTerm 744 780\texpression and perception of emotion\n",
      "T5\tGeneric 802 810\tdatabase\n",
      "T6\tOtherScientificTerm 918 942\tactivation-valence space\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tCOREF Arg1:T5 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2008_21_abs.ann\n",
      "T1\tTask 38 63\tCzech talking head system\n",
      "T2\tGeneric 89 96\tmethods\n",
      "T3\tTask 106 129\tvisual speech animation\n",
      "T4\tMethod 207 223\tsynthesis method\n",
      "T5\tMethod 227 245\t3D animation model\n",
      "T6\tMethod 260 292\tpseudo-muscular animation schema\n",
      "T7\tTask 308 334\tanimation of visual speech\n",
      "T8\tTask 357 367\tlipreading\n",
      "T9\tMethod 385 401\tanimation schema\n",
      "T10\tTask 499 532\tforming articulatory trajectories\n",
      "T11\tOtherScientificTerm 556 585\tlabial coarticulation effects\n",
      "T12\tGeneric 587 589\tIt\n",
      "T13\tMethod 606 622\tsynthesis method\n",
      "T14\tOtherScientificTerm 634 667\tselection of articulatory targets\n",
      "T15\tMethod 672 695\tinterpolation technique\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R4\tCOREF Arg1:T3 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R7\tCOREF Arg1:T10 Arg2:T12\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R9\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R10\tUSED-FOR Arg1:T15 Arg2:T12\n",
      "R11\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2008_28_abs.ann\n",
      "T1\tTask 19 33\tencoding sound\n",
      "T2\tTask 38 57\tneuronal processing\n",
      "T3\tOtherScientificTerm 74 94\tanalog pressure wave\n",
      "T4\tOtherScientificTerm 109 141\tdiscrete nerve-action potentials\n",
      "T5\tMethod 150 161\tpool models\n",
      "T6\tOtherScientificTerm 169 192\tinner hair cell synapse\n",
      "T7\tMethod 269 286\tvisual inspection\n",
      "T8\tMethod 291 325\tautomatic speech recognition (ASR)\n",
      "T9\tMethod 344 372\toffset adaptation (OA) model\n",
      "T10\tMethod 403 405\tOA\n",
      "T11\tTask 415 455\tphase locking in the auditory nerve (AN)\n",
      "T12\tMetric 467 479\tASR accuracy\n",
      "T13\tOtherScientificTerm 484 492\tfeatures\n",
      "T14\tOtherScientificTerm 506 522\tAN fibers (ANFs)\n",
      "T15\tMethod 543 545\tOA\n",
      "T16\tTask 561 580\tauditory processing\n",
      "T17\tOtherScientificTerm 584 603\tonset neurons (ONs)\n",
      "T18\tOtherScientificTerm 636 654\tauditory brainstem\n",
      "T19\tMethod 656 686\tMulti-layer perceptrons (MLPs)\n",
      "T20\tMethod 723 753\tGaussian mixture models (GMMs)\n",
      "T21\tOtherScientificTerm 767 807\tANF-based and ON-based auditory features\n",
      "T22\tOtherScientificTerm 855 911\tMSG (Modulation-filtered Spec-troGram) auditory features\n",
      "T23\tOtherScientificTerm 963 971\tfeatures\n",
      "T24\tMethod 995 999\tMLPs\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R5\tCOREF Arg1:T10 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R8\tCOREF Arg1:T15 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R10\tUSED-FOR Arg1:T17 Arg2:T15\n",
      "R11\tCOMPARE Arg1:T19 Arg2:T20\n",
      "R12\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R13\tUSED-FOR Arg1:T19 Arg2:T21\n",
      "R14\tCOREF Arg1:T24 Arg2:T19\n",
      "R15\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R16\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R17\tUSED-FOR Arg1:T10 Arg2:T13\n",
      "R18\tEVALUATE-FOR Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2013_21_abs.ann\n",
      "T1\tOtherScientificTerm 59 77\tlack of structures\n",
      "T2\tTask 59 106\tlack of structures in traditional n-gram models\n",
      "T3\tMethod 93 106\tn-gram models\n",
      "T4\tTask 125 160\tweakly supervised dependency parser\n",
      "T5\tOtherScientificTerm 176 189\tspeech syntax\n",
      "T6\tMaterial 213 238\tannotated training corpus\n",
      "T7\tOtherScientificTerm 240 252\tLabeled data\n",
      "T8\tOtherScientificTerm 274 292\thand-crafted rules\n",
      "T9\tOtherScientificTerm 311 330\tsyntactic knowledge\n",
      "T10\tMethod 332 350\tBayesian inference\n",
      "T11\tOtherScientificTerm 368 373\trules\n",
      "T12\tGeneric 404 408\tthem\n",
      "T13\tOtherScientificTerm 419 442\tcomplex tree structures\n",
      "T14\tOtherScientificTerm 459 491\tdiscriminative model's posterior\n",
      "T15\tMaterial 504 520\tunlabeled corpus\n",
      "T16\tGeneric 527 536\tposterior\n",
      "T17\tOtherScientificTerm 545 576\tsparse se-lectional preferences\n",
      "T18\tGeneric 621 626\tmodel\n",
      "T19\tMaterial 643 676\tEnglish and Czech newspaper texts\n",
      "T20\tMaterial 703 739\tFrench broadcast news transcriptions\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R3\tCOREF Arg1:T11 Arg2:T12\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R8\tCOREF Arg1:T14 Arg2:T16\n",
      "R9\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R10\tEVALUATE-FOR Arg1:T19 Arg2:T18\n",
      "R11\tEVALUATE-FOR Arg1:T20 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2013_28_abs.ann\n",
      "T1\tMaterial 26 74\tunder-explored language genre of spoken language\n",
      "T2\tMaterial 75 90\tlyrics in music\n",
      "T3\tMethod 106 129\tunsuper-vised induction\n",
      "T4\tMethod 136 177\tSMT-style stochastic transduction grammar\n",
      "T5\tMaterial 182 196\thip hop lyrics\n",
      "T6\tMethod 209 262\tfully-automatically learned challenge-response system\n",
      "T7\tMaterial 277 291\trhyming lyrics\n",
      "T8\tMaterial 357 371\thip hop lyrics\n",
      "T9\tGeneric 442 450\tapproach\n",
      "T10\tOtherScientificTerm 507 546\tpriori linguistic or phonetic knowledge\n",
      "T11\tGeneric 606 611\tmodel\n",
      "T12\tOtherScientificTerm 661 677\thuman evaluators\n",
      "T13\tMethod 730 753\tphrase-based SMT models\n",
      "T14\tGeneric 768 772\ttask\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R5\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R6\tCOREF Arg1:T9 Arg2:T6\n",
      "R7\tCOREF Arg1:T11 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T3 Arg2:T6\n",
      "R9\tCOMPARE Arg1:T11 Arg2:T13\n",
      "R10\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R11\tEVALUATE-FOR Arg1:T14 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2013_31_abs.ann\n",
      "T1\tMethod 28 73\tdigital signal processor (DSP) implementation\n",
      "T2\tMethod 77 120\treal-time statistical voice conversion (VC)\n",
      "T3\tTask 125 150\tsilent speech enhancement\n",
      "T4\tTask 155 190\telectrolaryngeal speech enhancement\n",
      "T5\tOtherScientificTerm 197 220\tsilent speech interface\n",
      "T6\tMaterial 234 258\tnon-audible murmur (NAM)\n",
      "T7\tMaterial 298 312\taudible speech\n",
      "T8\tMaterial 332 355\tElectrolaryngeal speech\n",
      "T9\tMaterial 387 404\talaryngeal speech\n",
      "T10\tMethod 432 447\tspeaking method\n",
      "T11\tOtherScientificTerm 452 466\tlaryngectomees\n",
      "T12\tMetric 481 494\tsound quality\n",
      "T13\tMaterial 498 501\tNAM\n",
      "T14\tMaterial 498 529\tNAM and electrolaryngeal speech\n",
      "T15\tMethod 564 566\tVC\n",
      "T16\tGeneric 645 647\tit\n",
      "T17\tGeneric 685 692\tdevices\n",
      "T18\tMaterial 698 732\tsufficient computational resources\n",
      "T19\tGeneric 755 762\tdevices\n",
      "T20\tMaterial 797 828\tlimited computational resources\n",
      "T21\tMethod 911 923\treal-time VC\n",
      "T22\tOtherScientificTerm 929 932\tDSP\n",
      "T23\tMethod 955 981\tspeech enhancement systems\n",
      "T24\tMethod 991 1003\treal-time VC\n",
      "T25\tGeneric 1005 1008\tone\n",
      "T26\tMaterial 1014 1017\tNAM\n",
      "T27\tMaterial 1023 1038\twhispered voice\n",
      "T28\tGeneric 1047 1052\tother\n",
      "T29\tMaterial 1058 1081\telectrolaryngeal speech\n",
      "T30\tMaterial 1087 1100\tnatural voice\n",
      "T31\tGeneric 1121 1128\tmethods\n",
      "T32\tMetric 1142 1160\tcomputational cost\n",
      "T33\tMetric 1178 1197\tconversion accuracy\n",
      "T34\tMethod 1249 1261\treal-time VC\n",
      "T35\tOtherScientificTerm 1289 1292\tDSP\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "R4\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R5\tHYPONYM-OF Arg1:T8 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R8\tCOREF Arg1:T13 Arg2:T6\n",
      "R9\tEVALUATE-FOR Arg1:T12 Arg2:T14\n",
      "R10\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "R11\tCOREF Arg1:T21 Arg2:T24\n",
      "R12\tCOREF Arg1:T6 Arg2:T26\n",
      "R13\tEVALUATE-FOR Arg1:T32 Arg2:T31\n",
      "R14\tCONJUNCTION Arg1:T32 Arg2:T33\n",
      "R15\tEVALUATE-FOR Arg1:T33 Arg2:T31\n",
      "R16\tCOREF Arg1:T24 Arg2:T34\n",
      "R17\tCOREF Arg1:T22 Arg2:T35\n",
      "R18\tUSED-FOR Arg1:T35 Arg2:T34\n",
      "R19\tUSED-FOR Arg1:T24 Arg2:T23\n",
      "R20\tHYPONYM-OF Arg1:T25 Arg2:T23\n",
      "R21\tHYPONYM-OF Arg1:T28 Arg2:T23\n",
      "R22\tCONJUNCTION Arg1:T25 Arg2:T28\n",
      "R23\tCOREF Arg1:T15 Arg2:T16\n",
      "R24\tFEATURE-OF Arg1:T18 Arg2:T17\n",
      "R25\tFEATURE-OF Arg1:T20 Arg2:T19\n",
      "R26\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R27\tCOREF Arg1:T2 Arg2:T21\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2014_20_abs.ann\n",
      "T1\tTask 26 65\tmultilingual feature-level data sharing\n",
      "T2\tMethod 70 123\tDeep Neural Network (DNN) stacked bottleneck features\n",
      "T3\tTask 177 200\tlanguage identification\n",
      "T4\tMaterial 286 308\tmultilingual resources\n",
      "T5\tMaterial 331 352\tIARPA-Babel languages\n",
      "T6\tOtherScientificTerm 363 382\tbottleneck features\n",
      "T7\tGeneric 447 452\tthose\n",
      "T8\tGeneric 532 536\tdata\n",
      "T9\tTask 582 603\tmultilingual training\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tCOMPARE Arg1:T7 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2014_28_abs.ann\n",
      "T1\tMethod 28 80\tstatistical singing voice conversion (SVC) technique\n",
      "T2\tMethod 86 114\tdirect waveform modification\n",
      "T3\tOtherScientificTerm 128 149\tspectrum differential\n",
      "T4\tOtherScientificTerm 167 179\tvoice timbre\n",
      "T5\tMethod 244 251\tvocoder\n",
      "T6\tOtherScientificTerm 264 297\tconverted singing voice waveforms\n",
      "T7\tMethod 299 302\tSVC\n",
      "T8\tOtherScientificTerm 332 361\tsinging voice characteristics\n",
      "T9\tMetric 443 457\tspeech quality\n",
      "T10\tOtherScientificTerm 465 488\tconverted singing voice\n",
      "T11\tOtherScientificTerm 537 558\tnatural singing voice\n",
      "T12\tMethod 627 650\tvocoder-based framework\n",
      "T13\tMethod 696 726\tstatistical conversion process\n",
      "T14\tOtherScientificTerm 820 827\tspectra\n",
      "T15\tOtherScientificTerm 882 911\tdifferential spectral feature\n",
      "T16\tMethod 942 983\tdifferential Gaussian mixture model (GMM)\n",
      "T17\tMethod 1034 1037\tGMM\n",
      "T18\tMethod 1048 1064\tconversion model\n",
      "T19\tMethod 1085 1088\tSVC\n",
      "T20\tGeneric 1145 1151\tmethod\n",
      "T21\tMetric 1195 1209\tspeech quality\n",
      "T22\tMetric 1262 1300\tconversion accuracy of singer identity\n",
      "T23\tMethod 1330 1333\tSVC\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tCOREF Arg1:T7 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R6\tEVALUATE-FOR Arg1:T9 Arg2:T10\n",
      "R7\tCOMPARE Arg1:T10 Arg2:T11\n",
      "R8\tEVALUATE-FOR Arg1:T9 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R11\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R12\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R13\tEVALUATE-FOR Arg1:T21 Arg2:T20\n",
      "R14\tCOMPARE Arg1:T20 Arg2:T23\n",
      "R15\tEVALUATE-FOR Arg1:T22 Arg2:T20\n",
      "R16\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R17\tEVALUATE-FOR Arg1:T21 Arg2:T23\n",
      "R18\tCOREF Arg1:T13 Arg2:T20\n",
      "R19\tCOREF Arg1:T13 Arg2:T1\n",
      "R20\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2014_31_abs.ann\n",
      "T1\tMaterial 63 81\ti-vector challenge\n",
      "T2\tMaterial 113 156\tNIST Speaker Recognition Evaluations (SREs)\n",
      "T3\tMaterial 184 194\tSRE series\n",
      "T4\tMaterial 200 218\ti-vector challenge\n",
      "T5\tOtherScientificTerm 252 280\tfixed-length feature vectors\n",
      "T6\tOtherScientificTerm 298 331\tlow-dimensional space (i-vectors)\n",
      "T7\tMaterial 344 360\taudio recordings\n",
      "T8\tOtherScientificTerm 464 486\taudio processing field\n",
      "T9\tMaterial 509 512\tSRE\n",
      "T10\tMaterial 518 536\ti-vector challenge\n",
      "T11\tGeneric 729 743\tleading system\n",
      "T12\tGeneric 800 815\tbaseline system\n",
      "R1\tCOREF Arg1:T1 Arg2:T4\n",
      "R2\tCOREF Arg1:T2 Arg2:T9\n",
      "R3\tCOMPARE Arg1:T11 Arg2:T12\n",
      "R4\tCOMPARE Arg1:T9 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R6\tCOREF Arg1:T2 Arg2:T3\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R8\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R9\tCOMPARE Arg1:T7 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2014_40_abs.ann\n",
      "T1\tOtherScientificTerm 52 96\tfundamental frequency (F0) contour of speech\n",
      "T2\tMaterial 104 114\ttext input\n",
      "T3\tTask 119 143\ttext-to-speech synthesis\n",
      "T4\tMethod 177 194\tstatistical model\n",
      "T5\tOtherScientificTerm 232 250\tspeech F0 contours\n",
      "T6\tMethod 294 308\tFujisaki model\n",
      "T7\tOtherScientificTerm 314 332\tremarkable feature\n",
      "T8\tGeneric 341 346\tmodel\n",
      "T9\tGeneric 355 357\tit\n",
      "T10\tGeneric 396 405\talgorithm\n",
      "T11\tMethod 424 443\tstatistical methods\n",
      "T12\tOtherScientificTerm 463 488\tFujisaki-model parameters\n",
      "T13\tOtherScientificTerm 494 509\traw F0 contours\n",
      "T14\tOtherScientificTerm 542 567\tFujisaki-model parameters\n",
      "T15\tMaterial 575 585\ttext input\n",
      "T16\tMethod 595 615\tstatistical learning\n",
      "T17\tGeneric 652 657\tmodel\n",
      "T18\tMethod 707 735\tparameter training algorithm\n",
      "T19\tGeneric 752 757\tmodel\n",
      "T20\tMethod 769 807\tdecision tree-based context clustering\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tCOREF Arg1:T1 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tCOREF Arg1:T4 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R7\tFEATURE-OF Arg1:T7 Arg2:T8\n",
      "R8\tCOREF Arg1:T8 Arg2:T9\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R10\tCOREF Arg1:T9 Arg2:T10\n",
      "R11\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R12\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R13\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R14\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R15\tUSED-FOR Arg1:T20 Arg2:T18\n",
      "R16\tCOREF Arg1:T9 Arg2:T17\n",
      "R17\tUSED-FOR Arg1:T16 Arg2:T14\n",
      "R18\tCOREF Arg1:T19 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2015_16_abs.ann\n",
      "T1\tMethod 10 37\tStacked Auto-Encoders (SAE)\n",
      "T2\tTask 70 98\tlearning imbalanced datasets\n",
      "T3\tMethod 155 180\tNeural Network classifier\n",
      "T4\tMethod 197 210\tSAE structure\n",
      "T5\tMethod 253 294\tAutomatic Speech Recognition (ASR) system\n",
      "T6\tTask 296 311\tError detection\n",
      "T7\tMaterial 318 341\tautomatic transcription\n",
      "T8\tMethod 367 377\tASR system\n",
      "T9\tMetric 403 418\tword error rate\n",
      "T10\tMethod 545 563\tbinary classi-fier\n",
      "T11\tMethod 625 636\tclassifiers\n",
      "T12\tTask 641 675\tautomatically detecting ASR errors\n",
      "T13\tGeneric 691 694\tone\n",
      "T14\tMethod 706 739\tstacked auto-encoder architecture\n",
      "T15\tMaterial 827 851\tautomatic transcriptions\n",
      "T16\tMaterial 858 872\tEnglish corpus\n",
      "T17\tMaterial 888 897\tTED talks\n",
      "T18\tMethod 932 942\tclassifier\n",
      "T19\tMetric 965 990\treceiving operating curve\n",
      "T20\tGeneric 1001 1008\tmeasure\n",
      "T21\tMetric 1017 1036\tmean absolute error\n",
      "T22\tMetric 1093 1108\tword error rate\n",
      "T23\tMethod 1144 1154\tclassifier\n",
      "T24\tMethod 1164 1167\tSAE\n",
      "T25\tOtherScientificTerm 1180 1190\tASR errors\n",
      "T26\tMethod 1213 1235\tclassification methods\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T4 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tCOREF Arg1:T8 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R8\tHYPONYM-OF Arg1:T13 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R10\tCOREF Arg1:T14 Arg2:T1\n",
      "R11\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R12\tFEATURE-OF Arg1:T16 Arg2:T15\n",
      "R13\tCOREF Arg1:T21 Arg2:T20\n",
      "R14\tEVALUATE-FOR Arg1:T19 Arg2:T18\n",
      "R15\tEVALUATE-FOR Arg1:T20 Arg2:T18\n",
      "R16\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R17\tCOREF Arg1:T24 Arg2:T14\n",
      "R18\tUSED-FOR Arg1:T24 Arg2:T23\n",
      "R19\tUSED-FOR Arg1:T23 Arg2:T25\n",
      "R20\tCOMPARE Arg1:T23 Arg2:T26\n",
      "R21\tUSED-FOR Arg1:T26 Arg2:T25\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2015_9_abs.ann\n",
      "T1\tMaterial 23 32\ttext data\n",
      "T2\tMaterial 50 53\tweb\n",
      "T3\tMethod 65 80\tlanguage models\n",
      "T4\tTask 85 113\tAutomatic Speech Recognition\n",
      "T5\tTask 118 132\tKeyword Search\n",
      "T6\tMaterial 137 159\tLow Resource Languages\n",
      "T7\tGeneric 190 196\tgenres\n",
      "T8\tMaterial 207 212\tblogs\n",
      "T9\tMaterial 214 225\tonline news\n",
      "T10\tMaterial 227 247\ttranslated TED talks\n",
      "T11\tMaterial 253 262\tsubtitles\n",
      "T12\tMethod 270 307\tlinearly interpolated language models\n",
      "T13\tMaterial 322 327\tblogs\n",
      "T14\tMaterial 332 347\tmovie subtitles\n",
      "T15\tMethod 370 422\tlanguage modeling of conversational telephone speech\n",
      "T16\tOtherScientificTerm 454 480\tout-of-vocabulary keywords\n",
      "T17\tMaterial 512 520\tweb data\n",
      "T18\tMetric 533 560\tTerm Error Rate Performance\n",
      "T19\tMetric 582 609\tMaximum Term-Weighted Value\n",
      "T20\tTask 613 627\tKeyword Search\n",
      "T21\tOtherScientificTerm 694 730\treduction of out-of-vocabulary items\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R5\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R6\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R7\tHYPONYM-OF Arg1:T10 Arg2:T7\n",
      "R8\tHYPONYM-OF Arg1:T11 Arg2:T7\n",
      "R9\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R10\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R11\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R13\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R14\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R15\tEVALUATE-FOR Arg1:T19 Arg2:T20\n",
      "R16\tCOREF Arg1:T8 Arg2:T13\n",
      "R17\tCOREF Arg1:T11 Arg2:T14\n",
      "R18\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R19\tUSED-FOR Arg1:T17 Arg2:T20\n",
      "R20\tEVALUATE-FOR Arg1:T18 Arg2:T20\n",
      "R21\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R22\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R23\tUSED-FOR Arg1:T12 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J05-1003.ann\n",
      "T1\tGeneric 24 34\tapproaches\n",
      "T2\tMethod 75 95\tprobabilistic parser\n",
      "T3\tMethod 109 115\tparser\n",
      "T4\tOtherScientificTerm 136 152\tcandidate parses\n",
      "T5\tOtherScientificTerm 238 245\tranking\n",
      "T6\tGeneric 257 263\tparses\n",
      "T7\tGeneric 277 282\tmodel\n",
      "T8\tOtherScientificTerm 328 335\tranking\n",
      "T9\tOtherScientificTerm 357 365\tfeatures\n",
      "T10\tOtherScientificTerm 375 379\ttree\n",
      "T11\tGeneric 414 422\tapproach\n",
      "T12\tGeneric 431 433\tit\n",
      "T13\tOtherScientificTerm 444 448\ttree\n",
      "T14\tOtherScientificTerm 492 500\tfeatures\n",
      "T15\tOtherScientificTerm 538 546\tfeatures\n",
      "T16\tOtherScientificTerm 602 612\tderivation\n",
      "T17\tMethod 620 636\tgenerative model\n",
      "T18\tOtherScientificTerm 657 665\tfeatures\n",
      "T19\tGeneric 701 707\tmethod\n",
      "T20\tTask 717 731\treranking task\n",
      "T21\tMethod 749 766\tboosting approach\n",
      "T22\tTask 772 788\tranking problems\n",
      "T23\tMethod 839 854\tboosting method\n",
      "T24\tTask 860 867\tparsing\n",
      "T25\tMaterial 874 902\tWall Street Journal treebank\n",
      "T26\tGeneric 910 916\tmethod\n",
      "T27\tOtherScientificTerm 931 945\tlog-likelihood\n",
      "T28\tMethod 956 970\tbaseline model\n",
      "T29\tOtherScientificTerm 1039 1047\tfeatures\n",
      "T30\tOtherScientificTerm 1055 1066\tparse trees\n",
      "T31\tGeneric 1108 1113\tmodel\n",
      "T32\tGeneric 1126 1131\tmodel\n",
      "T33\tMetric 1150 1159\tF-measure\n",
      "T34\tMetric 1191 1200\tF-measure\n",
      "T35\tGeneric 1218 1232\tbaseline model\n",
      "T36\tGeneric 1286 1295\talgorithm\n",
      "T37\tMethod 1305 1322\tboosting approach\n",
      "T38\tOtherScientificTerm 1354 1383\tsparsity of the feature space\n",
      "T39\tMaterial 1393 1405\tparsing data\n",
      "T40\tGeneric 1467 1476\talgorithm\n",
      "T41\tMethod 1519 1536\tboosting approach\n",
      "T42\tGeneric 1558 1564\tmethod\n",
      "T43\tMethod 1652 1677\tfeature selection methods\n",
      "T44\tMethod 1687 1722\tlog-linear (maximum-entropy) models\n",
      "T45\tTask 1775 1805\tnatural language parsing (NLP)\n",
      "T46\tTask 1858 1870\tNLP problems\n",
      "T47\tTask 1903 1916\tranking tasks\n",
      "T48\tTask 1934 1952\tspeech recognition\n",
      "T49\tTask 1957 1976\tmachine translation\n",
      "T50\tTask 1984 2011\tnatural language generation\n",
      "R1\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R2\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R3\tEVALUATE-FOR Arg1:T33 Arg2:T32\n",
      "R4\tFEATURE-OF Arg1:T38 Arg2:T39\n",
      "R5\tPART-OF Arg1:T43 Arg2:T44\n",
      "R6\tCOREF Arg1:T3 Arg2:T2\n",
      "R7\tCOREF Arg1:T6 Arg2:T4\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R10\tCOREF Arg1:T12 Arg2:T11\n",
      "R11\tCOREF Arg1:T11 Arg2:T1\n",
      "R12\tCOREF Arg1:T15 Arg2:T14\n",
      "R13\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R14\tUSED-FOR Arg1:T21 Arg2:T19\n",
      "R15\tUSED-FOR Arg1:T23 Arg2:T24\n",
      "R16\tCOREF Arg1:T26 Arg2:T23\n",
      "R17\tCONJUNCTION Arg1:T27 Arg2:T28\n",
      "R18\tPART-OF Arg1:T27 Arg2:T26\n",
      "R19\tCOREF Arg1:T31 Arg2:T28\n",
      "R20\tCOREF Arg1:T32 Arg2:T26\n",
      "R21\tUSED-FOR Arg1:T36 Arg2:T37\n",
      "R22\tUSED-FOR Arg1:T38 Arg2:T36\n",
      "R23\tCOREF Arg1:T40 Arg2:T36\n",
      "R24\tCOMPARE Arg1:T40 Arg2:T41\n",
      "R25\tCOREF Arg1:T42 Arg2:T40\n",
      "R26\tHYPONYM-OF Arg1:T48 Arg2:T46\n",
      "R27\tHYPONYM-OF Arg1:T49 Arg2:T46\n",
      "R28\tHYPONYM-OF Arg1:T50 Arg2:T46\n",
      "R29\tCONJUNCTION Arg1:T48 Arg2:T49\n",
      "R30\tCONJUNCTION Arg1:T49 Arg2:T50\n",
      "R31\tCOREF Arg1:T23 Arg2:T21\n",
      "R32\tCOREF Arg1:T41 Arg2:T37\n",
      "R33\tCOREF Arg1:T5 Arg2:T8\n",
      "R34\tCOREF Arg1:T20 Arg2:T22\n",
      "R35\tCOREF Arg1:T22 Arg2:T47\n",
      "R36\tUSED-FOR Arg1:T25 Arg2:T23\n",
      "R37\tCOREF Arg1:T37 Arg2:T32\n",
      "R38\tCOMPARE Arg1:T35 Arg2:T32\n",
      "R39\tCOREF Arg1:T35 Arg2:T28\n",
      "R40\tUSED-FOR Arg1:T47 Arg2:T46\n",
      "R41\tHYPONYM-OF Arg1:T48 Arg2:T47\n",
      "R42\tHYPONYM-OF Arg1:T49 Arg2:T47\n",
      "R43\tHYPONYM-OF Arg1:T50 Arg2:T47\n",
      "R44\tCOREF Arg1:T33 Arg2:T34\n",
      "R45\tEVALUATE-FOR Arg1:T34 Arg2:T35\n",
      "R46\tFEATURE-OF Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J05-4003.ann\n",
      "T1\tGeneric 21 27\tmethod\n",
      "T2\tTask 33 63\tdiscovering parallel sentences\n",
      "T3\tMaterial 69 101\tcomparable, non-parallel corpora\n",
      "T4\tMethod 117 143\tmaximum entropy classifier\n",
      "T5\tGeneric 269 277\tapproach\n",
      "T6\tMaterial 291 304\tparallel data\n",
      "T7\tMaterial 318 377\tChinese, Arabic, and English non-parallel newspaper corpora\n",
      "T8\tGeneric 445 447\tit\n",
      "T9\tMethod 496 534\tstatistical machine translation system\n",
      "T10\tMethod 572 581\tMT system\n",
      "T11\tMaterial 640 655\tparallel corpus\n",
      "T12\tMaterial 700 719\tnon-parallel corpus\n",
      "T13\tGeneric 733 739\tmethod\n",
      "T14\tMaterial 809 826\tscarce  resources\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tPART-OF Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R5\tCOREF Arg1:T5 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R7\tCOREF Arg1:T10 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R9\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R10\tCOREF Arg1:T5 Arg2:T8\n",
      "R11\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R12\tCOREF Arg1:T5 Arg2:T4\n",
      "R13\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R14\tCOREF Arg1:T8 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J81-1002.ann\n",
      "T1\tGeneric 41 48\tmethods\n",
      "T2\tTask 54 84\tcreating natural language text\n",
      "T3\tGeneric 94 113\tprocessing paradigm\n",
      "T4\tMethod 123 143\tFragment-and-Compose\n",
      "T5\tMethod 382 413\tKDS (Knowledge Delivery System)\n",
      "T6\tGeneric 436 444\tparadigm\n",
      "T7\tMethod 781 810\tFragment-and-Compose paradigm\n",
      "T8\tGeneric 821 842\tcomputational methods\n",
      "T9\tMethod 848 851\tKDS\n",
      "R1\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T4 Arg2:T3\n",
      "R4\tCOREF Arg1:T6 Arg2:T3\n",
      "R5\tCOREF Arg1:T7 Arg2:T6\n",
      "R6\tCOREF Arg1:T9 Arg2:T5\n",
      "R7\tCOREF Arg1:T3 Arg2:T1\n",
      "R8\tPART-OF Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J82-3002.ann\n",
      "T1\tMethod 55 97\tnatural language question answering system\n",
      "T2\tMethod 109 116\tChat-80\n",
      "T3\tMethod 121 128\tChat-80\n",
      "T4\tGeneric 224 230\tsystem\n",
      "T5\tOtherScientificTerm 259 265\tProlog\n",
      "T6\tOtherScientificTerm 272 292\tprogramming language\n",
      "T7\tOtherScientificTerm 304 309\tlogic\n",
      "T8\tMethod 332 361\tlogic-based grammar formalism\n",
      "T9\tMethod 371 393\textraposition grammars\n",
      "T10\tMethod 398 405\tChat-80\n",
      "T11\tOtherScientificTerm 448 472\tProlog   subset of logic\n",
      "T12\tOtherScientificTerm 491 509\tlogical expression\n",
      "T13\tMethod 537 555\tplanning algorithm\n",
      "T14\tOtherScientificTerm 573 579\tProlog\n",
      "T15\tMethod 588 606\tquery optimisation\n",
      "T16\tMaterial 614 633\trelational database\n",
      "T17\tOtherScientificTerm 651 662\tProlog form\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R3\tCOREF Arg1:T3 Arg2:T2\n",
      "R4\tCOREF Arg1:T4 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R6\tHYPONYM-OF Arg1:T5 Arg2:T6\n",
      "R7\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "R8\tCOREF Arg1:T10 Arg2:T4\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R11\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J86-1002.ann\n",
      "T1\tGeneric 5 11\tmethod\n",
      "T2\tTask 17 33\terror correction\n",
      "T3\tMaterial 39 55\till-formed input\n",
      "T4\tOtherScientificTerm 85 102\tdialogue patterns\n",
      "T5\tGeneric 137 145\tpatterns\n",
      "T6\tTask 171 187\tError correction\n",
      "T7\tTask 218 225\tparsing\n",
      "T8\tMethod 340 383\tdialogue acquisition and tracking algorithm\n",
      "T9\tMethod 453 477\tvoice interactive system\n",
      "T10\tMethod 541 569\terror correction methodology\n",
      "T11\tMaterial 577 597\tstereotypic dialogue\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T5 Arg2:T4\n",
      "R5\tCOREF Arg1:T6 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R7\tCOREF Arg1:T10 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J86-3001.ann\n",
      "T1\tMethod 35 64\ttheory of discourse structure\n",
      "T2\tOtherScientificTerm 123 132\tdiscourse\n",
      "T3\tGeneric 144 150\ttheory\n",
      "T4\tOtherScientificTerm 153 172\tdiscourse structure\n",
      "T5\tGeneric 221 231\tcomponents\n",
      "T6\tOtherScientificTerm 292 312\tlinguistic structure\n",
      "T7\tOtherScientificTerm 356 377\tintentional structure\n",
      "T8\tOtherScientificTerm 433 450\tattentional state\n",
      "T9\tOtherScientificTerm 460 480\tlinguistic structure\n",
      "T10\tOtherScientificTerm 511 520\tdiscourse\n",
      "T11\tOtherScientificTerm 576 597\tintentional structure\n",
      "T12\tOtherScientificTerm 613 640\tdiscourse-relevant purposes\n",
      "T13\tOtherScientificTerm 733 750\tattentional state\n",
      "T14\tOtherScientificTerm 828 837\tdiscourse\n",
      "T15\tOtherScientificTerm 853 870\tattentional state\n",
      "T16\tOtherScientificTerm 975 984\tdiscourse\n",
      "T17\tOtherScientificTerm 1084 1103\tdiscourse phenomena\n",
      "T18\tOtherScientificTerm 1109 1120\tcue phrases\n",
      "T19\tOtherScientificTerm 1125 1146\treferring expressions\n",
      "T20\tOtherScientificTerm 1155 1168\tinterruptions\n",
      "T21\tMethod 1177 1238\ttheory of attention, intention, and aggregation of utterances\n",
      "T22\tOtherScientificTerm 1294 1304\tdiscourses\n",
      "T23\tOtherScientificTerm 1331 1340\tdiscourse\n",
      "T24\tOtherScientificTerm 1396 1407\tcue phrases\n",
      "T25\tOtherScientificTerm 1412 1433\treferring expressions\n",
      "T26\tOtherScientificTerm 1442 1455\tinterruptions\n",
      "T27\tGeneric 1477 1483\ttheory\n",
      "T28\tOtherScientificTerm 1558 1567\tdiscourse\n",
      "T29\tMethod 1572 1592\tDiscourse processing\n",
      "T30\tOtherScientificTerm 1644 1653\tdiscourse\n",
      "T31\tOtherScientificTerm 1730 1739\tdiscourse\n",
      "T32\tOtherScientificTerm 1802 1811\tdiscourse\n",
      "T33\tOtherScientificTerm 1870 1887\tattentional state\n",
      "T34\tGeneric 1896 1906\tprocessing\n",
      "T35\tTask 1939 1956\trecognition tasks\n",
      "T36\tOtherScientificTerm 1992 2001\tdiscourse\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R2\tPART-OF Arg1:T5 Arg2:T4\n",
      "R3\tPART-OF Arg1:T6 Arg2:T5\n",
      "R4\tPART-OF Arg1:T7 Arg2:T5\n",
      "R5\tPART-OF Arg1:T8 Arg2:T5\n",
      "R6\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R7\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R8\tCOREF Arg1:T9 Arg2:T6\n",
      "R9\tCOREF Arg1:T11 Arg2:T7\n",
      "R10\tCOREF Arg1:T13 Arg2:T8\n",
      "R11\tCOREF Arg1:T15 Arg2:T13\n",
      "R12\tHYPONYM-OF Arg1:T18 Arg2:T17\n",
      "R13\tHYPONYM-OF Arg1:T19 Arg2:T17\n",
      "R14\tHYPONYM-OF Arg1:T20 Arg2:T17\n",
      "R15\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R16\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R17\tCOREF Arg1:T27 Arg2:T21\n",
      "R18\tCOREF Arg1:T34 Arg2:T29\n",
      "R19\tCOREF Arg1:T3 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J86-4002.ann\n",
      "T1\tTask 47 73\thuman-machine interactions\n",
      "T2\tOtherScientificTerm 81 109\tnatural language environment\n",
      "T3\tOtherScientificTerm 484 502\treference failures\n",
      "T4\tOtherScientificTerm 534 553\tspeaker's intention\n",
      "T5\tTask 590 606\tmiscommunication\n",
      "T6\tTask 720 737\tmiscommunications\n",
      "T7\tGeneric 754 758\tthem\n",
      "T8\tTask 805 821\tmiscommunication\n",
      "T9\tTask 828 846\treference problems\n",
      "T10\tGeneric 883 893\ttechniques\n",
      "T11\tTask 908 929\tfailures of reference\n",
      "T12\tTask 1173 1194\textensional reference\n",
      "R1\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T7 Arg2:T6\n",
      "R3\tCOREF Arg1:T6 Arg2:T5\n",
      "R4\tCOREF Arg1:T8 Arg2:T6\n",
      "R5\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J87-1003.ann\n",
      "T1\tMaterial 2 9\tEnglish\n",
      "T2\tOtherScientificTerm 62 75\tcoordinations\n",
      "T3\tOtherScientificTerm 116 157\tstrictly syntactic cross-serial agreement\n",
      "T4\tGeneric 165 174\tagreement\n",
      "T5\tOtherScientificTerm 210 215\tnouns\n",
      "T6\tOtherScientificTerm 222 240\treflexive pronouns\n",
      "T7\tOtherScientificTerm 299 317\tgrammatical number\n",
      "T8\tMaterial 323 330\tEnglish\n",
      "T9\tOtherScientificTerm 339 357\tgrammatical gender\n",
      "T10\tMaterial 363 372\tlanguages\n",
      "T11\tMaterial 383 389\tFrench\n",
      "T12\tMethod 463 480\tInterchange Lemma\n",
      "T13\tMaterial 541 548\tEnglish\n",
      "R1\tCOREF Arg1:T4 Arg2:T3\n",
      "R2\tHYPONYM-OF Arg1:T11 Arg2:T10\n",
      "R3\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R4\tFEATURE-OF Arg1:T9 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J87-3001.ann\n",
      "T1\tOtherScientificTerm 23 56\tdictionary word sense definitions\n",
      "T2\tMethod 88 118\thierarchy of  phrasal patterns\n",
      "T3\tGeneric 137 143\tsystem\n",
      "T4\tGeneric 159 168\tmechanism\n",
      "T5\tMaterial 229 271\tLongman Dictionary of Contemporary English\n",
      "T6\tGeneric 294 304\tdictionary\n",
      "T7\tGeneric 324 330\tsystem\n",
      "T8\tGeneric 340 342\tit\n",
      "T9\tOtherScientificTerm 351 372\trestricted vocabulary\n",
      "T10\tOtherScientificTerm 382 404\tword sense definitions\n",
      "T11\tTask 492 527\tclassification  of new  word senses\n",
      "T12\tOtherScientificTerm 573 594\trestricted vocabulary\n",
      "T13\tOtherScientificTerm 803 825\tphrasal analysis rules\n",
      "T14\tTask 1155 1174\trobustness problems\n",
      "T15\tMethod 1207 1242\tnatural language processing systems\n",
      "T16\tMaterial 1260 1279\tincomplete  lexicon\n",
      "T17\tOtherScientificTerm 1290 1338\tincomplete  knowledge  of  phrasal constructions\n",
      "R1\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R2\tFEATURE-OF Arg1:T14 Arg2:T15\n",
      "R3\tCOREF Arg1:T6 Arg2:T5\n",
      "R4\tCOREF Arg1:T7 Arg2:T3\n",
      "R5\tCOREF Arg1:T6 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R7\tCOREF Arg1:T12 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R9\tCOREF Arg1:T4 Arg2:T2\n",
      "R10\tPART-OF Arg1:T4 Arg2:T3\n",
      "R11\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R12\tHYPONYM-OF Arg1:T16 Arg2:T14\n",
      "R13\tHYPONYM-OF Arg1:T17 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J88-3002.ann\n",
      "T1\tMethod 8 39\tintelligent interactive systems\n",
      "T2\tGeneric 91 95\tthey\n",
      "T3\tTask 176 189\tuser modeling\n",
      "T4\tMethod 200 207\tsystems\n",
      "T5\tMethod 256 266\tuser model\n",
      "T6\tGeneric 279 281\tit\n",
      "T7\tMethod 328 338\tuser model\n",
      "T8\tMethod 415 426\tUser models\n",
      "T9\tGeneric 561 565\tthey\n",
      "T10\tMethod 636 646\tuser model\n",
      "T11\tTask 677 690\tuser modeling\n",
      "T12\tMethod 778 801\tuser modeling component\n",
      "T13\tGeneric 809 815\tsystem\n",
      "T14\tGeneric 917 923\tsystem\n",
      "T15\tTask 968 981\tuser modeling\n",
      "T16\tMethod 1087 1108\tuser modeling systems\n",
      "R1\tPART-OF Arg1:T3 Arg2:T4\n",
      "R2\tCOREF Arg1:T2 Arg2:T1\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tCOREF Arg1:T7 Arg2:T5\n",
      "R5\tCOREF Arg1:T8 Arg2:T7\n",
      "R6\tCOREF Arg1:T9 Arg2:T8\n",
      "R7\tCOREF Arg1:T10 Arg2:T9\n",
      "R8\tCOREF Arg1:T14 Arg2:T13\n",
      "R9\tPART-OF Arg1:T12 Arg2:T13\n",
      "R10\tCOREF Arg1:T6 Arg2:T5\n",
      "R11\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R12\tCOREF Arg1:T11 Arg2:T3\n",
      "R13\tCOREF Arg1:T15 Arg2:T11\n",
      "R14\tCOREF Arg1:T16 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J89-4003.ann\n",
      "T1\tGeneric 4 9\tmodel\n",
      "T2\tOtherScientificTerm 45 63\tclass of languages\n",
      "T3\tOtherScientificTerm 85 98\treduplication\n",
      "T4\tMaterial 104 126\tcontext-free languages\n",
      "T5\tMethod 134 139\tmodel\n",
      "T6\tMethod 147 165\tpushdown automaton\n",
      "T7\tOtherScientificTerm 204 217\treduplication\n",
      "T8\tOtherScientificTerm 233 238\tstack\n",
      "T9\tOtherScientificTerm 259 277\tclass of languages\n",
      "T10\tMaterial 327 349\tcontext-free languages\n",
      "T11\tMaterial 360 377\tindexed languages\n",
      "T12\tGeneric 385 390\tmodel\n",
      "T13\tOtherScientificTerm 438 452\treduplications\n",
      "T14\tMaterial 491 508\tnatural languages\n",
      "T15\tGeneric 515 517\tit\n",
      "T16\tMethod 577 590\tformal models\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R3\tCOREF Arg1:T5 Arg2:T1\n",
      "R4\tHYPONYM-OF Arg1:T5 Arg2:T6\n",
      "R5\tCOREF Arg1:T9 Arg2:T2\n",
      "R6\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R7\tCOREF Arg1:T12 Arg2:T5\n",
      "R8\tCOREF Arg1:T15 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R10\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R11\tCOREF Arg1:T4 Arg2:T10\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J90-3002.ann\n",
      "T1\tMethod 38 44\teditor\n",
      "T2\tMaterial 59 81\tstructured  dictionary\n",
      "T3\tMethod 118 124\teditor\n",
      "T4\tGeneric 212 222\tdictionary\n",
      "T5\tMethod 243 260\tlinguistic theory\n",
      "T6\tTask 330 357\tnatural language processing\n",
      "T7\tMaterial 453 473\tlinguistic databases\n",
      "T8\tMethod 518 524\teditor\n",
      "T9\tOtherScientificTerm 550 565\tcoherence rules\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R3\tCOREF Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R5\tCOREF Arg1:T7 Arg2:T4\n",
      "R6\tCOREF Arg1:T8 Arg2:T3\n",
      "R7\tCOREF Arg1:T2 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J97-1004.ann\n",
      "T1\tMethod 36 54\texplanation system\n",
      "T2\tOtherScientificTerm 183 214\tmultisentential discourse plans\n",
      "T3\tOtherScientificTerm 234 249\tdiscourse plans\n",
      "T4\tTask 499 521\texplanation generation\n",
      "T5\tMaterial 529 575\tsemantically rich, large-scale knowledge bases\n",
      "T6\tMethod 609 634\trobust explanation system\n",
      "T7\tOtherScientificTerm 653 701\tmultisentential and multi-paragraph explanations\n",
      "T8\tMaterial 715 741\tlarge-scale knowledge base\n",
      "T9\tMaterial 760 777\tbotanical anatomy\n",
      "T10\tMaterial 779 789\tphysiology\n",
      "T11\tMaterial 795 806\tdevelopment\n",
      "T12\tGeneric 825 847\tevaluation methodology\n",
      "T13\tGeneric 900 911\tmethodology\n",
      "T14\tMethod 971 989\texplanation system\n",
      "T15\tGeneric 999 1009\tevaluation\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R4\tCOREF Arg1:T6 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R7\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T13 Arg2:T12\n",
      "R9\tCOREF Arg1:T14 Arg2:T6\n",
      "R10\tEVALUATE-FOR Arg1:T13 Arg2:T14\n",
      "R11\tCOREF Arg1:T15 Arg2:T13\n",
      "R12\tCOREF Arg1:T6 Arg2:T1\n",
      "R13\tFEATURE-OF Arg1:T9 Arg2:T8\n",
      "R14\tFEATURE-OF Arg1:T10 Arg2:T8\n",
      "R15\tFEATURE-OF Arg1:T11 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\L08-1050.ann\n",
      "T1\tMaterial 69 104\tlanguage corpus annotation scenario\n",
      "T2\tOtherScientificTerm 121 140\tdiscourse relations\n",
      "T3\tMaterial 146 151\tCzech\n",
      "T4\tOtherScientificTerm 200 248\tsyntactically motivated relations  in  discourse\n",
      "T5\tMaterial 309 339\tPrague Dependency Treebank 2.0\n",
      "T6\tMaterial 350 375\tPenn Discourse Treebank 2\n",
      "T7\tOtherScientificTerm 417 466\tsyntactico-semantic (tectogrammatical) annotation\n",
      "T8\tMaterial 476 502\tPrague Dependency Treebank\n",
      "T9\tGeneric 512 514\tit\n",
      "T10\tTask 538 579\tsentence-boundary-crossing representation\n",
      "T11\tTask 614 645\tdiscourse level  of  annotation\n",
      "T12\tMethod 746 780\tPraguian dependency-based approach\n",
      "T13\tMethod 799 824\tPenn discourse annotation\n",
      "T14\tMethod 849 902\tanalysis and classification of  discourse connectives\n",
      "R1\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R2\tCOREF Arg1:T7 Arg2:T9\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R6\tPART-OF Arg1:T7 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R8\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R9\tCOMPARE Arg1:T13 Arg2:T12\n",
      "R10\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R11\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R12\tEVALUATE-FOR Arg1:T14 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\L08-1097.ann\n",
      "T1\tTask 44 140\tunsupervised automatic acquisition  of  Italian and English verb subcategorization frames (SCFs)\n",
      "T2\tOtherScientificTerm 84 140\tItalian and English verb subcategorization frames (SCFs)\n",
      "T3\tMaterial 148 174\tgeneral and domain corpora\n",
      "T4\tGeneric 190 199\ttechnique\n",
      "T5\tMaterial 213 249\tsyntactically shallow-parsed corpora\n",
      "T6\tMethod 288 305\tsearch heuristics\n",
      "T7\tOtherScientificTerm 336 362\tlexico-syntactic knowledge\n",
      "T8\tOtherScientificTerm 371 375\tSCFs\n",
      "T9\tMethod 452 479\tlexical acquisition systems\n",
      "T10\tOtherScientificTerm 528 546\tSCFs distributions\n",
      "T11\tOtherScientificTerm 565 592\tsimilar semantic properties\n",
      "T12\tMethod 702 744\tMinimum Description Length Principle (MDL)\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R3\tCOREF Arg1:T8 Arg2:T2\n",
      "R4\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\L08-1110.ann\n",
      "T1\tMethod 46 68\tstatistical techniques\n",
      "T2\tTask 74 81\tranking\n",
      "T3\tOtherScientificTerm 126 159\tgraph  of  translation hypotheses\n",
      "T4\tOtherScientificTerm 222 238\thypotheses graph\n",
      "T5\tMethod 262 277\tshallow mapping\n",
      "T6\tMethod 284 301\tpermutation rules\n",
      "T7\tOtherScientificTerm 335 340\tnodes\n",
      "T8\tOtherScientificTerm 357 405\tvectors representing morpho-syntactic properties\n",
      "T9\tGeneric 466 473\tmethods\n",
      "T10\tOtherScientificTerm 491 520\tstatistical feature functions\n",
      "T11\tMethod 540 557\tvector components\n",
      "T12\tOtherScientificTerm 565 582\tfeature functions\n",
      "T13\tOtherScientificTerm 645 667\tlog-linear combination\n",
      "T14\tOtherScientificTerm 706 723\ttranslation paths\n",
      "T15\tOtherScientificTerm 733 738\tgraph\n",
      "T16\tMethod 757 784\tlanguage modelling toolkits\n",
      "T17\tMethod 792 817\tCMU  and the  SRI toolkit\n",
      "T18\tMethod 852 892\tword-lemma based feature function models\n",
      "T19\tMethod 923 941\ttoken-based models\n",
      "T20\tOtherScientificTerm 957 981\tPoS-tag feature function\n",
      "T21\tMethod 991 1007\tword-lemma model\n",
      "T22\tTask 1051 1071\tlexical translations\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tCOMPARE Arg1:T18 Arg2:T19\n",
      "R3\tPART-OF Arg1:T20 Arg2:T21\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R6\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R7\tCOREF Arg1:T12 Arg2:T10\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R10\tCOREF Arg1:T21 Arg2:T18\n",
      "R11\tCOREF Arg1:T4 Arg2:T15\n",
      "R12\tCOREF Arg1:T4 Arg2:T3\n",
      "R13\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R14\tPART-OF Arg1:T14 Arg2:T15\n",
      "R15\tHYPONYM-OF Arg1:T17 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\L08-1154.ann\n",
      "T1\tOtherScientificTerm 63 98\tinternal and contextual information\n",
      "T2\tOtherScientificTerm 117 138\tdomain specific terms\n",
      "T3\tOtherScientificTerm 192 200\tfeatures\n",
      "T4\tOtherScientificTerm 271 279\tfeatures\n",
      "T5\tGeneric 359 367\tapproach\n",
      "T6\tTask 373 388\tterm extraction\n",
      "T7\tOtherScientificTerm 400 410\tdelimiters\n",
      "T8\tGeneric 476 484\tapproach\n",
      "T9\tOtherScientificTerm 509 523\tterm frequency\n",
      "T10\tGeneric 557 565\tapproach\n",
      "T11\tOtherScientificTerm 590 600\thard rules\n",
      "T12\tOtherScientificTerm 679 695\tdomain knowledge\n",
      "T13\tGeneric 780 788\tapproach\n",
      "T14\tGeneric 838 840\tit\n",
      "T15\tMaterial 867 891\tresource-limited domains\n",
      "T16\tGeneric 894 905\tEvaluations\n",
      "T17\tTask 948 971\tChinese term extraction\n",
      "T18\tTask 1105 1124\tnew term extraction\n",
      "T19\tGeneric 1153 1161\tapproach\n",
      "T20\tGeneric 1193 1197\ttool\n",
      "T21\tTask 1203 1227\tdomain lexicon expansion\n",
      "R1\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R4\tCOREF Arg1:T8 Arg2:T5\n",
      "R5\tCOMPARE Arg1:T8 Arg2:T9\n",
      "R6\tCOREF Arg1:T10 Arg2:T8\n",
      "R7\tCOREF Arg1:T13 Arg2:T10\n",
      "R8\tCOREF Arg1:T13 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R10\tEVALUATE-FOR Arg1:T16 Arg2:T17\n",
      "R11\tCOREF Arg1:T19 Arg2:T13\n",
      "R12\tUSED-FOR Arg1:T19 Arg2:T21\n",
      "R13\tCOREF Arg1:T20 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\L08-1260.ann\n",
      "T1\tMethod 88 124\tlexicon grammar for Polish (SyntLex)\n",
      "T2\tTask 156 244\tcomputer-assisted acquisition and morpho-syntactic description of verb-noun collocations\n",
      "T3\tMaterial 250 256\tPolish\n",
      "T4\tGeneric 327 333\tphases\n",
      "T5\tTask 346 399\tdictionary-based acquisition  of  collocation lexicon\n",
      "T6\tTask 402 419\tfeasibility study\n",
      "T7\tTask 425 464\tcorpus-based lexicon enlargement  phase\n",
      "T8\tTask 467 529\tcorpus-based lexicon enlargement  and  collocation description\n",
      "T9\tMethod 610 631\tcorpus-based approach\n",
      "T10\tMaterial 670 702\tverb-noun collocation dictionary\n",
      "T11\tMaterial 707 713\tPolish\n",
      "T12\tMaterial 746 780\tSyntLex Dictionary of Collocations\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T5 Arg2:T4\n",
      "R3\tHYPONYM-OF Arg1:T8 Arg2:T4\n",
      "R4\tFEATURE-OF Arg1:T11 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R7\tHYPONYM-OF Arg1:T6 Arg2:T4\n",
      "R8\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R9\tCONJUNCTION Arg1:T8 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\L08-1540.ann\n",
      "T1\tMaterial 50 74\tlarge Czech MWE database\n",
      "T2\tOtherScientificTerm 110 114\tMWEs\n",
      "T3\tOtherScientificTerm 129 142\tlexical units\n",
      "T4\tGeneric 146 148\tIt\n",
      "T5\tMaterial 194 207\tencyclopedias\n",
      "T6\tMaterial 214 226\tdictionaries\n",
      "T7\tMaterial 229 279\tpublic  databases  of  proper names  and  toponyms\n",
      "T8\tGeneric 283 295\tcollocations\n",
      "T9\tMaterial 312 325\tCzech WordNet\n",
      "T10\tMaterial 328 368\tlists of  botanical and zoological terms\n",
      "T11\tGeneric 416 424\tdatabase\n",
      "T12\tOtherScientificTerm 451 455\tMWEs\n",
      "T13\tMaterial 516 529\tMWEs database\n",
      "T14\tMaterial 560 581\tCzech National Corpus\n",
      "T15\tOtherScientificTerm 669 673\tMWEs\n",
      "T16\tGeneric 708 714\tcorpus\n",
      "T17\tOtherScientificTerm 797 801\tMWEs\n",
      "T18\tGeneric 824 833\ttechnique\n",
      "T19\tTask 850 868\tWord Sketch Engine\n",
      "T20\tOtherScientificTerm 901 923\tstatistical parameters\n",
      "T21\tOtherScientificTerm 947 951\tMWEs\n",
      "T22\tOtherScientificTerm 1020 1024\tMWEs\n",
      "T23\tGeneric 1064 1072\tdatabase\n",
      "T24\tTask 1107 1114\ttagging\n",
      "T25\tTask 1121 1134\tlemmatization\n",
      "T26\tOtherScientificTerm 1180 1184\tMWEs\n",
      "T27\tGeneric 1217 1221\tthem\n",
      "T28\tOtherScientificTerm 1235 1248\tlexical units\n",
      "T29\tTask 1266 1273\ttagging\n",
      "T30\tTask 1280 1293\tlemmatization\n",
      "R1\tCOREF Arg1:T9 Arg2:T8\n",
      "R2\tFEATURE-OF Arg1:T20 Arg2:T19\n",
      "R3\tUSED-FOR Arg1:T23 Arg2:T24\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T4\n",
      "R8\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R9\tCOREF Arg1:T11 Arg2:T4\n",
      "R10\tCOREF Arg1:T13 Arg2:T11\n",
      "R11\tCOREF Arg1:T16 Arg2:T14\n",
      "R12\tCOREF Arg1:T17 Arg2:T15\n",
      "R13\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R14\tCOREF Arg1:T22 Arg2:T21\n",
      "R15\tCONJUNCTION Arg1:T24 Arg2:T25\n",
      "R16\tUSED-FOR Arg1:T23 Arg2:T25\n",
      "R17\tCOREF Arg1:T27 Arg2:T26\n",
      "R18\tCOREF Arg1:T15 Arg2:T12\n",
      "R19\tCOREF Arg1:T23 Arg2:T13\n",
      "R20\tUSED-FOR Arg1:T26 Arg2:T29\n",
      "R21\tUSED-FOR Arg1:T26 Arg2:T30\n",
      "R22\tCONJUNCTION Arg1:T29 Arg2:T30\n",
      "R23\tUSED-FOR Arg1:T7 Arg2:T4\n",
      "R24\tUSED-FOR Arg1:T10 Arg2:T4\n",
      "R25\tCONJUNCTION Arg1:T10 Arg2:T8\n",
      "R26\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R27\tCOREF Arg1:T29 Arg2:T24\n",
      "R28\tCOREF Arg1:T30 Arg2:T25\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\M91-1029.ann\n",
      "T1\tMethod 6 69\tPRC Adaptive Knowledge-based Text Understanding System (PAKTUS)\n",
      "T2\tGeneric 195 201\tsystem\n",
      "T3\tOtherScientificTerm 225 245\tcore English lexicon\n",
      "T4\tMethod 249 256\tgrammar\n",
      "T5\tMethod 263 286\tconcept representations\n",
      "T6\tMethod 302 343\tnatural language processing (NLP) systems\n",
      "T7\tTask 350 368\ttext understanding\n",
      "T8\tMethod 391 397\tPAKTUS\n",
      "T9\tTask 433 456\tknowledge based systems\n",
      "T10\tMethod 492 502\tNLP system\n",
      "T11\tMaterial 543 568\telectronic message stream\n",
      "T12\tMaterial 581 590\tnews wire\n",
      "T13\tMethod 593 599\tPAKTUS\n",
      "T14\tMaterial 671 688\tJINTACCS messages\n",
      "T15\tMaterial 692 709\tRAINFORM messages\n",
      "T16\tOtherScientificTerm 713 725\tnews reports\n",
      "T17\tOtherScientificTerm 752 757\tevent\n",
      "T18\tMaterial 767 786\tfinancial transfers\n",
      "T19\tMaterial 790 804\tterrorist acts\n",
      "T20\tMethod 826 865\tsublanguage and domain-specific grammar\n",
      "T21\tGeneric 869 874\twords\n",
      "T22\tOtherScientificTerm 876 895\tconceptual mappings\n",
      "T23\tOtherScientificTerm 903 921\tdiscourse patterns\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R3\tCOREF Arg1:T2 Arg2:T1\n",
      "R4\tPART-OF Arg1:T3 Arg2:T2\n",
      "R5\tPART-OF Arg1:T4 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T2 Arg2:T6\n",
      "R7\tPART-OF Arg1:T5 Arg2:T2\n",
      "R8\tCOREF Arg1:T8 Arg2:T2\n",
      "R9\tCOREF Arg1:T10 Arg2:T6\n",
      "R10\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R11\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R12\tCOREF Arg1:T13 Arg2:T8\n",
      "R13\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R14\tUSED-FOR Arg1:T13 Arg2:T16\n",
      "R15\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R16\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R17\tHYPONYM-OF Arg1:T18 Arg2:T17\n",
      "R18\tHYPONYM-OF Arg1:T19 Arg2:T17\n",
      "R19\tUSED-FOR Arg1:T20 Arg2:T13\n",
      "R20\tUSED-FOR Arg1:T23 Arg2:T13\n",
      "R21\tUSED-FOR Arg1:T21 Arg2:T13\n",
      "R22\tUSED-FOR Arg1:T22 Arg2:T13\n",
      "R23\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R24\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "R25\tCONJUNCTION Arg1:T22 Arg2:T23\n",
      "R26\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R27\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R28\tFEATURE-OF Arg1:T17 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N01-1003.ann\n",
      "T1\tTask 2 19\tSentence planning\n",
      "T2\tGeneric 60 65\ttasks\n",
      "T3\tTask 84 100\tsentence scoping\n",
      "T4\tOtherScientificTerm 124 143\tsyntactic structure\n",
      "T5\tOtherScientificTerm 161 172\tspeech acts\n",
      "T6\tMethod 272 276\tSPoT\n",
      "T7\tMethod 283 299\tsentence planner\n",
      "T8\tGeneric 313 324\tmethodology\n",
      "T9\tMethod 353 357\tSPoT\n",
      "T10\tMethod 492 532\trandomized sentence-plan-generator (SPG)\n",
      "T11\tOtherScientificTerm 582 596\tsentence plans\n",
      "T12\tOtherScientificTerm 611 626\ttext-plan input\n",
      "T13\tMethod 643 669\tsentence-plan-ranker (SPR)\n",
      "T14\tOtherScientificTerm 697 711\tsentence plans\n",
      "T15\tMethod 761 764\tSPR\n",
      "T16\tOtherScientificTerm 772 785\tranking rules\n",
      "T17\tMethod 858 861\tSPR\n",
      "T18\tOtherScientificTerm 883 896\tsentence plan\n",
      "T19\tOtherScientificTerm 949 979\ttop human-ranked sentence plan\n",
      "R1\tCOMPARE Arg1:T18 Arg2:T19\n",
      "R2\tCOREF Arg1:T2 Arg2:T1\n",
      "R3\tPART-OF Arg1:T3 Arg2:T2\n",
      "R4\tHYPONYM-OF Arg1:T6 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R6\tCOREF Arg1:T9 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R10\tCOREF Arg1:T14 Arg2:T11\n",
      "R11\tCOREF Arg1:T15 Arg2:T13\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R13\tCOREF Arg1:T17 Arg2:T15\n",
      "R14\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R15\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-1001.ann\n",
      "T1\tGeneric 24 30\tmethod\n",
      "T2\tTask 36 60\tutterance classification\n",
      "T3\tMaterial 85 105\tmanual transcription\n",
      "T4\tGeneric 132 138\tmethod\n",
      "T5\tMethod 149 183\tdomain independent acoustic models\n",
      "T6\tMethod 205 216\tclassifiers\n",
      "T7\tTask 227 251\tutterance classification\n",
      "T8\tMethod 336 360\tword-trigram recognition\n",
      "T9\tMaterial 373 393\tmanual transcription\n",
      "T10\tGeneric 404 410\tmethod\n",
      "T11\tMethod 413 434\tunsupervised training\n",
      "T12\tMethod 462 480\tphone n-gram model\n",
      "T13\tGeneric 500 506\tdomain\n",
      "T14\tGeneric 551 556\tmodel\n",
      "T15\tMethod 579 602\tphone-string classifier\n",
      "T16\tMetric 611 634\tclassification accuracy\n",
      "T17\tGeneric 643 649\tmethod\n",
      "T18\tMaterial 683 713\tspoken language system domains\n",
      "R1\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tPART-OF Arg1:T5 Arg2:T4\n",
      "R6\tCONJUNCTION Arg1:T6 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T4\n",
      "R8\tCOREF Arg1:T10 Arg2:T4\n",
      "R9\tPART-OF Arg1:T11 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R11\tCOREF Arg1:T14 Arg2:T12\n",
      "R12\tCOREF Arg1:T17 Arg2:T10\n",
      "R13\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R14\tEVALUATE-FOR Arg1:T16 Arg2:T17\n",
      "R15\tUSED-FOR Arg1:T4 Arg2:T7\n",
      "R16\tCOREF Arg1:T7 Arg2:T2\n",
      "R17\tPART-OF Arg1:T6 Arg2:T4\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-1004.ann\n",
      "T1\tMethod 30 46\tensemble methods\n",
      "T2\tTask 52 68\tmachine learning\n",
      "T3\tTask 90 117\tnatural language processing\n",
      "T4\tMethod 137 177\tmulti-strategy and multi-source approach\n",
      "T5\tTask 181 199\tquestion answering\n",
      "T6\tMethod 257 273\tanswering agents\n",
      "T7\tMethod 328 344\tanswering agents\n",
      "T8\tGeneric 376 386\tstrategies\n",
      "T9\tGeneric 388 391\tone\n",
      "T10\tMethod 413 439\tknowledge-based mechanisms\n",
      "T11\tGeneric 449 454\tother\n",
      "T12\tMethod 465 487\tstatistical techniques\n",
      "T13\tMethod 507 546\tmulti-level answer resolution algorithm\n",
      "T14\tMethod 580 596\tanswering agents\n",
      "T15\tOtherScientificTerm 606 645\tquestion, passage, and/or answer levels\n",
      "T16\tMethod 698 725\tanswer resolution algorithm\n",
      "T17\tGeneric 771 786\tbaseline system\n",
      "T18\tMetric 880 904\taverage precision metric\n",
      "R1\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R4\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "R5\tHYPONYM-OF Arg1:T11 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R10\tCOREF Arg1:T16 Arg2:T13\n",
      "R11\tEVALUATE-FOR Arg1:T18 Arg2:T16\n",
      "R12\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R13\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R14\tCOREF Arg1:T7 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-1012.ann\n",
      "T1\tMethod 27 36\tONTOSCORE\n",
      "T2\tGeneric 42 48\tsystem\n",
      "T3\tOtherScientificTerm 100 108\tontology\n",
      "T4\tGeneric 125 131\tsystem\n",
      "T5\tOtherScientificTerm 170 205\tspeech recognition hypotheses (SRH)\n",
      "T6\tOtherScientificTerm 226 244\tsemantic coherence\n",
      "T7\tOtherScientificTerm 396 425\tspeech recognition hypotheses\n",
      "T8\tGeneric 450 456\tsystem\n",
      "T9\tGeneric 498 500\tit\n",
      "T10\tMaterial 537 550\tGerman corpus\n",
      "T11\tOtherScientificTerm 562 566\tSRHs\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tCOREF Arg1:T4 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tCOREF Arg1:T8 Arg2:T4\n",
      "R6\tCOREF Arg1:T8 Arg2:T9\n",
      "R7\tCOREF Arg1:T9 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-1017.ann\n",
      "T1\tMethod 19 49\tphrase-based translation model\n",
      "T2\tMethod 56 74\tdecoding algorithm\n",
      "T3\tMethod 146 177\tphrase-based translation models\n",
      "T4\tGeneric 192 201\tframework\n",
      "T5\tMethod 284 303\tphrase-based models\n",
      "T6\tMethod 317 334\tword-based models\n",
      "T7\tGeneric 497 502\tmeans\n",
      "T8\tMethod 505 548\theuristic learning  of  phrase translations\n",
      "T9\tMethod 556 577\tword-based alignments\n",
      "T10\tMethod 584 626\tlexical weighting  of  phrase translations\n",
      "T11\tMethod 718 759\thigh-accuracy word-level alignment models\n",
      "T12\tGeneric 887 894\tsystems\n",
      "R1\tCOMPARE Arg1:T5 Arg2:T6\n",
      "R2\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T5 Arg2:T3\n",
      "R4\tCOREF Arg1:T12 Arg2:T1\n",
      "R5\tCOREF Arg1:T4 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R7\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R8\tHYPONYM-OF Arg1:T10 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-1018.ann\n",
      "T1\tMethod 32 98\tgenerative probabilistic optical character recognition (OCR) model\n",
      "T2\tMethod 145 168\tnoisy channel framework\n",
      "T3\tOtherScientificTerm 273 283\tOCR system\n",
      "T4\tGeneric 292 297\tmodel\n",
      "T5\tTask 323 339\terror correction\n",
      "T6\tTask 360 375\tpost-processing\n",
      "T7\tOtherScientificTerm 382 415\toutput  of black-box  OCR systems\n",
      "T8\tOtherScientificTerm 404 415\tOCR systems\n",
      "T9\tGeneric 434 436\tit\n",
      "T10\tTask 454 463\tNLP tasks\n",
      "T11\tGeneric 504 509\tmodel\n",
      "T12\tMethod 521 540\tfinite-state models\n",
      "T13\tGeneric 561 566\tmodel\n",
      "T14\tMetric 604 633\tcharacter and word error rate\n",
      "T15\tTask 679 725\tautomatic extraction  of  translation lexicons\n",
      "T16\tMaterial 733 745\tprinted text\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R3\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R6\tPART-OF Arg1:T6 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R8\tCOREF Arg1:T11 Arg2:T4\n",
      "R9\tCOREF Arg1:T7 Arg2:T9\n",
      "R10\tCOREF Arg1:T3 Arg2:T8\n",
      "R11\tCOREF Arg1:T13 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R13\tEVALUATE-FOR Arg1:T15 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-1026.ann\n",
      "T1\tMethod 31 89\tambiguity packing and stochastic disambiguation techniques\n",
      "T2\tMethod 96 129\tLexical-Functional Grammars (LFG)\n",
      "T3\tTask 149 170\tsentence condensation\n",
      "T4\tGeneric 178 184\tsystem\n",
      "T5\tMethod 201 228\tlinguistic parser/generator\n",
      "T6\tMethod 235 238\tLFG\n",
      "T7\tMethod 245 263\ttransfer component\n",
      "T8\tTask 270 285\tparse reduction\n",
      "T9\tOtherScientificTerm 301 321\tpacked parse forests\n",
      "T10\tMethod 332 353\tmaximum-entropy model\n",
      "T11\tTask 360 387\tstochastic output selection\n",
      "T12\tMethod 436 461\tparser evaluation methods\n",
      "T13\tMetric 497 519\tsummarization  quality\n",
      "T14\tMethod 524 553\tsentence condensation systems\n",
      "T15\tMetric 590 612\tsummarization  quality\n",
      "T16\tMethod 652 684\tautomatic parse-based evaluation\n",
      "T17\tMethod 693 710\tmanual evaluation\n",
      "T18\tMetric 746 768\tsummarization  quality\n",
      "T19\tGeneric 785 791\tsystem\n",
      "T20\tMetric 830 844\tgrammaticality\n",
      "T21\tMethod 890 923\tconstraint-based parser/generator\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R6\tPART-OF Arg1:T5 Arg2:T4\n",
      "R7\tPART-OF Arg1:T7 Arg2:T4\n",
      "R8\tCONJUNCTION Arg1:T5 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R10\tCONJUNCTION Arg1:T7 Arg2:T10\n",
      "R11\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R12\tCOREF Arg1:T19 Arg2:T14\n",
      "R13\tUSED-FOR Arg1:T21 Arg2:T19\n",
      "R14\tCOREF Arg1:T12 Arg2:T16\n",
      "R15\tCOREF Arg1:T14 Arg2:T4\n",
      "R16\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "R17\tCOREF Arg1:T4 Arg2:T1\n",
      "R18\tCOREF Arg1:T15 Arg2:T18\n",
      "R19\tEVALUATE-FOR Arg1:T13 Arg2:T14\n",
      "R20\tEVALUATE-FOR Arg1:T12 Arg2:T13\n",
      "R21\tCOREF Arg1:T15 Arg2:T13\n",
      "R22\tCOREF Arg1:T15 Arg2:T13\n",
      "R23\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R24\tEVALUATE-FOR Arg1:T20 Arg2:T19\n",
      "R25\tCOREF Arg1:T2 Arg2:T6\n",
      "R26\tPART-OF Arg1:T10 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-1033.ann\n",
      "T1\tMethod 19 40\tpart-of-speech tagger\n",
      "T2\tOtherScientificTerm 131 143\ttag contexts\n",
      "T3\tMethod 152 185\tdependency network representation\n",
      "T4\tOtherScientificTerm 208 224\tlexical features\n",
      "T5\tOtherScientificTerm 263 289\tmultiple consecutive words\n",
      "T6\tOtherScientificTerm 317 357\tpriors  in  conditional loglinear models\n",
      "T7\tMethod 370 417\tfine-grained modeling of  unknown word features\n",
      "T8\tMethod 464 470\ttagger\n",
      "T9\tMetric 488 496\taccuracy\n",
      "T10\tMaterial 506 523\tPenn Treebank WSJ\n",
      "T11\tMetric 531 536\terror\n",
      "T12\tTask 607 614\ttagging\n",
      "R1\tEVALUATE-FOR Arg1:T9 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R3\tCOREF Arg1:T8 Arg2:T1\n",
      "R4\tEVALUATE-FOR Arg1:T10 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T1\n",
      "R7\tEVALUATE-FOR Arg1:T11 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-2003.ann\n",
      "T1\tMethod 42 59\tlanguage modeling\n",
      "T2\tMaterial 65 86\tconversational speech\n",
      "T3\tTask 251 267\trecognition task\n",
      "T4\tMethod 358 400\tclass-dependent interpolation  of  N-grams\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-2006.ann\n",
      "T1\tMethod 49 53\tEBMT\n",
      "T2\tMaterial 66 95\tsmall-sized  bilingual corpus\n",
      "T3\tMaterial 109 140\tout-of-domain  bilingual corpus\n",
      "T4\tMethod 165 179\tlanguage model\n",
      "T5\tMaterial 187 216\tin-domain  monolingual corpus\n",
      "T6\tMethod 254 265\tEBMT system\n",
      "T7\tMetric 278 297\tevaluation measures\n",
      "T8\tMetric 307 317\tBLEU score\n",
      "T9\tMetric 328 338\tNIST score\n",
      "T10\tMaterial 376 407\tout-of-domain  bilingual corpus\n",
      "T11\tMethod 443 457\tlanguage model\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R2\tCOREF Arg1:T6 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R4\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R5\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R6\tEVALUATE-FOR Arg1:T7 Arg2:T11\n",
      "R7\tCOREF Arg1:T11 Arg2:T4\n",
      "R8\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R10\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R11\tUSED-FOR Arg1:T7 Arg2:T10\n",
      "R12\tCOREF Arg1:T10 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-2015.ann\n",
      "T1\tMethod 23 45\tunsupervised technique\n",
      "T2\tTask 61 71\tmorphology\n",
      "T3\tOtherScientificTerm 89 93\thubs\n",
      "T4\tOtherScientificTerm 102 111\tautomaton\n",
      "T5\tOtherScientificTerm 136 139\thub\n",
      "T6\tOtherScientificTerm 147 151\tnode\n",
      "T7\tOtherScientificTerm 159 164\tgraph\n",
      "T8\tMethod 248 257\tword-trie\n",
      "T9\tGeneric 271 273\tit\n",
      "T10\tOtherScientificTerm 282 293\tminimal DFA\n",
      "T11\tOtherScientificTerm 312 316\thubs\n",
      "T12\tOtherScientificTerm 327 331\thubs\n",
      "T13\tOtherScientificTerm 360 364\troot\n",
      "T14\tOtherScientificTerm 371 377\tsuffix\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T5 Arg2:T3\n",
      "R4\tHYPONYM-OF Arg1:T5 Arg2:T6\n",
      "R5\tPART-OF Arg1:T6 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T11 Arg2:T5\n",
      "R9\tCOREF Arg1:T12 Arg2:T11\n",
      "R10\tPART-OF Arg1:T3 Arg2:T4\n",
      "R11\tCOREF Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-2017.ann\n",
      "T1\tOtherScientificTerm 15 38\tsyntax-based constraint\n",
      "T2\tTask 45 59\tword alignment\n",
      "T3\tOtherScientificTerm 77 96\tcohesion constraint\n",
      "T4\tGeneric 100 102\tIt\n",
      "T5\tMaterial 122 137\tEnglish phrases\n",
      "T6\tMaterial 189 204\tFrench sentence\n",
      "T7\tGeneric 241 251\tconstraint\n",
      "T8\tGeneric 270 280\talgorithms\n",
      "T9\tGeneric 304 306\tit\n",
      "T10\tMetric 349 366\talignment quality\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T4 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R5\tCOREF Arg1:T7 Arg2:T4\n",
      "R6\tCOREF Arg1:T9 Arg2:T7\n",
      "R7\tEVALUATE-FOR Arg1:T8 Arg2:T7\n",
      "R8\tEVALUATE-FOR Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-2025.ann\n",
      "T1\tMethod 10 32\tbootstrapping approach\n",
      "T2\tTask 38 63\tNamed Entity (NE) tagging\n",
      "T3\tOtherScientificTerm 72 91\tconcept-based seeds\n",
      "T4\tMethod 98 117\tsuccessive learners\n",
      "T5\tGeneric 138 146\tapproach\n",
      "T6\tOtherScientificTerm 253 255\tNE\n",
      "T7\tOtherScientificTerm 286 295\tPERSON NE\n",
      "T8\tMethod 304 327\tbootstrapping procedure\n",
      "T9\tMethod 361 380\tsuccessive learners\n",
      "T10\tOtherScientificTerm 392 405\tdecision list\n",
      "T11\tOtherScientificTerm 429 451\tparsing-based NE rules\n",
      "T12\tMethod 464 483\tHidden Markov Model\n",
      "T13\tGeneric 545 552\tlearner\n",
      "T14\tMethod 571 580\tNE system\n",
      "T15\tTask 594 607\tsupervised NE\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R5\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R6\tCOREF Arg1:T5 Arg2:T1\n",
      "R7\tHYPONYM-OF Arg1:T7 Arg2:T6\n",
      "R8\tCOREF Arg1:T8 Arg2:T5\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R11\tHYPONYM-OF Arg1:T13 Arg2:T9\n",
      "R12\tCOREF Arg1:T9 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-2036.ann\n",
      "T1\tMethod 31 57\tphrase-based unigram model\n",
      "T2\tTask 64 95\tstatistical machine translation\n",
      "T3\tOtherScientificTerm 130 146\tmodel parameters\n",
      "T4\tMethod 162 181\tphrase-based models\n",
      "T5\tOtherScientificTerm 217 223\tblocks\n",
      "T6\tTask 256 264\tdecoding\n",
      "T7\tMethod 278 297\tblock unigram model\n",
      "T8\tMethod 306 339\tword-based trigram language model\n",
      "T9\tTask 351 359\ttraining\n",
      "T10\tOtherScientificTerm 368 374\tblocks\n",
      "T11\tMethod 394 421\tsource interval projections\n",
      "T12\tMethod 444 458\tword alignment\n",
      "T13\tMetric 495 519\tblock selection criteria\n",
      "T14\tOtherScientificTerm 531 546\tunigram  counts\n",
      "T15\tOtherScientificTerm 552 566\tphrase  length\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tCOMPARE Arg1:T1 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R7\tCONJUNCTION Arg1:T8 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R9\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R11\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R12\tCOREF Arg1:T10 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-3010.ann\n",
      "T1\tMethod 36 53\tCooperative Model\n",
      "T2\tTask 60 90\tnatural language understanding\n",
      "T3\tTask 98 113\tdialogue system\n",
      "T4\tGeneric 126 130\tthis\n",
      "T5\tMethod 146 170\tFinite State Model (FSM)\n",
      "T6\tMethod 177 209\tStatistical Learning Model (SLM)\n",
      "T7\tMethod 214 217\tFSM\n",
      "T8\tTask 248 270\tlanguage understanding\n",
      "T9\tMethod 337 357\tStatistical approach\n",
      "T10\tMethod 399 416\tCooperative Model\n",
      "R1\tCOREF Arg1:T4 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R4\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R5\tCOREF Arg1:T7 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tCOREF Arg1:T9 Arg2:T6\n",
      "R8\tCOREF Arg1:T10 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R10\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-4004.ann\n",
      "T1\tTask 8 44\tTAP-XL Automated Analyst's Assistant\n",
      "T2\tMaterial 183 212\tmultilingual, multimedia data\n",
      "T3\tGeneric 216 218\tIt\n",
      "T4\tMethod 377 402\thuman language technology\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-4010.ann\n",
      "T1\tMethod 6 20\tJAVELIN system\n",
      "T2\tMethod 46 73\tplanning-based architecture\n",
      "T3\tMethod 94 121\tlanguage processing modules\n",
      "T4\tTask 138 179\topen-domain question answering capability\n",
      "T5\tMethod 235 242\tJAVELIN\n",
      "T6\tGeneric 368 374\tsystem\n",
      "T7\tGeneric 469 475\tsystem\n",
      "T8\tTask 489 507\tquestion answering\n",
      "R1\tPART-OF Arg1:T2 Arg2:T1\n",
      "R2\tPART-OF Arg1:T3 Arg2:T1\n",
      "R3\tCONJUNCTION Arg1:T3 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R5\tCOREF Arg1:T5 Arg2:T1\n",
      "R6\tCOREF Arg1:T6 Arg2:T5\n",
      "R7\tCOREF Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N04-1008.ann\n",
      "T1\tMethod 43 68\tQuestion Answering system\n",
      "T2\tMaterial 129 159\tFAQ-like questions and answers\n",
      "T3\tGeneric 177 183\tsystem\n",
      "T4\tMethod 194 220\tnoisy-channel architecture\n",
      "T5\tMethod 245 259\tlanguage model\n",
      "T6\tMethod 282 302\ttransformation model\n",
      "T7\tMaterial 411 414\tWeb\n",
      "R1\tCOREF Arg1:T3 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N04-1022.ann\n",
      "T1\tMethod 13 46\tMinimum Bayes-Risk (MBR) decoding\n",
      "T2\tTask 53 84\tstatistical machine translation\n",
      "T3\tMethod 92 112\tstatistical approach\n",
      "T4\tOtherScientificTerm 131 144\texpected loss\n",
      "T5\tOtherScientificTerm 150 168\ttranslation errors\n",
      "T6\tOtherScientificTerm 177 191\tloss functions\n",
      "T7\tTask 207 218\ttranslation\n",
      "T8\tOtherScientificTerm 261 275\tloss functions\n",
      "T9\tOtherScientificTerm 315 337\tlinguistic information\n",
      "T10\tOtherScientificTerm 361 384\tword-to-word alignments\n",
      "T11\tMethod 395 404\tMT system\n",
      "T12\tOtherScientificTerm 412 431\tsyntactic structure\n",
      "T13\tOtherScientificTerm 439 450\tparse-trees\n",
      "T14\tMethod 531 543\tMBR decoders\n",
      "T15\tTask 551 586\tChinese-to-English translation task\n",
      "T16\tMethod 612 624\tMBR decoding\n",
      "T17\tMethod 647 661\tstatistical MT\n",
      "T18\tOtherScientificTerm 689 703\tloss functions\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R3\tPART-OF Arg1:T10 Arg2:T11\n",
      "R4\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T8\n",
      "R6\tPART-OF Arg1:T13 Arg2:T12\n",
      "R7\tCOREF Arg1:T14 Arg2:T1\n",
      "R8\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R9\tCOREF Arg1:T16 Arg2:T14\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T18\n",
      "R11\tEVALUATE-FOR Arg1:T6 Arg2:T7\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R13\tCOREF Arg1:T3 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N04-1024.ann\n",
      "T1\tTask 2 45\tCriterionSM Online Essay Evaluation Service\n",
      "T2\tOtherScientificTerm 120 150\tessay-based discourse elements\n",
      "T3\tOtherScientificTerm 160 177\tthesis statements\n",
      "T4\tGeneric 200 206\tsystem\n",
      "T5\tOtherScientificTerm 222 246\tCriterion  's capability\n",
      "T6\tMetric 283 304\tcoherence  in  essays\n",
      "T7\tGeneric 313 319\tsystem\n",
      "T8\tOtherScientificTerm 332 340\tfeatures\n",
      "T9\tMetric 367 395\tsemantic similarity measures\n",
      "T10\tOtherScientificTerm 402 421\tdiscourse structure\n",
      "T11\tMethod 428 450\tsupport vector machine\n",
      "T12\tOtherScientificTerm 464 472\tfeatures\n",
      "T13\tOtherScientificTerm 486 509\tbreakdowns in coherence\n",
      "T14\tOtherScientificTerm 579 597\tdiscourse elements\n",
      "T15\tMetric 602 626\tIntra-sentential quality\n",
      "T16\tMethod 647 668\trule-based heuristics\n",
      "T17\tGeneric 698 704\tsystem\n",
      "T18\tGeneric 739 747\tbaseline\n",
      "R1\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R2\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "R3\tPART-OF Arg1:T2 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tCOREF Arg1:T7 Arg2:T4\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tCONJUNCTION Arg1:T10 Arg2:T9\n",
      "R8\tCOREF Arg1:T17 Arg2:T7\n",
      "R9\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R10\tCOMPARE Arg1:T17 Arg2:T18\n",
      "R11\tCOREF Arg1:T12 Arg2:T8\n",
      "R12\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R13\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R14\tEVALUATE-FOR Arg1:T6 Arg2:T4\n",
      "R15\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N04-2005.ann\n",
      "T1\tTask 6 81\ttranslation  of  English text  into  American Sign Language (ASL) animation\n",
      "T2\tMethod 116 140\tMT architectural designs\n",
      "T3\tMethod 150 173\tsemantic representation\n",
      "T4\tMethod 198 240\tvirtual reality 3D scene modeling software\n",
      "T5\tOtherScientificTerm 254 285\tspatially complex ASL phenomena\n",
      "T6\tOtherScientificTerm 296 317\tclassifier predicates\n",
      "T7\tGeneric 325 330\tmodel\n",
      "T8\tOtherScientificTerm 343 354\tinterlingua\n",
      "T9\tMethod 370 406\tmulti-pathway MT architecture design\n",
      "T10\tOtherScientificTerm 432 440\ttransfer\n",
      "T11\tGeneric 447 464\tdirect approaches\n",
      "T12\tGeneric 480 486\tsystem\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R3\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R4\tPART-OF Arg1:T10 Arg2:T12\n",
      "R5\tPART-OF Arg1:T11 Arg2:T12\n",
      "R6\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R7\tCOREF Arg1:T12 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N04-4028.ann\n",
      "T1\tMethod 2 35\tInformation extraction techniques\n",
      "T2\tMaterial 59 79\tstructured databases\n",
      "T3\tMaterial 87 112\tunstructured data sources\n",
      "T4\tMaterial 127 130\tWeb\n",
      "T5\tMaterial 135 153\tnewswire documents\n",
      "T6\tGeneric 187 194\tsystems\n",
      "T7\tMetric 197 205\taccuracy\n",
      "T8\tGeneric 318 324\tsystem\n",
      "T9\tMethod 380 409\tinformation extraction system\n",
      "T10\tMethod 438 481\tlinear-chain conditional random field (CRF)\n",
      "T11\tMethod 487 506\tprobabilistic model\n",
      "T12\tTask 537 565\tinformation extraction tasks\n",
      "T13\tOtherScientificTerm 601 633\tarbitrary, overlapping  features\n",
      "T14\tGeneric 643 648\tinput\n",
      "T15\tMethod 656 668\tMarkov model\n",
      "T16\tGeneric 692 702\ttechniques\n",
      "T17\tGeneric 741 757\textracted fields\n",
      "T18\tMaterial 771 790\tmulti-field records\n",
      "T19\tMetric 807 824\taverage precision\n",
      "T20\tMaterial 877 896\tmulti-field records\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R5\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R6\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R7\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R8\tCOREF Arg1:T8 Arg2:T1\n",
      "R9\tCOREF Arg1:T6 Arg2:T1\n",
      "R10\tHYPONYM-OF Arg1:T10 Arg2:T11\n",
      "R11\tEVALUATE-FOR Arg1:T19 Arg2:T16\n",
      "R12\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R13\tCOREF Arg1:T20 Arg2:T18\n",
      "R14\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R15\tCOREF Arg1:T9 Arg2:T8\n",
      "R16\tFEATURE-OF Arg1:T13 Arg2:T14\n",
      "R17\tPART-OF Arg1:T13 Arg2:T15\n",
      "R18\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N06-1007.ann\n",
      "T1\tTask 37 84\tautomatic acquisition  of  entailment relations\n",
      "T2\tGeneric 114 118\ttask\n",
      "T3\tTask 144 167\tparaphrases acquisition\n",
      "T4\tOtherScientificTerm 193 213\tsemantic equivalence\n",
      "T5\tTask 255 277\tentailment acquisition\n",
      "T6\tOtherScientificTerm 294 331\tasymmetric, or directional, relations\n",
      "T7\tOtherScientificTerm 390 424\tlocal structure  of  coherent text\n",
      "T8\tGeneric 440 446\tmethod\n",
      "T9\tTask 463 478\tverb entailment\n",
      "T10\tOtherScientificTerm 502 521\tdiscourse relations\n",
      "T11\tMaterial 557 570\tparsed corpus\n",
      "T12\tGeneric 619 625\tmethod\n",
      "T13\tOtherScientificTerm 656 677\tverb entailment types\n",
      "T14\tTask 695 718\tmapping  between  verbs\n",
      "T15\tOtherScientificTerm 725 759\thighly varied  argument structures\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R2\tCOMPARE Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R6\tCOREF Arg1:T12 Arg2:T8\n",
      "R7\tCOREF Arg1:T2 Arg2:T1\n",
      "R8\tCOREF Arg1:T5 Arg2:T2\n",
      "R9\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R11\tFEATURE-OF Arg1:T15 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N06-1018.ann\n",
      "T1\tOtherScientificTerm 68 88\ttemporal information\n",
      "T2\tTask 93 122\tnatural language applications\n",
      "T3\tOtherScientificTerm 222 242\ttemporal expressions\n",
      "T4\tOtherScientificTerm 222 262\ttemporal expressions  in  newswire texts\n",
      "T5\tMaterial 248 262\tnewswire texts\n",
      "T6\tOtherScientificTerm 312 332\ttemporal expressions\n",
      "T7\tMaterial 354 360\temails\n",
      "T8\tGeneric 406 417\texpressions\n",
      "T9\tOtherScientificTerm 439 479\tconstraint-based representation  of time\n",
      "T10\tOtherScientificTerm 482 523\tTime Calculus for Natural Language (TCNL)\n",
      "T11\tMethod 561 595\tTemporal Expression Anchoror (TEA)\n",
      "T12\tGeneric 624 626\tit\n",
      "T13\tGeneric 667 675\tbaseline\n",
      "R1\tCOREF Arg1:T8 Arg2:T6\n",
      "R2\tHYPONYM-OF Arg1:T10 Arg2:T9\n",
      "R3\tCOREF Arg1:T11 Arg2:T12\n",
      "R4\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R5\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R6\tFEATURE-OF Arg1:T5 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N06-1037.ann\n",
      "T1\tMethod 31 68\tconvolution kernel  over  parse trees\n",
      "T2\tOtherScientificTerm 80 111\tsyntactic structure information\n",
      "T3\tTask 118 137\trelation extraction\n",
      "T4\tOtherScientificTerm 168 196\tsyntactic structure features\n",
      "T5\tOtherScientificTerm 213 223\tparse tree\n",
      "T6\tTask 249 268\trelation extraction\n",
      "T7\tGeneric 280 288\tfeatures\n",
      "T8\tMethod 318 341\tconvolution tree kernel\n",
      "T9\tMaterial 363 378\tACE 2003 corpus\n",
      "T10\tMethod 396 433\tconvolution kernel  over  parse trees\n",
      "T11\tMethod 502 523\tfeature-based methods\n",
      "T12\tGeneric 582 588\tmethod\n",
      "T13\tMethod 633 656\tdependency tree kernels\n",
      "R1\tFEATURE-OF Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R4\tCOREF Arg1:T7 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R6\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R8\tCOREF Arg1:T1 Arg2:T8\n",
      "R9\tEVALUATE-FOR Arg1:T9 Arg2:T10\n",
      "R10\tCOREF Arg1:T12 Arg2:T10\n",
      "R11\tCOREF Arg1:T10 Arg2:T8\n",
      "R12\tCOMPARE Arg1:T11 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N06-2009.ann\n",
      "T1\tMethod 21 52\tQuestion Answering (QA) systems\n",
      "T2\tMethod 249 280\tMT-based paraphrasing technique\n",
      "T3\tMethod 298 307\tQA system\n",
      "T4\tMaterial 325 346\tparaphrased questions\n",
      "T5\tMetric 391 394\tMRR\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tEVALUATE-FOR Arg1:T4 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N06-2038.ann\n",
      "T1\tGeneric 21 31\tapproaches\n",
      "T2\tTask 44 66\tinformation extraction\n",
      "T3\tTask 74 99\ttoken classification task\n",
      "T4\tMethod 118 136\ttagging strategies\n",
      "T5\tMethod 186 204\ttagging strategies\n",
      "T6\tGeneric 308 316\tstrategy\n",
      "T7\tMethod 326 345\tBegin/After tagging\n",
      "T8\tMethod 351 354\tBIA\n",
      "T9\tGeneric 372 374\tit\n",
      "T10\tGeneric 408 418\tstrategies\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T8 Arg2:T7\n",
      "R5\tCOREF Arg1:T7 Arg2:T6\n",
      "R6\tCOREF Arg1:T6 Arg2:T9\n",
      "R7\tCOMPARE Arg1:T9 Arg2:T10\n",
      "R8\tCOREF Arg1:T4 Arg2:T1\n",
      "R9\tCOREF Arg1:T5 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N06-4001.ann\n",
      "T1\tMethod 23 58\tinteractive corpus exploration tool\n",
      "T2\tMethod 68 79\tInfoMagnets\n",
      "T3\tMethod 84 95\tInfoMagnets\n",
      "T4\tTask 113 140\texploratory corpus analysis\n",
      "T5\tTask 192 203\ttext mining\n",
      "T6\tGeneric 252 254\tit\n",
      "T7\tGeneric 390 397\tdomains\n",
      "T8\tMaterial 400 417\ttutorial dialogue\n",
      "T9\tMaterial 449 468\ton-line communities\n",
      "T10\tMethod 502 518\teducational tool\n",
      "T11\tGeneric 522 524\tit\n",
      "T12\tTask 561 578\tprotocol analysis\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R3\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R4\tCOREF Arg1:T3 Arg2:T2\n",
      "R5\tCOREF Arg1:T6 Arg2:T3\n",
      "R6\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R7\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R8\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R9\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R10\tCOREF Arg1:T10 Arg2:T3\n",
      "R11\tCOREF Arg1:T10 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_1996_15_abs.ann\n",
      "T1\tOtherScientificTerm 19 41\tanalytical expressions\n",
      "T2\tMethod 110 157\ttemporal difference value estimation algorithms\n",
      "T3\tOtherScientificTerm 211 224\tMarkov chains\n",
      "T4\tMethod 231 259\tlookup table representations\n",
      "T5\tOtherScientificTerm 286 309\tlearning curve behavior\n",
      "T6\tOtherScientificTerm 395 437\tstep-size and eligibility trace parameters\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_1996_22_abs.ann\n",
      "T1\tOtherScientificTerm 13 36\tnumber of hidden layers\n",
      "T2\tMethod 51 77\tmultilayer neu-ral network\n",
      "T3\tOtherScientificTerm 83 98\tthreshold units\n",
      "T4\tOtherScientificTerm 223 235\thidden layer\n",
      "T5\tOtherScientificTerm 538 550\thidden layer\n",
      "T6\tOtherScientificTerm 642 662\tglobal computability\n",
      "T7\tOtherScientificTerm 672 684\thidden layer\n",
      "T8\tOtherScientificTerm 706 729\tnon-local configuration\n",
      "T9\tOtherScientificTerm 735 751\t\"critical cycle\"\n",
      "T10\tOtherScientificTerm 801 813\thidden layer\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_1998_18_abs.ann\n",
      "T1\tOtherScientificTerm 0 38\tVisually-guided arm reaching movements\n",
      "T2\tMethod 55 82\tdistributed neural networks\n",
      "T3\tOtherScientificTerm 331 361\tcoordinated action of neu-rons\n",
      "T4\tOtherScientificTerm 388 420\tneuronal population vector (NPV)\n",
      "T5\tOtherScientificTerm 436 439\tNPV\n",
      "T6\tOtherScientificTerm 577 588\tarm posture\n",
      "T7\tGeneric 615 620\tmodel\n",
      "T8\tOtherScientificTerm 628 650\tcortical motor command\n",
      "T9\tOtherScientificTerm 784 787\tNPV\n",
      "T10\tOtherScientificTerm 791 803\tmotor cortex\n",
      "T11\tGeneric 809 814\tmodel\n",
      "T12\tMethod 820 860\ttwo-layer self-organizing neural network\n",
      "T13\tOtherScientificTerm 876 915\tbroadly-tuned (muscular) proprioceptive\n",
      "T14\tOtherScientificTerm 920 950\t(cartesian) visual information\n",
      "T15\tOtherScientificTerm 964 988\t(angular) motor commands\n",
      "T16\tOtherScientificTerm 1031 1043\ttwo-link arm\n",
      "T17\tGeneric 1049 1056\tnetwork\n",
      "T18\tGeneric 1135 1142\tnetwork\n",
      "T19\tOtherScientificTerm 1403 1406\tNPV\n",
      "T20\tOtherScientificTerm 1457 1460\tNPV\n",
      "T21\tOtherScientificTerm 1486 1514\timage of cortical processing\n",
      "T22\tOtherScientificTerm 1522 1544\tarm reaching movements\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R3\tCOREF Arg1:T5 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tCOREF Arg1:T9 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R7\tCOREF Arg1:T11 Arg2:T7\n",
      "R8\tCOREF Arg1:T12 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T12 Arg2:T15\n",
      "R12\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R13\tCOREF Arg1:T17 Arg2:T12\n",
      "R14\tCOREF Arg1:T18 Arg2:T17\n",
      "R15\tCOREF Arg1:T19 Arg2:T9\n",
      "R16\tCOREF Arg1:T20 Arg2:T19\n",
      "R17\tFEATURE-OF Arg1:T22 Arg2:T21\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2001_10_abs.ann\n",
      "T1\tGeneric 26 34\tapproach\n",
      "T2\tTask 49 63\tfast detection\n",
      "T3\tOtherScientificTerm 85 97\tdistribution\n",
      "T4\tMaterial 101 131\tpositive and negative examples\n",
      "T5\tTask 155 169\tface detection\n",
      "T6\tTask 173 191\tdatabase retrieval\n",
      "T7\tMethod 212 241\tcascade of simple classifiers\n",
      "T8\tMethod 230 241\tclassifiers\n",
      "T9\tMetric 271 286\tdetection rates\n",
      "T10\tMetric 291 318\tmodest false positive rates\n",
      "T11\tGeneric 337 345\tdetector\n",
      "T12\tOtherScientificTerm 366 374\tfeatures\n",
      "T13\tMetric 391 406\tdetection rates\n",
      "T14\tMetric 417 437\tfalse positive rates\n",
      "T15\tMetric 443 459\tfast performance\n",
      "T16\tMetric 486 501\tdetection rates\n",
      "T17\tMetric 515 524\tlow error\n",
      "T18\tMethod 563 590\tmachine learning algorithms\n",
      "T19\tMethod 620 628\tAdaBoost\n",
      "T20\tOtherScientificTerm 668 679\tclassifiers\n",
      "T21\tGeneric 692 699\tcascade\n",
      "T22\tTask 739 753\tface detection\n",
      "T23\tMethod 763 781\ttraining algorithm\n",
      "T24\tMethod 847 855\tAdaBoost\n",
      "T25\tMethod 867 888\tface detection system\n",
      "T26\tMetric 941 950\tdetection\n",
      "T27\tMetric 958 977\tfalse positive rate\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R3\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R4\tFEATURE-OF Arg1:T12 Arg2:T11\n",
      "R5\tCOREF Arg1:T13 Arg2:T9\n",
      "R6\tCOREF Arg1:T16 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R8\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R9\tCOMPARE Arg1:T24 Arg2:T23\n",
      "R10\tUSED-FOR Arg1:T23 Arg2:T22\n",
      "R11\tUSED-FOR Arg1:T24 Arg2:T22\n",
      "R12\tEVALUATE-FOR Arg1:T9 Arg2:T8\n",
      "R13\tEVALUATE-FOR Arg1:T10 Arg2:T8\n",
      "R14\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R15\tUSED-FOR Arg1:T7 Arg2:T11\n",
      "R16\tCOREF Arg1:T21 Arg2:T7\n",
      "R17\tCOREF Arg1:T20 Arg2:T8\n",
      "R18\tCOREF Arg1:T22 Arg2:T5\n",
      "R19\tCOREF Arg1:T25 Arg2:T1\n",
      "R20\tCONJUNCTION Arg1:T26 Arg2:T27\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2001_11_abs.ann\n",
      "T1\tMethod 2 23\tmixed-signal paradigm\n",
      "T2\tTask 41 91\thigh-resolution parallel inner-product computation\n",
      "T3\tMethod 158 165\tkernels\n",
      "T4\tTask 169 185\timage processing\n",
      "T5\tMethod 206 237\texternally digital architecture\n",
      "T6\tOtherScientificTerm 243 279\thigh-density, low-power analog array\n",
      "T7\tMethod 291 341\tbinary-binary partial matrix-vector multiplication\n",
      "T8\tMetric 343 366\tFull digital resolution\n",
      "T9\tMethod 391 434\tlow-resolution analog-to-digital conversion\n",
      "T10\tOtherScientificTerm 445 462\trandom statistics\n",
      "T11\tOtherScientificTerm 470 505\tanalog summation of binary products\n",
      "T12\tMethod 509 533\trandom modulation scheme\n",
      "T13\tOtherScientificTerm 543 568\tnear-Bernoulli statistics\n",
      "T14\tMaterial 578 602\thighly correlated inputs\n",
      "T15\tGeneric 608 616\tapproach\n",
      "T16\tMaterial 635 650\treal image data\n",
      "T17\tOtherScientificTerm 689 720\tCID/DRAM analog array prototype\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tPART-OF Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R6\tPART-OF Arg1:T10 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R9\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "R10\tCOREF Arg1:T1 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2001_18_abs.ann\n",
      "T1\tMethod 0 15\tFactor analysis\n",
      "T2\tMethod 20 49\tprincipal components analysis\n",
      "T3\tOtherScientificTerm 71 118\tlinear relationships between observed variables\n",
      "T4\tMaterial 136 157\thigh-dimensional data\n",
      "T5\tOtherScientificTerm 163 193\tlower-dimensional hidden space\n",
      "T6\tMethod 198 213\tfactor analysis\n",
      "T7\tMethod 249 308\tlinear combination of normally distributed hidden variables\n",
      "T8\tMethod 324 367\tnonlinear generalization of factor analysis\n",
      "T9\tMethod 352 367\tfactor analysis\n",
      "T10\tMethod 377 396\t\"product analy-sis\"\n",
      "T11\tOtherScientificTerm 414 432\tobserved variables\n",
      "T12\tOtherScientificTerm 438 509\tlinear combination of products of normally distributed hidden variables\n",
      "T13\tMethod 519 534\tfactor analysis\n",
      "T14\tMethod 552 582\tunsupervised linear regression\n",
      "T15\tOtherScientificTerm 607 635\tdistributed hidden variables\n",
      "T16\tMethod 637 653\tproduct analysis\n",
      "T17\tMethod 671 701\tunsupervised linear regression\n",
      "T18\tOtherScientificTerm 738 766\tdistributed hidden variables\n",
      "T19\tOtherScientificTerm 805 817\thidden space\n",
      "T20\tMethod 845 878\tapproximate variational technique\n",
      "T21\tTask 883 892\tinference\n",
      "T22\tTask 897 905\tlearning\n",
      "T23\tMethod 913 929\tproduct analysis\n",
      "T24\tMethod 935 968\tgeneralization of factor analysis\n",
      "T25\tMethod 953 968\tfactor analysis\n",
      "T26\tMethod 970 986\tproduct analysis\n",
      "T27\tMethod 1030 1045\tfactor analysis\n",
      "T28\tTask 1066 1085\tpattern recognition\n",
      "T29\tTask 1090 1129\tillumination-invariant image clustering\n",
      "R1\tCOREF Arg1:T6 Arg2:T1\n",
      "R2\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R5\tCOREF Arg1:T9 Arg2:T6\n",
      "R6\tHYPONYM-OF Arg1:T10 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T8\n",
      "R9\tCOREF Arg1:T13 Arg2:T6\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R11\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R12\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R13\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "R14\tUSED-FOR Arg1:T20 Arg2:T22\n",
      "R15\tCOREF Arg1:T23 Arg2:T16\n",
      "R16\tCOREF Arg1:T16 Arg2:T10\n",
      "R17\tCOREF Arg1:T26 Arg2:T23\n",
      "R18\tHYPONYM-OF Arg1:T23 Arg2:T24\n",
      "R19\tCOREF Arg1:T25 Arg2:T27\n",
      "R20\tCOMPARE Arg1:T26 Arg2:T27\n",
      "R21\tCOREF Arg1:T25 Arg2:T13\n",
      "R22\tCONJUNCTION Arg1:T28 Arg2:T29\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2001_21_abs.ann\n",
      "T1\tTask 25 48\tblind source separation\n",
      "T2\tOtherScientificTerm 63 92\tinstantaneous linear mixtures\n",
      "T3\tOtherScientificTerm 104 117\tmixing matrix\n",
      "T4\tOtherScientificTerm 178 197\tsparsity of sources\n",
      "T5\tOtherScientificTerm 249 266\tsignal dictionary\n",
      "T6\tMetric 294 315\tquality of separation\n",
      "T7\tOtherScientificTerm 353 375\tmulti scale transforms\n",
      "T8\tOtherScientificTerm 385 411\twavelet or wavelet packets\n",
      "T9\tOtherScientificTerm 447 461\tlocal features\n",
      "T10\tOtherScientificTerm 486 494\tsparsity\n",
      "T11\tOtherScientificTerm 575 583\tfeatures\n",
      "T12\tGeneric 631 640\talgorithm\n",
      "T13\tMaterial 656 681\tnoise-free and noisy data\n",
      "T14\tMaterial 700 717\tsimulated signals\n",
      "T15\tMaterial 719 733\tmusical sounds\n",
      "T16\tMaterial 738 744\timages\n",
      "T17\tMetric 784 802\tseparation quality\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tEVALUATE-FOR Arg1:T6 Arg2:T4\n",
      "R4\tEVALUATE-FOR Arg1:T13 Arg2:T12\n",
      "R5\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R6\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R7\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R8\tEVALUATE-FOR Arg1:T16 Arg2:T17\n",
      "R9\tEVALUATE-FOR Arg1:T15 Arg2:T17\n",
      "R10\tEVALUATE-FOR Arg1:T14 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2002_10_abs.ann\n",
      "T1\tTask 0 20\tIdentity uncertainty\n",
      "T2\tTask 47 71\treal-world data analysis\n",
      "T3\tGeneric 128 139\tidentifiers\n",
      "T4\tGeneric 154 165\tidentifiers\n",
      "T5\tGeneric 307 314\tproblem\n",
      "T6\tTask 333 350\tcitation matching\n",
      "T7\tOtherScientificTerm 381 390\tcitations\n",
      "T8\tOtherScientificTerm 414 425\tpublication\n",
      "T9\tGeneric 431 439\tapproach\n",
      "T10\tMethod 465 493\trelational probability model\n",
      "T11\tMethod 506 522\tgenerative model\n",
      "T12\tGeneric 531 537\tdomain\n",
      "T13\tMethod 549 586\tmodels of author and title corruption\n",
      "T14\tMethod 593 623\tprobabilistic citation grammar\n",
      "T15\tTask 625 645\tIdentity uncertainty\n",
      "T16\tGeneric 679 685\tmodels\n",
      "T17\tOtherScientificTerm 733 741\tmappings\n",
      "T18\tOtherScientificTerm 791 797\tdomain\n",
      "T19\tTask 799 808\tInference\n",
      "T20\tMethod 821 845\tMarkov chain Monte Carlo\n",
      "T21\tGeneric 871 878\tmethods\n",
      "T22\tMaterial 972 990\tcitation data sets\n",
      "T23\tGeneric 1005 1011\tmethod\n",
      "T24\tMethod 1024 1042\tcurrent algorithms\n",
      "T25\tTask 1047 1064\tcitation matching\n",
      "T26\tGeneric 1108 1113\tmodel\n",
      "T27\tGeneric 1134 1143\talgorithm\n",
      "T28\tOtherScientificTerm 1158 1180\tobject characteristics\n",
      "T29\tOtherScientificTerm 1189 1201\tauthor names\n",
      "T30\tOtherScientificTerm 1224 1233\tcitations\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R3\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R4\tCOMPARE Arg1:T23 Arg2:T24\n",
      "R5\tUSED-FOR Arg1:T23 Arg2:T25\n",
      "R6\tUSED-FOR Arg1:T24 Arg2:T25\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R8\tPART-OF Arg1:T13 Arg2:T10\n",
      "R9\tPART-OF Arg1:T14 Arg2:T10\n",
      "R10\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R11\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R12\tCOREF Arg1:T12 Arg2:T6\n",
      "R13\tCOREF Arg1:T5 Arg2:T1\n",
      "R14\tCOREF Arg1:T4 Arg2:T3\n",
      "R15\tCOREF Arg1:T15 Arg2:T1\n",
      "R16\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R17\tEVALUATE-FOR Arg1:T22 Arg2:T23\n",
      "R18\tCOREF Arg1:T25 Arg2:T6\n",
      "R19\tCOREF Arg1:T23 Arg2:T9\n",
      "R20\tCOREF Arg1:T26 Arg2:T23\n",
      "R21\tCOREF Arg1:T27 Arg2:T26\n",
      "R22\tHYPONYM-OF Arg1:T29 Arg2:T28\n",
      "R23\tUSED-FOR Arg1:T27 Arg2:T28\n",
      "R24\tUSED-FOR Arg1:T21 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2002_11_abs.ann\n",
      "T1\tTask 22 32\tclustering\n",
      "T2\tMethod 124 141\tunified framework\n",
      "T3\tTask 146 155\treasoning\n",
      "T4\tMethod 342 353\tunification\n",
      "T5\tMethod 373 394\timpossibility theorem\n",
      "T6\tOtherScientificTerm 459 478\tclustering function\n",
      "T7\tMethod 604 638\twell-studied clustering techniques\n",
      "T8\tMethod 647 661\tsingle-linkage\n",
      "T9\tMethod 663 675\tsum-of-pairs\n",
      "T10\tMethod 677 684\tk-means\n",
      "T11\tMethod 690 698\tk-median\n",
      "R1\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R2\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R3\tHYPONYM-OF Arg1:T10 Arg2:T7\n",
      "R4\tHYPONYM-OF Arg1:T11 Arg2:T7\n",
      "R5\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R6\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R7\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R9\tCOREF Arg1:T2 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2002_18_abs.ann\n",
      "T1\tMethod 2 20\tbio-inspired model\n",
      "T2\tTask 28 70\tanalog programmable array processor (APAP)\n",
      "T3\tOtherScientificTerm 96 113\tvertebrate retina\n",
      "T4\tOtherScientificTerm 148 193\tcomplex programmable spatio-temporal dynamics\n",
      "T5\tTask 197 201\tVLSI\n",
      "T6\tGeneric 208 213\tmodel\n",
      "T7\tMaterial 238 244\timages\n",
      "T8\tMethod 266 280\tvisual pathway\n",
      "T9\tTask 347 366\tvision applications\n",
      "T10\tOtherScientificTerm 395 409\tprototype chip\n",
      "T11\tOtherScientificTerm 463 475\tCMOS process\n",
      "T12\tMetric 477 501\tComputing power per area\n",
      "T13\tMetric 506 523\tpower consumption\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tFEATURE-OF Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R5\tCOREF Arg1:T6 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R7\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2003_10_abs.ann\n",
      "T1\tTask 25 46\tvisual classification\n",
      "T2\tMethod 68 115\tpsy-chophysical and machine learning techniques\n",
      "T3\tOtherScientificTerm 117 145\tFrontal views of human faces\n",
      "T4\tTask 162 188\tgender classification task\n",
      "T5\tOtherScientificTerm 236 251\tgender judgment\n",
      "T6\tOtherScientificTerm 253 266\treaction time\n",
      "T7\tOtherScientificTerm 271 288\tconfidence rating\n",
      "T8\tMethod 312 342\thyperplane learning algorithms\n",
      "T9\tTask 365 384\tclassification task\n",
      "T10\tOtherScientificTerm 395 430\tPrincipal Components of the texture\n",
      "T11\tMethod 435 472\tflowfield representation of the faces\n",
      "T12\tTask 478 492\tclassification\n",
      "T13\tMethod 512 531\tlearning algorithms\n",
      "T14\tTask 556 569\tface database\n",
      "T15\tOtherScientificTerm 755 792\thyperplane of the learning algorithms\n",
      "T16\tMethod 773 792\tlearning algorithms\n",
      "T17\tTask 819 839\thuman classification\n",
      "T18\tMethod 863 884\thyperplane algorithms\n",
      "T19\tOtherScientificTerm 892 905\tfeature space\n",
      "T20\tTask 919 933\tclassification\n",
      "T21\tOtherScientificTerm 994 1004\thyperplane\n",
      "T22\tGeneric 1014 1019\tthose\n",
      "R1\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R2\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R7\tCONJUNCTION Arg1:T11 Arg2:T10\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T8\n",
      "R9\tCOREF Arg1:T12 Arg2:T9\n",
      "R10\tCOREF Arg1:T9 Arg2:T1\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R12\tCOREF Arg1:T16 Arg2:T13\n",
      "R13\tCOREF Arg1:T13 Arg2:T8\n",
      "R14\tCOREF Arg1:T20 Arg2:T17\n",
      "R15\tCOREF Arg1:T21 Arg2:T15\n",
      "R16\tFEATURE-OF Arg1:T19 Arg2:T18\n",
      "R17\tCOMPARE Arg1:T21 Arg2:T22\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2003_18_abs.ann\n",
      "T1\tGeneric 23 32\talgorithm\n",
      "T2\tTask 37 93\tlearning the time-varying shape of a non-rigid 3D object\n",
      "T3\tMaterial 99 128\tuncalibrated 2D tracking data\n",
      "T4\tOtherScientificTerm 139 151\tshape motion\n",
      "T5\tMethod 157 172\trigid component\n",
      "T6\tOtherScientificTerm 174 182\trotation\n",
      "T7\tOtherScientificTerm 187 198\ttranslation\n",
      "T8\tOtherScientificTerm 216 237\tnon-rigid deformation\n",
      "T9\tOtherScientificTerm 239 253\tReconstruction\n",
      "T10\tOtherScientificTerm 270 292\tarbitrary deformations\n",
      "T11\tOtherScientificTerm 352 364\tobject shape\n",
      "T12\tMethod 402 423\tGaussian distribution\n",
      "T13\tGeneric 455 464\talgorithm\n",
      "T14\tOtherScientificTerm 490 509\t3D shape and motion\n",
      "T15\tMethod 560 568\tGaussian\n",
      "T16\tGeneric 632 641\talgorithm\n",
      "T17\tOtherScientificTerm 651 686\ttemporal smoothness in object shape\n",
      "T18\tGeneric 702 704\tit\n",
      "T19\tMaterial 731 743\tmissing data\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R3\tCOREF Arg1:T13 Arg2:T1\n",
      "R4\tCOREF Arg1:T15 Arg2:T12\n",
      "R5\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R6\tCOREF Arg1:T16 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R8\tCOREF Arg1:T16 Arg2:T18\n",
      "R9\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2014_10_abs.ann\n",
      "T1\tMethod 13 60\treweighted version of the Kikuchi approximation\n",
      "T2\tMethod 39 60\tKikuchi approximation\n",
      "T3\tTask 80 128\tlog partition function of a product distribution\n",
      "T4\tOtherScientificTerm 144 156\tregion graph\n",
      "T5\tOtherScientificTerm 201 210\tconcavity\n",
      "T6\tOtherScientificTerm 218 247\treweighted objective function\n",
      "T7\tOtherScientificTerm 260 278\tweight assignments\n",
      "T8\tOtherScientificTerm 286 303\tKikuchi expansion\n",
      "T9\tMethod 321 368\treweighted version of the sum product algorithm\n",
      "T10\tOtherScientificTerm 384 404\tKikuchi region graph\n",
      "T11\tOtherScientificTerm 418 431\tglobal optima\n",
      "T12\tMethod 439 460\tKikuchi approximation\n",
      "T13\tGeneric 474 483\talgorithm\n",
      "T14\tOtherScientificTerm 504 516\tregion graph\n",
      "T15\tMethod 552 571\tBethe approximation\n",
      "T16\tOtherScientificTerm 616 625\tconcavity\n",
      "T17\tOtherScientificTerm 714 723\tconcavity\n",
      "T18\tOtherScientificTerm 740 755\tcycle structure\n",
      "T19\tOtherScientificTerm 763 775\tregion graph\n",
      "T20\tMethod 845 872\treweighted Kikuchi approach\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R4\tFEATURE-OF Arg1:T11 Arg2:T12\n",
      "R5\tCOREF Arg1:T12 Arg2:T2\n",
      "R6\tFEATURE-OF Arg1:T18 Arg2:T19\n",
      "R7\tCOREF Arg1:T1 Arg2:T20\n",
      "R8\tFEATURE-OF Arg1:T5 Arg2:T6\n",
      "R9\tCOREF Arg1:T9 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2014_18_abs.ann\n",
      "T1\tTask 15 77\tclassical decision-theoretic problem of weighted expert voting\n",
      "T2\tMethod 85 117\tstatistical learning perspective\n",
      "T3\tOtherScientificTerm 207 239\tNitzan-Paroush weighted majority\n",
      "T4\tOtherScientificTerm 280 304\texpert competence levels\n",
      "T5\tMethod 314 335\tsharp error estimates\n",
      "T6\tOtherScientificTerm 344 356\toptimal rule\n",
      "T7\tOtherScientificTerm 367 384\tcompetence levels\n",
      "T8\tMethod 461 478\tBayesian analyses\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2014_21_abs.ann\n",
      "T1\tTask 3 41\treal-world action recognition problems\n",
      "T2\tOtherScientificTerm 43 61\tlow-level features\n",
      "T3\tOtherScientificTerm 97 129\trich spatial-temporal structures\n",
      "T4\tMaterial 133 146\taction videos\n",
      "T5\tOtherScientificTerm 226 245\thigh-level concepts\n",
      "T6\tOtherScientificTerm 324 341\taction attributes\n",
      "T7\tOtherScientificTerm 355 372\taction attributes\n",
      "T8\tOtherScientificTerm 416 438\tdata-driven attributes\n",
      "T9\tMethod 474 501\tdictionary learning methods\n",
      "T10\tMethod 503 533\tAttribute-based representation\n",
      "T11\tOtherScientificTerm 567 597\tnoisy and redundant attributes\n",
      "T12\tMethod 612 669\tdiscriminative and compact attribute-based representation\n",
      "T13\tOtherScientificTerm 695 720\tdiscriminative attributes\n",
      "T14\tMetric 755 783\tattribute selection criteria\n",
      "T15\tTask 817 848\tsubmodular optimization problem\n",
      "T16\tMethod 852 881\tgreedy optimization algorithm\n",
      "T17\tMaterial 991 1025\tOlympic Sports and UCF101 datasets\n",
      "T18\tMethod 1056 1086\tattribute-based representation\n",
      "T19\tMethod 1130 1159\taction recognition algorithms\n",
      "T20\tMethod 1198 1220\trecognition approaches\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R3\tEVALUATE-FOR Arg1:T17 Arg2:T18\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R6\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R7\tCOMPARE Arg1:T19 Arg2:T20\n",
      "R8\tCOREF Arg1:T18 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2015_10_abs.ann\n",
      "T1\tMethod 23 54\tnon-uniform sampling strategies\n",
      "T2\tMethod 87 121\tstochastic optimization algorithms\n",
      "T3\tOtherScientificTerm 127 145\tlinear convergence\n",
      "T4\tMethod 156 199\tStochastic Variance Reduced Gradient (SVRG)\n",
      "T5\tMethod 204 244\tStochastic Dual Coordinate Ascent (SDCA)\n",
      "T6\tTask 268 314\tpenalized empirical risk minimization problems\n",
      "T7\tGeneric 321 328\tmethods\n",
      "T8\tOtherScientificTerm 337 368\tdata dependent local smoothness\n",
      "T9\tOtherScientificTerm 376 390\tloss functions\n",
      "T10\tOtherScientificTerm 400 407\toptimum\n",
      "T11\tOtherScientificTerm 427 449\tconvergence guarantees\n",
      "T12\tOtherScientificTerm 514 530\tlocal smoothness\n",
      "T13\tGeneric 659 665\ttheory\n",
      "T14\tGeneric 691 701\talgorithms\n",
      "T15\tOtherScientificTerm 713 729\tlocal smoothness\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R3\tHYPONYM-OF Arg1:T4 Arg2:T2\n",
      "R4\tHYPONYM-OF Arg1:T5 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tFEATURE-OF Arg1:T8 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R10\tCOREF Arg1:T7 Arg2:T1\n",
      "R11\tCOREF Arg1:T13 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2015_18_abs.ann\n",
      "T1\tTask 15 32\tmodeling problems\n",
      "T2\tMaterial 41 54\tdiscrete data\n",
      "T3\tMethod 95 135\tmultinomial or categorical distributions\n",
      "T4\tMaterial 150 179\tnucleotides in a DNA sequence\n",
      "T5\tMaterial 229 243\ttext documents\n",
      "T6\tMethod 274 299\tmultinomial distributions\n",
      "T7\tOtherScientificTerm 381 391\tnucleotide\n",
      "T8\tOtherScientificTerm 415 425\tDNA strand\n",
      "T9\tOtherScientificTerm 444 465\tpreceding nucleotides\n",
      "T10\tMethod 636 669\tDirichlet-multinomial formulation\n",
      "T11\tMethod 691 729\tlogistic stick-breaking representation\n",
      "T12\tTask 756 780\tPÃ³lya-gamma augmentation\n",
      "T13\tMethod 801 825\tmultinomial distribution\n",
      "T14\tOtherScientificTerm 838 854\tlatent variables\n",
      "T15\tOtherScientificTerm 860 888\tjointly Gaussian likelihoods\n",
      "T16\tMethod 933 962\tBayesian inference techniques\n",
      "T17\tMethod 967 982\tGaussian models\n",
      "T18\tOtherScientificTerm 988 1004\tminimal overhead\n",
      "R1\tHYPONYM-OF Arg1:T6 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R5\tFEATURE-OF Arg1:T18 Arg2:T17\n",
      "R6\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R8\tFEATURE-OF Arg1:T15 Arg2:T14\n",
      "R9\tPART-OF Arg1:T14 Arg2:T13\n",
      "R10\tCOREF Arg1:T13 Arg2:T6\n",
      "R11\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R12\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2015_21_abs.ann\n",
      "T1\tMethod 23 52\tconvolutional neural networks\n",
      "T2\tGeneric 91 95\tthey\n",
      "T3\tMethod 130 163\tStochastic attention-based models\n",
      "T4\tMetric 191 215\tcomputational efficiency\n",
      "T5\tGeneric 234 238\tthey\n",
      "T6\tTask 276 307\tintractable posterior inference\n",
      "T7\tTask 333 362\tstochastic gradient estimates\n",
      "T8\tMethod 364 384\tBorrowing techniques\n",
      "T9\tMethod 417 439\tdeep generative models\n",
      "T10\tMethod 456 492\tWake-Sleep Recurrent Attention Model\n",
      "T11\tGeneric 496 502\tmethod\n",
      "T12\tMethod 516 545\tstochastic attention networks\n",
      "T13\tTask 561 580\tposterior inference\n",
      "T14\tOtherScientificTerm 622 642\tstochastic gradients\n",
      "T15\tGeneric 661 667\tmethod\n",
      "T16\tMetric 693 706\ttraining time\n",
      "T17\tMethod 711 740\tstochastic attention networks\n",
      "T18\tTask 759 779\timage classification\n",
      "T19\tTask 784 802\tcaption generation\n",
      "R1\tEVALUATE-FOR Arg1:T4 Arg2:T3\n",
      "R2\tCOREF Arg1:T10 Arg2:T11\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R6\tCOREF Arg1:T10 Arg2:T15\n",
      "R7\tEVALUATE-FOR Arg1:T18 Arg2:T15\n",
      "R8\tEVALUATE-FOR Arg1:T19 Arg2:T15\n",
      "R9\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R10\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R11\tCOREF Arg1:T3 Arg2:T5\n",
      "R12\tCOREF Arg1:T1 Arg2:T2\n",
      "R13\tCOREF Arg1:T3 Arg2:T12\n",
      "R14\tCOREF Arg1:T17 Arg2:T12\n",
      "R15\tFEATURE-OF Arg1:T16 Arg2:T17\n",
      "R16\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2016_560_abs.ann\n",
      "T1\tTask 0 30\tJoint matrix triangularization\n",
      "T2\tOtherScientificTerm 64 84\tjoint eigenstructure\n",
      "T3\tTask 130 147\tsignal processing\n",
      "T4\tTask 152 168\tmachine learning\n",
      "T5\tTask 197 239\tapproximate joint matrix triangularization\n",
      "T6\tOtherScientificTerm 400 423\tfirst-order upper bound\n",
      "T7\tMethod 452 484\tapproximate joint triangularizer\n",
      "T8\tMethod 515 541\texact joint triangularizer\n",
      "T9\tGeneric 568 573\tbound\n",
      "T10\tMethod 718 732\ttriangularizer\n",
      "T11\tOtherScientificTerm 869 885\tposteriori bound\n",
      "T12\tTask 890 916\tjoint matrix decomposition\n",
      "T13\tMaterial 946 960\tsynthetic data\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "R5\tHYPONYM-OF Arg1:T5 Arg2:T1\n",
      "R6\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R7\tCOREF Arg1:T9 Arg2:T6\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2016_80_abs.ann\n",
      "T1\tGeneric 0 15\tFast algorithms\n",
      "T2\tTask 20 48\tnearest neighbor (NN) search\n",
      "T3\tOtherScientificTerm 81 89\tdistance\n",
      "T4\tGeneric 110 118\tapproach\n",
      "T5\tOtherScientificTerm 123 133\t1 distance\n",
      "T6\tOtherScientificTerm 175 204\tdistance-preserving embedding\n",
      "T7\tGeneric 241 245\tthis\n",
      "T8\tMethod 279 310\trandom-projection based methods\n",
      "T9\tTask 317 326\tNN search\n",
      "T10\tMethod 336 368\tlocality-sensitive hashing (LSH)\n",
      "T11\tMethod 372 395\trandom projection trees\n",
      "T12\tMethod 490 493\tLSH\n",
      "T13\tGeneric 499 501\tit\n",
      "T14\tGeneric 544 556\talternatives\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tCOREF Arg1:T2 Arg2:T9\n",
      "R4\tCOREF Arg1:T4 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R6\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R7\tHYPONYM-OF Arg1:T10 Arg2:T8\n",
      "R8\tHYPONYM-OF Arg1:T11 Arg2:T8\n",
      "R9\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R10\tCOREF Arg1:T10 Arg2:T12\n",
      "R11\tCOREF Arg1:T12 Arg2:T13\n",
      "R12\tCOMPARE Arg1:T13 Arg2:T14\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\P01-1004.ann\n",
      "T1\tOtherScientificTerm 52 65\tsegment order\n",
      "T2\tOtherScientificTerm 70 82\tsegmentation\n",
      "T3\tOtherScientificTerm 89 107\tsegment contiguity\n",
      "T4\tTask 117 126\tretrieval\n",
      "T5\tMethod 146 171\ttranslation memory system\n",
      "T6\tMethod 204 270\tbag-of-words and segment order-sensitive string comparison methods\n",
      "T7\tMaterial 298 332\tcharacter- and word-segmented data\n",
      "T8\tMethod 368 399\tlocal segment contiguity models\n",
      "T9\tMethod 418 425\tN-grams\n",
      "T10\tTask 475 483\tindexing\n",
      "T11\tMethod 506 523\tcharacter bigrams\n",
      "T12\tMetric 537 555\tretrieval accuracy\n",
      "T13\tMethod 588 606\tword N-gram models\n",
      "T14\tMethod 654 674\tbag-of-words methods\n",
      "T15\tMethod 707 738\tsegment order-sensitive methods\n",
      "T16\tMetric 753 771\tretrieval accuracy\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R3\tCOMPARE Arg1:T14 Arg2:T15\n",
      "R4\tEVALUATE-FOR Arg1:T4 Arg2:T5\n",
      "R5\tCONJUNCTION Arg1:T8 Arg2:T6\n",
      "R6\tFEATURE-OF Arg1:T9 Arg2:T8\n",
      "R7\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R8\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R9\tUSED-FOR Arg1:T1 Arg2:T5\n",
      "R10\tUSED-FOR Arg1:T2 Arg2:T5\n",
      "R11\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R12\tCOMPARE Arg1:T11 Arg2:T13\n",
      "R13\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "R14\tEVALUATE-FOR Arg1:T16 Arg2:T14\n",
      "R15\tCOREF Arg1:T16 Arg2:T12\n",
      "R16\tEVALUATE-FOR Arg1:T12 Arg2:T13\n",
      "R17\tEVALUATE-FOR Arg1:T12 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P01-1007.ann\n",
      "T1\tMethod 31 74\trange concatenation grammar [RCG] formalism\n",
      "T2\tTask 138 141\tNLP\n",
      "T3\tOtherScientificTerm 161 196\trange concatenation languages [RCL]\n",
      "T4\tOtherScientificTerm 216 231\tpolynomial time\n",
      "T5\tMethod 253 275\tgrammatical formalisms\n",
      "T6\tMethod 312 316\tRCGs\n",
      "T7\tMetric 344 378\tworst-case parsing time complexity\n",
      "T8\tMethod 435 438\tRCG\n",
      "T9\tMethod 447 469\ttree adjoining grammar\n",
      "T10\tOtherScientificTerm 489 499\tO(n6) time\n",
      "T11\tMethod 530 547\tparsing technique\n",
      "T12\tMethod 606 617\tRCL parsers\n",
      "T13\tMethod 626 651\tnon-deterministic parsing\n",
      "T14\tMethod 669 680\tmain parser\n",
      "T15\tOtherScientificTerm 689 699\tlanguage L\n",
      "T16\tOtherScientificTerm 743 767\tshared derivation forest\n",
      "T17\tMethod 788 798\tRCL parser\n",
      "T18\tGeneric 879 885\tmethod\n",
      "T19\tMethod 892 921\twide coverage English grammar\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "R3\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R5\tCOREF Arg1:T1 Arg2:T6\n",
      "R6\tEVALUATE-FOR Arg1:T7 Arg2:T5\n",
      "R7\tCOREF Arg1:T6 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R9\tEVALUATE-FOR Arg1:T19 Arg2:T18\n",
      "R10\tCOREF Arg1:T12 Arg2:T17\n",
      "R11\tCOREF Arg1:T11 Arg2:T18\n",
      "R12\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P01-1008.ann\n",
      "T1\tMethod 8 20\tparaphrasing\n",
      "T2\tTask 44 93\tinterpretation and generation of natural language\n",
      "T3\tGeneric 105 112\tsystems\n",
      "T4\tMethod 117 149\tmanual or semi-automatic methods\n",
      "T5\tOtherScientificTerm 162 173\tparaphrases\n",
      "T6\tMethod 192 223\tunsupervised learning algorithm\n",
      "T7\tTask 230 259\tidentification of paraphrases\n",
      "T8\tMaterial 269 308\tcorpus of multiple English translations\n",
      "T9\tGeneric 342 350\tapproach\n",
      "T10\tOtherScientificTerm 359 402\tphrasal and single word lexical paraphrases\n",
      "T11\tOtherScientificTerm 416 437\tsyntactic paraphrases\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R7\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R9\tCOREF Arg1:T6 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P01-1009.ann\n",
      "T1\tMethod 24 39\tformal analysis\n",
      "T2\tOtherScientificTerm 78 97\talternative markers\n",
      "T3\tGeneric 170 175\twords\n",
      "T4\tOtherScientificTerm 206 212\tdialog\n",
      "T5\tMethod 260 291\tnatural language search engines\n",
      "T6\tGeneric 332 336\tthem\n",
      "T7\tMethod 374 387\tsearch engine\n",
      "T8\tMethod 438 475\tapproximation of the  formal analysis\n",
      "T9\tMethod 460 475\tformal analysis\n",
      "T10\tMethod 506 519\tsearch engine\n",
      "T11\tOtherScientificTerm 525 546\toperational semantics\n",
      "T12\tGeneric 568 576\tapproach\n",
      "T13\tOtherScientificTerm 593 614\toperational semantics\n",
      "T14\tTask 620 649\tnatural language applications\n",
      "R1\tPART-OF Arg1:T13 Arg2:T14\n",
      "R2\tCOREF Arg1:T1 Arg2:T9\n",
      "R3\tPART-OF Arg1:T11 Arg2:T10\n",
      "R4\tPART-OF Arg1:T8 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tCOREF Arg1:T1 Arg2:T12\n",
      "R7\tCOREF Arg1:T7 Arg2:T10\n",
      "R8\tCOREF Arg1:T5 Arg2:T7\n",
      "R9\tCOREF Arg1:T2 Arg2:T3\n",
      "R10\tCOREF Arg1:T3 Arg2:T6\n",
      "R11\tPART-OF Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P01-1047.ann\n",
      "T1\tMethod 15 58\tlogical definition  of  Minimalist grammars\n",
      "T2\tMethod 72 129\tStabler's formalization  of  Chomsky's minimalist program\n",
      "T3\tMethod 138 156\tlogical definition\n",
      "T4\tMethod 187 205\tcategorial grammar\n",
      "T5\tOtherScientificTerm 235 253\tMontague semantics\n",
      "T6\tMethod 261 281\tparsing-as-deduction\n",
      "T7\tOtherScientificTerm 289 313\tresource sensitive logic\n",
      "T8\tMethod 324 342\tlearning algorithm\n",
      "T9\tMaterial 350 365\tstructured data\n",
      "T10\tMethod 380 396\ttyping-algorithm\n",
      "T11\tMethod 403 419\ttype-unification\n",
      "T12\tOtherScientificTerm 461 479\tMontague semantics\n",
      "T13\tOtherScientificTerm 507 547\tformal computation  of the  logical form\n",
      "T14\tOtherScientificTerm 535 547\tlogical form\n",
      "R1\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R2\tCOREF Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T8\n",
      "R5\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R6\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R7\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R8\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P01-1056.ann\n",
      "T1\tGeneric 2 12\tTechniques\n",
      "T2\tMethod 17 48\tautomatically training  modules\n",
      "T3\tMethod 55 81\tnatural language generator\n",
      "T4\tMetric 154 177\tquality  of  utterances\n",
      "T5\tOtherScientificTerm 167 177\tutterances\n",
      "T6\tMethod 194 214\ttrainable components\n",
      "T7\tMethod 234 286\thand-crafted template-based or rule-based approaches\n",
      "T8\tMethod 334 360\ttrainable sentence planner\n",
      "T9\tMethod 369 391\tspoken dialogue system\n",
      "T10\tOtherScientificTerm 407 433\tsubjective human judgments\n",
      "T11\tMethod 503 551\thand-crafted template-based generation component\n",
      "T12\tMethod 560 588\trule-based sentence planners\n",
      "T13\tMethod 601 627\tbaseline sentence planners\n",
      "T14\tMethod 649 675\ttrainable sentence planner\n",
      "T15\tMethod 703 721\trule-based systems\n",
      "T16\tGeneric 732 741\tbaselines\n",
      "T17\tMethod 765 784\thand-crafted system\n",
      "R1\tCOMPARE Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R3\tCOMPARE Arg1:T14 Arg2:T15\n",
      "R4\tEVALUATE-FOR Arg1:T5 Arg2:T6\n",
      "R5\tPART-OF Arg1:T2 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R7\tEVALUATE-FOR Arg1:T10 Arg2:T8\n",
      "R8\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R9\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R10\tCOMPARE Arg1:T14 Arg2:T17\n",
      "R11\tCOMPARE Arg1:T14 Arg2:T16\n",
      "R12\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R13\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R14\tCOREF Arg1:T12 Arg2:T15\n",
      "R15\tCOREF Arg1:T13 Arg2:T16\n",
      "R16\tCOREF Arg1:T11 Arg2:T17\n",
      "R17\tCOREF Arg1:T8 Arg2:T14\n",
      "R18\tEVALUATE-FOR Arg1:T5 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P01-1070.ann\n",
      "T1\tMethod 23 50\tsupervised machine learning\n",
      "T2\tMethod 98 134\tstatistical models  of  WH-questions\n",
      "T3\tGeneric 145 151\tmodels\n",
      "T4\tOtherScientificTerm 177 219\tshallow linguistic features  of  questions\n",
      "T5\tOtherScientificTerm 283 309\tuser's informational goals\n",
      "T6\tGeneric 384 390\tmodels\n",
      "T7\tOtherScientificTerm 430 458\ttraining and testing factors\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R4\tCOREF Arg1:T3 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P02-1023.ann\n",
      "T1\tTask 1 35\tReducing  language model (LM) size\n",
      "T2\tMethod 74 76\tLM\n",
      "T3\tOtherScientificTerm 115 134\tmemory constraints.\n",
      "T4\tTask 197 207\tLM pruning\n",
      "T5\tOtherScientificTerm 233 237\trank\n",
      "T6\tOtherScientificTerm 245 252\tentropy\n",
      "T7\tOtherScientificTerm 298 314\tpruning criteria\n",
      "T8\tMaterial 342 360\tChinese text input\n",
      "T9\tMetric 375 401\tcharacter error rate (CER)\n",
      "T10\tOtherScientificTerm 460 464\trank\n",
      "T11\tOtherScientificTerm 542 546\trank\n",
      "T12\tMetric 585 595\terror rate\n",
      "T13\tGeneric 622 628\tmethod\n",
      "T14\tTask 659 672\tmodel pruning\n",
      "T15\tMetric 843 846\tCER\n",
      "R1\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R3\tEVALUATE-FOR Arg1:T9 Arg2:T7\n",
      "R4\tEVALUATE-FOR Arg1:T12 Arg2:T11\n",
      "R5\tCOREF Arg1:T15 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P02-1059.ann\n",
      "T1\tMethod 65 84\tsupervised learning\n",
      "T2\tMethod 92 113\tunsupervised learning\n",
      "T3\tTask 128 158\thuman biases in  summarization\n",
      "T4\tOtherScientificTerm 199 226\tprobabilistic decision tree\n",
      "T5\tMethod 239 259\tclustering framework\n",
      "T6\tMaterial 315 338\thuman created summaries\n",
      "T7\tMaterial 346 379\tcorpus  of human created extracts\n",
      "T8\tMaterial 399 415\tnewspaper corpus\n",
      "T9\tOtherScientificTerm 451 479\tprobabilistic decision trees\n",
      "T10\tGeneric 524 528\tthem\n",
      "T11\tMethod 538 558\tclustering framework\n",
      "T12\tGeneric 582 588\tcorpus\n",
      "R1\tCONJUNCTION Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R4\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R6\tCOREF Arg1:T7 Arg2:T12\n",
      "R7\tCOREF Arg1:T9 Arg2:T10\n",
      "R8\tCONJUNCTION Arg1:T11 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P02-1060.ann\n",
      "T1\tMethod 24 49\tHidden Markov Model (HMM)\n",
      "T2\tMethod 59 81\tHMM-based chunk tagger\n",
      "T3\tMethod 98 140\tnamed entity (NE) recognition (NER) system\n",
      "T4\tOtherScientificTerm 178 183\tnames\n",
      "T5\tOtherScientificTerm 187 217\ttimes and numerical quantities\n",
      "T6\tMethod 233 236\tHMM\n",
      "T7\tOtherScientificTerm 339 383\tdeterministic internal feature of the  words\n",
      "T8\tOtherScientificTerm 395 409\tcapitalization\n",
      "T9\tOtherScientificTerm 415 429\tdigitalization\n",
      "T10\tOtherScientificTerm 491 517\tinternal gazetteer feature\n",
      "T11\tOtherScientificTerm 524 554\texternal macro context feature\n",
      "T12\tTask 575 586\tNER problem\n",
      "T13\tGeneric 636 642\tsystem\n",
      "T14\tMaterial 648 680\tMUC-6 and MUC-7 English NE tasks\n",
      "T15\tMetric 692 702\tF-measures\n",
      "T16\tMethod 819 842\tmachine-learning system\n",
      "T17\tOtherScientificTerm 922 939\thandcrafted rules\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T1 Arg2:T6\n",
      "R5\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R6\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R7\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R8\tEVALUATE-FOR Arg1:T15 Arg2:T13\n",
      "R9\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R10\tCOREF Arg1:T3 Arg2:T13\n",
      "R11\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R12\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R13\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1002.ann\n",
      "T1\tMethod 51 62\tIE paradigm\n",
      "T2\tOtherScientificTerm 89 118\tpredicate-argument structures\n",
      "T3\tTask 153 209\tautomatically identifying  predicate argument structures\n",
      "T4\tMethod 238 249\tIE paradigm\n",
      "T5\tGeneric 253 255\tIt\n",
      "T6\tOtherScientificTerm 293 301\tfeatures\n",
      "T7\tMethod 314 346\tinductive decision tree learning\n",
      "T8\tOtherScientificTerm 406 435\tpredicate-argument structures\n",
      "T9\tTask 458 460\tIE\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R3\tCOREF Arg1:T5 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1005.ann\n",
      "T1\tMethod 26 75\tHierarchical Directed Acyclic Graph (HDAG) Kernel\n",
      "T2\tMaterial 82 114\tstructured natural language data\n",
      "T3\tMethod 123 134\tHDAG Kernel\n",
      "T4\tMethod 311 316\tHDAGs\n",
      "T5\tGeneric 344 350\tmethod\n",
      "T6\tTask 355 409\tquestion classification  and  sentence alignment tasks\n",
      "T7\tMetric 445 463\tsimilarity measure\n",
      "T8\tMethod 472 487\tkernel function\n",
      "T9\tMethod 544 555\tHDAG Kernel\n",
      "T10\tMethod 579 595\tkernel functions\n",
      "T11\tGeneric 602 618\tbaseline methods\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOMPARE Arg1:T9 Arg2:T10\n",
      "R3\tCOREF Arg1:T3 Arg2:T1\n",
      "R4\tCOREF Arg1:T3 Arg2:T4\n",
      "R5\tCOREF Arg1:T4 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R7\tCOREF Arg1:T5 Arg2:T9\n",
      "R8\tCOMPARE Arg1:T9 Arg2:T11\n",
      "R9\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R10\tEVALUATE-FOR Arg1:T7 Arg2:T5\n",
      "R11\tEVALUATE-FOR Arg1:T8 Arg2:T5\n",
      "R12\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1009.ann\n",
      "T1\tMethod 52 62\tclustering\n",
      "T2\tTask 67 98\tinducing  semantic verb classes\n",
      "T3\tMaterial 105 133\tundisambiguated  corpus data\n",
      "T4\tGeneric 155 163\tapproach\n",
      "T5\tTask 179 235\tclustering  subcategorization frame (SCF)  distributions\n",
      "T6\tMethod 247 302\tInformation Bottleneck  and  nearest neighbour  methods\n",
      "T7\tTask 359 386\tclustering  polysemic verbs\n",
      "T8\tOtherScientificTerm 371 386\tpolysemic verbs\n",
      "T9\tGeneric 399 416\tevaluation scheme\n",
      "T10\tOtherScientificTerm 464 472\tpolysemy\n",
      "T11\tOtherScientificTerm 482 490\tclusters\n",
      "T12\tTask 560 611\tsemantically classifying   undisambiguated SCF data\n",
      "R1\tFEATURE-OF Arg1:T10 Arg2:T11\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tPART-OF Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R7\tEVALUATE-FOR Arg1:T9 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1022.ann\n",
      "T1\tMethod 13 41\tdecision tree based approach\n",
      "T2\tTask 47 65\tpronoun resolution\n",
      "T3\tTask 71 86\tspoken dialogue\n",
      "T4\tGeneric 94 100\tsystem\n",
      "T5\tOtherScientificTerm 113 121\tpronouns\n",
      "T6\tOtherScientificTerm 129 155\tNP- and non-NP-antecedents\n",
      "T7\tOtherScientificTerm 180 188\tfeatures\n",
      "T8\tTask 204 222\tpronoun resolution\n",
      "T9\tTask 228 243\tspoken dialogue\n",
      "T10\tOtherScientificTerm 279 287\tfeatures\n",
      "T11\tGeneric 307 313\tsystem\n",
      "T12\tMaterial 325 346\tSwitchboard dialogues\n",
      "T13\tGeneric 362 364\tit\n",
      "T14\tMethod 383 419\tByron's (2002) manually tuned system\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R6\tCOREF Arg1:T1 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R8\tCOREF Arg1:T4 Arg2:T11\n",
      "R9\tEVALUATE-FOR Arg1:T12 Arg2:T11\n",
      "R10\tCOREF Arg1:T11 Arg2:T13\n",
      "R11\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R12\tCOREF Arg1:T3 Arg2:T9\n",
      "R13\tCOREF Arg1:T2 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1030.ann\n",
      "T1\tTask 2 16\tLink detection\n",
      "T2\tTask 66 125\tTopic Detection and Tracking tasks  of  new event detection\n",
      "T3\tTask 157 177\tstory link detection\n",
      "T4\tTask 184 203\tnew event detection\n",
      "T5\tTask 209 235\tinformation retrieval task\n",
      "T6\tMetric 271 280\tprecision\n",
      "T7\tMetric 287 293\trecall\n",
      "T8\tGeneric 303 310\tsystems\n",
      "T9\tMethod 371 403\tperformance enhancing techniques\n",
      "T10\tMethod 415 437\tpart of speech tagging\n",
      "T11\tMethod 446 465\tsimilarity measures\n",
      "T12\tOtherScientificTerm 471 491\texpanded  stop lists\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T3\n",
      "R4\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R5\tHYPONYM-OF Arg1:T4 Arg2:T8\n",
      "R6\tHYPONYM-OF Arg1:T3 Arg2:T8\n",
      "R7\tEVALUATE-FOR Arg1:T7 Arg2:T8\n",
      "R8\tEVALUATE-FOR Arg1:T6 Arg2:T8\n",
      "R9\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R10\tPART-OF Arg1:T10 Arg2:T9\n",
      "R11\tPART-OF Arg1:T11 Arg2:T9\n",
      "R12\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R13\tPART-OF Arg1:T12 Arg2:T9\n",
      "R14\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1031.ann\n",
      "T1\tTask 26 57\tdiscourse understanding process\n",
      "T2\tMethod 63 86\tspoken dialogue systems\n",
      "T3\tGeneric 115 121\tsystem\n",
      "T4\tMaterial 137 152\tuser utterances\n",
      "T5\tMaterial 277 291\tuser utterance\n",
      "T6\tOtherScientificTerm 305 340\tambiguity  of  speech understanding\n",
      "T7\tOtherScientificTerm 423 437\tuser utterance\n",
      "T8\tGeneric 521 530\tambiguity\n",
      "T9\tMetric 567 599\tdiscourse understanding accuracy\n",
      "T10\tGeneric 640 646\tmethod\n",
      "T11\tGeneric 667 676\tambiguity\n",
      "T12\tOtherScientificTerm 688 711\tstatistical information\n",
      "T13\tMaterial 728 744\tdialogue corpora\n",
      "T14\tGeneric 768 775\tmethods\n",
      "T15\tOtherScientificTerm 786 804\thand-crafted rules\n",
      "T16\tGeneric 821 827\tmethod\n",
      "T17\tTask 856 887\tdiscourse understanding process\n",
      "T18\tGeneric 928 934\tsystem\n",
      "T19\tGeneric 962 968\tmethod\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R3\tCOREF Arg1:T2 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R5\tCOREF Arg1:T6 Arg2:T8\n",
      "R6\tCOREF Arg1:T8 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R10\tCOREF Arg1:T10 Arg2:T16\n",
      "R11\tCOREF Arg1:T1 Arg2:T17\n",
      "R12\tCOREF Arg1:T16 Arg2:T19\n",
      "R13\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1033.ann\n",
      "T1\tMethod 25 38\tuser modeling\n",
      "T2\tOtherScientificTerm 62 83\tcooperative responses\n",
      "T3\tTask 104 127\tspoken dialogue systems\n",
      "T4\tGeneric 147 154\tstudies\n",
      "T5\tMethod 226 236\tuser model\n",
      "T6\tMethod 317 328\tuser models\n",
      "T7\tGeneric 449 455\tmodels\n",
      "T8\tMethod 487 509\tdecision tree learning\n",
      "T9\tMaterial 517 536\treal  dialogue data\n",
      "T10\tGeneric 555 561\tsystem\n",
      "T11\tMetric 587 610\tclassification accuracy\n",
      "T12\tMethod 633 652\tDialogue strategies\n",
      "T13\tMethod 668 681\tuser modeling\n",
      "T14\tMethod 703 736\tKyoto city bus information system\n",
      "T15\tOtherScientificTerm 821 842\tcooperative responses\n",
      "T16\tOtherScientificTerm 941 958\tdialogue duration\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R4\tPART-OF Arg1:T1 Arg2:T3\n",
      "R5\tCOREF Arg1:T5 Arg2:T1\n",
      "R6\tCOREF Arg1:T5 Arg2:T6\n",
      "R7\tCOREF Arg1:T6 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R10\tCOREF Arg1:T7 Arg2:T13\n",
      "R11\tCOMPARE Arg1:T4 Arg2:T5\n",
      "R12\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1034.ann\n",
      "T1\tMethod 2 53\tPipelined Natural Language Generation (NLG) systems\n",
      "T2\tMethod 91 112\tarchitectural modules\n",
      "T3\tOtherScientificTerm 137 161\tlanguage functionalities\n",
      "T4\tOtherScientificTerm 172 193\treferring expressions\n",
      "T5\tOtherScientificTerm 197 211\tlexical choice\n",
      "T6\tOtherScientificTerm 219 227\trevision\n",
      "T7\tGeneric 308 315\tmodules\n",
      "T8\tGeneric 324 345\toverall  architecture\n",
      "T9\tMaterial 382 402\tmulti-paragraph text\n",
      "T10\tOtherScientificTerm 406 423\tdiscourse markers\n",
      "T11\tMethod 468 504\tdiscourse marker insertion algorithm\n",
      "T12\tMethod 560 586\tpipelined NLG architecture\n",
      "T13\tGeneric 598 606\tapproach\n",
      "T14\tGeneric 626 628\tit\n",
      "T15\tMethod 635 653\trevision component\n",
      "T16\tGeneric 681 689\tapproach\n",
      "T17\tTask 704 721\tmulti-page system\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tPART-OF Arg1:T15 Arg2:T12\n",
      "R3\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R4\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R5\tHYPONYM-OF Arg1:T6 Arg2:T3\n",
      "R6\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R7\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R8\tCOREF Arg1:T2 Arg2:T7\n",
      "R9\tPART-OF Arg1:T7 Arg2:T8\n",
      "R10\tCOREF Arg1:T1 Arg2:T8\n",
      "R11\tCOREF Arg1:T8 Arg2:T12\n",
      "R12\tEVALUATE-FOR Arg1:T17 Arg2:T16\n",
      "R13\tCOREF Arg1:T11 Arg2:T14\n",
      "R14\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R15\tCOREF Arg1:T13 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1050.ann\n",
      "T1\tMethod 25 55\tunsupervised learning approach\n",
      "T2\tTask 72 100\tnon-English (Arabic) stemmer\n",
      "T3\tMethod 109 123\tstemming model\n",
      "T4\tMethod 138 169\tstatistical machine translation\n",
      "T5\tGeneric 175 177\tit\n",
      "T6\tMethod 187 202\tEnglish stemmer\n",
      "T7\tMaterial 233 248\tparallel corpus\n",
      "T8\tMaterial 289 302\tparallel text\n",
      "T9\tMaterial 344 373\tMonolingual, unannotated text\n",
      "T10\tMethod 411 418\tstemmer\n",
      "T11\tGeneric 432 434\tit\n",
      "T12\tMaterial 519 525\tArabic\n",
      "T13\tGeneric 537 545\tapproach\n",
      "T14\tOtherScientificTerm 590 603\taffix removal\n",
      "T15\tMethod 612 636\tresource-frugal approach\n",
      "T16\tMetric 656 665\tagreement\n",
      "T17\tMethod 705 719\tArabic stemmer\n",
      "T18\tOtherScientificTerm 734 739\trules\n",
      "T19\tMaterial 744 755\taffix lists\n",
      "T20\tMaterial 764 784\thuman annotated text\n",
      "T21\tMethod 807 829\tunsupervised component\n",
      "T22\tMethod 834 855\tTask-based evaluation\n",
      "T23\tTask 864 892\tArabic information retrieval\n",
      "T24\tMetric 933 950\taverage precision\n",
      "T25\tMaterial 958 972\tunstemmed text\n",
      "T26\tMethod 1023 1030\tstemmer\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R3\tCOREF Arg1:T3 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R7\tCOREF Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T2 Arg2:T3\n",
      "R9\tCOREF Arg1:T5 Arg2:T10\n",
      "R10\tCOREF Arg1:T1 Arg2:T13\n",
      "R11\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R12\tUSED-FOR Arg1:T19 Arg2:T17\n",
      "R13\tUSED-FOR Arg1:T20 Arg2:T17\n",
      "R14\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R15\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R16\tUSED-FOR Arg1:T21 Arg2:T17\n",
      "R17\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R18\tCOMPARE Arg1:T15 Arg2:T17\n",
      "R19\tEVALUATE-FOR Arg1:T16 Arg2:T17\n",
      "R20\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "R21\tCOREF Arg1:T13 Arg2:T15\n",
      "R22\tCOREF Arg1:T17 Arg2:T26\n",
      "R23\tUSED-FOR Arg1:T23 Arg2:T22\n",
      "R24\tEVALUATE-FOR Arg1:T24 Arg2:T22\n",
      "R25\tEVALUATE-FOR Arg1:T24 Arg2:T25\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1058.ann\n",
      "T1\tTask 24 55\tword sense disambiguation (WSD)\n",
      "T2\tMaterial 73 99\tmanually sense-tagged data\n",
      "T3\tMethod 115 134\tsupervised learning\n",
      "T4\tGeneric 168 176\tapproach\n",
      "T5\tMaterial 203 229\tsense-tagged training data\n",
      "T6\tMaterial 237 269\tEnglish-Chinese parallel corpora\n",
      "T7\tOtherScientificTerm 317 322\tnouns\n",
      "T8\tMaterial 332 370\tSENSEVAL-2 English lexical sample task\n",
      "T9\tGeneric 411 417\tmethod\n",
      "T10\tTask 421 448\tacquiring sense-tagged data\n",
      "T11\tOtherScientificTerm 499 515\tSENSEVAL-2 nouns\n",
      "T12\tMetric 524 532\taccuracy\n",
      "T13\tMaterial 671 697\tmanually sense-tagged data\n",
      "T14\tMetric 714 728\tsense coverage\n",
      "T15\tOtherScientificTerm 793 810\tdomain dependence\n",
      "T16\tTask 815 839\tevaluating  WSD programs\n",
      "T17\tTask 827 839\tWSD programs\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T7\n",
      "R5\tPART-OF Arg1:T7 Arg2:T8\n",
      "R6\tCOREF Arg1:T1 Arg2:T17\n",
      "R7\tFEATURE-OF Arg1:T15 Arg2:T16\n",
      "R8\tFEATURE-OF Arg1:T14 Arg2:T13\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R10\tCOREF Arg1:T4 Arg2:T9\n",
      "R11\tCOREF Arg1:T2 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1068.ann\n",
      "T1\tMaterial 51 80\tsemantically annotated corpus\n",
      "T2\tTask 117 170\tlarge-scale  acquisition of word-semantic information\n",
      "T3\tTask 183 225\tconstruction of  domain-independent lexica\n",
      "T4\tOtherScientificTerm 250 260\tannotation\n",
      "T5\tOtherScientificTerm 267 281\tsemantic roles\n",
      "T6\tMethod 291 315\tframe semantics paradigm\n",
      "T7\tMaterial 359 373\tannotated data\n",
      "T8\tOtherScientificTerm 448 457\tvagueness\n",
      "T9\tOtherScientificTerm 464 473\tambiguity\n",
      "T10\tMethod 479 498\tsemantic annotation\n",
      "R1\tPART-OF Arg1:T5 Arg2:T6\n",
      "R2\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R3\tFEATURE-OF Arg1:T9 Arg2:T10\n",
      "R4\tFEATURE-OF Arg1:T8 Arg2:T10\n",
      "R5\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1070.ann\n",
      "T1\tMethod 21 47\tverbal and nonverbal means\n",
      "T2\tTask 54 63\tgrounding\n",
      "T3\tGeneric 81 87\tdesign\n",
      "T4\tMethod 93 123\tembodied conversational agents\n",
      "T5\tTask 178 191\tcommon ground\n",
      "T6\tTask 197 223\thuman-computer interaction\n",
      "T7\tOtherScientificTerm 240 248\teye gaze\n",
      "T8\tOtherScientificTerm 253 262\thead nods\n",
      "T9\tOtherScientificTerm 269 286\tattentional focus\n",
      "T10\tTask 309 330\tdirection-giving task\n",
      "T11\tOtherScientificTerm 355 374\tnonverbal behaviors\n",
      "T12\tOtherScientificTerm 411 424\tdialogue move\n",
      "T13\tOtherScientificTerm 501 518\tnegative feedback\n",
      "T14\tMethod 561 564\tECA\n",
      "T15\tOtherScientificTerm 577 612\tverbal and nonverbal grounding acts\n",
      "T16\tOtherScientificTerm 625 639\tdialogue state\n",
      "R1\tPART-OF Arg1:T9 Arg2:T10\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R5\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R7\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R8\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R9\tPART-OF Arg1:T8 Arg2:T10\n",
      "R10\tPART-OF Arg1:T7 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-2036.ann\n",
      "T1\tMethod 29 53\tCFG filtering techniques\n",
      "T2\tMethod 60 64\tLTAG\n",
      "T3\tMethod 71 75\tHPSG\n",
      "T4\tMethod 114 136\tapproximation of  HPSG\n",
      "T5\tMethod 132 136\tHPSG\n",
      "T6\tMethod 165 175\tCFG filter\n",
      "T7\tGeneric 182 186\tthat\n",
      "T8\tMethod 191 195\tLTAG\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tCOMPARE Arg1:T2 Arg2:T3\n",
      "R4\tCOMPARE Arg1:T6 Arg2:T7\n",
      "R5\tCOREF Arg1:T5 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R8\tCOREF Arg1:T2 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P04-1030.ann\n",
      "T1\tMethod 42 79\thead-driven statistical parsing model\n",
      "T2\tMethod 105 132\tsimultaneous language model\n",
      "T3\tMethod 139 145\tparser\n",
      "T4\tTask 152 187\tlarge-vocabulary speech recognition\n",
      "T5\tGeneric 194 199\tmodel\n",
      "T6\tMethod 218 251\tonline left to right chart-parser\n",
      "T7\tOtherScientificTerm 258 271\tword lattices\n",
      "T8\tOtherScientificTerm 286 328\tacoustic, n-gram, and parser probabilities\n",
      "T9\tMethod 335 341\tparser\n",
      "T10\tOtherScientificTerm 349 384\tstructural and lexical dependencies\n",
      "T11\tMethod 405 418\tn-gram models\n",
      "T12\tMaterial 513 541\tWall Street Journal treebank\n",
      "T13\tMaterial 547 562\tlattice corpora\n",
      "T14\tMetric 569 585\tword error rates\n",
      "T15\tMethod 618 639\tn-gram language model\n",
      "T16\tOtherScientificTerm 670 692\tstructural information\n",
      "T17\tTask 706 726\tspeech understanding\n",
      "R1\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R2\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T1 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R7\tPART-OF Arg1:T8 Arg2:T6\n",
      "R8\tCOREF Arg1:T6 Arg2:T9\n",
      "R9\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R10\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "R11\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R12\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R13\tEVALUATE-FOR Arg1:T14 Arg2:T15\n",
      "R14\tEVALUATE-FOR Arg1:T13 Arg2:T15\n",
      "R15\tEVALUATE-FOR Arg1:T12 Arg2:T15\n",
      "R16\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P04-2005.ann\n",
      "T1\tGeneric 20 28\tapproach\n",
      "T2\tTask 33 82\tautomatically acquiring  English topic signatures\n",
      "T3\tOtherScientificTerm 105 112\tconcept\n",
      "T4\tOtherScientificTerm 119 129\tword sense\n",
      "T5\tOtherScientificTerm 135 150\ttopic signature\n",
      "T6\tOtherScientificTerm 204 220\tTopic signatures\n",
      "T7\tTask 252 298\tNatural Language Processing (NLP) applications\n",
      "T8\tTask 310 341\tWord Sense Disambiguation (WSD)\n",
      "T9\tTask 348 366\tText Summarisation\n",
      "T10\tGeneric 373 379\tmethod\n",
      "T11\tOtherScientificTerm 427 438\tword senses\n",
      "T12\tMaterial 460 467\tEnglish\n",
      "T13\tMaterial 474 481\tChinese\n",
      "T14\tMaterial 523 535\tChinese text\n",
      "T15\tGeneric 551 558\tcorpora\n",
      "T16\tMaterial 571 574\tWeb\n",
      "T17\tOtherScientificTerm 594 610\ttopic signatures\n",
      "T18\tTask 618 626\tWSD task\n",
      "T19\tMethod 649 691\tsecond-order vector cooccurrence algorithm\n",
      "T20\tMaterial 706 718\tWSD datasets\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R2\tPART-OF Arg1:T14 Arg2:T15\n",
      "R3\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T9\n",
      "R7\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R8\tCOREF Arg1:T1 Arg2:T10\n",
      "R9\tPART-OF Arg1:T14 Arg2:T16\n",
      "R10\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R11\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R12\tCOREF Arg1:T8 Arg2:T18\n",
      "R13\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R14\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P04-2010.ann\n",
      "T1\tMethod 30 56\tensemble learning approach\n",
      "T2\tOtherScientificTerm 72 87\tGerman pronouns\n",
      "T3\tMethod 91 99\tBoosting\n",
      "T4\tMethod 184 195\tclassifiers\n",
      "T5\tGeneric 255 263\tapproach\n",
      "T6\tMethod 289 313\tdecision-tree classifier\n",
      "T7\tMethod 343 360\tstandalone system\n",
      "T8\tOtherScientificTerm 377 385\tpronouns\n",
      "T9\tMaterial 391 407\tunannotated text\n",
      "T10\tMethod 449 470\tpreprocessing modules\n",
      "T11\tTask 489 514\tmanual annotation process\n",
      "T12\tGeneric 530 536\tsystem\n",
      "T13\tMaterial 569 583\ttextual domain\n",
      "T14\tGeneric 621 623\tit\n",
      "T15\tTask 639 669\topen-domain question answering\n",
      "T16\tTask 676 694\ttext summarisation\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R3\tCOMPARE Arg1:T13 Arg2:T15\n",
      "R4\tCOREF Arg1:T3 Arg2:T5\n",
      "R5\tCOMPARE Arg1:T5 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tPART-OF Arg1:T8 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T10 Arg2:T7\n",
      "R10\tCOREF Arg1:T7 Arg2:T12\n",
      "R11\tEVALUATE-FOR Arg1:T13 Arg2:T12\n",
      "R12\tCOREF Arg1:T12 Arg2:T14\n",
      "R13\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R14\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R15\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R16\tCOREF Arg1:T1 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1010.ann\n",
      "T1\tMethod 23 70\tgenerative probabilistic model  of  parse trees\n",
      "T2\tMethod 88 95\tPCFG-LA\n",
      "T3\tGeneric 104 109\tmodel\n",
      "T4\tMethod 131 135\tPCFG\n",
      "T5\tOtherScientificTerm 147 167\tnon-terminal symbols\n",
      "T6\tOtherScientificTerm 189 205\tlatent variables\n",
      "T7\tOtherScientificTerm 208 230\tFinegrained  CFG rules\n",
      "T8\tMaterial 266 279\tparsed corpus\n",
      "T9\tMethod 298 311\tPCFG-LA model\n",
      "T10\tMethod 323 335\tEM-algorithm\n",
      "T11\tTask 346 360\texact  parsing\n",
      "T12\tMethod 370 377\tPCFG-LA\n",
      "T13\tMaterial 484 499\tPenn WSJ corpus\n",
      "T14\tGeneric 529 534\tmodel\n",
      "T15\tMetric 567 569\tF1\n",
      "T16\tMethod 633 658\tunlexicalized PCFG parser\n",
      "T17\tMethod 685 709\tmanual feature selection\n",
      "R1\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R3\tCOREF Arg1:T1 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R6\tPART-OF Arg1:T5 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R10\tCOMPARE Arg1:T14 Arg2:T16\n",
      "R11\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R12\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R13\tEVALUATE-FOR Arg1:T13 Arg2:T14\n",
      "R14\tEVALUATE-FOR Arg1:T13 Arg2:T16\n",
      "R15\tCOREF Arg1:T2 Arg2:T9\n",
      "R16\tCOREF Arg1:T9 Arg2:T12\n",
      "R17\tCOREF Arg1:T12 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1018.ann\n",
      "T1\tTask 37 77\tautomatic assessment of  local coherence\n",
      "T2\tMethod 100 142\tentity-based representation  of  discourse\n",
      "T3\tMethod 166 182\tCentering Theory\n",
      "T4\tMaterial 224 232\traw text\n",
      "T5\tTask 244 264\tcoherence assessment\n",
      "T6\tTask 272 296\tranking learning problem\n",
      "T7\tMethod 326 350\tdiscourse representation\n",
      "T8\tOtherScientificTerm 390 406\tranking function\n",
      "T9\tMethod 447 460\tinduced model\n",
      "T10\tMetric 493 501\taccuracy\n",
      "T11\tMethod 528 543\tcoherence model\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T2\n",
      "R4\tCOREF Arg1:T1 Arg2:T5\n",
      "R5\tCOREF Arg1:T2 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tEVALUATE-FOR Arg1:T10 Arg2:T9\n",
      "R8\tCOMPARE Arg1:T9 Arg2:T11\n",
      "R9\tEVALUATE-FOR Arg1:T10 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1028.ann\n",
      "T1\tTask 24 36\tcorpus study\n",
      "T2\tOtherScientificTerm 135 154\tinformation graphic\n",
      "T3\tMethod 190 219\tgraphic interpretation system\n",
      "T4\tMaterial 259 280\tcommunicative signals\n",
      "T5\tMethod 344 362\tshallow processing\n",
      "T6\tMaterial 371 388\tgraphic's caption\n",
      "T7\tGeneric 421 427\tsystem\n",
      "T8\tOtherScientificTerm 503 523\tsight-impaired users\n",
      "T9\tOtherScientificTerm 551 571\tinformation graphics\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R4\tCOREF Arg1:T3 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1032.ann\n",
      "T1\tOtherScientificTerm 36 50\tdata structure\n",
      "T2\tTask 57 101\tphrase-based statistical machine translation\n",
      "T3\tTask 125 164\tretrieval  of arbitrarily long  phrases\n",
      "T4\tOtherScientificTerm 199 205\tmemory\n",
      "T5\tMethod 236 243\tdecoder\n",
      "T6\tMetric 277 301\tcomputational complexity\n",
      "T7\tMetric 308 331\taverage retrieval times\n",
      "T8\tOtherScientificTerm 349 368\tphrase translations\n",
      "T9\tOtherScientificTerm 378 411\tsuffix array-based data structure\n",
      "T10\tMethod 428 436\tsampling\n",
      "T11\tMetric 465 479\tretrieval time\n",
      "T12\tMetric 521 540\ttranslation quality\n",
      "R1\tPART-OF Arg1:T8 Arg2:T9\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R4\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R5\tEVALUATE-FOR Arg1:T11 Arg2:T10\n",
      "R6\tEVALUATE-FOR Arg1:T12 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1034.ann\n",
      "T1\tGeneric 21 29\tapproach\n",
      "T2\tTask 34 65\tstatistical machine translation\n",
      "T3\tOtherScientificTerm 82 103\tsyntactic information\n",
      "T4\tTask 155 174\tphrasal translation\n",
      "T5\tGeneric 183 189\tmethod\n",
      "T6\tMethod 202 237\tsource-language   dependency parser\n",
      "T7\tMethod 242 277\ttarget language   word segmentation\n",
      "T8\tMethod 287 324\tunsupervised word alignment component\n",
      "T9\tMaterial 340 355\tparallel corpus\n",
      "T10\tOtherScientificTerm 372 395\tsource dependency parse\n",
      "T11\tOtherScientificTerm 435 471\tdependency treelet translation pairs\n",
      "T12\tMethod 488 513\ttree-based ordering model\n",
      "T13\tMethod 543 550\tdecoder\n",
      "T14\tMethod 579 596\ttree-based models\n",
      "T15\tMethod 632 642\tSMT models\n",
      "T16\tGeneric 665 673\tapproach\n",
      "T17\tMethod 706 717\tphrasal SMT\n",
      "T18\tOtherScientificTerm 728 749\tlinguistic generality\n",
      "T19\tMethod 766 772\tparser\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R3\tPART-OF Arg1:T3 Arg2:T1\n",
      "R4\tPART-OF Arg1:T4 Arg2:T1\n",
      "R5\tCOREF Arg1:T1 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T5\n",
      "R9\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R10\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R11\tCOREF Arg1:T12 Arg2:T14\n",
      "R12\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R13\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R14\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R15\tUSED-FOR Arg1:T17 Arg2:T19\n",
      "R16\tFEATURE-OF Arg1:T18 Arg2:T19\n",
      "R17\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1039.ann\n",
      "T1\tMethod 31 51\tunlexicalized parser\n",
      "T2\tMaterial 58 64\tGerman\n",
      "T3\tMethod 81 90\tsmoothing\n",
      "T4\tMethod 97 112\tsuffix analysis\n",
      "T5\tMetric 128 152\tlabelled bracket F-score\n",
      "T6\tMaterial 211 223\tNEGRA corpus\n",
      "T7\tMetric 251 259\taccuracy\n",
      "T8\tGeneric 268 273\tmodel\n",
      "T9\tMethod 287 296\tsmoothing\n",
      "T10\tMethod 305 325\tunlexicalized parser\n",
      "T11\tMethod 378 387\tsmoothing\n",
      "T12\tMethod 394 401\tparsing\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R5\tEVALUATE-FOR Arg1:T5 Arg2:T1\n",
      "R6\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R7\tEVALUATE-FOR Arg1:T7 Arg2:T8\n",
      "R8\tCOREF Arg1:T1 Arg2:T8\n",
      "R9\tCOREF Arg1:T8 Arg2:T10\n",
      "R10\tEVALUATE-FOR Arg1:T6 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1046.ann\n",
      "T1\tMethod 36 69\tinformation extraction techniques\n",
      "T2\tMaterial 108 132\tsupervised training data\n",
      "T3\tTask 169 202\tfield structured extraction tasks\n",
      "T4\tMaterial 213 238\tclassified advertisements\n",
      "T5\tMaterial 243 266\tbibliographic citations\n",
      "T6\tOtherScientificTerm 286 301\tprior knowledge\n",
      "T7\tMethod 388 415\thidden Markov models (HMMs)\n",
      "T8\tMethod 437 453\tgenerative model\n",
      "T9\tMaterial 460 481\tfield structured text\n",
      "T10\tMethod 493 518\tunsupervised HMM learning\n",
      "T11\tOtherScientificTerm 675 690\tprior knowledge\n",
      "T12\tMethod 750 770\tunsupervised methods\n",
      "T13\tMetric 784 794\taccuracies\n",
      "T14\tMaterial 806 824\tunlabeled examples\n",
      "T15\tMethod 859 877\tsupervised methods\n",
      "T16\tMaterial 886 902\tlabeled examples\n",
      "T17\tMethod 915 938\tsemi-supervised methods\n",
      "T18\tMaterial 979 991\tlabeled data\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R5\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R6\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R7\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R8\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R9\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R10\tEVALUATE-FOR Arg1:T13 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R12\tCOMPARE Arg1:T12 Arg2:T15\n",
      "R13\tEVALUATE-FOR Arg1:T13 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1048.ann\n",
      "T1\tMethod 62 93\tword sense disambigation models\n",
      "T2\tMetric 101 142\tstatistical machine translation   quality\n",
      "T3\tMethod 257 296\tChinese word sense disambiguation model\n",
      "T4\tOtherScientificTerm 309 331\ttranslation candidates\n",
      "T5\tMethod 348 373\tIBM statistical MT system\n",
      "T6\tMethod 391 416\tword sense disambiguation\n",
      "T7\tMetric 455 474\ttranslation quality\n",
      "T8\tMethod 486 524\tstatistical machine translation system\n",
      "T9\tMethod 534 548\tError analysis\n",
      "T10\tMethod 654 682\tstatistical MT architectures\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tCOREF Arg1:T1 Arg2:T6\n",
      "R4\tCOMPARE Arg1:T6 Arg2:T8\n",
      "R5\tEVALUATE-FOR Arg1:T7 Arg2:T8\n",
      "R6\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1056.ann\n",
      "T1\tTask 2 29\tSentence boundary detection\n",
      "T2\tMaterial 35 41\tspeech\n",
      "T3\tOtherScientificTerm 71 97\tspeech recognition  output\n",
      "T4\tGeneric 106 108\tit\n",
      "T5\tMethod 207 273\thidden Markov model (HMM) and maximum entropy (Maxent) classifiers\n",
      "T6\tMaterial 290 329\ttextual and prosodic  knowledge sources\n",
      "T7\tTask 335 365\tdetecting  sentence boundaries\n",
      "T8\tMethod 409 439\tconditional random field (CRF)\n",
      "T9\tGeneric 450 454\ttask\n",
      "T10\tGeneric 484 489\tmodel\n",
      "T11\tGeneric 532 539\tcorpora\n",
      "T12\tMaterial 541 573\tconversational  telephone speech\n",
      "T13\tMaterial 580 601\tbroadcast news speech\n",
      "T14\tOtherScientificTerm 613 633\thuman transcriptions\n",
      "T15\tOtherScientificTerm 640 666\tspeech recognition  output\n",
      "T16\tMethod 685 695\tCRF  model\n",
      "T17\tMetric 711 721\terror rate\n",
      "T18\tMethod 732 754\tHMM and Max-ent models\n",
      "T19\tMaterial 764 801\tNIST sentence boundary detection task\n",
      "T20\tMaterial 807 813\tspeech\n",
      "T21\tMethod 890 906\tthree-way voting\n",
      "T22\tMethod 919 930\tclassifiers\n",
      "T23\tGeneric 968 973\tmodel\n",
      "T24\tMaterial 1032 1049\tknowledge sources\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R2\tCOREF Arg1:T1 Arg2:T7\n",
      "R3\tCOREF Arg1:T7 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R5\tCOREF Arg1:T8 Arg2:T10\n",
      "R6\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R7\tHYPONYM-OF Arg1:T13 Arg2:T11\n",
      "R8\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R9\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R10\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R11\tCOREF Arg1:T3 Arg2:T4\n",
      "R12\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R13\tEVALUATE-FOR Arg1:T11 Arg2:T14\n",
      "R14\tEVALUATE-FOR Arg1:T11 Arg2:T15\n",
      "R15\tCOREF Arg1:T8 Arg2:T16\n",
      "R16\tEVALUATE-FOR Arg1:T17 Arg2:T16\n",
      "R17\tEVALUATE-FOR Arg1:T17 Arg2:T18\n",
      "R18\tCOMPARE Arg1:T16 Arg2:T18\n",
      "R19\tFEATURE-OF Arg1:T20 Arg2:T19\n",
      "R20\tEVALUATE-FOR Arg1:T19 Arg2:T18\n",
      "R21\tEVALUATE-FOR Arg1:T19 Arg2:T16\n",
      "R22\tUSED-FOR Arg1:T23 Arg2:T24\n",
      "R23\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R24\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1057.ann\n",
      "T1\tGeneric 14 23\tframework\n",
      "T2\tTask 29 43\tword alignment\n",
      "T3\tMethod 55 72\tlog-linear models\n",
      "T4\tMaterial 80 97\tknowledge sources\n",
      "T5\tOtherScientificTerm 115 132\tfeature functions\n",
      "T6\tMethod 250 267\tLog-linear models\n",
      "T7\tMethod 276 304\tstatistical alignment models\n",
      "T8\tOtherScientificTerm 346 367\tsyntactic information\n",
      "T9\tOtherScientificTerm 393 428\tIBM Model 3 alignment probabilities\n",
      "T10\tOtherScientificTerm 432 450\tPOS correspondence\n",
      "T11\tOtherScientificTerm 458 487\tbilingual dictionary coverage\n",
      "T12\tOtherScientificTerm 493 501\tfeatures\n",
      "T13\tMethod 531 548\tlog-linear models\n",
      "T14\tMethod 576 598\tIBM translation models\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R4\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R8\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T12\n",
      "R10\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R11\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R12\tCOREF Arg1:T6 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1058.ann\n",
      "T1\tMethod 25 54\talignment adaptation approach\n",
      "T2\tTask 68 110\tdomain-specific (in-domain) word alignment\n",
      "T3\tMethod 132 152\talignment adaptation\n",
      "T4\tMaterial 165 185\tout-of-domain corpus\n",
      "T5\tTask 199 223\tin-domain word alignment\n",
      "T6\tMethod 269 302\tstatistical word alignment models\n",
      "T7\tMaterial 313 346\tlarge-scale  out-of-domain corpus\n",
      "T8\tMaterial 356 385\tsmall-scale  in-domain corpus\n",
      "T9\tGeneric 432 438\tmodels\n",
      "T10\tTask 455 485\tdomain-specific word alignment\n",
      "T11\tGeneric 523 531\tapproach\n",
      "T12\tTask 542 572\tdomain-specific word alignment\n",
      "T13\tMetric 592 601\tprecision\n",
      "T14\tMetric 608 614\trecall\n",
      "T15\tMetric 630 659\trelative error rate reduction\n",
      "T16\tGeneric 691 720\tstate-of-the-art technologies\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T1 Arg2:T3\n",
      "R3\tCOREF Arg1:T2 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R7\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R9\tCOREF Arg1:T6 Arg2:T9\n",
      "R10\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R11\tCOREF Arg1:T5 Arg2:T10\n",
      "R12\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R13\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R14\tEVALUATE-FOR Arg1:T13 Arg2:T11\n",
      "R15\tEVALUATE-FOR Arg1:T14 Arg2:T11\n",
      "R16\tCOMPARE Arg1:T11 Arg2:T16\n",
      "R17\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R18\tEVALUATE-FOR Arg1:T15 Arg2:T11\n",
      "R19\tCOREF Arg1:T12 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1067.ann\n",
      "T1\tTask 2 51\tSyntax-based statistical machine translation (MT)\n",
      "T2\tMethod 71 89\tstatistical models\n",
      "T3\tMaterial 95 110\tstructured data\n",
      "T4\tTask 143 194\tsyntax-based statistical machine translation system\n",
      "T5\tMethod 208 262\tprobabilistic synchronous dependency insertion grammar\n",
      "T6\tMethod 267 308\tSynchronous dependency insertion grammars\n",
      "T7\tMethod 328 348\tsynchronous grammars\n",
      "T8\tOtherScientificTerm 362 378\tdependency trees\n",
      "T9\tGeneric 405 413\tapproach\n",
      "T10\tMethod 434 441\tgrammar\n",
      "T11\tMaterial 449 465\tparallel corpora\n",
      "T12\tMethod 494 509\tgraphical model\n",
      "T13\tTask 520 544\tmachine translation task\n",
      "T14\tMethod 579 613\tstochastic tree-to-tree transducer\n",
      "T15\tMethod 633 667\tpolynomial time decoding algorithm\n",
      "T16\tGeneric 678 683\tmodel\n",
      "T17\tMethod 719 728\tMT system\n",
      "T18\tMetric 741 787\tNIST and Bleu automatic MT evaluation software\n",
      "T19\tGeneric 817 823\tsystem\n",
      "T20\tGeneric 841 856\tbaseline system\n",
      "T21\tMethod 872 882\tIBM models\n",
      "T22\tMetric 893 922\ttranslation speed and quality\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R4\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R5\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R6\tCOREF Arg1:T1 Arg2:T4\n",
      "R7\tHYPONYM-OF Arg1:T6 Arg2:T7\n",
      "R8\tCOREF Arg1:T6 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R11\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R12\tCOREF Arg1:T12 Arg2:T16\n",
      "R13\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R14\tCOREF Arg1:T17 Arg2:T1\n",
      "R15\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R16\tCOREF Arg1:T17 Arg2:T19\n",
      "R17\tCOMPARE Arg1:T19 Arg2:T20\n",
      "R18\tEVALUATE-FOR Arg1:T22 Arg2:T20\n",
      "R19\tEVALUATE-FOR Arg1:T22 Arg2:T19\n",
      "R20\tCOREF Arg1:T5 Arg2:T6\n",
      "R21\tFEATURE-OF Arg1:T8 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1069.ann\n",
      "T1\tMethod 36 51\ttraining method\n",
      "T2\tMethod 60 99\tlocalized phrase-based prediction model\n",
      "T3\tTask 106 143\tstatistical machine translation (SMT)\n",
      "T4\tGeneric 152 157\tmodel\n",
      "T5\tTask 205 229\tlocal phrase re-ordering\n",
      "T6\tOtherScientificTerm 243 271\tmaximum likelihood criterion\n",
      "T7\tMethod 285 314\tlog-linear block bigram model\n",
      "T8\tOtherScientificTerm 328 348\treal-valued features\n",
      "T9\tOtherScientificTerm 359 379\tlanguage model score\n",
      "T10\tOtherScientificTerm 395 410\tbinary features\n",
      "T11\tMethod 489 507\ttraining algorithm\n",
      "T12\tOtherScientificTerm 540 548\tfeatures\n",
      "T13\tGeneric 561 567\tsystem\n",
      "T14\tGeneric 606 614\tbaseline\n",
      "T15\tTask 631 662\tArabic-English translation task\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T2 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R6\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R8\tCOREF Arg1:T11 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R10\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R11\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R12\tEVALUATE-FOR Arg1:T15 Arg2:T13\n",
      "R13\tUSED-FOR Arg1:T10 Arg2:T7\n",
      "R14\tCONJUNCTION Arg1:T8 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1073.ann\n",
      "T1\tTask 43 65\tsemantic role labeling\n",
      "T2\tMethod 100 123\tindependent classifiers\n",
      "T3\tMethod 159 180\tlabel sequence models\n",
      "T4\tMethod 187 203\tViterbi decoding\n",
      "T5\tOtherScientificTerm 274 293\tcore argument frame\n",
      "T6\tMethod 389 421\tjoint model  of  argument frames\n",
      "T7\tOtherScientificTerm 445 453\tfeatures\n",
      "T8\tMethod 491 523\tdiscriminative log-linear models\n",
      "T9\tGeneric 531 537\tsystem\n",
      "T10\tMetric 551 566\terror reduction\n",
      "T11\tMethod 646 669\tindependent  classifier\n",
      "T12\tOtherScientificTerm 676 701\tgold-standard parse trees\n",
      "T13\tMaterial 707 715\tPropBank\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tPART-OF Arg1:T7 Arg2:T8\n",
      "R3\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R4\tCOREF Arg1:T6 Arg2:T9\n",
      "R5\tCOMPARE Arg1:T11 Arg2:T9\n",
      "R6\tPART-OF Arg1:T12 Arg2:T13\n",
      "R7\tCOREF Arg1:T2 Arg2:T11\n",
      "R8\tEVALUATE-FOR Arg1:T10 Arg2:T9\n",
      "R9\tEVALUATE-FOR Arg1:T10 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R11\tEVALUATE-FOR Arg1:T12 Arg2:T11\n",
      "R12\tEVALUATE-FOR Arg1:T12 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1074.ann\n",
      "T1\tMaterial 25 53\tmonolingual parallel corpora\n",
      "T2\tOtherScientificTerm 80 91\tparaphrases\n",
      "T3\tGeneric 113 117\ttask\n",
      "T4\tMaterial 137 163\tbilingual parallel corpora\n",
      "T5\tMethod 218 238\talignment techniques\n",
      "T6\tTask 246 290\tphrase-based statistical machine translation\n",
      "T7\tOtherScientificTerm 307 318\tparaphrases\n",
      "T8\tOtherScientificTerm 418 440\tparaphrase probability\n",
      "T9\tOtherScientificTerm 455 466\tparaphrases\n",
      "T10\tMaterial 486 511\tbilingual parallel corpus\n",
      "T11\tOtherScientificTerm 533 558\ttranslation probabilities\n",
      "T12\tGeneric 575 577\tit\n",
      "T13\tOtherScientificTerm 602 624\tcontextual information\n",
      "T14\tMethod 657 698\tparaphrase extraction and ranking methods\n",
      "T15\tMaterial 716 738\tmanual word alignments\n",
      "T16\tMetric 760 767\tquality\n",
      "T17\tOtherScientificTerm 775 786\tparaphrases\n",
      "T18\tOtherScientificTerm 804 824\tautomatic alignments\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tPART-OF Arg1:T9 Arg2:T10\n",
      "R3\tPART-OF Arg1:T17 Arg2:T18\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R8\tCOREF Arg1:T8 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R10\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R11\tEVALUATE-FOR Arg1:T16 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1076.ann\n",
      "T1\tGeneric 31 37\tsystem\n",
      "T2\tTask 44 99\tacquiring adjectival subcategorization frames  ( scfs )\n",
      "T3\tOtherScientificTerm 65 99\tsubcategorization frames  ( scfs )\n",
      "T4\tMaterial 143 164\tEnglish   corpus data\n",
      "T5\tGeneric 172 178\tsystem\n",
      "T6\tMethod 196 220\tdecision-tree classifier\n",
      "T7\tOtherScientificTerm 274 304\tgrammatical relations  ( grs )\n",
      "T8\tMethod 326 352\trobust  statistical parser\n",
      "T9\tGeneric 355 357\tIt\n",
      "T10\tOtherScientificTerm 375 400\tpattern-matching language\n",
      "T11\tOtherScientificTerm 415 418\tgrs\n",
      "T12\tOtherScientificTerm 472 496\tinheritance-based lexica\n",
      "T13\tGeneric 532 538\tsystem\n",
      "T14\tMetric 580 589\tprecision\n",
      "T15\tMetric 600 606\trecall\n",
      "T16\tGeneric 621 625\ttool\n",
      "T17\tTask 632 663\tlinguistic annotation  of  scfs\n",
      "T18\tOtherScientificTerm 659 663\tscfs\n",
      "T19\tMaterial 760 782\ttraining and test data\n",
      "T20\tTask 789 818\tsubcategorization acquisition\n",
      "R1\tPART-OF Arg1:T6 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T1 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tCOREF Arg1:T11 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T5 Arg2:T9\n",
      "R9\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R10\tCOREF Arg1:T13 Arg2:T9\n",
      "R11\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R12\tEVALUATE-FOR Arg1:T15 Arg2:T13\n",
      "R13\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R14\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R15\tCOREF Arg1:T3 Arg2:T18\n",
      "R16\tCOREF Arg1:T2 Arg2:T20\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-2008.ann\n",
      "T1\tTask 2 26\tSentiment Classification\n",
      "T2\tMethod 171 198\tmachine learning techniques\n",
      "T3\tGeneric 226 233\tproblem\n",
      "T4\tMaterial 342 364\ttraining and test data\n",
      "T5\tMaterial 520 533\ttraining data\n",
      "T6\tOtherScientificTerm 549 558\temoticons\n",
      "R1\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "R2\tCOREF Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-2013.ann\n",
      "T1\tTask 36 106\tautomatically inducing a  Combinatory Categorial Grammar (CCG) lexicon\n",
      "T2\tOtherScientificTerm 62 106\tCombinatory Categorial Grammar (CCG) lexicon\n",
      "T3\tMaterial 116 143\tTurkish dependency treebank\n",
      "T4\tMaterial 161 168\tTurkish\n",
      "T5\tMaterial 177 215\tagglutinating free word order language\n",
      "T6\tMethod 243 260\tlanguage theories\n",
      "T7\tOtherScientificTerm 302 317\tcompact lexicon\n",
      "T8\tMethod 337 351\tCCG principles\n",
      "T9\tGeneric 362 370\ttreebank\n",
      "T10\tMaterial 417 425\tPenn WSJ\n",
      "R1\tPART-OF Arg1:T2 Arg2:T3\n",
      "R2\tHYPONYM-OF Arg1:T4 Arg2:T5\n",
      "R3\tCOMPARE Arg1:T9 Arg2:T10\n",
      "R4\tPART-OF Arg1:T7 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-2016.ann\n",
      "T1\tMethod 15 67\tCzech-English statistical machine translation system\n",
      "T2\tTask 85 136\ttree-to-tree translation  of  dependency structures\n",
      "T3\tMaterial 150 168\tbilingual resource\n",
      "T4\tMaterial 185 217\tsentence-aligned parallel corpus\n",
      "T5\tGeneric 328 334\tsystem\n",
      "T6\tGeneric 353 369\tbenchmark system\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R3\tCOMPARE Arg1:T5 Arg2:T6\n",
      "R4\tCOREF Arg1:T1 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-3001.ann\n",
      "T1\tMethod 16 31\tdialogue system\n",
      "T2\tMethod 115 145\tconcise,  modular architecture\n",
      "T3\tTask 177 190\tunderstanding\n",
      "T4\tTask 197 207\tgeneration\n",
      "T5\tMethod 214 250\tinformation-state model of reference\n",
      "T6\tOtherScientificTerm 281 290\tsemantics\n",
      "T7\tTask 297 326\tcollaborative problem solving\n",
      "R1\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-3025.ann\n",
      "T1\tGeneric 26 32\tmethod\n",
      "T2\tTask 37 105\tinteractively visualizing and directing the process  of  translating\n",
      "T3\tGeneric 124 130\tmethod\n",
      "T4\tGeneric 161 166\tmodel\n",
      "T5\tTask 172 221\tsyntax-based statistical machine translation (MT)\n",
      "T6\tGeneric 244 249\tmodel\n",
      "T7\tGeneric 295 297\tit\n",
      "T8\tMethod 308 318\tMT systems\n",
      "T9\tMethod 334 354\tvisualization method\n",
      "T10\tMethod 423 432\tMT system\n",
      "T11\tMethod 506 526\tsyntax-based decoder\n",
      "R1\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R6\tCOREF Arg1:T6 Arg2:T7\n",
      "R7\tCOMPARE Arg1:T7 Arg2:T8\n",
      "R8\tCOREF Arg1:T4 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-3030.ann\n",
      "T1\tGeneric 14 20\tmethod\n",
      "T2\tTask 24 52\torganizing reading materials\n",
      "T3\tTask 58 77\tvocabulary learning\n",
      "T4\tGeneric 80 82\tIt\n",
      "T5\tOtherScientificTerm 185 202\ttarget vocabulary\n",
      "T6\tMaterial 325 342\tEnglish Wikipedia\n",
      "T7\tMaterial 347 372\tfree-content encyclopedia\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R3\tCOREF Arg1:T1 Arg2:T4\n",
      "R4\tHYPONYM-OF Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-1012.ann\n",
      "T1\tOtherScientificTerm 74 86\tsense priors\n",
      "T2\tMetric 170 178\taccuracy\n",
      "T3\tMethod 183 222\tword sense disambiguation (WSD) systems\n",
      "T4\tGeneric 290 296\tmethod\n",
      "T5\tOtherScientificTerm 314 337\tsense priors  of  words\n",
      "T6\tMaterial 352 363\tnew  domain\n",
      "T7\tOtherScientificTerm 406 435\twell calibrated probabilities\n",
      "T8\tGeneric 460 471\testimations\n",
      "T9\tOtherScientificTerm 484 513\twell calibrated probabilities\n",
      "T10\tOtherScientificTerm 545 557\tsense priors\n",
      "T11\tMetric 611 623\tWSD accuracy\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R3\tEVALUATE-FOR Arg1:T2 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-1013.ann\n",
      "T1\tMethod 2 21\tCombination methods\n",
      "T2\tMethod 117 135\tsystem combination\n",
      "T3\tTask 142 158\tunsupervised WSD\n",
      "T4\tMethod 186 234\tvoting- and arbiter-based combination strategies\n",
      "T5\tMethod 260 284\tunsupervised WSD systems\n",
      "T6\tMethod 293 312\tcombination methods\n",
      "T7\tOtherScientificTerm 323 341\tpredominant senses\n",
      "T8\tMaterial 381 389\traw text\n",
      "T9\tMaterial 416 449\tSemCor  and  Senseval-3 data sets\n",
      "T10\tGeneric 472 481\tensembles\n",
      "T11\tGeneric 536 552\tstate-of-the-art\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R5\tCOREF Arg1:T6 Arg2:T10\n",
      "R6\tCOREF Arg1:T10 Arg2:T11\n",
      "R7\tEVALUATE-FOR Arg1:T9 Arg2:T10\n",
      "R8\tEVALUATE-FOR Arg1:T9 Arg2:T11\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-1018.ann\n",
      "T1\tMethod 34 56\tmathematical formalism\n",
      "T2\tGeneric 90 100\tstructures\n",
      "T3\tOtherScientificTerm 105 112\tstrings\n",
      "T4\tOtherScientificTerm 117 122\ttrees\n",
      "T5\tOtherScientificTerm 127 131\tdags\n",
      "T6\tOtherScientificTerm 136 142\tgraphs\n",
      "T7\tGeneric 162 166\tthem\n",
      "T8\tOtherScientificTerm 173 185\tpolarization\n",
      "T9\tOtherScientificTerm 210 231\telementary structures\n",
      "T10\tGeneric 291 300\tformalism\n",
      "T11\tMethod 367 385\tgrammar formalisms\n",
      "T12\tMethod 398 415\trewriting systems\n",
      "T13\tMethod 420 439\tdependency grammars\n",
      "T14\tOtherScientificTerm 444 447\tTAG\n",
      "T15\tOtherScientificTerm 452 456\tHPSG\n",
      "T16\tOtherScientificTerm 463 466\tLFG\n",
      "R1\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T4 Arg2:T2\n",
      "R3\tHYPONYM-OF Arg1:T5 Arg2:T2\n",
      "R4\tHYPONYM-OF Arg1:T6 Arg2:T2\n",
      "R5\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R6\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R7\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R8\tCOREF Arg1:T2 Arg2:T7\n",
      "R9\tCOREF Arg1:T1 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R11\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R12\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R13\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R14\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R15\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R16\tHYPONYM-OF Arg1:T13 Arg2:T11\n",
      "R17\tHYPONYM-OF Arg1:T14 Arg2:T11\n",
      "R18\tHYPONYM-OF Arg1:T15 Arg2:T11\n",
      "R19\tHYPONYM-OF Arg1:T16 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-1052.ann\n",
      "T1\tGeneric 25 34\talgorithm\n",
      "T2\tTask 44 74\tredundancy elimination problem\n",
      "T3\tMethod 88 132\tunderspecified semantic representation (USR)\n",
      "T4\tOtherScientificTerm 140 155\tscope ambiguity\n",
      "T5\tMethod 171 174\tUSR\n",
      "T6\tMaterial 197 216\tequivalent readings\n",
      "T7\tGeneric 224 233\talgorithm\n",
      "T8\tMethod 247 283\tunderspecified chart representations\n",
      "T9\tOtherScientificTerm 309 325\tdominance graphs\n",
      "T10\tGeneric 329 331\tit\n",
      "T11\tMethod 355 359\tUSRs\n",
      "T12\tMethod 374 394\tlarge-scale grammars\n",
      "T13\tGeneric 414 423\talgorithm\n",
      "T14\tGeneric 454 456\tit\n",
      "T15\tOtherScientificTerm 469 489\tdegree of  ambiguity\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T3 Arg2:T5\n",
      "R4\tCOREF Arg1:T13 Arg2:T14\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tCOREF Arg1:T1 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R9\tCOREF Arg1:T7 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R11\tCOREF Arg1:T3 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R13\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-1053.ann\n",
      "T1\tOtherScientificTerm 6 33\tpsycholinguistic literature\n",
      "T2\tOtherScientificTerm 58 75\tsyntactic priming\n",
      "T3\tGeneric 142 148\tmethod\n",
      "T4\tOtherScientificTerm 168 175\tpriming\n",
      "T5\tMethod 186 218\tincremental probabilistic parser\n",
      "T6\tOtherScientificTerm 263 270\tpriming\n",
      "T7\tOtherScientificTerm 276 281\trules\n",
      "T8\tOtherScientificTerm 336 357\tcoordinate structures\n",
      "T9\tOtherScientificTerm 414 433\tparallel structures\n",
      "T10\tMaterial 445 455\thuman data\n",
      "T11\tMetric 502 518\tparsing accuracy\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tPART-OF Arg1:T9 Arg2:T10\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R5\tCOREF Arg1:T2 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-1088.ann\n",
      "T1\tMetric 29 37\taccuracy\n",
      "T2\tMaterial 44 58\tnewspaper text\n",
      "T3\tTask 62 90\tpart of speech (pos) tagging\n",
      "T4\tMethod 177 183\tparser\n",
      "T5\tOtherScientificTerm 197 214\tpos tag ambiguity\n",
      "T6\tMethod 260 278\tgrammar formalisms\n",
      "T7\tOtherScientificTerm 296 331\tfine-grained grammatical categories\n",
      "T8\tOtherScientificTerm 347 350\ttag\n",
      "T9\tOtherScientificTerm 357 360\tccg\n",
      "T10\tMetric 364 380\ttagging accuracy\n",
      "T11\tGeneric 417 427\tformalisms\n",
      "T12\tOtherScientificTerm 430 461\tpremature  ambiguity resolution\n",
      "T13\tTask 470 477\tparsing\n",
      "T14\tMethod 506 528\tmulti-tagging approach\n",
      "T15\tOtherScientificTerm 567 593\tlexical category ambiguity\n",
      "T16\tTask 623 634\tccg parsing\n",
      "T17\tMethod 653 675\tmulti-tagging approach\n",
      "T18\tOtherScientificTerm 685 694\tpos level\n",
      "T19\tOtherScientificTerm 753 761\tpos tags\n",
      "T20\tMetric 774 794\tpos tagging accuracy\n",
      "T21\tOtherScientificTerm 826 843\tpos tag ambiguity\n",
      "T22\tMethod 853 881\tlanguage processing pipeline\n",
      "T23\tMethod 909 925\tccg supertagging\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R4\tEVALUATE-FOR Arg1:T1 Arg2:T3\n",
      "R5\tEVALUATE-FOR Arg1:T2 Arg2:T3\n",
      "R6\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R7\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R8\tEVALUATE-FOR Arg1:T10 Arg2:T6\n",
      "R9\tCOREF Arg1:T6 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T13 Arg2:T11\n",
      "R11\tFEATURE-OF Arg1:T15 Arg2:T14\n",
      "R12\tCOREF Arg1:T14 Arg2:T17\n",
      "R13\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R14\tFEATURE-OF Arg1:T21 Arg2:T22\n",
      "R15\tUSED-FOR Arg1:T21 Arg2:T23\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-1112.ann\n",
      "T1\tOtherScientificTerm 27 68\tcorrelation of  dependency relation paths\n",
      "T2\tTask 100 117\tanswer extraction\n",
      "T3\tMetric 131 150\tcorrelation measure\n",
      "T4\tOtherScientificTerm 165 185\tdependency relations\n",
      "T5\tMethod 349 385\tapproximate phrase mapping algorithm\n",
      "T6\tOtherScientificTerm 408 421\tmapping score\n",
      "T7\tMetric 433 452\tcorrelation measure\n",
      "T8\tGeneric 459 471\tcorrelations\n",
      "T9\tMethod 505 540\tMaximum Entropy-based ranking model\n",
      "T10\tGeneric 623 629\tmethod\n",
      "T11\tMethod 674 706\tsyntactic relation-based methods\n",
      "T12\tMetric 725 728\tMRR\n",
      "R1\tPART-OF Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T1 Arg2:T8\n",
      "R5\tPART-OF Arg1:T8 Arg2:T9\n",
      "R6\tCOMPARE Arg1:T10 Arg2:T11\n",
      "R7\tEVALUATE-FOR Arg1:T12 Arg2:T11\n",
      "R8\tEVALUATE-FOR Arg1:T12 Arg2:T10\n",
      "R9\tCOREF Arg1:T5 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-2001.ann\n",
      "T1\tMethod 48 75\tmachine learning techniques\n",
      "T2\tMethod 89 102\tcomma checker\n",
      "T3\tMethod 127 142\tgrammar checker\n",
      "T4\tMaterial 149 155\tBasque\n",
      "T5\tGeneric 246 252\tsystem\n",
      "T6\tMetric 300 309\tprecision\n",
      "T7\tMetric 325 331\trecall\n",
      "T8\tGeneric 341 343\tIt\n",
      "T9\tMetric 357 366\tprecision\n",
      "T10\tMetric 382 388\trecall\n",
      "T11\tTask 412 427\tplacing  commas\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tPART-OF Arg1:T2 Arg2:T3\n",
      "R4\tCOREF Arg1:T2 Arg2:T5\n",
      "R5\tEVALUATE-FOR Arg1:T6 Arg2:T5\n",
      "R6\tEVALUATE-FOR Arg1:T7 Arg2:T5\n",
      "R7\tCOREF Arg1:T8 Arg2:T5\n",
      "R8\tEVALUATE-FOR Arg1:T9 Arg2:T8\n",
      "R9\tEVALUATE-FOR Arg1:T10 Arg2:T8\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-2012.ann\n",
      "T1\tMethod 25 55\tunsupervised learning approach\n",
      "T2\tOtherScientificTerm 81 114\trelations between  named entities\n",
      "T3\tOtherScientificTerm 135 165\tlexical and syntactic features\n",
      "T4\tGeneric 189 191\tIt\n",
      "T5\tOtherScientificTerm 214 226\teigenvectors\n",
      "T6\tOtherScientificTerm 235 265\tadjacency graph  's  Laplacian\n",
      "T7\tOtherScientificTerm 281 292\tsubmanifold\n",
      "T8\tOtherScientificTerm 310 335\thigh dimensionality space\n",
      "T9\tTask 358 383\tcluster number estimation\n",
      "T10\tOtherScientificTerm 393 405\teigenvectors\n",
      "T11\tMaterial 432 443\tACE corpora\n",
      "T12\tMethod 461 495\tspectral clustering based approach\n",
      "T13\tMethod 520 538\tclustering methods\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R2\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R3\tCOREF Arg1:T1 Arg2:T4\n",
      "R4\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T7\n",
      "R7\tCOREF Arg1:T5 Arg2:T10\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R9\tEVALUATE-FOR Arg1:T11 Arg2:T12\n",
      "R10\tEVALUATE-FOR Arg1:T11 Arg2:T13\n",
      "R11\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R12\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R13\tUSED-FOR Arg1:T9 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-2059.ann\n",
      "T1\tGeneric 29 35\tmethod\n",
      "T2\tTask 39 71\tbuilding  polarity-tagged corpus\n",
      "T3\tMaterial 79 93\tHTML documents\n",
      "T4\tGeneric 125 131\tmethod\n",
      "T5\tGeneric 140 142\tit\n",
      "T6\tMaterial 195 209\tHTML documents\n",
      "T7\tGeneric 233 239\tmethod\n",
      "T8\tOtherScientificTerm 263 280\tlayout structures\n",
      "T9\tOtherScientificTerm 287 305\tlinguistic pattern\n",
      "T10\tGeneric 318 322\tthem\n",
      "T11\tGeneric 415 421\tmethod\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T1 Arg2:T4\n",
      "R4\tCOREF Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R6\tCOREF Arg1:T3 Arg2:T6\n",
      "R7\tCOREF Arg1:T4 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T7\n",
      "R10\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R11\tHYPONYM-OF Arg1:T8 Arg2:T10\n",
      "R12\tHYPONYM-OF Arg1:T9 Arg2:T10\n",
      "R13\tCOREF Arg1:T7 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-2067.ann\n",
      "T1\tMethod 66 84\tstatistical parser\n",
      "T2\tTask 103 139\tparsing  written and spoken language\n",
      "T3\tMaterial 112 139\twritten and spoken language\n",
      "T4\tTask 148 183\tgenerating  sub-categorization cues\n",
      "T5\tMaterial 191 218\twritten and spoken language\n",
      "T6\tMethod 231 245\tBikel's parser\n",
      "T7\tMetric 266 274\taccuracy\n",
      "T8\tTask 280 305\tparsing  written language\n",
      "T9\tMaterial 289 305\twritten language\n",
      "T10\tGeneric 308 310\tit\n",
      "T11\tMetric 330 338\taccuracy\n",
      "T12\tOtherScientificTerm 357 379\tsubcategorization cues\n",
      "T13\tMaterial 387 402\tspoken language\n",
      "T14\tGeneric 444 454\ttechnology\n",
      "T15\tTask 460 495\textracting subcategorization frames\n",
      "T16\tMaterial 521 534\twritten texts\n",
      "T17\tMaterial 560 575\tspoken language\n",
      "T18\tOtherScientificTerm 619 630\tpunctuation\n",
      "T19\tMethod 644 651\tparsing\n",
      "T20\tTask 658 696\textraction  of  subcategorization cues\n",
      "T21\tOtherScientificTerm 726 737\tpunctuation\n",
      "T22\tTask 760 784\tparsing  spoken language\n",
      "T23\tMaterial 769 784\tspoken language\n",
      "T24\tTask 790 824\textracting  subcategorization cues\n",
      "T25\tOtherScientificTerm 802 824\tsubcategorization cues\n",
      "T26\tMaterial 832 847\tspoken language\n",
      "T27\tOtherScientificTerm 895 906\tpunctuation\n",
      "T28\tMaterial 925 939\tspoken corpora\n",
      "T29\tMethod 966 973\tparsers\n",
      "R1\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R2\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R3\tPART-OF Arg1:T25 Arg2:T26\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R6\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R7\tCOREF Arg1:T1 Arg2:T6\n",
      "R8\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R9\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R10\tCOREF Arg1:T6 Arg2:T10\n",
      "R11\tEVALUATE-FOR Arg1:T11 Arg2:T10\n",
      "R12\tPART-OF Arg1:T12 Arg2:T13\n",
      "R13\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R14\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R15\tUSED-FOR Arg1:T14 Arg2:T17\n",
      "R16\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R17\tUSED-FOR Arg1:T18 Arg2:T20\n",
      "R18\tCONJUNCTION Arg1:T2 Arg2:T4\n",
      "R19\tUSED-FOR Arg1:T26 Arg2:T24\n",
      "R20\tCONJUNCTION Arg1:T22 Arg2:T24\n",
      "R21\tCOREF Arg1:T3 Arg2:T5\n",
      "R22\tCOREF Arg1:T23 Arg2:T13\n",
      "R23\tHYPONYM-OF Arg1:T9 Arg2:T5\n",
      "R24\tHYPONYM-OF Arg1:T23 Arg2:T5\n",
      "R25\tCOREF Arg1:T23 Arg2:T26\n",
      "R26\tCOREF Arg1:T17 Arg2:T26\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-2110.ann\n",
      "T1\tOtherScientificTerm 37 63\tsimilarity  between  words\n",
      "T2\tOtherScientificTerm 101 113\tword vectors\n",
      "T3\tMethod 123 141\tvector space model\n",
      "T4\tGeneric 177 184\tmethods\n",
      "T5\tTask 189 214\tconstructing word vectors\n",
      "T6\tMethod 225 283\tLSA-based, cooccurrence-based and dictionary-based methods\n",
      "T7\tGeneric 352 362\tsimilarity\n",
      "T8\tOtherScientificTerm 373 393\ttaxonomic similarity\n",
      "T9\tOtherScientificTerm 400 422\tassociative similarity\n",
      "T10\tOtherScientificTerm 469 498\tdictionary-based word vectors\n",
      "T11\tOtherScientificTerm 516 536\ttaxonomic similarity\n",
      "T12\tOtherScientificTerm 551 600\tLSA-based and the cooccurrence-based word vectors\n",
      "T13\tOtherScientificTerm 618 640\tassociative similarity\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R3\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R4\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R7\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R8\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R9\tCOREF Arg1:T6 Arg2:T4\n",
      "R10\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-3007.ann\n",
      "T1\tMethod 18 106\tindependent and relevant event-based extractive  mutli-document summarization approaches\n",
      "T2\tMethod 202 222\tindependent approach\n",
      "T3\tMethod 289 306\trelevant approach\n",
      "T4\tMethod 343 361\tPageRank algorithm\n",
      "T5\tOtherScientificTerm 371 380\tevent map\n",
      "T6\tMaterial 400 409\tdocuments\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-3008.ann\n",
      "T1\tOtherScientificTerm 7 27\trhetorical structure\n",
      "T2\tOtherScientificTerm 34 45\tpunctuation\n",
      "T3\tTask 69 89\tdiscourse processing\n",
      "T4\tTask 104 129\tcorpus annotation project\n",
      "T5\tTask 156 205\tdiscursive usage  of 6  Chinese punctuation marks\n",
      "T6\tOtherScientificTerm 180 205\tChinese punctuation marks\n",
      "T7\tMaterial 211 232\tnews commentary texts\n",
      "T8\tOtherScientificTerm 236 241\tColon\n",
      "T9\tOtherScientificTerm 245 249\tDash\n",
      "T10\tOtherScientificTerm 253 261\tEllipsis\n",
      "T11\tOtherScientificTerm 265 281\tExclamation Mark\n",
      "T12\tOtherScientificTerm 285 298\tQuestion Mark\n",
      "T13\tOtherScientificTerm 306 315\tSemicolon\n",
      "T14\tOtherScientificTerm 323 342\trhetorical patterns\n",
      "T15\tGeneric 353 358\tmarks\n",
      "T16\tOtherScientificTerm 381 410\tpatterns  around  cue phrases\n",
      "T17\tOtherScientificTerm 449 474\tChinese punctuation marks\n",
      "T18\tOtherScientificTerm 506 517\tcue phrases\n",
      "T19\tOtherScientificTerm 621 645\tindicators of nuclearity\n",
      "T20\tMaterial 650 663\tChinese texts\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tCOMPARE Arg1:T17 Arg2:T18\n",
      "R3\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R5\tPART-OF Arg1:T6 Arg2:T7\n",
      "R6\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R7\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R8\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R9\tHYPONYM-OF Arg1:T8 Arg2:T6\n",
      "R10\tHYPONYM-OF Arg1:T9 Arg2:T6\n",
      "R11\tHYPONYM-OF Arg1:T10 Arg2:T6\n",
      "R12\tHYPONYM-OF Arg1:T11 Arg2:T6\n",
      "R13\tHYPONYM-OF Arg1:T12 Arg2:T6\n",
      "R14\tHYPONYM-OF Arg1:T13 Arg2:T6\n",
      "R16\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R17\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R18\tCOREF Arg1:T6 Arg2:T15\n",
      "R19\tFEATURE-OF Arg1:T14 Arg2:T15\n",
      "R20\tCOMPARE Arg1:T14 Arg2:T16\n",
      "R21\tCOREF Arg1:T17 Arg2:T15\n",
      "R22\tFEATURE-OF Arg1:T20 Arg2:T19\n",
      "R23\tUSED-FOR Arg1:T17 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-4007.ann\n",
      "T1\tMethod 25 31\tFERRET\n",
      "T2\tMethod 39 82\tinteractive question-answering (Q/A) system\n",
      "T3\tTask 122 191\tintegrating  automatic Q/A  applications into real-world environments\n",
      "T4\tMethod 194 200\tFERRET\n",
      "T5\tGeneric 219 227\tapproach\n",
      "T6\tMethod 232 235\tQ/A\n",
      "T7\tMethod 247 269\tpredictive questioning\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T4 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R5\tCOREF Arg1:T7 Arg2:T5\n",
      "R6\tCOREF Arg1:T2 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-4011.ann\n",
      "T1\tGeneric 27 33\tmethod\n",
      "T2\tTask 39 80\tcomputational analysis of move structures\n",
      "T3\tMaterial 86 118\tabstracts  of  research articles\n",
      "T4\tGeneric 129 137\tapproach\n",
      "T5\tOtherScientificTerm 242 262\trhetorical functions\n",
      "T6\tGeneric 270 276\tmethod\n",
      "T7\tMaterial 329 338\tabstracts\n",
      "T8\tMaterial 350 353\tWeb\n",
      "T9\tMethod 371 385\tlanguage model\n",
      "T10\tMaterial 391 405\tabstract moves\n",
      "T11\tMethod 427 450\tprototype  concordancer\n",
      "T12\tMethod 455 459\tCARE\n",
      "T13\tMaterial 483 504\tmove-tagged abstracts\n",
      "T14\tTask 511 527\tdigital learning\n",
      "T15\tGeneric 536 542\tsystem\n",
      "T16\tGeneric 564 572\tapproach\n",
      "T17\tTask 577 621\tWeb-based computer-assisted academic writing\n",
      "R1\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R2\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R5\tCOREF Arg1:T1 Arg2:T4\n",
      "R6\tCOREF Arg1:T4 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R10\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R11\tCOREF Arg1:T15 Arg2:T12\n",
      "R12\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-4014.ann\n",
      "T1\tMethod 8 29\tLOGON MT demonstrator\n",
      "T2\tMethod 65 95\tgeneral-purpose NLP components\n",
      "T3\tMethod 105 133\tmachine translation pipeline\n",
      "T4\tTask 178 190\tdemonstrator\n",
      "T5\tMaterial 231 261\thand-built, symbolic resources\n",
      "T6\tMethod 268 288\tstochastic processes\n",
      "R1\tPART-OF Arg1:T2 Arg2:T3\n",
      "R2\tCOREF Arg1:T1 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R5\tPART-OF Arg1:T5 Arg2:T4\n",
      "R6\tPART-OF Arg1:T6 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P08-1105.ann\n",
      "T1\tTask 2 29\tTopical blog post retrieval\n",
      "T2\tTask 46 65\tranking  blog posts\n",
      "T3\tMaterial 55 65\tblog posts\n",
      "T4\tMetric 90 99\trelevance\n",
      "T5\tTask 134 161\ttopical blog post retrieval\n",
      "T6\tOtherScientificTerm 179 209\ttextual credibility indicators\n",
      "T7\tMethod 219 236\tretrieval process\n",
      "T8\tGeneric 266 276\tindicators\n",
      "T9\tMaterial 338 348\tblog posts\n",
      "T10\tMaterial 422 427\tblogs\n",
      "T11\tGeneric 466 476\tindicators\n",
      "T12\tGeneric 499 503\tthem\n",
      "T13\tMethod 512 530\tretrieval approach\n",
      "T14\tMethod 542 557\tlanguage models\n",
      "T15\tMaterial 580 604\tTREC Blog track test set\n",
      "T16\tOtherScientificTerm 632 654\tcredibility indicators\n",
      "T17\tMetric 679 702\tretrieval effectiveness\n",
      "R1\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T1 Arg2:T5\n",
      "R5\tPART-OF Arg1:T6 Arg2:T7\n",
      "R6\tCOREF Arg1:T6 Arg2:T8\n",
      "R7\tCOREF Arg1:T8 Arg2:T11\n",
      "R8\tCOREF Arg1:T11 Arg2:T12\n",
      "R9\tPART-OF Arg1:T12 Arg2:T13\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R11\tCOREF Arg1:T11 Arg2:T16\n",
      "R12\tEVALUATE-FOR Arg1:T17 Arg2:T16\n",
      "R13\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P08-2034.ann\n",
      "T1\tTask 2 43\tLyric-based song sentiment classification\n",
      "T2\tMethod 157 216\tvector space model (VSM)-based text classification approach\n",
      "T3\tMaterial 255 266\tsong lyrics\n",
      "T4\tOtherScientificTerm 299 308\tsentiment\n",
      "T5\tOtherScientificTerm 381 390\tNegations\n",
      "T6\tOtherScientificTerm 397 406\tmodifiers\n",
      "T7\tOtherScientificTerm 420 438\tsentiment keywords\n",
      "T8\tOtherScientificTerm 474 483\tsentiment\n",
      "T9\tMaterial 490 500\tSong lyric\n",
      "T10\tMethod 557 593\tsentiment vector space model (s-VSM)\n",
      "T11\tMaterial 621 640\tsong lyric document\n",
      "T12\tMethod 687 698\ts-VSM model\n",
      "T13\tMethod 717 726\tVSM model\n",
      "T14\tTask 736 782\tlyric-based song sentiment classification task\n",
      "R1\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R2\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R3\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T8\n",
      "R6\tCOREF Arg1:T3 Arg2:T9\n",
      "R7\tCOREF Arg1:T10 Arg2:T12\n",
      "R8\tEVALUATE-FOR Arg1:T14 Arg2:T12\n",
      "R9\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P80-1004.ann\n",
      "T1\tTask 3 26\tInterpreting  metaphors\n",
      "T2\tTask 71 110\thuman understanding of natural language\n",
      "T3\tGeneric 138 144\tmethod\n",
      "T4\tTask 148 167\tanalyzing metaphors\n",
      "T5\tMethod 214 243\tgeneralized metaphor mappings\n",
      "T6\tOtherScientificTerm 253 273\tgeneralized metaphor\n",
      "T7\tMethod 287 306\trecognition network\n",
      "T8\tMethod 313 326\tbasic mapping\n",
      "T9\tMethod 342 359\ttransfer mappings\n",
      "T10\tMethod 371 399\timplicit intention component\n",
      "T11\tGeneric 425 431\tmethod\n",
      "T12\tTask 441 464\tmetaphor interpretation\n",
      "T13\tTask 474 488\treconstruction\n",
      "T14\tTask 496 512\trecognition task\n",
      "T15\tTask 568 585\tlanguage learning\n",
      "R1\tPART-OF Arg1:T7 Arg2:T6\n",
      "R2\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R5\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R6\tCONJUNCTION Arg1:T9 Arg2:T8\n",
      "R7\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R8\tPART-OF Arg1:T8 Arg2:T6\n",
      "R9\tPART-OF Arg1:T9 Arg2:T6\n",
      "R10\tPART-OF Arg1:T10 Arg2:T6\n",
      "R11\tCOREF Arg1:T3 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R13\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R14\tCOREF Arg1:T12 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P80-1019.ann\n",
      "T1\tOtherScientificTerm 12 39\tnatural language interfaces\n",
      "T2\tMethod 148 156\tdecoding\n",
      "T3\tOtherScientificTerm 220 247\tnatural language interfaces\n",
      "T4\tGeneric 298 302\tthey\n",
      "T5\tMethod 330 366\tnon-literal aspects of communication\n",
      "T6\tMethod 378 410\trobust  communication procedures\n",
      "T7\tMethod 546 582\tnon-literal aspects of communication\n",
      "T8\tOtherScientificTerm 623 641\tpersonal computers\n",
      "T9\tOtherScientificTerm 658 675\tgraphics displays\n",
      "T10\tOtherScientificTerm 928 955\tnatural language interfaces\n",
      "R1\tPART-OF Arg1:T9 Arg2:T8\n",
      "R2\tCOREF Arg1:T3 Arg2:T4\n",
      "R3\tPART-OF Arg1:T5 Arg2:T4\n",
      "R4\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P80-1026.ann\n",
      "T1\tOtherScientificTerm 19 35\tnatural language\n",
      "T2\tGeneric 73 75\tit\n",
      "T3\tMethod 284 299\tcomputer system\n",
      "T4\tOtherScientificTerm 319 341\tnatural language input\n",
      "T5\tOtherScientificTerm 456 477\tparsing flexibilities\n",
      "T6\tGeneric 491 497\tsystem\n",
      "T7\tMethod 537 542\tFlexP\n",
      "T8\tMethod 549 582\tbottom-up pattern-matching parser\n",
      "T9\tGeneric 639 652\tflexibilities\n",
      "T10\tOtherScientificTerm 658 685\trestricted natural language\n",
      "T11\tMethod 698 728\tlimited-domain computer system\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T6\n",
      "R3\tHYPONYM-OF Arg1:T7 Arg2:T8\n",
      "R4\tCOREF Arg1:T5 Arg2:T9\n",
      "R5\tFEATURE-OF Arg1:T9 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R8\tPART-OF Arg1:T9 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P81-1032.ann\n",
      "T1\tTask 9 40\tnatural language interpretation\n",
      "T2\tMethod 59 81\tsemantic domain models\n",
      "T3\tMethod 85 114\tfail-soft recovery heuristics\n",
      "T4\tOtherScientificTerm 136 154\tcontrol structures\n",
      "T5\tMethod 167 190\tsingle-strategy parsers\n",
      "T6\tMethod 231 254\tmulti-strategy approach\n",
      "T7\tOtherScientificTerm 347 377\ttask-specific domain knowledge\n",
      "T8\tOtherScientificTerm 396 424\tgeneral linguistic knowledge\n",
      "T9\tOtherScientificTerm 444 479\tgrammatical and ungrammatical input\n",
      "T10\tMethod 485 502\tparsing algorithm\n",
      "T11\tMethod 552 570\tparsing strategies\n",
      "T12\tOtherScientificTerm 579 603\tcase-frame instantiation\n",
      "T13\tMethod 632 650\tparsing strategies\n",
      "T14\tOtherScientificTerm 764 776\tconjunctions\n",
      "T15\tOtherScientificTerm 780 797\tfragmentary input\n",
      "T16\tOtherScientificTerm 805 829\tungrammatical structures\n",
      "T17\tOtherScientificTerm 848 884\texotic,  grammatically correct input\n",
      "T18\tMethod 896 915\tspecific heuristics\n",
      "T19\tOtherScientificTerm 931 950\tungrammatical input\n",
      "T20\tMethod 979 1003\tmulti-strategy framework\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R3\tPART-OF Arg1:T11 Arg2:T10\n",
      "R4\tPART-OF Arg1:T18 Arg2:T20\n",
      "R5\tCOREF Arg1:T11 Arg2:T13\n",
      "R6\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R7\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R8\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R9\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R10\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R11\tCOMPARE Arg1:T5 Arg2:T6\n",
      "R12\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R13\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R14\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R15\tUSED-FOR Arg1:T13 Arg2:T16\n",
      "R16\tUSED-FOR Arg1:T13 Arg2:T17\n",
      "R17\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R18\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R19\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R20\tCOREF Arg1:T6 Arg2:T20\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P81-1033.ann\n",
      "T1\tMethod 4 19\tflexible parser\n",
      "T2\tGeneric 113 115\tit\n",
      "T3\tMethod 134 140\tparser\n",
      "T4\tOtherScientificTerm 431 440\tambiguity\n",
      "T5\tMethod 500 506\tparser\n",
      "T6\tMethod 687 717\tconstruction-specific approach\n",
      "T7\tTask 723 739\tflexible parsing\n",
      "T8\tMethod 748 778\tspecialized parsing techniques\n",
      "T9\tTask 798 810\tconstruction\n",
      "T10\tMethod 830 855\tambiguity representations\n",
      "T11\tOtherScientificTerm 875 884\tambiguity\n",
      "T12\tTask 905 917\tconstruction\n",
      "T13\tMethod 940 970\tconstruction-specific approach\n",
      "T14\tTask 986 1020\ttask-specific language development\n",
      "T15\tMethod 1159 1184\tuniform grammar formalism\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R4\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R5\tCOREF Arg1:T1 Arg2:T2\n",
      "R6\tCOREF Arg1:T1 Arg2:T3\n",
      "R7\tCOREF Arg1:T3 Arg2:T5\n",
      "R8\tCONJUNCTION Arg1:T6 Arg2:T8\n",
      "R9\tCONJUNCTION Arg1:T8 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P83-1003.ann\n",
      "T1\tGeneric 4 13\textension\n",
      "T2\tMethod 22 48\tGPSG grammatical formalism\n",
      "T3\tOtherScientificTerm 73 86\tnon-terminals\n",
      "T4\tOtherScientificTerm 155 174\tschematic variables\n",
      "T5\tGeneric 210 219\textension\n",
      "T6\tMethod 278 285\tgrammar\n",
      "T7\tOtherScientificTerm 292 319\tcrossed serial dependencies\n",
      "T8\tOtherScientificTerm 340 365\tDutch subordinate clauses\n",
      "T9\tTask 401 414\tconstructions\n",
      "T10\tGeneric 526 535\textension\n",
      "T11\tGeneric 573 582\textension\n",
      "T12\tMethod 599 613\tparsing method\n",
      "T13\tMethod 620 624\tGPSG\n",
      "R1\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R2\tCOREF Arg1:T1 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R4\tCOREF Arg1:T5 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R7\tCOREF Arg1:T2 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P83-1004.ann\n",
      "T1\tMethod 2 28\tMetagrammatical formalisms\n",
      "T2\tOtherScientificTerm 44 79\tcontext-free phrase structure rules\n",
      "T3\tOtherScientificTerm 86 110\tmetarules (MPS grammars)\n",
      "T4\tOtherScientificTerm 166 195\tsyntax  of  natural languages\n",
      "T5\tMethod 199 225\tUnconstrained MPS grammars\n",
      "T6\tGeneric 320 324\tthem\n",
      "T7\tMetric 352 403\tcomputational tractability and explanatory adequacy\n",
      "T8\tGeneric 427 431\tthem\n",
      "T9\tGeneric 447 455\tcriteria\n",
      "T10\tMethod 513 539\tmetagrammatical formalisms\n",
      "R1\tPART-OF Arg1:T2 Arg2:T1\n",
      "R2\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R3\tPART-OF Arg1:T3 Arg2:T1\n",
      "R4\tCOREF Arg1:T5 Arg2:T6\n",
      "R5\tCOREF Arg1:T6 Arg2:T8\n",
      "R6\tCOREF Arg1:T7 Arg2:T9\n",
      "R7\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P84-1020.ann\n",
      "T1\tMethod 30 53\tnatural language system\n",
      "T2\tOtherScientificTerm 82 101\tungrammatical input\n",
      "T3\tGeneric 159 161\tit\n",
      "T4\tTask 166 205\tcomputer aided second language learning\n",
      "T5\tGeneric 218 222\tthis\n",
      "T6\tGeneric 275 281\tsystem\n",
      "T7\tGeneric 321 323\tit\n",
      "T8\tGeneric 446 448\tit\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T1 Arg2:T6\n",
      "R5\tCOREF Arg1:T4 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R7\tCOREF Arg1:T6 Arg2:T7\n",
      "R8\tCOREF Arg1:T7 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P84-1047.ann\n",
      "T1\tMethod 7 31\tentity-oriented approach\n",
      "T2\tTask 35 60\trestricted-domain parsing\n",
      "T3\tGeneric 83 91\tapproach\n",
      "T4\tOtherScientificTerm 117 176\tstructure  and  surface representation  of  domain entities\n",
      "T5\tMethod 206 222\tsemantic grammar\n",
      "T6\tGeneric 226 230\tthis\n",
      "T7\tOtherScientificTerm 260 284\tlimited domain semantics\n",
      "T8\tGeneric 301 303\tit\n",
      "T9\tTask 317 340\tfragmentary recognition\n",
      "T10\tMethod 358 385\tmultiple parsing strategies\n",
      "T11\tOtherScientificTerm 431 469\trecognition of extra-grammatical input\n",
      "T12\tOtherScientificTerm 588 623\tentity-oriented language definition\n",
      "T13\tOtherScientificTerm 654 671\tcontrol structure\n",
      "T14\tMethod 681 703\tentity-oriented parser\n",
      "T15\tMethod 713 731\tparsing strategies\n",
      "T16\tOtherScientificTerm 747 764\tcontrol structure\n",
      "T17\tMethod 805 811\tparser\n",
      "T18\tOtherScientificTerm 832 849\tcontrol structure\n",
      "T19\tMethod 860 878\tparsing strategies\n",
      "R1\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R2\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R3\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R4\tPART-OF Arg1:T18 Arg2:T17\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tCOREF Arg1:T6 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R10\tCOREF Arg1:T16 Arg2:T13\n",
      "R11\tCOREF Arg1:T18 Arg2:T16\n",
      "R12\tCOREF Arg1:T19 Arg2:T15\n",
      "R14\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R15\tCOREF Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P84-1078.ann\n",
      "T1\tMethod 26 30\tPaul\n",
      "T2\tMethod 37 68\tcomputer text generation system\n",
      "T3\tMaterial 90 103\tcohesive text\n",
      "T4\tOtherScientificTerm 125 146\tlexical substitutions\n",
      "T5\tGeneric 169 175\tsystem\n",
      "T6\tOtherScientificTerm 225 242\tpronominalization\n",
      "T7\tOtherScientificTerm 247 273\tsuperordinate substitution\n",
      "T8\tOtherScientificTerm 281 314\tdefinite  noun phrase reiteration\n",
      "T9\tGeneric 322 328\tsystem\n",
      "T10\tTask 355 375\tantecedence recovery\n",
      "T11\tOtherScientificTerm 394 415\tlexical substitutions\n",
      "R1\tCOMPARE Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R3\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R5\tCOREF Arg1:T1 Arg2:T5\n",
      "R6\tCOREF Arg1:T5 Arg2:T9\n",
      "R7\tCOMPARE Arg1:T7 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P85-1019.ann\n",
      "T1\tMethod 24 48\trestricted domain parser\n",
      "T2\tMethod 58 63\tPlume\n",
      "T3\tMethod 139 155\tPlume's approach\n",
      "T4\tTask 159 166\tparsing\n",
      "T5\tOtherScientificTerm 181 213\tsemantic caseframe instantiation\n",
      "T6\tOtherScientificTerm 260 277\tgrammatical input\n",
      "T7\tMetric 285 295\trobustness\n",
      "T8\tOtherScientificTerm 313 332\tungrammatical input\n",
      "T9\tMethod 342 347\tPlume\n",
      "T10\tMaterial 376 413\tdeclarative and imperative utterances\n",
      "T11\tGeneric 416 418\tit\n",
      "T12\tOtherScientificTerm 428 436\tpassives\n",
      "T13\tOtherScientificTerm 440 456\trelative clauses\n",
      "T14\tOtherScientificTerm 463 477\tinterrogatives\n",
      "T15\tOtherScientificTerm 510 536\tpatchy  syntactic coverage\n",
      "T16\tMethod 560 565\tPlume\n",
      "T17\tGeneric 570 572\tit\n",
      "T18\tMethod 639 644\tPlume\n",
      "T19\tOtherScientificTerm 657 665\tpassives\n",
      "T20\tOtherScientificTerm 669 685\trelative clauses\n",
      "T21\tOtherScientificTerm 693 707\tinterrogatives\n",
      "R1\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T3\n",
      "R5\tCOREF Arg1:T3 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R7\tCOREF Arg1:T9 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R10\tUSED-FOR Arg1:T11 Arg2:T14\n",
      "R11\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R12\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R13\tCOREF Arg1:T9 Arg2:T16\n",
      "R14\tCOREF Arg1:T16 Arg2:T17\n",
      "R15\tCOREF Arg1:T17 Arg2:T18\n",
      "R16\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R17\tUSED-FOR Arg1:T18 Arg2:T20\n",
      "R18\tUSED-FOR Arg1:T18 Arg2:T21\n",
      "R19\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R20\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R21\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P86-1011.ann\n",
      "T1\tMethod 48 70\tgrammatical formalisms\n",
      "T2\tMethod 75 98\tTree Adjoining Grammars\n",
      "T3\tMethod 105 118\tHead Grammars\n",
      "T4\tGeneric 180 190\tformalisms\n",
      "T5\tOtherScientificTerm 238 263\tlinguistic expressiveness\n",
      "T6\tGeneric 277 287\tformalisms\n",
      "R1\tCOMPARE Arg1:T2 Arg2:T3\n",
      "R2\tFEATURE-OF Arg1:T5 Arg2:T6\n",
      "R3\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R4\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R5\tCOREF Arg1:T1 Arg2:T4\n",
      "R6\tCOREF Arg1:T4 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W02-1403.ann\n",
      "T1\tTask 2 25\tTerminology structuring\n",
      "T2\tMaterial 193 199\tcorpus\n",
      "T3\tOtherScientificTerm 215 257\thierarchical (or other types of) relations\n",
      "T4\tTask 313 336\tterminology structuring\n",
      "T5\tMethod 342 357\tlexical methods\n",
      "T6\tOtherScientificTerm 427 449\tmorphological variants\n",
      "T7\tMaterial 543 580\thierarchically-structured terminology\n",
      "T8\tMaterial 610 656\tUS National Library of Medicine MeSH thesaurus\n",
      "T9\tOtherScientificTerm 675 702\tlexically-induced relations\n",
      "T10\tOtherScientificTerm 723 737\tMeSH relations\n",
      "T11\tMetric 801 829\trecall and precision metrics\n",
      "T12\tOtherScientificTerm 917 921\tMeSH\n",
      "T13\tMethod 981 1007\tlexical structuring method\n",
      "T14\tOtherScientificTerm 1117 1121\tMeSH\n",
      "T15\tTask 1197 1218\tautomatic structuring\n",
      "R1\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tCOREF Arg1:T12 Arg2:T10\n",
      "R4\tCOMPARE Arg1:T9 Arg2:T10\n",
      "R5\tEVALUATE-FOR Arg1:T11 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W02-1404.ann\n",
      "T1\tMethod 30 58\tknowledge-independent method\n",
      "T2\tMaterial 124 153\tsmall, domain-specific corpus\n",
      "T3\tMaterial 170 214\tparallel English and Chinese court judgments\n",
      "T4\tMaterial 240 263\tsentence-aligned corpus\n",
      "T5\tOtherScientificTerm 267 291\ttranslation equivalences\n",
      "T6\tGeneric 325 343\tfrequency profiles\n",
      "T7\tOtherScientificTerm 349 370\tparallel concordances\n",
      "T8\tGeneric 377 383\tmethod\n",
      "T9\tMethod 427 446\tstatistical methods\n",
      "T10\tMaterial 463 476\tlarge corpora\n",
      "T11\tMethod 500 518\tlexical approaches\n",
      "T12\tMaterial 546 568\tbilingual dictionaries\n",
      "T13\tMaterial 591 606\tparallel corpus\n",
      "T14\tMetric 689 698\tprecision\n",
      "T15\tMetric 709 715\trecall\n",
      "T16\tGeneric 756 765\talgorithm\n",
      "T17\tOtherScientificTerm 817 836\ttranslation lexicon\n",
      "T18\tMaterial 843 860\tlegal terminology\n",
      "R1\tPART-OF Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R3\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R4\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R5\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R6\tPART-OF Arg1:T3 Arg2:T2\n",
      "R7\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R8\tCOREF Arg1:T8 Arg2:T1\n",
      "R9\tCOMPARE Arg1:T8 Arg2:T9\n",
      "R10\tCOMPARE Arg1:T8 Arg2:T11\n",
      "R11\tCOREF Arg1:T16 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W02-1602.ann\n",
      "T1\tTask 2 11\tCoedition\n",
      "T2\tMaterial 19 40\tnatural language text\n",
      "T3\tOtherScientificTerm 135 148\ttext revision\n",
      "T4\tMaterial 158 167\tlanguages\n",
      "T5\tOtherScientificTerm 192 202\tUNL graphs\n",
      "T6\tOtherScientificTerm 428 433\tgraph\n",
      "T7\tOtherScientificTerm 450 455\tgraph\n",
      "T8\tMethod 478 496\tUNL-L0 deconverter\n",
      "T9\tOtherScientificTerm 580 585\tgraph\n",
      "T10\tMethod 600 611\tdeconverter\n",
      "T11\tOtherScientificTerm 623 628\tgraph\n",
      "T12\tMethod 642 654\tdeconverters\n",
      "T13\tMaterial 880 910\toriginal multilingual document\n",
      "T14\tOtherScientificTerm 1019 1027\tliaisons\n",
      "T15\tGeneric 1118 1127\tresources\n",
      "T16\tMaterial 1139 1179\tLO-English or better a L0-UNL dictionary\n",
      "T17\tMethod 1185 1213\tmorphosyntactic parser of L0\n",
      "T18\tOtherScientificTerm 1223 1258\tcanonical graph2tree transformation\n",
      "T19\tOtherScientificTerm 1312 1323\tUNL-tree+L0\n",
      "T20\tOtherScientificTerm 1336 1351\tMS-L0 structure\n",
      "T21\tOtherScientificTerm 1358 1365\tlattice\n",
      "T22\tMaterial 1391 1401\tdictionary\n",
      "T23\tOtherScientificTerm 1477 1494\tcrossing liaisons\n",
      "T24\tTask 1570 1578\tpivot MT\n",
      "T25\tTask 1582 1596\tinteractive MT\n",
      "T26\tTask 1604 1631\tmultilingual text authoring\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R2\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R3\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R4\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R7\tCOREF Arg1:T8 Arg2:T10\n",
      "R8\tCOREF Arg1:T10 Arg2:T12\n",
      "R9\tCONJUNCTION Arg1:T25 Arg2:T26\n",
      "R10\tCONJUNCTION Arg1:T24 Arg2:T25\n",
      "R11\tHYPONYM-OF Arg1:T16 Arg2:T15\n",
      "R12\tHYPONYM-OF Arg1:T17 Arg2:T15\n",
      "R13\tHYPONYM-OF Arg1:T18 Arg2:T15\n",
      "R14\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R15\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W03-0406.ann\n",
      "T1\tMethod 31 59\tunsupervised learning method\n",
      "T2\tMethod 72 111\tExpectation-Maximization (EM) algorithm\n",
      "T3\tTask 143 171\ttext classification problems\n",
      "T4\tGeneric 191 193\tit\n",
      "T5\tTask 198 238\tword sense disambiguation (WSD) problems\n",
      "T6\tGeneric 254 260\tmethod\n",
      "T7\tMethod 272 284\tEM algorithm\n",
      "T8\tOtherScientificTerm 294 318\toptimum iteration number\n",
      "T9\tGeneric 338 344\tnumber\n",
      "T10\tTask 400 417\tnoun WSD problems\n",
      "T11\tTask 427 451\tJapanese Dictionary Task\n",
      "T12\tMaterial 455 464\tSENSEVAL2\n",
      "T13\tGeneric 484 490\tmethod\n",
      "T14\tGeneric 536 540\ttask\n",
      "T15\tGeneric 559 566\tmethods\n",
      "T16\tTask 608 625\tverb WSD problems\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tCOREF Arg1:T6 Arg2:T1\n",
      "R6\tCOREF Arg1:T9 Arg2:T8\n",
      "R7\tFEATURE-OF Arg1:T11 Arg2:T12\n",
      "R8\tCOREF Arg1:T14 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R10\tCOREF Arg1:T15 Arg2:T13\n",
      "R11\tCOREF Arg1:T13 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W03-2907.ann\n",
      "T1\tGeneric 24 32\tapproach\n",
      "T2\tTask 41 83\tunsupervised learning  of  parts of speech\n",
      "T3\tOtherScientificTerm 102 141\tmorphological and syntactic information\n",
      "T4\tGeneric 155 160\tmodel\n",
      "T5\tGeneric 183 188\tthose\n",
      "T6\tTask 219 265\tunsupervised learning  of  POS tags in English\n",
      "T7\tOtherScientificTerm 284 305\tsyntactic information\n",
      "T8\tOtherScientificTerm 375 385\tmorphology\n",
      "T9\tOtherScientificTerm 418 428\tmorphology\n",
      "T10\tOtherScientificTerm 479 489\tword order\n",
      "T11\tGeneric 508 527\tcomputational model\n",
      "T12\tTask 534 546\tPOS learning\n",
      "T13\tGeneric 582 584\tit\n",
      "T14\tMaterial 589 598\tBulgarian\n",
      "T15\tMaterial 604 619\tSlavic language\n",
      "T16\tOtherScientificTerm 638 653\tfree word order\n",
      "T17\tOtherScientificTerm 660 675\trich morphology\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R2\tHYPONYM-OF Arg1:T14 Arg2:T15\n",
      "R3\tCOMPARE Arg1:T9 Arg2:T10\n",
      "R4\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R7\tCOREF Arg1:T4 Arg2:T1\n",
      "R8\tCOMPARE Arg1:T4 Arg2:T5\n",
      "R9\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R10\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R11\tCOREF Arg1:T11 Arg2:T4\n",
      "R12\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R13\tFEATURE-OF Arg1:T16 Arg2:T14\n",
      "R14\tFEATURE-OF Arg1:T17 Arg2:T14\n",
      "R15\tCOREF Arg1:T13 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W04-1307.ann\n",
      "T1\tMethod 25 44\tcomputational model\n",
      "T2\tTask 50 67\tword segmentation\n",
      "T3\tTask 105 126\trealistic acquisition\n",
      "T4\tMethod 188 219\tstatistical learning mechanisms\n",
      "T5\tMaterial 262 282\tcognitive psychology\n",
      "T6\tMaterial 289 300\tlinguistics\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R4\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W04-2204.ann\n",
      "T1\tMaterial 44 63\ttransfer dictionary\n",
      "T2\tTask 81 104\tDictionary construction\n",
      "T3\tTask 156 182\tmachine translation system\n",
      "T4\tGeneric 253 263\tdictionary\n",
      "T5\tMaterial 281 301\tlinguistic resources\n",
      "T6\tMaterial 404 433\tKorean-to-Japanese dictionary\n",
      "T7\tMaterial 442 449\tEnglish\n",
      "T8\tTask 491 513\tautomatic construction\n",
      "T9\tOtherScientificTerm 549 581\tdirectionality  of  dictionaries\n",
      "T10\tGeneric 569 581\tdictionaries\n",
      "T11\tMethod 605 630\t\"one-time look up\" method\n",
      "T12\tMaterial 641 695\tKorean-to-English and a Japanese-to-English dictionary\n",
      "T13\tGeneric 716 722\tmethod\n",
      "T14\tOtherScientificTerm 730 754\t\"overlapping constraint\"\n",
      "T15\tMaterial 764 792\tKorean-to-English dictionary\n",
      "T16\tMaterial 802 832\tEnglish-to-Japanese dictionary\n",
      "T17\tGeneric 874 880\tmethod\n",
      "T18\tGeneric 909 919\tdictionary\n",
      "T19\tMaterial 926 954\tEnglish-to-Korean dictionary\n",
      "T20\tMaterial 961 991\tEnglish-to-Japanese dictionary\n",
      "T21\tGeneric 1018 1024\tmethod\n",
      "R1\tPART-OF Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R5\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R6\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R7\tCOREF Arg1:T4 Arg2:T1\n",
      "R8\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T13\n",
      "R11\tCOREF Arg1:T21 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R13\tHYPONYM-OF Arg1:T19 Arg2:T18\n",
      "R14\tHYPONYM-OF Arg1:T20 Arg2:T18\n",
      "R15\tCOREF Arg1:T10 Arg2:T4\n",
      "R16\tEVALUATE-FOR Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W04-2703.ann\n",
      "T1\tTask 30 68\tlarge scale discourse-level annotation\n",
      "T2\tMaterial 85 115\tPenn Discourse TreeBank (PDTB)\n",
      "T3\tGeneric 132 140\tapproach\n",
      "T4\tOtherScientificTerm 167 186\tdiscourse structure\n",
      "T5\tOtherScientificTerm 218 239\tdiscourse connectives\n",
      "T6\tMaterial 269 273\tPDTB\n",
      "T7\tMaterial 314 327\tPenn TreeBank\n",
      "T8\tMaterial 334 342\tPropbank\n",
      "T9\tTask 365 418\textraction of useful  syntactic and semantic features\n",
      "T10\tMethod 492 512\tpractical algorithms\n",
      "T11\tMetric 562 587\tinter-annotator agreement\n",
      "T12\tMetric 601 619\tlevel of agreement\n",
      "T13\tOtherScientificTerm 639 664\tinter-annotator variation\n",
      "R1\tCOREF Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T6 Arg2:T2\n",
      "R3\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T5 Arg2:T3\n",
      "R8\tEVALUATE-FOR Arg1:T6 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T6 Arg2:T9\n",
      "R10\tFEATURE-OF Arg1:T12 Arg2:T11\n",
      "R11\tFEATURE-OF Arg1:T13 Arg2:T11\n",
      "R12\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W05-1308.ann\n",
      "T1\tMethod 30 63\tfully automated extraction system\n",
      "T2\tMethod 73 78\tIntEx\n",
      "T3\tTask 94 123\tgene and protein interactions\n",
      "T4\tMaterial 129 144\tbiomedical text\n",
      "T5\tGeneric 151 159\tapproach\n",
      "T6\tOtherScientificTerm 253 268\tsyntactic roles\n",
      "T7\tOtherScientificTerm 286 305\tbiological entities\n",
      "T8\tOtherScientificTerm 325 361\tbiomedical and linguistic ontologies\n",
      "T9\tOtherScientificTerm 447 462\tsyntactic roles\n",
      "T10\tMethod 520 537\textraction system\n",
      "T11\tOtherScientificTerm 581 613\tmultiple and nested interactions\n",
      "T12\tMethod 700 718\textraction systems\n",
      "T13\tMethod 739 751\tIntEx system\n",
      "T14\tOtherScientificTerm 812 843\tpattern engineering requirement\n",
      "R1\tCOMPARE Arg1:T13 Arg2:T12\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R5\tCOREF Arg1:T5 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R7\tCOREF Arg1:T10 Arg2:T5\n",
      "R8\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R9\tCOREF Arg1:T13 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W06-1605.ann\n",
      "T1\tGeneric 14 23\tframework\n",
      "T2\tOtherScientificTerm 58 66\tconcepts\n",
      "T3\tMethod 74 120\tdistributional measures of word co-occurrences\n",
      "T4\tOtherScientificTerm 178 201\tcoarse-grained concepts\n",
      "T5\tOtherScientificTerm 263 285\tconcept-concept matrix\n",
      "T6\tMethod 379 404\tconcept-distance measures\n",
      "T7\tMethod 430 467\tdistributional word-distance measures\n",
      "T8\tGeneric 476 481\ttasks\n",
      "T9\tTask 489 540\tranking  word pairs  in order of  semantic distance\n",
      "T10\tTask 551 588\tcorrecting  real-word spelling errors\n",
      "T11\tGeneric 605 609\ttask\n",
      "T12\tMethod 623 645\tWordNet-based measures\n",
      "T13\tMethod 710 750\tdistributional concept-distance measures\n",
      "R1\tCOMPARE Arg1:T7 Arg2:T6\n",
      "R2\tCOMPARE Arg1:T13 Arg2:T12\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "R5\tHYPONYM-OF Arg1:T10 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R8\tCOREF Arg1:T11 Arg2:T10\n",
      "R9\tCOREF Arg1:T6 Arg2:T1\n",
      "R10\tCONJUNCTION Arg1:T10 Arg2:T9\n",
      "R11\tEVALUATE-FOR Arg1:T11 Arg2:T12\n",
      "R12\tEVALUATE-FOR Arg1:T11 Arg2:T13\n",
      "R13\tCOREF Arg1:T13 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W07-0208.ann\n",
      "T1\tMethod 38 60\tlabeled directed graph\n",
      "T2\tOtherScientificTerm 93 114\tlinguistic structures\n",
      "T3\tGeneric 136 140\tthis\n",
      "T4\tTask 161 170\tNLP tasks\n",
      "T5\tTask 176 197\tgraph transformations\n",
      "T6\tMethod 221 227\tmethod\n",
      "T7\tGeneric 247 262\ttransformations\n",
      "T8\tMaterial 273 289\tannotated corpus\n",
      "T9\tGeneric 325 337\tapplications\n",
      "T10\tGeneric 345 351\tmethod\n",
      "T11\tTask 354 393\tidentification of non-local depenencies\n",
      "T12\tMaterial 403 421\tPenn Treebank data\n",
      "T13\tTask 429 451\tsemantic role labeling\n",
      "T14\tMaterial 461 482\tProposition Bank data\n",
      "R1\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R2\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R5\tCOREF Arg1:T3 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R8\tCOREF Arg1:T7 Arg2:T5\n",
      "R9\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R10\tCOREF Arg1:T10 Arg2:T6\n",
      "R11\tHYPONYM-OF Arg1:T11 Arg2:T9\n",
      "R12\tHYPONYM-OF Arg1:T13 Arg2:T9\n",
      "R13\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W08-2122.ann\n",
      "T1\tTask 48 70\tCoNLL 2008 shared task\n",
      "T2\tMethod 85 131\tgenerative history-based latent variable model\n",
      "T3\tTask 179 208\tsynchronous dependency parser\n",
      "T4\tOtherScientificTerm 220 255\tsyntactic and semantic dependencies\n",
      "T5\tGeneric 273 278\tmodel\n",
      "T6\tMetric 294 322\tmacro-average F1 performance\n",
      "T7\tGeneric 339 343\ttask\n",
      "T8\tMetric 352 378\tsyntactic dependencies LAS\n",
      "T9\tMetric 391 415\tsemantic dependencies F1\n",
      "T10\tGeneric 428 433\tmodel\n",
      "T11\tMetric 478 494\tmacro-average F1\n",
      "T12\tMetric 504 530\tsyntactic dependencies LAS\n",
      "T13\tMetric 544 568\tsemantic dependencies F1\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T5 Arg2:T2\n",
      "R3\tEVALUATE-FOR Arg1:T6 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R6\tCOREF Arg1:T7 Arg2:T1\n",
      "R7\tEVALUATE-FOR Arg1:T6 Arg2:T7\n",
      "R8\tEVALUATE-FOR Arg1:T8 Arg2:T7\n",
      "R9\tEVALUATE-FOR Arg1:T9 Arg2:T7\n",
      "R10\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R11\tEVALUATE-FOR Arg1:T11 Arg2:T10\n",
      "R12\tEVALUATE-FOR Arg1:T12 Arg2:T10\n",
      "R13\tEVALUATE-FOR Arg1:T13 Arg2:T10\n",
      "R14\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R15\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W99-0408.ann\n",
      "T1\tMethod 38 74\tuser knowledge modeling architecture\n",
      "T2\tTask 85 98\tICICLE system\n",
      "T3\tTask 104 133\tlanguage tutoring application\n",
      "T4\tOtherScientificTerm 139 152\tdeaf learners\n",
      "T5\tMaterial 157 172\twritten English\n",
      "T6\tGeneric 179 184\tmodel\n",
      "T7\tTask 285 301\twriting analysis\n",
      "T8\tTask 308 327\tfeedback production\n",
      "T9\tGeneric 347 359\tmodel design\n",
      "T10\tTask 393 440\tsecond language and cognitive skill acquisition\n",
      "T11\tGeneric 510 516\tdesign\n",
      "T12\tGeneric 551 557\tdesign\n",
      "T13\tTask 613 657\tlanguage assessment / correction application\n",
      "T14\tOtherScientificTerm 671 687\tuser proficiency\n",
      "T15\tMetric 708 719\tgranularity\n",
      "T16\tMetric 724 735\tspecificity\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T3\n",
      "R3\tCOREF Arg1:T6 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R6\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R7\tCOREF Arg1:T9 Arg2:T6\n",
      "R8\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R9\tCOREF Arg1:T11 Arg2:T9\n",
      "R10\tCOREF Arg1:T12 Arg2:T11\n",
      "R11\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R13\tUSED-FOR Arg1:T5 Arg2:T3\n",
      "R14\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R15\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R16\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R17\tEVALUATE-FOR Arg1:T16 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\X96-1041.ann\n",
      "T1\tMethod 6 26\tTIPSTER Architecture\n",
      "T2\tTask 80 97\ttext applications\n",
      "T3\tMethod 116 146\tcommon text processing modules\n",
      "T4\tOtherScientificTerm 156 171\tuser interfaces\n",
      "T5\tGeneric 215 227\tapplications\n",
      "T6\tOtherScientificTerm 270 306\tuser interface styles or conventions\n",
      "T7\tOtherScientificTerm 330 364\tTIPSTER Architecture specification\n",
      "T8\tTask 443 463\tTIPSTER applications\n",
      "T9\tOtherScientificTerm 504 544\tGraphical User Interface (GUI) functions\n",
      "T10\tOtherScientificTerm 554 558\tGUIs\n",
      "T11\tMethod 584 627\tCRL's TIPSTER User Interface Toolkit (TUIT)\n",
      "T12\tMethod 631 635\tTUIT\n",
      "T13\tMethod 643 659\tsoftware library\n",
      "T14\tOtherScientificTerm 692 728\tmultilingual TIPSTER user interfaces\n",
      "T15\tMethod 779 783\tTUIT\n",
      "T16\tMethod 821 836\tTIPSTER modules\n",
      "T17\tMethod 976 980\tTUIT\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R5\tCOREF Arg1:T10 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R7\tCOREF Arg1:T12 Arg2:T11\n",
      "R8\tHYPONYM-OF Arg1:T12 Arg2:T13\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R10\tCOREF Arg1:T15 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R12\tCOREF Arg1:T17 Arg2:T15\n",
      "R13\tCOREF Arg1:T16 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\X96-1059.ann\n",
      "T1\tTask 2 29\tRecognition of proper nouns\n",
      "T2\tOtherScientificTerm 17 29\tproper nouns\n",
      "T3\tMaterial 35 48\tJapanese text\n",
      "T4\tTask 109 131\tmorphological analysis\n",
      "T5\tTask 137 161\tJapanese text processing\n",
      "T6\tGeneric 174 176\tIt\n",
      "T7\tTask 220 251\tJapanese information extraction\n",
      "T8\tGeneric 280 288\tapproach\n",
      "T9\tTask 296 331\tMulti-lingual Evaluation Task (MET)\n",
      "T10\tMaterial 337 350\tJapanese text\n",
      "T11\tGeneric 377 381\ttask\n",
      "T12\tTask 388 418\tmorphological analysis problem\n",
      "T13\tMaterial 424 432\tJapanese\n",
      "T14\tMethod 440 462\tmorphological analyzer\n",
      "T15\tTask 505 587\trecognition and classification of proper names, numerical and temporal expressions\n",
      "T16\tOtherScientificTerm 539 587\tproper names, numerical and temporal expressions\n",
      "T17\tOtherScientificTerm 594 617\tNamed Entity (NE) items\n",
      "T18\tMaterial 627 640\tJapanese text\n",
      "T19\tGeneric 648 656\tanalyzer\n",
      "T20\tMethod 668 676\t\"Amorph\"\n",
      "T21\tMethod 678 684\tAmorph\n",
      "T22\tOtherScientificTerm 697 705\tNE items\n",
      "T23\tMethod 723 740\tdictionary lookup\n",
      "T24\tMethod 747 763\trule application\n",
      "T25\tGeneric 773 775\tit\n",
      "T26\tOtherScientificTerm 799 811\tdictionaries\n",
      "T27\tOtherScientificTerm 833 859\tJapanese character strings\n",
      "T28\tMethod 915 938\tdictionary lookup stage\n",
      "T29\tOtherScientificTerm 951 956\trules\n",
      "T30\tOtherScientificTerm 1018 1026\tNE items\n",
      "T31\tOtherScientificTerm 1065 1072\tNE item\n",
      "R1\tPART-OF Arg1:T1 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R5\tCOREF Arg1:T9 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R8\tCOREF Arg1:T12 Arg2:T4\n",
      "R9\tCOREF Arg1:T10 Arg2:T3\n",
      "R10\tCOREF Arg1:T10 Arg2:T13\n",
      "R11\tCOREF Arg1:T1 Arg2:T6\n",
      "R12\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R13\tCOREF Arg1:T19 Arg2:T14\n",
      "R14\tCOREF Arg1:T20 Arg2:T19\n",
      "R15\tCOREF Arg1:T21 Arg2:T20\n",
      "R16\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R17\tCONJUNCTION Arg1:T23 Arg2:T24\n",
      "R18\tPART-OF Arg1:T23 Arg2:T21\n",
      "R19\tPART-OF Arg1:T24 Arg2:T21\n",
      "R20\tCOREF Arg1:T21 Arg2:T25\n",
      "R21\tUSED-FOR Arg1:T26 Arg2:T27\n",
      "R22\tUSED-FOR Arg1:T26 Arg2:T25\n",
      "R23\tCOREF Arg1:T28 Arg2:T23\n",
      "R24\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R25\tHYPONYM-OF Arg1:T17 Arg2:T16\n",
      "R26\tPART-OF Arg1:T17 Arg2:T18\n",
      "R27\tCOREF Arg1:T13 Arg2:T18\n",
      "R28\tUSED-FOR Arg1:T29 Arg2:T30\n",
      "R29\tPART-OF Arg1:T2 Arg2:T3\n",
      "R30\tUSED-FOR Arg1:T28 Arg2:T29\n",
      "R31\tCOREF Arg1:T17 Arg2:T30\n",
      "R32\tCOREF Arg1:T31 Arg2:T30\n",
      "R33\tCOREF Arg1:T22 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\X98-1022.ann\n",
      "T1\tTask 2 25\tAutomatic summarization\n",
      "T2\tTask 32 54\tinformation extraction\n",
      "T3\tMaterial 94 97\tMUC\n",
      "T4\tMaterial 104 110\tSUMMAC\n",
      "T5\tTask 201 224\tautomatic summarization\n",
      "T6\tGeneric 253 259\tmodels\n",
      "T7\tTask 288 306\tsummary generation\n",
      "T8\tGeneric 318 323\ttasks\n",
      "T9\tMaterial 338 346\tSUMMAC-1\n",
      "T10\tTask 354 373\tcategorization task\n",
      "T11\tOtherScientificTerm 377 401\tpositive feature vectors\n",
      "T12\tOtherScientificTerm 408 432\tnegative feature vectors\n",
      "T13\tOtherScientificTerm 470 500\tgeneric, indicative  summaries\n",
      "T14\tTask 507 517\tadhoc task\n",
      "T15\tMethod 522 532\ttext model\n",
      "T16\tOtherScientificTerm 618 635\tdiscourse segment\n",
      "T17\tOtherScientificTerm 689 712\tuser-directed summaries\n",
      "T18\tMetric 742 747\tNormF\n",
      "T19\tTask 803 814\tadhoc tasks\n",
      "T20\tMetric 842 847\tNormF\n",
      "T21\tTask 904 923\tcategorization task\n",
      "T22\tGeneric 952 958\tsystem\n",
      "T23\tGeneric 983 989\tsystem\n",
      "T24\tTask 994 1013\tcategorization task\n",
      "T25\tTask 1040 1050\tadhoc task\n",
      "R1\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T1 Arg2:T5\n",
      "R3\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T17\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R9\tCOREF Arg1:T20 Arg2:T18\n",
      "R10\tEVALUATE-FOR Arg1:T20 Arg2:T21\n",
      "R11\tCOREF Arg1:T21 Arg2:T10\n",
      "R12\tCOREF Arg1:T14 Arg2:T19\n",
      "R13\tCOREF Arg1:T24 Arg2:T21\n",
      "R14\tEVALUATE-FOR Arg1:T24 Arg2:T23\n",
      "R15\tEVALUATE-FOR Arg1:T24 Arg2:T22\n",
      "R16\tCOMPARE Arg1:T22 Arg2:T23\n",
      "R17\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R18\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R19\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R20\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "R21\tEVALUATE-FOR Arg1:T25 Arg2:T24\n",
      "R22\tEVALUATE-FOR Arg1:T25 Arg2:T22\n",
      "R23\tCOREF Arg1:T19 Arg2:T25\n",
      "R24\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R25\tPART-OF Arg1:T8 Arg2:T9\n",
      "R26\tHYPONYM-OF Arg1:T10 Arg2:T8\n",
      "R27\tHYPONYM-OF Arg1:T14 Arg2:T8\n",
      "R28\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R29\tCOREF Arg1:T6 Arg2:T22\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# Directory path:\n",
    "directory_path = './benchmarking/input/sciERC_raw'\n",
    "\n",
    "# Get the list of .ann files in the directory\n",
    "ann_files = glob.glob(os.path.join(directory_path, '*.ann'))\n",
    "\n",
    "# Iterate over each .ann file\n",
    "for ann_file in ann_files:\n",
    "    # Load the .ann file\n",
    "    with open(ann_file, 'r') as f:\n",
    "        annotations = f.readlines()\n",
    "\n",
    "    # Print the .ann file name\n",
    "    print(\"Annotations in\", ann_file)\n",
    "\n",
    "    # Print the annotations\n",
    "    for annotation in annotations:\n",
    "        print(annotation.strip())\n",
    "\n",
    "    print(\"-----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2164da23",
   "metadata": {},
   "source": [
    "## Extract entities and relationships data into separate cols, corresponding to the .ann file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "598fcfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory path where your files are stored\n",
    "directory_path = './benchmarking/input/sciERC_raw'\n",
    "\n",
    "# Initialize empty lists to store the data\n",
    "abstracts = []\n",
    "entities = []\n",
    "relationships = []\n",
    "\n",
    "# Get the list of .ann files in the directory\n",
    "ann_files = glob.glob(os.path.join(directory_path, '*.ann'))\n",
    "\n",
    "# Iterate over each .ann file\n",
    "for ann_file in ann_files:\n",
    "    # Load the .ann file\n",
    "    with open(ann_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Extract the abstract (title of .ann file)\n",
    "    abstract = os.path.splitext(os.path.basename(ann_file))[0]\n",
    "\n",
    "    # Store the annotations in a dictionary\n",
    "    ann_dict = {}\n",
    "    rel_dict = {}\n",
    "    for line in lines:\n",
    "        line_parts = line.strip().split('\\t')\n",
    "        if line_parts[0].startswith('T'):\n",
    "            ann_id = line_parts[0]\n",
    "            ann_type = line_parts[1].split()[0]\n",
    "            start_offset = int(line_parts[1].split()[1])\n",
    "            end_offset = int(line_parts[1].split()[2])\n",
    "            annotated_text = line_parts[2]\n",
    "            ann_dict[ann_id] = {\n",
    "                'Annotation ID': ann_id,\n",
    "                'Entity': ann_type,\n",
    "                'Start Offset': start_offset,\n",
    "                'End Offset': end_offset,\n",
    "                'Annotated Text': annotated_text\n",
    "            }\n",
    "        elif line_parts[0].startswith('R'):\n",
    "            rel_id = line_parts[0]\n",
    "            rel_type = line_parts[1].split()[0]\n",
    "            arg1_id = line_parts[1].split()[1].split(':')[1]\n",
    "            arg2_id = line_parts[1].split()[2].split(':')[1]\n",
    "            rel_dict[rel_id] = {\n",
    "                'Relationship ID': rel_id,\n",
    "                'Type': rel_type,\n",
    "                'Arg1': arg1_id,\n",
    "                'Arg2': arg2_id\n",
    "            }\n",
    "\n",
    "    # Append the data to the lists\n",
    "    abstracts.append(abstract)\n",
    "    entities.append(ann_dict)\n",
    "    relationships.append(rel_dict)\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "data = {\n",
    "    'abstract_id': abstracts,\n",
    "    'entities': entities,\n",
    "    'relationships': relationships\n",
    "}\n",
    "\n",
    "annotations_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "176aea5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "1    A00-2023   \n",
       "2    A88-1001   \n",
       "3    A88-1003   \n",
       "4    A92-1010   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "1  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "2  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "3  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "4  {'T1': {'Annotation ID': 'T1', 'Entity': 'Task...   \n",
       "\n",
       "                                       relationships  \n",
       "0  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...  \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Type': 'COMP...  \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...  \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Type': 'PART...  \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(annotations_df))\n",
    "annotations_df.head()\n",
    "\n",
    "# export to excel to view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105dfba6",
   "metadata": {},
   "source": [
    "### Create populated_rels column, replacing entity IDs in the relationships col."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4da029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'populated_rels' in annotations_df\n",
    "annotations_df['populated_rels'] = None\n",
    "\n",
    "# Iterate over each row in annotations_df\n",
    "for index, row in annotations_df.iterrows():\n",
    "    # Get the entities and relationships dictionaries for the current row\n",
    "    entities_dict = row['entities']\n",
    "    relationships_dict = row['relationships']\n",
    "    \n",
    "    # Create a new dictionary to store the populated relationships\n",
    "    populated_rels_dict = {}\n",
    "    \n",
    "    # Iterate over each relationship in relationships_dict\n",
    "    for rel_id, rel_info in relationships_dict.items():\n",
    "        # Get the argument IDs\n",
    "        arg1_id = rel_info['Arg1']\n",
    "        arg2_id = rel_info['Arg2']\n",
    "        \n",
    "        # Get the corresponding annotated texts from entities_dict\n",
    "        arg1_text = entities_dict[arg1_id]['Annotated Text']\n",
    "        arg2_text = entities_dict[arg2_id]['Annotated Text']\n",
    "        \n",
    "        # Create the populated relationship string\n",
    "        rel_text = f\"{arg1_text} {rel_info['Type']} {arg2_text}\"\n",
    "        \n",
    "        # Store the populated relationship in the new dictionary\n",
    "        populated_rels_dict[rel_id] = {\n",
    "            'Relationship ID': rel_id,\n",
    "            'Rel': rel_text\n",
    "        }\n",
    "    \n",
    "    # Assign the populated relationships dictionary to the 'populated_rels' column\n",
    "    annotations_df.at[index, 'populated_rels'] = populated_rels_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e41bbb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMP...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'prono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'displ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "1    A00-2023   \n",
       "2    A88-1001   \n",
       "3    A88-1003   \n",
       "4    A92-1010   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "1  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "2  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "3  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "4  {'T1': {'Annotation ID': 'T1', 'Entity': 'Task...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Type': 'COMP...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Type': 'PART...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "\n",
       "                                      populated_rels  \n",
       "0  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...  \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...  \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...  \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Rel': 'prono...  \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Rel': 'displ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(annotations_df))\n",
    "annotations_df.head()\n",
    "\n",
    "# export to excel to view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a10c632",
   "metadata": {},
   "source": [
    "### Create a simplified populated_rels col, and a count_of_rels col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dcdb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'simplified_populated_rels' in annotations_df\n",
    "annotations_df['simplified_populated_rels'] = None\n",
    "\n",
    "# Iterate over each row in annotations_df\n",
    "for index, row in annotations_df.iterrows():\n",
    "    # Get the populated relationships dictionary for the current row\n",
    "    populated_rels_dict = row['populated_rels']\n",
    "    \n",
    "    # Extract the relationship strings from populated_rels_dict\n",
    "    rel_strings = [rel_info['Rel'] for rel_info in populated_rels_dict.values()]\n",
    "    \n",
    "    # Assign the simplified relationship strings to the 'simplified_populated_rels' column\n",
    "    annotations_df.at[index, 'simplified_populated_rels'] = rel_strings\n",
    "    \n",
    "# Create a new column 'rel_count' in annotations_df\n",
    "annotations_df['rel_count'] = annotations_df['simplified_populated_rels'].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "683988b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMP...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...</td>\n",
       "      <td>[ranking algorithm COMPARE lattice-based appro...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...</td>\n",
       "      <td>[feedback FEATURE-OF discourse, videodisc imag...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'prono...</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'displ...</td>\n",
       "      <td>[display of graphical information USED-FOR cog...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "1    A00-2023   \n",
       "2    A88-1001   \n",
       "3    A88-1003   \n",
       "4    A92-1010   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "1  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "2  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "3  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "4  {'T1': {'Annotation ID': 'T1', 'Entity': 'Task...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Type': 'COMP...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Type': 'PART...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "\n",
       "                                      populated_rels  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Rel': 'prono...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Rel': 'displ...   \n",
       "\n",
       "                           simplified_populated_rels  \\\n",
       "0  [multi-component architecture USED-FOR system,...   \n",
       "1  [ranking algorithm COMPARE lattice-based appro...   \n",
       "2  [feedback FEATURE-OF discourse, videodisc imag...   \n",
       "3  [pronominal anaphora resolution module PART-OF...   \n",
       "4  [display of graphical information USED-FOR cog...   \n",
       "\n",
       "   rel_count  \n",
       "0         13  \n",
       "1          9  \n",
       "2          9  \n",
       "3          3  \n",
       "4          3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(annotations_df))\n",
    "annotations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20db4404",
   "metadata": {},
   "source": [
    "## Load .txt files (same name as corresponding .ann files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cf4d21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>\\nThis paper presents a new approach to  stati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>\\n This paper describes a domain independent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>\\n In this paper, we describe the  pronominal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>\\nIn our current research into the design of  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "1    A00-2023   \n",
       "2    A88-1001   \n",
       "3    A88-1003   \n",
       "4    A92-1010   \n",
       "\n",
       "                                                text  \n",
       "0  \\nThis paper introduces a  system for categori...  \n",
       "1  \\nThis paper presents a new approach to  stati...  \n",
       "2   \\n This paper describes a domain independent ...  \n",
       "3   \\n In this paper, we describe the  pronominal...  \n",
       "4  \\nIn our current research into the design of  ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the directory containing the .txt files\n",
    "txt_directory = './benchmarking/input/sciERC_raw'\n",
    "\n",
    "# Create an empty DataFrame to store the text data\n",
    "text_df = pd.DataFrame(columns=['abstract_id', 'text'])\n",
    "\n",
    "# Iterate over the rows of annotations_df\n",
    "for index, row in annotations_df.iterrows():\n",
    "    # Extract the abstract name\n",
    "    abstract = row['abstract_id']\n",
    "    \n",
    "    # Construct the path to the corresponding .txt file\n",
    "    txt_file_path = os.path.join(txt_directory, f'{abstract}.txt')\n",
    "    \n",
    "    # Load the text from the .txt file\n",
    "    with open(txt_file_path, 'r') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # Append the abstract name and text to text_df\n",
    "    text_df = pd.concat([text_df, pd.DataFrame({'abstract_id': [abstract], 'text': [text]})], ignore_index=True)\n",
    "    \n",
    "print(len(text_df))\n",
    "text_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f677612e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categori...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>\\nThis paper presents a new approach to  stati...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMP...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...</td>\n",
       "      <td>[ranking algorithm COMPARE lattice-based appro...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>\\n This paper describes a domain independent ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...</td>\n",
       "      <td>[feedback FEATURE-OF discourse, videodisc imag...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>\\n In this paper, we describe the  pronominal...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'prono...</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>\\nIn our current research into the design of  ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'displ...</td>\n",
       "      <td>[display of graphical information USED-FOR cog...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "1    A00-2023   \n",
       "2    A88-1001   \n",
       "3    A88-1003   \n",
       "4    A92-1010   \n",
       "\n",
       "                                                text  \\\n",
       "0  \\nThis paper introduces a  system for categori...   \n",
       "1  \\nThis paper presents a new approach to  stati...   \n",
       "2   \\n This paper describes a domain independent ...   \n",
       "3   \\n In this paper, we describe the  pronominal...   \n",
       "4  \\nIn our current research into the design of  ...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "1  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "2  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "3  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "4  {'T1': {'Annotation ID': 'T1', 'Entity': 'Task...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Type': 'COMP...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Type': 'PART...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "\n",
       "                                      populated_rels  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Rel': 'prono...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Rel': 'displ...   \n",
       "\n",
       "                           simplified_populated_rels  \\\n",
       "0  [multi-component architecture USED-FOR system,...   \n",
       "1  [ranking algorithm COMPARE lattice-based appro...   \n",
       "2  [feedback FEATURE-OF discourse, videodisc imag...   \n",
       "3  [pronominal anaphora resolution module PART-OF...   \n",
       "4  [display of graphical information USED-FOR cog...   \n",
       "\n",
       "   rel_count  \n",
       "0         13  \n",
       "1          9  \n",
       "2          9  \n",
       "3          3  \n",
       "4          3  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform an inner join between annotations_df and text_df based on the 'Abstract' column\n",
    "scierc_full = pd.merge(text_df, annotations_df, on='abstract_id', how='inner')\n",
    "\n",
    "print(len(scierc_full))\n",
    "scierc_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61754d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "316\n"
     ]
    }
   ],
   "source": [
    "scierc_full['word_count'] = scierc_full['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "smallest_word_count = scierc_full['word_count'].min()\n",
    "largest_word_count = scierc_full['word_count'].max()\n",
    "\n",
    "print(smallest_word_count)\n",
    "print(largest_word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00110a3a",
   "metadata": {},
   "source": [
    "### Distinct relationship types\n",
    "\n",
    "* Seems as if EVALUATE-FOR is not mentioned in the annotation_guideline.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb1e163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USED-FOR\n",
      "PART-OF\n",
      "HYPONYM-OF\n",
      "COREF\n",
      "EVALUATE-FOR\n",
      "CONJUNCTION\n",
      "COMPARE\n",
      "FEATURE-OF\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# Extract unique 'Types' from the 'relationships' column\n",
    "unique_types = scierc_full['relationships'].apply(lambda x: [rel_info['Type'] for rel_info in x.values()]).explode().unique().tolist()\n",
    "\n",
    "# Print the list of unique 'Types' prettily\n",
    "for type in unique_types:\n",
    "    print(type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87080b9f",
   "metadata": {},
   "source": [
    "# Prompt generation to detect rels\n",
    "* Attempting to use similar prompt format as used in main KG_construction, for consistency.\n",
    "* Aim is to benchmark against a rel-annotated dataset (scierc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1708c661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categori...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>\\nThis paper presents a new approach to  stati...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMP...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...</td>\n",
       "      <td>[ranking algorithm COMPARE lattice-based appro...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>\\n This paper describes a domain independent ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...</td>\n",
       "      <td>[feedback FEATURE-OF discourse, videodisc imag...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>\\n In this paper, we describe the  pronominal...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'prono...</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>\\nIn our current research into the design of  ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'displ...</td>\n",
       "      <td>[display of graphical information USED-FOR cog...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "1    A00-2023   \n",
       "2    A88-1001   \n",
       "3    A88-1003   \n",
       "4    A92-1010   \n",
       "\n",
       "                                                text  \\\n",
       "0  \\nThis paper introduces a  system for categori...   \n",
       "1  \\nThis paper presents a new approach to  stati...   \n",
       "2   \\n This paper describes a domain independent ...   \n",
       "3   \\n In this paper, we describe the  pronominal...   \n",
       "4  \\nIn our current research into the design of  ...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "1  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "2  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "3  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "4  {'T1': {'Annotation ID': 'T1', 'Entity': 'Task...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Type': 'COMP...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Type': 'PART...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "\n",
       "                                      populated_rels  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Rel': 'prono...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Rel': 'displ...   \n",
       "\n",
       "                           simplified_populated_rels  \\\n",
       "0  [multi-component architecture USED-FOR system,...   \n",
       "1  [ranking algorithm COMPARE lattice-based appro...   \n",
       "2  [feedback FEATURE-OF discourse, videodisc imag...   \n",
       "3  [pronominal anaphora resolution module PART-OF...   \n",
       "4  [display of graphical information USED-FOR cog...   \n",
       "\n",
       "   rel_count  \n",
       "0         13  \n",
       "1          9  \n",
       "2          9  \n",
       "3          3  \n",
       "4          3  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(scierc_full))\n",
    "scierc_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63048ab8",
   "metadata": {},
   "source": [
    "#### Previous prompt used in main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e355259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d67e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed article to sentence.\n",
    "# simplified.\n",
    "\n",
    "# rel types:\n",
    "# USED-FOR\n",
    "# FEATURE-OF\n",
    "# HYPONYM-OF\n",
    "# PART-OF\n",
    "# EVALUATE-FOR\n",
    "# COMPARE\n",
    "# CONJUNCTION\n",
    "# COREF\n",
    "\n",
    "# Create a function to generate the prompt based on the row values\n",
    "def generate_prompt(row):\n",
    "\n",
    "    input_text = row['text']\n",
    "    \n",
    "    prompt = f'''Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
    "    ###\n",
    "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
    "    ###\n",
    "    Here are some examples of each type of relationship that may be detected:\n",
    "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
    "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
    "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
    "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
    "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
    "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
    "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
    "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
    "    ###\n",
    "    Desired response format: ###\n",
    "    [rel1, rel2, rel3]\n",
    "    ###\n",
    "    Example response: ###\n",
    "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
    "    ###\n",
    "    The provided abstract is: ###\n",
    "    {input_text}\n",
    "    ###\n",
    "    '''\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Add a new 'prompt' column by applying the generate_prompt function to each row\n",
    "scierc_full['prompt'] = scierc_full.apply(generate_prompt, axis=1)\n",
    "scierc_full['prompt'] = scierc_full['prompt'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56b933e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categori...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>\\nThis paper presents a new approach to  stati...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMP...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...</td>\n",
       "      <td>[ranking algorithm COMPARE lattice-based appro...</td>\n",
       "      <td>9</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>\\n This paper describes a domain independent ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...</td>\n",
       "      <td>[feedback FEATURE-OF discourse, videodisc imag...</td>\n",
       "      <td>9</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>\\n In this paper, we describe the  pronominal...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'prono...</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF...</td>\n",
       "      <td>3</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>\\nIn our current research into the design of  ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'displ...</td>\n",
       "      <td>[display of graphical information USED-FOR cog...</td>\n",
       "      <td>3</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "1    A00-2023   \n",
       "2    A88-1001   \n",
       "3    A88-1003   \n",
       "4    A92-1010   \n",
       "\n",
       "                                                text  \\\n",
       "0  \\nThis paper introduces a  system for categori...   \n",
       "1  \\nThis paper presents a new approach to  stati...   \n",
       "2   \\n This paper describes a domain independent ...   \n",
       "3   \\n In this paper, we describe the  pronominal...   \n",
       "4  \\nIn our current research into the design of  ...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "1  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "2  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "3  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "4  {'T1': {'Annotation ID': 'T1', 'Entity': 'Task...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Type': 'COMP...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Type': 'PART...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "\n",
       "                                      populated_rels  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Rel': 'prono...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Rel': 'displ...   \n",
       "\n",
       "                           simplified_populated_rels  \\\n",
       "0  [multi-component architecture USED-FOR system,...   \n",
       "1  [ranking algorithm COMPARE lattice-based appro...   \n",
       "2  [feedback FEATURE-OF discourse, videodisc imag...   \n",
       "3  [pronominal anaphora resolution module PART-OF...   \n",
       "4  [display of graphical information USED-FOR cog...   \n",
       "\n",
       "   rel_count  \\\n",
       "0         13   \n",
       "1          9   \n",
       "2          9   \n",
       "3          3   \n",
       "4          3   \n",
       "\n",
       "                                              prompt  \n",
       "0  Give me a comma-separated list of relationship...  \n",
       "1  Give me a comma-separated list of relationship...  \n",
       "2  Give me a comma-separated list of relationship...  \n",
       "3  Give me a comma-separated list of relationship...  \n",
       "4  Give me a comma-separated list of relationship...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(scierc_full))\n",
    "scierc_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1064cc",
   "metadata": {},
   "source": [
    "## Export the scierc_full df, with prompts, as input reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7288718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export DataFrame to Excel file\n",
    "# excel_file_path = './benchmarking/input/scierc_full_input.xlsx'\n",
    "# scierc_full.to_excel(excel_file_path, index=False)\n",
    "\n",
    "# # Export DataFrame to pickle file\n",
    "# pickle_file_path = './benchmarking/input/scierc_full_input.pickle'\n",
    "# scierc_full.to_pickle(pickle_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7358ddd",
   "metadata": {},
   "source": [
    "# Exploring prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f67b1b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    \n",
      "This paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\n",
      "\n",
      "    ###\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the display options to show all text and split by newline\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# Iterate over each row in the 'prompt' column\n",
    "for prompt in scierc_full['prompt'][:1]:\n",
    "    print(prompt)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "035ef90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "# convert to list to explore\n",
    "all_prompts = scierc_full['prompt'].tolist()\n",
    "print(len(all_prompts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8f872",
   "metadata": {},
   "source": [
    "## Investigate average length of tokens\n",
    "\n",
    "* Important for pricing forecast and LLM API restrictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8829216",
   "metadata": {},
   "source": [
    "### with tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "300088e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "#encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09f259c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fns to count strings in list of prompts:\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def count_tokens_in_list(prompt_list: list, encoding_name: str) -> list:\n",
    "    \"\"\"Returns a list of integers representing the number of tokens in each string in the input list.\"\"\"\n",
    "    token_counts = []\n",
    "    for prompt in prompt_list:\n",
    "        num_tokens = num_tokens_from_string(prompt, encoding_name)\n",
    "        token_counts.append(num_tokens)\n",
    "    return token_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aec8734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_name = \"cl100k_base\" # used for gpt-3.5-turbo\n",
    "token_counts = count_tokens_in_list(all_prompts, encoding_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab58f212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens on the smallest prompt: 419\n",
      "Number of tokens on the largest prompt: 839\n",
      "Total number of tokens for all prompts: 273934\n",
      "Average number of tokens in all_prompts: 547.868\n"
     ]
    }
   ],
   "source": [
    "min_tokens = min(token_counts)\n",
    "max_tokens = max(token_counts)\n",
    "total_tokens = sum(i for i in token_counts if isinstance(i, int))\n",
    "average_tokens = total_tokens / len(all_prompts)\n",
    "\n",
    "print(f\"Number of tokens on the smallest prompt: {min_tokens}\")\n",
    "print(f\"Number of tokens on the largest prompt: {max_tokens}\")\n",
    "print(f\"Total number of tokens for all prompts: {total_tokens}\")\n",
    "print(f\"Average number of tokens in all_prompts: {average_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07607a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimating max response tokens if prompt works correctly (update to reflect prompt used)\n",
    "\n",
    "#num_tokens_from_string(\"facing risk: yes. type of risk: thisis some text for a risk type.\", \"cl100k_base\")\n",
    "\n",
    "num_tokens_from_string(\n",
    "    \n",
    "    '''\n",
    "[\"NL evaluations COMPARE Message Understanding Conferences\", \"evaluation methodology USED-FOR mature, practical applications\", \"methodology USED-FOR comparative evaluation of SLS systems\", \"evaluation methodology EVALUATE-FOR competing claims and identifying promising technical approaches\", \"methodology USED-FOR automatic evaluation of question-answering NL systems\", \"methodology can be used with speech or text input\", \"methodology FEATURE-OF heart\", \"DARPA SLS program PART-OF methodology implementation\", \"NL interfaces HYPONYM-OF speech understanding\", \"SLS systems HYPONYM-OF question-answering NL systems\", \"SLS systems PART-OF DARPA Spoken Language Systems program\", \"SLS systems COMPARE NL evaluations other than Message Understanding Conferences\", \"researchers COREF they\"]\n",
    "    '''\n",
    "                       ,\"cl100k_base\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ece9ae",
   "metadata": {},
   "source": [
    "### Truncate tokens of long prompts\n",
    "\n",
    "**** NO NEED TO TRUNCATE PROMPTS WORKING WITH scierc_full ****\n",
    "**** All are below token input threshold ****\n",
    "\n",
    "* gpt-3.5-turbo has max tokens of 4,096 tokens\n",
    "* This includes prompt and response tokens combined.\n",
    "* response tokens should be short due to the attempt at prompt restrictions;\n",
    "    * i.e. Provide answers only in the format of <facing risk: <'yes'/'no'>. type of risk: < risk type >.> and nothing else.\n",
    "* so a generous estimate of response tokens would be 100, providing gpt-3.5-turbo successfully adheres to above prompting.\n",
    "* Therefore truncate prompt tokens to 3500 to be safe."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5b88ae8",
   "metadata": {},
   "source": [
    "def truncate_prompt(prompt: str, encoding_name: str, max_tokens: int) -> str:\n",
    "    \"\"\"Truncates a text string to the specified number of tokens.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    tokens = encoding.encode(prompt)[:max_tokens]\n",
    "    return encoding.decode(tokens)\n",
    "\n",
    "\n",
    "def count_tokens_for_truncating(prompt_list: list, encoding_name: str, max_tokens: int) -> list:\n",
    "    \"\"\"Returns a list of strings with a maximum of max_tokens tokens.\"\"\"\n",
    "    token_counts = []\n",
    "    truncated_prompts = []\n",
    "    for prompt in prompt_list:\n",
    "        num_tokens = num_tokens_from_string(prompt, encoding_name)\n",
    "        if num_tokens > max_tokens:\n",
    "            truncated_prompt = truncate_prompt(prompt, encoding_name, max_tokens)\n",
    "            token_counts.append(max_tokens)\n",
    "        else:\n",
    "            truncated_prompt = prompt\n",
    "            token_counts.append(num_tokens)\n",
    "        truncated_prompts.append(truncated_prompt)\n",
    "    return truncated_prompts, token_counts\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d79bb2a7",
   "metadata": {},
   "source": [
    "encoding_name = \"cl100k_base\" # used for gpt-3.5-turbo\n",
    "# encoding_name = \"r50k_base\" # used for GPT-3 models. todo check this.\n",
    "max_tokens = 3500 # Update this based on model to be used in 'Generating responses' section to correspond to token limitations.\n",
    "#all_prompts = # your list of prompts here\n",
    "\n",
    "truncated_prompts, token_counts = count_tokens_for_truncating(all_prompts, encoding_name, max_tokens)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4018a089",
   "metadata": {},
   "source": [
    "# Compare output to previous token counts.\n",
    "\n",
    "token_counts_truncated_prompts = count_tokens_in_list(truncated_prompts, encoding_name)\n",
    "min_tokens_truncated_prompts = min(token_counts_truncated_prompts)\n",
    "max_tokens_truncated_prompts = max(token_counts_truncated_prompts)\n",
    "total_tokens_truncated_prompts = sum(i for i in token_counts_truncated_prompts if isinstance(i, int))\n",
    "average_tokens_truncated_prompts = total_tokens_truncated_prompts / len(truncated_prompts)\n",
    "\n",
    "print(f\"Number of tokens on the smallest prompt: {min_tokens_truncated_prompts}\")\n",
    "print(f\"Number of tokens on the largest prompt: {max_tokens_truncated_prompts}\")\n",
    "print(f\"Total number of tokens for all prompts: {total_tokens_truncated_prompts}\")\n",
    "print(f\"Average number of tokens in all_prompts: {average_tokens_truncated_prompts}\")\n",
    "\n",
    "# Compare output to previous output (prior to truncation)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "95772e7a",
   "metadata": {},
   "source": [
    "print(\"Total number of truncated prompts: \",len(truncated_prompts))\n",
    "\n",
    "print(truncated_prompts[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2db20b",
   "metadata": {},
   "source": [
    "# Feed prompts into LLM\n",
    "\n",
    "* Initially was working from a list of prompts.\n",
    "* Modified to work from df and append response directly to df in new 'responses' col.\n",
    "    * Allows for linking to sent_id without feeding id into prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8737d98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Generic', 'Start Offset': 26, 'End Offset': 32, 'Annotated Text': 'system'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 37, 'End Offset': 63, 'Annotated Text': 'categorizing unknown words'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'Generic', 'Start Offset': 71, 'End Offset': 77, 'Annotated Text': 'system'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Method', 'Start Offset': 94, 'End Offset': 122, 'Annotated Text': 'multi-component architecture'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 136, 'End Offset': 145, 'Annotated Text': 'component'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'OtherScientificTerm', 'Start Offset': 192, 'End Offset': 205, 'Annotated Text': 'unknown words'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'Generic', 'Start Offset': 240, 'End Offset': 250, 'Annotated Text': 'components'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'OtherScientificTerm', 'Start Offset': 267, 'End Offset': 272, 'Annotated Text': 'names'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'OtherScientificTerm', 'Start Offset': 279, 'End Offset': 294, 'Annotated Text': 'spelling errors'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'Generic', 'Start Offset': 303, 'End Offset': 312, 'Annotated Text': 'component'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Method', 'Start Offset': 322, 'End Offset': 348, 'Annotated Text': 'decision tree architecture'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'OtherScientificTerm', 'Start Offset': 401, 'End Offset': 413, 'Annotated Text': 'unknown word'}, 'T13': {'Annotation ID': 'T13', 'Entity': 'Generic', 'Start Offset': 421, 'End Offset': 427, 'Annotated Text': 'system'}, 'T14': {'Annotation ID': 'T14', 'Entity': 'Material', 'Start Offset': 459, 'End Offset': 479, 'Annotated Text': 'live closed captions'}, 'T15': {'Annotation ID': 'T15', 'Entity': 'OtherScientificTerm', 'Start Offset': 523, 'End Offset': 536, 'Annotated Text': 'unknown words'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED-FOR', 'Arg1': 'T4', 'Arg2': 'T3'}, 'R2': {'Relationship ID': 'R2', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T8'}, 'R3': {'Relationship ID': 'R3', 'Type': 'USED-FOR', 'Arg1': 'T11', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'PART-OF', 'Arg1': 'T5', 'Arg2': 'T4'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T9'}, 'R6': {'Relationship ID': 'R6', 'Type': 'HYPONYM-OF', 'Arg1': 'T7', 'Arg2': 'T5'}, 'R7': {'Relationship ID': 'R7', 'Type': 'COREF', 'Arg1': 'T13', 'Arg2': 'T3'}, 'R8': {'Relationship ID': 'R8', 'Type': 'USED-FOR', 'Arg1': 'T5', 'Arg2': 'T6'}, 'R9': {'Relationship ID': 'R9', 'Type': 'EVALUATE-FOR', 'Arg1': 'T14', 'Arg2': 'T13'}, 'R10': {'Relationship ID': 'R10', 'Type': 'CONJUNCTION', 'Arg1': 'T8', 'Arg2': 'T9'}, 'R11': {'Relationship ID': 'R11', 'Type': 'COREF', 'Arg1': 'T10', 'Arg2': 'T7'}, 'R12': {'Relationship ID': 'R12', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R13': {'Relationship ID': 'R13', 'Type': 'COREF', 'Arg1': 'T1', 'Arg2': 'T3'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi-component architecture USED-FOR system'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'components USED-FOR names'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'decision tree architecture USED-FOR component'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'component PART-OF multi-component architecture'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'components USED-FOR spelling errors'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'components HYPONYM-OF component'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'system COREF system'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'component USED-FOR unknown words'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'live closed captions EVALUATE-FOR system'}, 'R10': {'Relationship ID': 'R10', 'Rel': 'names CONJUNCTION spelling errors'}, 'R11': {'Relationship ID': 'R11', 'Rel': 'component COREF components'}, 'R12': {'Relationship ID': 'R12', 'Rel': 'system USED-FOR categorizing unknown words'}, 'R13': {'Relationship ID': 'R13', 'Rel': 'system COREF system'}}</td>\n",
       "      <td>[multi-component architecture USED-FOR system, components USED-FOR names, decision tree architecture USED-FOR component, component PART-OF multi-component architecture, components USED-FOR spelling errors, components HYPONYM-OF component, system COREF system, component USED-FOR unknown words, live closed captions EVALUATE-FOR system, names CONJUNCTION spelling errors, component COREF components, system USED-FOR categorizing unknown words, system COREF system]</td>\n",
       "      <td>13</td>\n",
       "      <td>Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n\\n    ###\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 entities                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               relationships                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             populated_rels                                                                                                                                                                                                                                                                                                                                                                                                                                                        simplified_populated_rels  rel_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              prompt\n",
       "0    A00-1024  \\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n  {'T1': {'Annotation ID': 'T1', 'Entity': 'Generic', 'Start Offset': 26, 'End Offset': 32, 'Annotated Text': 'system'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 37, 'End Offset': 63, 'Annotated Text': 'categorizing unknown words'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'Generic', 'Start Offset': 71, 'End Offset': 77, 'Annotated Text': 'system'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Method', 'Start Offset': 94, 'End Offset': 122, 'Annotated Text': 'multi-component architecture'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 136, 'End Offset': 145, 'Annotated Text': 'component'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'OtherScientificTerm', 'Start Offset': 192, 'End Offset': 205, 'Annotated Text': 'unknown words'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'Generic', 'Start Offset': 240, 'End Offset': 250, 'Annotated Text': 'components'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'OtherScientificTerm', 'Start Offset': 267, 'End Offset': 272, 'Annotated Text': 'names'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'OtherScientificTerm', 'Start Offset': 279, 'End Offset': 294, 'Annotated Text': 'spelling errors'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'Generic', 'Start Offset': 303, 'End Offset': 312, 'Annotated Text': 'component'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Method', 'Start Offset': 322, 'End Offset': 348, 'Annotated Text': 'decision tree architecture'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'OtherScientificTerm', 'Start Offset': 401, 'End Offset': 413, 'Annotated Text': 'unknown word'}, 'T13': {'Annotation ID': 'T13', 'Entity': 'Generic', 'Start Offset': 421, 'End Offset': 427, 'Annotated Text': 'system'}, 'T14': {'Annotation ID': 'T14', 'Entity': 'Material', 'Start Offset': 459, 'End Offset': 479, 'Annotated Text': 'live closed captions'}, 'T15': {'Annotation ID': 'T15', 'Entity': 'OtherScientificTerm', 'Start Offset': 523, 'End Offset': 536, 'Annotated Text': 'unknown words'}}  {'R1': {'Relationship ID': 'R1', 'Type': 'USED-FOR', 'Arg1': 'T4', 'Arg2': 'T3'}, 'R2': {'Relationship ID': 'R2', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T8'}, 'R3': {'Relationship ID': 'R3', 'Type': 'USED-FOR', 'Arg1': 'T11', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'PART-OF', 'Arg1': 'T5', 'Arg2': 'T4'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T9'}, 'R6': {'Relationship ID': 'R6', 'Type': 'HYPONYM-OF', 'Arg1': 'T7', 'Arg2': 'T5'}, 'R7': {'Relationship ID': 'R7', 'Type': 'COREF', 'Arg1': 'T13', 'Arg2': 'T3'}, 'R8': {'Relationship ID': 'R8', 'Type': 'USED-FOR', 'Arg1': 'T5', 'Arg2': 'T6'}, 'R9': {'Relationship ID': 'R9', 'Type': 'EVALUATE-FOR', 'Arg1': 'T14', 'Arg2': 'T13'}, 'R10': {'Relationship ID': 'R10', 'Type': 'CONJUNCTION', 'Arg1': 'T8', 'Arg2': 'T9'}, 'R11': {'Relationship ID': 'R11', 'Type': 'COREF', 'Arg1': 'T10', 'Arg2': 'T7'}, 'R12': {'Relationship ID': 'R12', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R13': {'Relationship ID': 'R13', 'Type': 'COREF', 'Arg1': 'T1', 'Arg2': 'T3'}}  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi-component architecture USED-FOR system'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'components USED-FOR names'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'decision tree architecture USED-FOR component'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'component PART-OF multi-component architecture'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'components USED-FOR spelling errors'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'components HYPONYM-OF component'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'system COREF system'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'component USED-FOR unknown words'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'live closed captions EVALUATE-FOR system'}, 'R10': {'Relationship ID': 'R10', 'Rel': 'names CONJUNCTION spelling errors'}, 'R11': {'Relationship ID': 'R11', 'Rel': 'component COREF components'}, 'R12': {'Relationship ID': 'R12', 'Rel': 'system USED-FOR categorizing unknown words'}, 'R13': {'Relationship ID': 'R13', 'Rel': 'system COREF system'}}  [multi-component architecture USED-FOR system, components USED-FOR names, decision tree architecture USED-FOR component, component PART-OF multi-component architecture, components USED-FOR spelling errors, components HYPONYM-OF component, system COREF system, component USED-FOR unknown words, live closed captions EVALUATE-FOR system, names CONJUNCTION spelling errors, component COREF components, system USED-FOR categorizing unknown words, system COREF system]         13  Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n\\n    ###\\n    "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new df to contain responses at corresponding rows.\n",
    "# MODIFY TO SPECIFY AMOUNT OF INPUT.\n",
    "\n",
    "scierc_full_responses = scierc_full.copy()\n",
    "scierc_full_responses.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3007230",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf38fcb",
   "metadata": {},
   "source": [
    "## Prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "350fca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model:\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "# Retry parameters\n",
    "max_retries = 3\n",
    "retry_delay = 5  # in seconds\n",
    "\n",
    "# Initialize a new column 'responses' in the dataframe\n",
    "scierc_full_responses.loc[:, 'responses'] = ''\n",
    "\n",
    "def generate_responses(input_df):\n",
    "    for idx, row in tqdm(input_df.iterrows(), total=len(input_df), desc=\"Generating responses\"):\n",
    "        try:\n",
    "            query = row['prompt']\n",
    "\n",
    "            if query is None or query.strip() == '':\n",
    "                print(f\"Empty prompt at index {idx}. Skipping this row.\")\n",
    "                continue\n",
    "\n",
    "            retries = 0\n",
    "            while retries < max_retries:\n",
    "                try:\n",
    "                    response = openai.ChatCompletion.create(\n",
    "                        model=GPT_MODEL,\n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": \"You will perform relationship and coreference extraction on the given abstract, adhering to the restricted types listed in the query\"},\n",
    "                            {\"role\": \"user\", \"content\": query}, # In general, gpt-3.5-turbo-0301 does not pay strong attention to the system message, and therefore important instructions are often better placed in a user message.\n",
    "                        ],\n",
    "                        temperature=0,\n",
    "                        max_tokens=600,  # max tokens in response. token limit (4096) must be < largest query + message content + max_tokens\n",
    "                    )\n",
    "\n",
    "                    response_content = response['choices'][0]['message']['content']\n",
    "                    print(response_content)  # Print just the message content\n",
    "\n",
    "                    # Add the response to the 'responses' column of the dataframe\n",
    "                    input_df.loc[idx, 'responses'] = response_content\n",
    "\n",
    "                    break  # Break out of the retry loop if successful\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating response for prompt at index {idx}: {str(e)}\")\n",
    "                    print(f\"Query: {query}\")\n",
    "                    retries += 1\n",
    "                    print(f\"Retrying in {retry_delay} seconds...\")\n",
    "                    time.sleep(retry_delay)\n",
    "\n",
    "            if retries == max_retries:\n",
    "                print(f\"Max retries reached for prompt at index {idx}. Skipping this row.\")\n",
    "\n",
    "            # Add a delay between requests to avoid overwhelming the API\n",
    "            time.sleep(random.uniform(0.5, 1.5))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating response for prompt at index {idx}: {str(e)}\")\n",
    "            print(f\"Query: {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d2340a",
   "metadata": {},
   "source": [
    "## Run prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2605f8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"system PART-OF multi-component architecture\", \"component USED-FOR identifying unknown words\", \"names COREF spelling errors\", \"component FEATURE-OF decision tree architecture\", \"system EVALUATE-FOR live closed captions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   0%|          | 1/500 [00:05<49:41,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach FEATURE-OF statistical sentence generation\", \"alternative phrases PART-OF packed sets\", \"alternative phrases PART-OF forests\", \"representation FEATURE-OF advantages\", \"representation FEATURE-OF ability to represent syntactic information\", \"ranking algorithm FEATURE-OF efficient statistical ranking\", \"experimental results EVALUATE-FOR improvements over simple enumeration\", \"experimental results EVALUATE-FOR lattice-based approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   0%|          | 2/500 [00:16<1:11:12,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"natural language interface USED-FOR database query applications\", \"multimedia answers FEATURE-OF videodisc images, complete sentences\", \"text-to-speech form FEATURE-OF heuristically-produced sentences\", \"Deictic reference PART-OF multimedia answers\", \"feedback PART-OF discourse\", \"interface PRESENTS application as cooperative and conversational\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   1%|          | 3/500 [00:24<1:09:48,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 3: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2f4bdb74605d467dbf6116d650fec116 in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "     \n",
      " In this paper, we describe the  pronominal anaphora resolution module  of  Lucy  , a portable  English understanding system  . The design of this module was motivated by the observation that, although there exist many theories of  anaphora resolution  , no one of these theories is complete. Thus we have implemented a  blackboard-like architecture  in which individual  partial theories  can be encoded as separate modules that can interact to propose candidate  antecedents  and to evaluate each other's proposals. \n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"pronominal anaphora resolution module PART-OF Lucy\", \"anaphora resolution HYPONYM-OF theories\", \"blackboard-like architecture FEATURE-OF module design\", \"partial theories PART-OF blackboard-like architecture\", \"antecedents USED-FOR candidate proposals\", \"modules EVALUATE-FOR proposals\", \"proposals COMPARE each other's proposals\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   1%|          | 4/500 [01:08<3:03:58, 22.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"natural language generation USED-FOR interaction\", \"graphical information FEATURE-OF cognitively well-motivated interfaces\", \"information EVALUATE-FOR user support\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   1%|          | 5/500 [01:12<2:10:57, 15.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"NL evaluations COMPARE Message Understanding Conferences\", \"evaluation methodology USED-FOR mature, practical applications\", \"methodology USED-FOR comparative evaluation of SLS systems\", \"evaluation methodology EVALUATE-FOR competing claims and identifying promising technical approaches\", \"methodology USED-FOR automatic evaluation of question-answering NL systems\", \"methodology FEATURE-OF domain-independent\", \"methodology USED-FOR speech or text input\", \"DARPA Spoken Language Systems program PART-OF methodology\", \"SLS systems HYPONYM-OF question-answering NL systems\", \"researchers COREF developers of natural language interfaces\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   1%|          | 6/500 [01:26<2:06:27, 15.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"TACITUS HYPONYM-OF natural language processing\", \"MUC-3 evaluation FEATURE-OF TACITUS\", \"syntactic analysis USED-FOR agenda-based scheduling parser\", \"recovery technique FEATURE-OF syntactic analysis\", \"terminal substring parsing FEATURE-OF syntactic analysis\", \"abductive inference FEATURE-OF pragmatics processing\", \"interpretation EVALUATE-FOR world knowledge\", \"techniques COMPARE each other\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   1%|▏         | 7/500 [01:37<1:52:25, 13.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"chart-based phrase structure parsing USED-FOR natural language\", \"parser FEATURE-OF algorithmic efficiency\", \"edge PART-OF chart\", \"spanning edges EVALUATE-FOR correct ones\", \"constituent PART-OF final\", \"phrase boundary heuristics FEATURE-OF use\", \"function words PART-OF placement\", \"heuristic rules FEATURE-OF permit\", \"phrases PART-OF certain kinds\", \"unknown words PART-OF presence\", \"semantic categories USED-FOR reduction\", \"terminal edges HYPONYM-OF syntactic categories\", \"non-terminal edges HYPONYM-OF syntactic categories\", \"semantic interpretation HYPONYM-OF valid interpretation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   2%|▏         | 8/500 [01:51<1:54:55, 14.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"spelling correction USED-FOR agglutinative languages\", \"approach FEATURE-OF spelling correction\", \"two-level morphology FEATURE-OF approach\", \"search algorithm FEATURE-OF approach\", \"spelling correction EVALUATE-FOR Turkish\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   2%|▏         | 9/500 [01:58<1:34:48, 11.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"GLOSSER SUPPORT reading\", \"learning SUPPORT reading\", \"four language pairs SUPPORTED by GLOSSER\", \"English-Bulgarian SUPPORTED by GLOSSER\", \"English-Estonian SUPPORTED by GLOSSER\", \"English-Hungarian SUPPORTED by GLOSSER\", \"French-Dutch SUPPORTED by GLOSSER\", \"program OPERATIONAL on UNIX platforms\", \"program OPERATIONAL on Windows '95 platforms\", \"user-study UNDERGONE by program\", \"demonstration EMPHASIZES components\", \"morphological analysis PUT TO USE in ICALL\", \"disambiguated morphological analysis PUT TO USE in ICALL\", \"lemmatized indexing PUT TO USE in ICALL\", \"aligned bilingual corpus of word examples PART-OF demonstration\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   2%|▏         | 10/500 [02:15<1:48:13, 13.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"LCS representations PART-OF verbs\", \"relation BETWEEN broad semantic classes AND LCS meaning components\", \"acquisition program LEXICALL USED-FOR LCS representations\", \"input OF acquisition program LEXICALL result OF previous work ON verb classification AND thematic grid tagging\", \"English lexicons PART-OF representations\", \"Arabic lexicons PART-OF representations\", \"Spanish lexicons PART-OF representations\", \"lexicons EVALUATE-FOR operational foreign language tutoring AND machine translation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   2%|▏         | 11/500 [02:26<1:42:49, 12.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"NLP-system USED-FOR Dutch\", \"morphological component PART-OF NLP-system\", \"DMLP HYPONYM-OF LSP-MLP\", \"language independent developments FEATURE-OF NLP-system\", \"language independent modules PART-OF LSP-MLP\", \"idiosyncrasies EVALUATE-FOR Dutch\", \"relevant information FEATURE-OF patient discharge summary\", \"PDS HYPONYM-OF patient discharge summary\", \"modern HyperText Mark-Up Language FEATURE-OF technology\", \"application USED-FOR medical administrative purposes\", \"HTML technology PART-OF application\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   2%|▏         | 12/500 [02:40<1:46:03, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Named Entity task FEATURE-OF information extraction task\", \"corpora USED-FOR Named Entity task\", \"statistical analysis FEATURE-OF algorithm\", \"algorithm USED-FOR lower bound estimation\", \"Named Entity corpora PART-OF algorithm\", \"cross-lingual comparisons FEATURE-OF analysis\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   3%|▎         | 13/500 [02:46<1:29:57, 11.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"position COREF text\", \"training USED-FOR Optimal Position Policy\", \"position FEATURE-OF topic-bearing sentences\", \"genre-specific regularities FEATURE-OF discourse structure\", \"method USED-FOR information retrieval, routing, and text summarization\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   3%|▎         | 14/500 [02:53<1:18:01,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm USED-FOR translation lexicon acquisition\", \"SABLE USED-FOR translation lexicon acquisition\", \"corpus USED-FOR acquire general translation lexicons\", \"algorithm USED-FOR produce candidates for domain-specific translation lexicons\", \"corpus PART-OF translation lexicon acquisition\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   3%|▎         | 15/500 [03:00<1:11:57,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"subcategorization dictionary FEATURE-OF parser\", \"subcategorization dictionary USED-FOR improving parser accuracy\", \"technique COMPARE previous approaches\", \"dictionary entry PART-OF subcategorization dictionary\", \"experiment EVALUATE-FOR accuracy\", \"verbs HYPONYM-OF subcategorization classes\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   3%|▎         | 16/500 [03:08<1:10:58,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Rete algorithm FEATURE-OF Forward Chaining rule systems\", \"Treat algorithm FEATURE-OF Forward Chaining rule systems\", \"universal quantification EVALUATE-FOR rule\", \"full unification EVALUATE-FOR algorithms\", \"compile time checks COMPARE run time checks\", \"cost of supporting full unification EVALUATE-FOR practical systems\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   3%|▎         | 17/500 [03:18<1:13:41,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"propositional logic of context FEATURE-OF classical propositional logic\", \"modality ist(;) USED-FOR expressing that sentence holds in the context\", \"context PART-OF vocabulary\", \"Hilbert style proof system EVALUATE-FOR soundness and completeness\", \"extensions of general system COMPARE general system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   4%|▎         | 18/500 [03:27<1:12:11,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Verma constraints COMPARE conditional independencies\", \"dormant independencies USED-FOR model testing and induction\", \"conditional independencies FEATURE-OF causal induction algorithms\", \"independence COREF this independence\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   4%|▍         | 19/500 [03:35<1:09:27,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ensemble construction USED-FOR resampling pairwise constraints\", \"base classifiers FEATURE-OF diverse individual learners\", \"pairwise constraints PART-OF ensemble construction\", \"instances COREF pairwise constraints\", \"Bagging COMPARE Boosting\", \"experiments EVALUATE-FOR effectiveness of method\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   4%|▍         | 20/500 [03:41<1:02:14,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No relationships or coreferences detected in the provided abstract within the restricted types listed in the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   4%|▍         | 21/500 [03:44<50:41,  6.35s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"machine reading system COREF system\", \"natural language processing (NLP) AND information extraction (IE) CONJUNCTION core technologies\", \"machine reading system FEATURE-OF cognitive architecture\", \"knowledge levels PART-OF framework\", \"cognitive semantics AND construction grammar CONJUNCTION ideas\", \"NLP AND IE tools PART-OF system\", \"system EVALUATE-FOR complex and fairly idiosyncratic texts interpretation\", \"system COMPARE prior NLP AND IE research\", \"evaluations EVALUATE-FOR system performance\", \"possible future directions PART-OF summary\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   4%|▍         | 22/500 [03:56<1:05:21,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"outliers FEATURE-OF convex optimization problem\", \"algorithms USED-FOR solving convex optimization problem\", \"algorithms COMPARE baseline segmentation algorithms\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   5%|▍         | 23/500 [04:00<55:16,  6.95s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Semantic Web documents USED-FOR encoding facts about entities on the Web\", \"automatic summarization techniques EVALUATE-FOR identification of an entity\", \"diversified summaries FEATURE-OF entity summarization\", \"diversity-aware entity summarization approach COMPARE state-of-the-art techniques\", \"our work EVALUATE-FOR both the quality and the efficiency of entity summarization\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   5%|▍         | 24/500 [04:09<1:00:24,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"multimodal parsing and understanding USED-FOR speech and gesture streams\", \"multimodal parsing and understanding FEATURE-OF weighted finite-state device\", \"multimodal integration FEATURE-OF unification-based grammar\", \"multidimensional chart parser PART-OF unification-based grammar\", \"multimodal parsing and understanding EVALUATE-FOR multimodal ambiguity resolution\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   5%|▌         | 25/500 [04:18<1:02:31,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"statistical machine translation USED-FOR search procedure\", \"dynamic programming USED-FOR search procedure\", \"word reordering FEATURE-OF possible word reordering\", \"source language PART-OF word reordering\", \"target language PART-OF word reordering\", \"translation direction EVALUATE-FOR efficient search algorithm\", \"German HYPONYM-OF limited-domain spoken-language task\", \"Verbmobil task PART-OF limited-domain spoken-language task\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   5%|▌         | 26/500 [04:28<1:08:24,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"deep processing USED-FOR shallow techniques\", \"NLP system PART-OF preprocessing module\", \"PoS tagger FEATURE-OF linguistic processing\", \"chunker FEATURE-OF linguistic processing\", \"efficiency EVALUATE-FOR overall analysis\", \"system COREF system\", \"robustness EVALUATE-FOR linguistic processing\", \"accuracy EVALUATE-FOR grammar\", \"precision EVALUATE-FOR grammar\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   5%|▌         | 27/500 [04:39<1:11:57,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"unsupervised learning method FEATURE-OF associative relationships\", \"Q&A systems EVALUATE-FOR reliable\", \"user QUERY-COREF query\", \"Q&A system USED-FOR text\", \"description USED-FOR finding answer\", \"large-scale database MISSING-FOR associative relationship\", \"unsupervised learning method USED-FOR obtaining associative relationship\", \"scenario consistency HYPONYM-OF associative relationship\", \"expectation-maximization based word-clustering algorithm FEATURE-OF method\", \"Japanese verb phrases USED-FOR evaluation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   6%|▌         | 28/500 [04:51<1:19:40, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 28: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a5d710edc866c40d05f80ec0fcd42735 in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    \n",
      "We consider the problem of computing the  Kullback-Leibler distance , also called the  relative entropy , between a  probabilistic context-free grammar  and a  probabilistic finite automaton . We show that there is a  closed-form (analytical) solution  for one part of the  Kullback-Leibler distance , viz the  cross-entropy . We discuss several applications of the result to the problem of  distributional approximation  of  probabilistic context-free grammars  by means of  probabilistic finite automata .\n",
      "\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"Kullback-Leibler distance HYPONYM-OF relative entropy\", \"probabilistic context-free grammar PART-OF Kullback-Leibler distance\", \"probabilistic finite automaton PART-OF Kullback-Leibler distance\", \"cross-entropy FEATURE-OF Kullback-Leibler distance\", \"distributional approximation USED-FOR probabilistic context-free grammars\", \"probabilistic finite automata PART-OF distributional approximation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   6%|▌         | 29/500 [05:37<2:43:03, 20.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"factored language models FEATURE-OF new approaches\", \"model parameters PART-OF large space of models\", \"genetic search USED-FOR model selection procedure\", \"knowledge-based selection procedures COMPARE random selection procedures\", \"Arabic EVALUATE-FOR language modeling tasks\", \"Turkish EVALUATE-FOR language modeling tasks\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   6%|▌         | 30/500 [05:44<2:11:58, 16.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"parser COMPUTES parse forest representation\", \"parser USES bit-vector operations\", \"parser IS particularly useful\", \"analyses PART-OF complete set\", \"treebank grammars FEATURE-OF analyses\", \"input sentences FEATURE-OF analyses\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   6%|▌         | 31/500 [05:50<1:46:15, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"machine learning approach USED-FOR bare slice disambiguation\", \"heuristic principles FEATURE-OF Horn clauses\", \"predicates PART-OF Horn clauses\", \"domain independent features FEATURE-OF input dataset\", \"machine learning algorithms COMPARE SLIPPER, TiMBL\", \"success rates EVALUATE-FOR approx 90%\", \"features EVALUATE-FOR predictive power\", \"rules COMPARE Horn clauses\", \"rules EVALUATE-FOR learnt automatically from features\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   6%|▋         | 32/500 [06:02<1:40:40, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"word similarity measures HYPONYM-OF goal\", \"evaluation criterion FEATURE-OF word similarity measures\", \"meaning-entailing substitutability EVALUATE-FOR word similarity measures\", \"meaning-entailing substitutability FEATURE-OF semantic-oriented NLP applications\", \"distributional word feature vectors PART-OF word similarity results\", \"feature vector quality EVALUATE-FOR distributional word feature vectors\", \"feature weighting and selection function USED-FOR feature vectors\", \"feature weighting and selection function FEATURE-OF better word similarity performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   7%|▋         | 33/500 [06:18<1:48:56, 14.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"maximum entropy classifiers USED-FOR language processing tasks\", \"boosting USED-FOR language processing tasks\", \"SVMs USED-FOR language processing tasks\", \"error correction mechanisms FEATURE-OF classifiers\", \"NTPC USED-FOR error correction\", \"NTPC EVALUATE-FOR accuracy improvement\", \"base classifier USED-FOR error correction\", \"NTPC COMPARE complex models\", \"NTPC COMPARE damaging models\", \"NTPC COMPARE unnecessary models\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   7%|▋         | 34/500 [06:29<1:42:14, 13.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"project AIMED-AT clustering and summarise electronic discussions, summaries USED-FOR assist help-desk users and operators, features OF electronic discussions that influence clustering process, filtering mechanism FEATURE-OF clustering and filtering processes, clustering and filtering processes EVALUATE-FOR performance, coarse-level clustering COMPARE simple information retrieval\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   7%|▋         | 35/500 [06:37<1:28:56, 11.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"HMM tagger USED-FOR part-of-speech tagging\", \"unsupervised methods COMPARE supervised case\", \"lexicon FEATURE-OF accuracy\", \"HMM training EVALUATE-FOR accuracy\", \"training EVALUATE-FOR lexical probabilities\", \"tagger FEATURE-OF supervised framework\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   7%|▋         | 36/500 [06:45<1:19:41, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"generation algorithm FEATURE-OF proposed method\", \"perceptual groups PART-OF objects\", \"n-ary relations PART-OF objects\", \"proposed method EVALUATE-FOR proper referring expressions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   7%|▋         | 37/500 [06:50<1:07:34,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"orthographic variants PART-OF transliteration\", \"string similarity FEATURE-OF detection method\", \"contextual similarity FEATURE-OF detection method\", \"method EVALUATE-FOR 0.889 F-measure\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   8%|▊         | 38/500 [06:55<59:23,  7.71s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"machine transliteration/back-transliteration FEATURE-OF multilingual speech and language applications\", \"DOM USED-FOR machine transliteration/back-transliteration\", \"joint source-channel transliteration model FEATURE-OF transliteration process\", \"n-gram TM HYPONYM-OF joint source-channel transliteration model\", \"transliteration/backtransliteration experiments EVALUATE-FOR transliteration accuracy\", \"proposed method EVALUATE-FOR transliteration accuracy\", \"English/Japanese language pairs COMPARE English/Chinese language pairs\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   8%|▊         | 39/500 [07:06<1:07:48,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"analogies between words COREF noone\", \"analogies between sentences COMPARE analogies between words\", \"multilingual corpus PART-OF experiments\", \"analogy EVALUATE-FOR usefulness\", \"translation USED-FOR test for similar meanings\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   8%|▊         | 40/500 [07:13<1:02:05,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"corpus-based supervised word sense disambiguation system EVALUATE-FOR Dutch\", \"maximum entropy USED-FOR statistical classification\", \"linguistic information FEATURE-OF supervised word sense disambiguation system\", \"lemma-based approach FEATURE-OF novel method\", \"inflected forms PART-OF lemma-based approach\", \"training material FEATURE-OF algorithm\", \"lemma-based model COMPARE wordform model\", \"WSD system based on lemmas FEATURE-OF smaller and more robust system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   8%|▊         | 41/500 [07:24<1:08:24,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"text mining method USED-FOR finding synonymous expressions\", \"distributional hypothesis FEATURE-OF finding synonymous expressions\", \"corpora PART-OF distributional hypothesis\", \"methodology USED-FOR improving accuracy of term aggregation system\", \"author's text PART-OF coherent corpus\", \"person COREF one\", \"expression USED-FOR meaning\", \"words with similar context features HYPONYM-OF synonymous expressions\", \"proposed method EVALUATE-FOR accuracy of term aggregation system\", \"approach USED-FOR successful\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   8%|▊         | 42/500 [07:34<1:10:23,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 42: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a297fbed8114f4ab7826fad9b2ea927d in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    \n",
      "While  sentence extraction  as an approach to  summarization  has been shown to work in  documents  of certain  genres , because of the conversational nature of  email communication  where  utterances  are made in relation to one made previously,  sentence extraction  may not capture the necessary  segments  of  dialogue  that would make a  summary  coherent. In this paper, we present our work on the detection of  question-answer pairs  in an  email conversation  for the task of  email summarization . We show that various  features  based on the structure of email-threads can be used to improve upon  lexical similarity  of  discourse segments  for  question-answer pairing .\n",
      "\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"sentence extraction USED-FOR summarization\", \"email communication PART-OF conversation\", \"utterances PART-OF dialogue\", \"summary EVALUATE-FOR coherence\", \"question-answer pairs FEATURE-OF email summarization\", \"features USED-FOR question-answer pairing\", \"structure of email-threads FEATURE-OF features\", \"lexical similarity COMPARE discourse segments\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   9%|▊         | 43/500 [08:18<2:29:31, 19.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"lexical affinity models FEATURE-OF framework\", \"co-occurrence distribution PART-OF novel algorithm\", \"terms PART-OF co-occurrence distribution\", \"independence model FEATURE-OF framework\", \"parametric affinity model FEATURE-OF framework\", \"similarity COMPARE lexical affinity\", \"co-occurrence patterns USED-FOR models\", \"words PART-OF co-occurrence patterns\", \"phrases PART-OF co-occurrence patterns\", \"framework USED-FOR applications\", \"terabyte corpus PART-OF natural language tests\", \"encouraging results EVALUATE-FOR natural language tests\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   9%|▉         | 44/500 [08:31<2:15:02, 17.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method based-on parallel corpora FEATURE-OF word sense disambiguation\", \"word alignment USED-FOR word sense disambiguation\", \"word clustering USED-FOR word sense disambiguation\", \"automatic extraction USED-FOR word clustering\", \"translation equivalents USED-FOR word clustering\", \"wordnets FEATURE-OF automatic extraction\", \"wordnets FEATURE-OF aligned to Princeton Wordnet\", \"EuroWordNet HYPONYM-OF Princeton Wordnet\", \"WSD system EVALUATE-FOR encouraging results\", \"system COREF WSD system\", \"validation mode EVALUATE-FOR alignment errors\", \"multilingually aligned wordnets PART-OF BalkaNet\", \"multilingually aligned wordnets PART-OF EuroWordNet\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   9%|▉         | 45/500 [08:48<2:12:39, 17.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"source language FEATURE-OF speeches\", \"EUROPARL corpus PART-OF speeches\", \"frequency counts FEATURE-OF word n-grams\", \"accuracy EVALUATE-FOR classification method\", \"positive markers FEATURE-OF identification\", \"linguistic aspects FEATURE-OF positive markers\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   9%|▉         | 46/500 [08:56<1:50:08, 14.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Chinese word segmenter FEATURE-OF MT systems\", \"Bayesian semi-supervised Chinese word segmentation model USED-FOR MT\", \"monolingual and bilingual information PART-OF Bayesian semi-supervised Chinese word segmentation model\", \"state-of-the-art MT system EVALUATE-FOR method\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   9%|▉         | 47/500 [09:03<1:33:34, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Language resource quality FEATURE-OF NLP\", \"resources FEATURE-OF data\", \"data USED-FOR MT and reference translations\", \"automatic evaluations EVALUATE-FOR comparison of automatic and human translations\", \"resources EVALUATE-FOR being used\", \"different-quality references USED-FOR evaluation\", \"scores COMPARE quality\", \"automatic metrics LIMITATION-OF MT\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  10%|▉         | 48/500 [09:11<1:24:52, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"search tool USED-FOR linguistic knowledge discovery\", \"queries FEATURE-OF search tool\", \"wildcards FEATURE-OF queries\", \"fillers FEATURE-OF wildcards\", \"system PART-OF linguistic knowledge discovery and other NLP tasks\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  10%|▉         | 49/500 [09:18<1:12:50,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"FROFF system USED-FOR fair copy of texts, graphs and tables\", \"fonts FEATURE-OF FROFF system\", \"character size FEATURE-OF FROFF system\", \"typing location FEATURE-OF FROFF system\", \"character PART-OF line length\", \"commands USED-FOR construction of format\", \"rules USED-FOR construction of format\", \"mathematical expressions USED-FOR construction of format\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  10%|█         | 50/500 [09:27<1:11:16,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Augmented Transition Network USED-FOR procedural dialog model\", \"dialog schemata FEATURE-OF empirical conversation analysis\", \"models of verbal interaction FEATURE-OF dialog model\", \"dialog schemata FEATURE-OF dialog model\", \"verbal interaction FEATURE-OF dialog model\", \"knowledge FEATURE-OF device\", \"task-oriented and goal-directed dialogs FEATURE-OF device\", \"ATN PART-OF standard ATN\", \"verbal interactions PART-OF task-oriented dialogs\", \"ATN EVALUATE-FOR verbal interactions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  10%|█         | 51/500 [09:37<1:13:53,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"left corner parsing algorithm FEATURE-OF context-free grammars\", \"resulting algorithm USED-FOR parser\", \"parser USED-FOR natural language interface\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  10%|█         | 52/500 [09:42<1:02:18,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"interlingual approach USED-FOR machine translation\", \"Mu-project PART-OF transfer phase\", \"Japanese HYPONYM-OF natural language\", \"English HYPONYM-OF natural language\", \"transfer approach FEATURE-OF Mu-project\", \"transfer phase FEATURE-OF system\", \"interlingual approach COMPARE transfer approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  11%|█         | 53/500 [09:50<1:02:16,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"determiners FEATURE-OF utterance\", \"determiners ambiguity COREF\", \"logical formalism SUITABLE-FOR representing determiners\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  11%|█         | 54/500 [09:55<54:10,  7.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"hierarchical relations PART-OF thesaurus construction\", \"Japanese language dictionary FEATURE-OF pilot system\", \"definition sentences FEATURE-OF dictionary\", \"hierarchical relations USED-FOR thesaurus construction\", \"results EVALUATE-FOR estimation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  11%|█         | 55/500 [10:02<52:06,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"RAREAS draws on linguistic and non-linguistic knowledge\", \"synthesis USED-FOR marine weather forecasts\", \"RAREAS synthesizes marine weather forecasts directly from formatted weather data\", \"approach can be adapted to synthesize bilingual or multi-lingual texts\", \"temporal adverbs EVALUATE-FOR remote meteorological events\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  11%|█         | 56/500 [10:09<53:05,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Isomorphic Grammars approach USED-FOR Machine Translation\", \"Source and Target languages PART-OF Isomorphic Grammars\", \"SL and TL expressions HYPONYM-OF translation relation\", \"translation equivalence FEATURE-OF expressions\", \"semantic questions EVALUATE-FOR need for answers\", \"translation relation COMPARE textual representation\", \"monolingual UCG PART-OF MT system design\", \"English-Spanish fragment COREF implemented bi-directional fragment\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  11%|█▏        | 57/500 [10:20<1:01:04,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"demonstrative expressions USED-FOR discourse processing algorithms\", \"demonstrative forms and functions FEATURE-OF texts\", \"anaphoric expressions PART-OF larger study\", \"results of larger study EVALUATE-FOR natural language generation system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  12%|█▏        | 58/500 [10:26<56:39,  7.69s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Category Cooccurrence Restrictions (CCRs) FEATURE-OF Boolean conditions\", \"CCR formalism USED-FOR syntactic descriptions\", \"parsing algorithms PART-OF CCR formalism\", \"parser EVALUATE-FOR logical well-formedness conditions\", \"algorithms COMPARE CCR formalism to context free languages\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  12%|█▏        | 59/500 [10:34<56:54,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"theory of natural language presuppositions FEATURE-OF Soames 1979\", \"theory of natural language presuppositions PRESENTED-IN Gazdar 1979\", \"counterexamples HYPONYM-OF presuppositional nature of these sentences\", \"counterexamples USED-FOR reappraising\", \"inferential theory for natural language presuppositions FEATURE-OF Mercer 1987, 1988\", \"solution found in Soames 1982 COMPARE solution found in Mercer 1987\", \"counterexamples COREF these insightful counterexamples\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  12%|█▏        | 60/500 [10:46<1:06:24,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"computational model FEATURE-OF process\", \"discourse task HYPONYM-OF layout description\", \"model FEATURE-OF program APT\", \"organizational and discourse strategies FEATURE-OF model\", \"corpus FEATURE-OF analysis\", \"program APT USED-FOR reproducing tape-recorded descriptions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  12%|█▏        | 61/500 [10:54<1:02:29,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"chart parsing PART-OF directional\", \"chart PART-OF islands\", \"sentence PART-OF islands\", \"fragments EVALUATE-FOR predictions\", \"fragments PART-OF sentence\", \"left context COMPARE right context\", \"missing fragments COREF fragments\", \"left context COMPARE right context\", \"heuristics EVALUATE-FOR missing fragments\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  12%|█▏        | 62/500 [11:03<1:03:48,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"author COREF document\", \"ambiguity PART-OF sentence\", \"linguistic theory FEATURE-OF explanation\", \"translation process PART-OF analysis step\", \"interactive disambiguation scheme FEATURE-OF paper\", \"paraphrasing USED-FOR interactive disambiguation scheme\", \"parser PART-OF paraphrasing\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  13%|█▎        | 63/500 [11:11<1:01:50,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"linguistic representation FEATURE-OF language processing systems\", \"Dynamic Hierarchical Phrasal Lexicon (DHPL) FEATURE-OF linguistic representation\", \"language learning model USED-FOR RINA program\", \"lexical hierarchy FEATURE-OF RINA program\", \"linguistic concepts PART-OF lexical hierarchy\", \"linguistic concepts PART-OF training examples\", \"lexical unknown EVALUATE-FOR program stall\", \"hypothesis USED-FOR covering lexical gap\", \"program COREF RINA program\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  13%|█▎        | 64/500 [11:22<1:07:50,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"computational lexicon USED-FOR natural language system\", \"lexicon PART-OF system\", \"information FEATURE-OF lexicon\", \"shared lexical information FEATURE-OF COMPLEX\", \"COMPLEX USED-FOR NLP systems\", \"machine-readable dictionaries FEATURE-OF COMPLEX\", \"broad coverage lexicon FEATURE-OF COMPLEX\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  13%|█▎        | 65/500 [11:29<1:03:14,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"deterministic parser FEATURE-OF hybrid architecture\", \"connectionist component USED-FOR parsing process\", \"rules PART-OF deterministic grammar\", \"rule packets PART-OF deterministic parsers\", \"parsing EVALUATE-FOR robustness and error tolerance\", \"connectionist component COMPARE deterministic grammar\", \"linguistic rules USED-FOR parsing\", \"neural network HYPONYM-OF connectionist component\", \"expected sentences HYPONYM-OF grammatical sentences\", \"novel sentences HYPONYM-OF ungrammatical or lexically ambiguous sentences\", \"deterministic parsers COMPARE hybrid architecture\", \"parser COMPARE deterministic parser\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  13%|█▎        | 66/500 [11:42<1:12:15,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"bidirectional grammar generation system FEATURE-OF dialogue translation system\", \"typed feature structures USED-FOR top-down derivation\", \"disjunctive feature structures USED-FOR reduction of copies of derivation tree\", \"grammar FEATURE-OF generator\", \"speaker's intention PART-OF telephone dialogue\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  13%|█▎        | 67/500 [11:49<1:04:31,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"DoPS system FEATURE-OF disambiguation\", \"DoPS system USED-FOR resolving sentence ambiguities\", \"preference knowledge EXTRACTED-FROM target document\", \"preference knowledge EXTRACTED-FROM other documents\", \"sentence ambiguities RESOLVED-BY domain targeted preference knowledge\", \"large knowledgebases NOT-USED\", \"implementation DESCRIBED-FOR analysis of dependency structures\", \"empirical results DESCRIBED-FOR analysis of dependency structures\", \"Japanese patent claim sentences COREF\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  14%|█▎        | 68/500 [12:00<1:08:46,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"feature-based partial descriptions FEATURE-OF Halliday's systemic networks\", \"consistency checking USED-FOR feature-based partial descriptions\", \"algorithms EVALUATE-FOR consistency checking\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  14%|█▍        | 69/500 [12:05<58:43,  8.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Korean Phonology Structure Grammar (KPSG) FEATURE-OF phonological system\", \"KPSG USED-FOR speech recognition\", \"KPSG USED-FOR synthesis system\", \"KPSG COMPARE traditional generative phonological approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  14%|█▍        | 70/500 [12:13<58:52,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"TAGs HYPONYM-OF tree-adjoining grammars\", \"TAGs PART-OF syntax\", \"synchronous TAGs HYPONYM-OF TAGs\", \"synchronous TAGs USED-FOR semantic interpretation, automatic translation of natural language\", \"languages PART-OF synchronous TAGs\", \"expressions of natural languages COREF their associated semantics represented in a logical form language\", \"expressions of natural languages COREF their translates in another natural language\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  14%|█▍        | 71/500 [12:23<1:01:41,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Japanese sentence analyses USED-FOR argumentation system\", \"argumentation system FEATURE-OF defeasible reasoning\", \"defeasible reasoning PART-OF Konolige formalization\", \"defeat rules PART-OF defeasible reasoning\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  14%|█▍        | 72/500 [12:29<55:38,  7.80s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"semantic constraints FEATURE-OF manual acquisition\", \"statistics USED-FOR disambiguation tool\", \"anaphora references COREF pronoun 'it'\", \"cooccurrence patterns FEATURE-OF semantic constraints\", \"syntactic ambiguities EVALUATE-FOR statistics\", \"references PART-OF sentences\", \"cooccurrence statistics USED-FOR disambiguation tool\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  15%|█▍        | 73/500 [12:37<57:00,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"spelling-checkers FEATURE-OF text processing software\", \"spelling-checkers USED-FOR inflection\", \"inflection FEATURE-OF spelling-checkers\", \"English USED-FOR spelling-checkers\", \"Czech HYPONYM-OF Slavonic languages\", \"Russian HYPONYM-OF Slavonic languages\", \"Slovak HYPONYM-OF Slavonic languages\", \"main dictionary PART-OF resulting program\", \"recognized word forms FEATURE-OF resulting program\", \"word classification FEATURE-OF method\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  15%|█▍        | 74/500 [12:56<1:19:20, 11.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"discourse segments COREF segments\", \"method FEATURE-OF discourse segmentation\", \"abduction USED-FOR temporal relations\", \"method EVALUATE-FOR computational feasibility\", \"method COMPARE previous work\", \"temporal anaphora resolution PART-OF area\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  15%|█▌        | 75/500 [13:02<1:08:33,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"proposed method FEATURE-OF language model\", \"proposed algorithm EVALUATE-FOR syntactic disambiguation\", \"training corpus PART-OF proposed algorithm\", \"accuracy rate EVALUATE-FOR syntactic disambiguation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  15%|█▌        | 76/500 [13:08<1:01:53,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"unification-based grammar parsing USED-FOR graph unification\", \"structure-sharing FEATURE-OF method\", \"log(d) overheads HYPONYM-OF structure-sharing of graphs\", \"dependency pointers HYPONYM-OF costly dependency pointers\", \"redundant copying EVALUATE-FOR quasi-destructive scheme's ability\", \"early copying EVALUATE-FOR quasi-destructive scheme's ability\", \"cyclic structures EVALUATE-FOR quasi-destructive scheme's ability\", \"unmodified subgraphs PART-OF copying\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  15%|█▌        | 77/500 [13:22<1:11:23, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"machine translation systems HYPONYM-OF transfer phase\", \"transfer phase PART-OF machine translation systems\", \"case-based reasoning USED-FOR machine translation\", \"translation examples FEATURE-OF case-based reasoning\", \"SimTran PART-OF transfer system\", \"transfer system USED-FOR case-based MT\", \"CBMT HYPONYM-OF case-based MT\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  16%|█▌        | 78/500 [13:31<1:08:27,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"generalized LR parsing FEATURE-OF robust interactive method\", \"parser PART-OF approach\", \"fake non-terminal symbol FEATURE-OF parser\", \"re-utterance USED-FOR unidentified portion\", \"parse record USED-FOR re-utterance\", \"unknown words FEATURE-OF practical systems\", \"unknown words EVALUATE-FOR dictionary\", \"pilot system COREF approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  16%|█▌        | 79/500 [13:39<1:05:52,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"sublanguage FEATURE-OF mechanism\", \"unknown words USED-FOR personal names\", \"title-driven name recognition PART-OF proposed mechanism\", \"adaptive dynamic word formation PART-OF proposed mechanism\", \"2-character Chinese names without title PART-OF proposed mechanism\", \"corpora COMPARE results by NTHU's statistic-based system\", \"WI systems EVALUATE-FOR name identification capability\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  16%|█▌        | 80/500 [13:49<1:06:11,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SPRINT USED-FOR natural language texts\", \"geometric model PART-OF global scene\", \"qualitative spatial constraints FEATURE-OF model\", \"numerical constraints FEATURE-OF spatial attributes\", \"spatial concepts HYPONYM-OF entities\", \"interpretation EVALUATE-FOR maximally plausible interpretation\", \"belief EVALUATE-FOR temporary belief\", \"scenic descriptions COREF text\", \"described world COREF world\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  16%|█▌        | 81/500 [13:58<1:06:36,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"character-based collocation system USED-FOR avoiding pre-processing distortion, character-based collocation system FEATURE-OF sub-lexical information, word-based collocational properties PART-OF auxiliary module\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  16%|█▋        | 82/500 [14:04<58:04,  8.34s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm USED-FOR selecting appropriate classifier word\", \"classifier FEATURE-OF noun\", \"classifier selection HYPONYM-OF exact rule\", \"rule-based approach USED-FOR giving default rule\", \"corpus-based method USED-FOR generating Noun Classifier Associations\", \"NCA USED-FOR overcoming problems in classifier assignment and semantic construction of noun phrase\", \"NCA PART-OF concept hierarchy constraints\", \"NCA EVALUATE-FOR frequency of occurrences\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  17%|█▋        | 83/500 [14:15<1:02:32,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"word-sense ambiguity FEATURE-OF extraction\", \"semantic classification EVALUATE-FOR verbs\", \"verb semantics COMPARE syntactic behavior\", \"syntactic cues PART-OF semantic information\", \"syntactic cues HYPONYM-OF distinct groupings\", \"distinct groupings PART-OF word senses\", \"online sources USED-FOR acquisition techniques\", \"word-sense distinctions COMPARE 6.3% accuracy\", \"word-sense distinctions COMPARE 97.9% accuracy\", \"experiments COREF experiments\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  17%|█▋        | 84/500 [14:27<1:09:28, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"model FEATURE-OF interpretation\", \"rules FEATURE-OF interpretation\", \"Pustejovsky's principles FEATURE-OF predicative information\", \"semantic principles FEATURE-OF generalizable semantic principles\", \"semantic information FEATURE-OF domain-specific semantic information\", \"model USED-FOR interpretation of compounds\", \"complementary semantic information EVALUATE-FOR interpretation of compounds\", \"nominal constituents PART-OF compounds\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  17%|█▋        | 85/500 [14:36<1:07:02,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"NLP system USED-FOR syntactic parsing\", \"lexicon PART-OF syntactic parsing\", \"existing grammar FEATURE-OF lexicalized grammar\", \"domain HYPONYM-OF sublanguage\", \"hybrid system USED-FOR fitting lexicalized grammar to domain\", \"traditional knowledge-based techniques COMPARE corpus-based approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  17%|█▋        | 86/500 [14:43<1:02:25,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm USED-FOR labeling curvilinear structure\", \"CURVE-ELEMENT tokens FEATURE-OF image description\", \"tokens PART-OF data structure\", \"tokens EVALUATE-FOR selection and characterization of image portions\", \"support COMPARE best-first strategy\", \"tokens COMPARE multiple scales\", \"tokens COMPARE different scales\", \"tokens COMPARE more than one token at any given scale\", \"image contour COREF portions of the image\", \"image contour COREF local CURVE-ELEMENT attributes\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  17%|█▋        | 87/500 [14:54<1:05:09,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"model-based approach FEATURE-OF on-line cursive handwriting analysis and recognition\", \"on-line handwriting PART-OF modulation of cycloidal pen motion\", \"two coupled oscillations HYPONYM-OF simple cycloidal pen motion\", \"amplitudes and phase lags USED-FOR encoding general pen trajectory\", \"parameters EVALUATE-FOR writing intelligibility\", \"procedure USED-FOR estimation and quantization of cycloidal motion parameters\", \"discrete motor control representation FEATURE-OF continuous pen motion\", \"quantized levels COMPARE continuous pen motion\", \"word spotting EVALUATE-FOR cursive scripts\", \"experiments EVALUATE-FOR potential of dynamic representation for complete cursive handwriting recognition\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  18%|█▊        | 88/500 [15:09<1:15:46, 11.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"MINPRAN USED-FOR finding good fits in data sets with outliers\", \"MINPRAN does not rely on a known error bound FEATURE-OF good data\", \"bad data are randomly distributed within the dynamic range of the sensor PART-OF MINPRAN's assumption\", \"MINPRAN uses random sampling to search for the fit EVALUATE-FOR number of inliers\", \"MINPRAN distinguishes good fits from random data COMPARE least median of squares\", \"MINPRAN finds accurate fits and correct number of inliers EVALUATE-FOR true inliers\", \"MINPRAN's properties COMPARE favorably to least median of squares\", \"Related work applies MINPRAN to complex range and intensity data\", \"MINPRAN COREF\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  18%|█▊        | 89/500 [15:24<1:25:28, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"framework USED-FOR segmentation of complex scenes\", \"framework FEATURE-OF proposal\", \"approach USED-FOR segmentation of complex scenes\", \"approach FEATURE-OF coherent surfaces\", \"implementation USED-FOR new approach\", \"segmentations EVALUATE-FOR scenes\", \"objects PART-OF scenes\", \"approach COMPARE previous physics-based segmentation algorithms\", \"segmentations COMPARE segmentations found using only color\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  18%|█▊        | 90/500 [15:34<1:18:44, 11.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"representation USED-FOR video browsing, representation USED-FOR retrieval, representation USED-FOR compression, representation USED-FOR mosaicing, representation USED-FOR visual summarization\", \"single image map PART-OF representation\", \"dominant motion PART-OF representation\", \"capability to register frames PART-OF representation\", \"task EVALUATE-FOR registering frames with respect to dominant object\", \"temporally localized motion estimates COMPARE generic temporal constraint\", \"oscillation between different scene interpretations EVALUATE-FOR poor registration\", \"motion model AUGMENTED WITH generic temporal constraint\", \"robustness EVALUATE-FOR competing interpretations\", \"content summarization FEATURE-OF representation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  18%|█▊        | 91/500 [15:50<1:27:27, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"projective unifocal tensor HYPONYM-OF affine specialization\", \"bifocal tensor HYPONYM-OF affine specialization\", \"trifocal tensor HYPONYM-OF affine specialization\", \"tensors obtained FEATURE-OF registered tensors\", \"projective relations USED-FOR connecting points and lines\", \"affine cameras PART-OF simpler case\", \"components of trifocal tensor EVALUATE-FOR necessary and sufficient constraints\", \"estimation of tensors USED-FOR factorization\", \"estimation from line correspondences USED-FOR tensors\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  18%|█▊        | 92/500 [16:03<1:28:08, 12.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach FEATURE-OF extracting layers\", \"homographies INDUCED-BY planar patches FORM low dimensional linear subspace\", \"layers IN input images MAPPED IN subspace\", \"layers FORM well-defined clusters\", \"mean-shift based clustering algorithm IDENTIFIES layers\", \"valid regions SIMULTANEOUSLY taken into account FOR achieving global optimality\", \"noise EFFECTIVELY REDUCED BY enforcing subspace constraint\", \"layer descriptions SHOWN TO BE extracted IN experimental results\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  19%|█▊        | 93/500 [16:15<1:26:13, 12.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"LNMF COMPARE NMF\", \"LNMF COMPARE PCA\", \"localization constraint FEATURE-OF objective function\", \"non-negativity constraint FEATURE-OF standard NMF\", \"set of bases PART-OF subspace representation\", \"part-based representation FEATURE-OF images\", \"localized features FEATURE-OF bases components\", \"algorithm EVALUATE-FOR learning\", \"LNMF FEATURE-OF face representation\", \"LNMF FEATURE-OF recognition\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  19%|█▉        | 94/500 [16:25<1:21:08, 11.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ROD-TV USED-FOR reconstruction\", \"tensor voting USED-FOR local reconstruction algorithm\", \"per-vertex normals FEATURE-OF interpolative shading\", \"mesh connectivity PART-OF ROD-TV\", \"multiscale feature extraction FEATURE-OF ROD-TV\", \"data hierarchy PART-OF ROD-TV\", \"our approach COMPARE encouraging results\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  19%|█▉        | 95/500 [16:34<1:13:22, 10.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Markov random field models FEATURE-OF texture features\", \"ACGMRF model USED-FOR modelling rotated image textures\", \"ALSE method EVALUATE-FOR estimating parameters of ACGMRF model\", \"rotation-invariant features USED-FOR classifying SAR sea ice and Brodatz imagery\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  19%|█▉        | 96/500 [16:43<1:11:00, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"proposed method FEATURE-OF robust visual tracking\", \"parameterized object state PART-OF object intrinsic representation\", \"dimensionality reduction USED-FOR unsupervised learning\", \"density estimation USED-FOR unsupervised learning\", \"non-rigid part of object state HYPONYM-OF object intrinsic representation\", \"dynamical model FEATURE-OF particle-filter style tracker\", \"intrinsic object structure FEATURE-OF particle-filter style tracker\", \"proposed method EVALUATE-FOR existing trackers\", \"fish twisting with self-occlusion COREF large inter-frame lip motion\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  19%|█▉        | 97/500 [16:56<1:15:40, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"projective reconstruction FEATURE-OF determination\", \"3D geometrical configuration PART-OF set of 3D points and cameras\", \"correspondences COMPARE image coordinates\", \"configuration COMPARE projective transform\", \"configuration PART-OF cameras\", \"configuration PART-OF points\", \"configuration HYPONYM-OF critical configuration\", \"number of cameras PART-OF critical configuration\", \"number of points PART-OF critical configuration\", \"configuration HYPONYM-OF critical configuration\", \"set of points PART-OF alternative configuration\", \"set of cameras PART-OF alternative configuration\", \"rational quartic curve PART-OF alternative configuration\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  20%|█▉        | 98/500 [17:09<1:17:23, 11.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"proposed approach FEATURE-OF representation\", \"multi-view constraints USED-FOR acquisition of true three-dimensional models\", \"normalized representation USED-FOR matching and reconstruction\", \"affine-invariant image patches PART-OF novel representation\", \"spatial relationships PART-OF novel representation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  20%|█▉        | 99/500 [17:16<1:08:41, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"global alignment USED-FOR video analysis\", \"global alignment USED-FOR video representation\", \"problem global alignment super-resolution\", \"quality resulting mosaic EVALUATE-FOR amount of blurring\", \"graph-based technique FEATURE-OF global registration\", \"topological structure FEATURE-OF sequence induced by spatial overlap\", \"bundle adjustment FEATURE-OF global registration\", \"homographies FEATURE-OF bundle adjustment\", \"our approach COMPARE other techniques\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  20%|██        | 100/500 [17:25<1:07:16, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method FEATURE-OF shape constrained image segmentation\", \"method USED-FOR automated segmentation\", \"feature distributions FEATURE-OF color\", \"feature distributions FEATURE-OF texture\", \"approach PART-OF Bayesian statistics\", \"semantically meaningful segments EVALUATE-FOR ambiguous segmentations\", \"image data COREF data\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  20%|██        | 101/500 [17:34<1:03:30,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"measurement information FEATURE-OF tracking performance\", \"user initialization USED-FOR tracking process\", \"boosted shape detection USED-FOR generic measurement process\", \"local detection uncertainties EVALUATE-FOR shape alignment\", \"local detection uncertainties EVALUATE-FOR fusion with predicted shape prior\", \"local detection uncertainties EVALUATE-FOR fusion with subspace constraints\", \"sources of information CONJUNCTION unified way\", \"posterior shape model COREF shape with the maximum likelihood\", \"existing approaches COMPARE inter-expert variations\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  20%|██        | 102/500 [17:45<1:07:17, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"optical flow FEATURE-OF dynamic characteristics\", \"optical flow USED-FOR feature\", \"density estimation COMPARE kernels\", \"data-dependent bandwidth FEATURE-OF density estimation\", \"existing work COMPARE proposed approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  21%|██        | 103/500 [17:50<56:28,  8.54s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"probabilistic models USED-FOR modeling and recognition of human motion\", \"human motion model FEATURE-OF triangulated graph\", \"previous approaches IGNORED appearance of body parts\", \"heuristic approach COMMONLY USED to obtain translation invariance\", \"improved approach SUGGESTED for learning models and using them for human motion recognition\", \"suggested approach COMBINES multiple cues\", \"global variables PART-OF the model\", \"model learned in an unsupervised manner\", \"hybrid probabilistic model LEADS TO faster convergence of learning phase\", \"hybrid probabilistic model LEADS TO robustness to occlusions\", \"hybrid probabilistic model LEADS TO higher recognition rate\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  21%|██        | 104/500 [18:05<1:09:14, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"system COPES-WITH long-duration and complete occlusion\", \"system PRODUCES good segment and tracking results\", \"system PERFORMED extensive experiments using video sequences\", \"system PERFORMED experiments under different conditions indoor and outdoor\", \"occlusions PART-OF complete occlusion\", \"occlusions PART-OF long-duration\", \"background PART-OF changing background\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  21%|██        | 105/500 [18:14<1:06:43, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"embedding methods COMPARE embedding methods\", \"homographies FEATURE-OF complex bilinear form, homographies FEATURE-OF real quadratic form\", \"embedding REVEALS algebraic properties, embedding REVEALS relations\", \"segmentation solution EVALUATE-FOR closed-form segmentation\", \"piece-wise planar scene PART-OF 2-D images\", \"subsequent 3-D reconstruction EVALUATE-FOR better-conditioned\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  21%|██        | 106/500 [18:24<1:06:05, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"active shape models FEATURE-OF powerful and widely used tool\", \"PCA LINEARITY deteriorate resulting model\", \"non-linear extensions of active shape models HAVE BEEN PROPOSED\", \"user interaction NEEDED DURING model building\", \"minimum description length principle EVALUATE-FOR optimal subdivision\", \"linear modeling ADEQUATE FOR sub-parts\", \"proposed method EVALUATED ON synthetic data, medical images and hand contours\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  21%|██▏       | 107/500 [18:33<1:03:05,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"object detection FEATURE-OF support vector machines\", \"training examples PART-OF object detection\", \"prior HYPONYM-OF distribution of natural images\", \"separating hyperplane EVALUATE-FOR wide margin\", \"positive half space EVALUATE-FOR low probability to contain natural images\", \"detector COMPARE linear SVM and kernel SVM\", \"experiments COMPARE real data sets\", \"training examples COMPARE structure of the class\", \"detector EVALUATE-FOR robustness to choice of training examples\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  22%|██▏       | 108/500 [18:49<1:15:54, 11.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"scheme USED-FOR recognition\", \"efficiency EVALUATE-FOR entity retrieval\", \"quality EVALUATE-FOR entity retrieval\", \"vocabulary tree FEATURE-OF quantization\", \"quantization PART-OF indexing\", \"indexing PART-OF quantization\", \"quantization HYPONYM-OF vocabulary\", \"tree HYPONYM-OF vocabulary\", \"tree PART-OF quantization\", \"quantization PART-OF tree\", \"retrieval quality COMPARE dramatic improvement\", \"local region descriptors PART-OF scheme\", \"vocabulary tree COMPARE popular techniques\", \"database PART-OF retrieval\", \"ground truth PART-OF database\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  22%|██▏       | 109/500 [19:04<1:22:32, 12.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"image completion FEATURE-OF exemplar-based framework\", \"texture synthesis FEATURE-OF exemplar-based framework\", \"image inpainting FEATURE-OF exemplar-based framework\", \"Priority-BP COMPARE standard belief propagation\", \"Priority-BP FEATURE-OF optimization scheme\", \"message scheduling FEATURE-OF Priority-BP\", \"label pruning FEATURE-OF Priority-BP\", \"computational cost EVALUATE-FOR BP\", \"extensions EVALUATE-FOR computational cost\", \"extensions FEATURE-OF Priority-BP\", \"MRF energy function COMPARE BP\", \"method COREF our method\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  22%|██▏       | 110/500 [19:17<1:22:48, 12.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"prior knowledge FEATURE-OF registration criteria\", \"maximum mutual information USED-FOR good registration results\", \"low-level information COMPARE statistically learned prior knowledge\", \"kernel density estimate FEATURE-OF prior\", \"pre-registered image pairs PART-OF representative set\", \"intensity correspondences EVALUATE-FOR statistically consistent registration process\", \"missing low-level information COMPARE intensity correspondences\", \"image modalities CONJUNCTION slice locations\", \"non-rigid image registration HYPONYM-OF image processing algorithms\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  22%|██▏       | 111/500 [19:31<1:24:08, 12.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"traditional linear Fukunaga-Koontz Transform (FKT) USED-FOR discriminative subspaces building approach\", \"FKT EXTENDED-TO deal with small-sample-size\", \"traditional linear FKT EXTENDED-TO work in multi-class problem\", \"traditional linear FKT EXTENDED-TO work in higher dimensional subspaces\", \"proposed Kernel Fukunaga-Koontz Transform EVALUATE-FOR face recognition applications\", \"proposed non-linear generalization COMPARE linear generalization\", \"proposed non-linear generalization USED-FOR any other domain specific problems\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  22%|██▏       | 112/500 [19:44<1:24:55, 13.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Lagrangian Particle Dynamics USED-FOR segmentation of high density crowd flows\", \"flow field FEATURE-OF aperiodic dynamical system\", \"grid of particles PART-OF flow field\", \"numerical integration scheme USED-FOR advecting particles\", \"evolution of particles through flow COREF tracked using Flow Map\", \"spatial gradients of Flow Map USED-FOR setting up Cauchy Green Deformation tensor\", \"neighboring particles HYPONYM-OF particles\", \"maximum eigenvalue of tensor USED-FOR constructing FTLE field\", \"FTLE field USED-FOR revealing Lagrangian Coherent Structures\", \"LCS USED-FOR locating boundaries of flow segments\", \"normalized cuts framework USED-FOR locating boundaries of flow segments\", \"change in number of flow segments EVALUATE-FOR instability\", \"correspondences between flow segments COMPARE over time\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  23%|██▎       | 113/500 [20:02<1:32:45, 14.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"system USED-FOR computer vision applications\", \"linear Support Vector Machine classifier FEATURE-OF system\", \"classification progress USED-FOR embedded hardware\", \"motion features FEATURE-OF system\", \"Motion History Image LIMITATION-OF HMHH\", \"Hierarchical Motion History Histogram FEATURE-OF motion information\", \"MHI PART-OF feature vector\", \"HMHH PART-OF feature vector\", \"system EVALUATE-FOR recognition performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  23%|██▎       | 114/500 [20:12<1:24:48, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"classification of outdoor scenes FEATURE-OF images\", \"one-class classifiers USED-FOR modeling regions with uniform color and texture properties\", \"clustering of patches USED-FOR detecting structures in remaining regions\", \"regions PART-OF images\", \"codebook PART-OF region types\", \"bag of individual regions REPRESENTATION-OF scene representation\", \"bag of region pairs REPRESENTATION-OF scene representation\", \"Bayesian classifiers EVALUATE-FOR scene classification\", \"proposed models COMPARE baseline global feature-based approach\", \"region types EVALUATE-FOR identifying particular class of scenes\", \"region types EVALUATE-FOR occurring together in same class of scenes\", \"LabelMe data set COREF\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  23%|██▎       | 115/500 [20:27<1:27:31, 13.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"structured-light methods USED-FOR robust 3D reconstruction\", \"Photogeometric Structured Light FEATURE-OF standard structured light method\", \"photometric processing USED-FOR increasing amount of recovered surface detail\", \"photometric processing USED-FOR enabling structured-light setup to be robustly self-calibrated\", \"framework USED-FOR photogeometric optimization\", \"photogeometric optimization USED-FOR simultaneous use of multiple cameras and projectors\", \"photogeometric optimization EVALUATE-FOR single and accurate multi-view 3D model\", \"multi-view 3D model COMPARE photometric and geometric data\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  23%|██▎       | 116/500 [20:39<1:25:41, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"blur features FEATURE-OF image color, gradient, and spectrum information\", \"blur detection USED-FOR motion analysis and image restoration\", \"image patches PART-OF region-wise training and classification\", \"our method EVALUATE-FOR challenging image data\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  23%|██▎       | 117/500 [20:48<1:16:09, 11.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"object model USED-FOR visual object tracking\", \"local optimization USED-FOR track local mode of similarity measure\", \"object PART-OF parameter space of translation, rotation and scale\", \"local tracking prone to failure WHEN object partially or totally occluded\", \"prediction techniques LIKE Kalman filter do not provide good estimate of object parameters in future frames\", \"object detection SOLVED-VIA Adaptive Simulated Annealing\", \"ASA stochastically samples parameter space\", \"cluster analysis APPLIED-ON sampled parameter space to redetect object\", \"numerical hybrid local and global mode-seeking tracker VALIDATED-ON challenging airborne videos\", \"approach OUTPERFORMS state-of-the-art trackers on VIVID benchmark datasets\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  24%|██▎       | 118/500 [21:03<1:22:32, 12.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"qualitative prior COMPARE quantitative prior\", \"BN model parameters USED-FOR reliable and representative training data\", \"qualitative knowledge FEATURE-OF BN parameter learning\", \"Maximum Likelihood estimation method COMPARE our method\", \"Expectation Maximization algorithm COMPARE our method\", \"limited training data EVALUATE-FOR BN parameter learning\", \"our method EVALUATE-FOR BN parameter learning\", \"facial Action Unit recognition PART-OF BN model\", \"real image data PART-OF facial Action Unit recognition\", \"training data EVALUATE-FOR BN model parameter estimation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  24%|██▍       | 119/500 [21:16<1:21:01, 12.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 119: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 010dcbf4bfe98a9040996ece8e12b05a in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    We propose a novel step toward the unsupervised seg-mentation of whole objects by combining \" hints \" of partial scene segmentation offered by multiple soft, binary mattes. These mattes are implied by a set of hypothesized object boundary fragments in the scene. Rather than trying to find or define a single \" best \" segmentation, we generate multiple segmentations of an image. This reflects contemporary methods for unsupervised object discovery from groups of images, and it allows us to define intuitive evaluation met-rics for our sets of segmentations based on the accurate and parsimonious delineation of scene objects. Our proposed approach builds on recent advances in spectral clustering, image matting, and boundary detection. It is demonstrated qualitatively and quantitatively on a dataset of scenes and is suitable for current work in unsupervised object discovery without top-down knowledge.\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "Error generating response for prompt at index 119: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e6d21e72e7cda57378786578c6291331 in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    We propose a novel step toward the unsupervised seg-mentation of whole objects by combining \" hints \" of partial scene segmentation offered by multiple soft, binary mattes. These mattes are implied by a set of hypothesized object boundary fragments in the scene. Rather than trying to find or define a single \" best \" segmentation, we generate multiple segmentations of an image. This reflects contemporary methods for unsupervised object discovery from groups of images, and it allows us to define intuitive evaluation met-rics for our sets of segmentations based on the accurate and parsimonious delineation of scene objects. Our proposed approach builds on recent advances in spectral clustering, image matting, and boundary detection. It is demonstrated qualitatively and quantitatively on a dataset of scenes and is suitable for current work in unsupervised object discovery without top-down knowledge.\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"unsupervised object discovery COMPARE groups of images\", \"spectral clustering FEATURE-OF proposed approach\", \"image matting FEATURE-OF proposed approach\", \"boundary detection FEATURE-OF proposed approach\", \"multiple segmentations EVALUATE-FOR accurate and parsimonious delineation of scene objects\", \"hints COREF partial scene segmentation\", \"multiple soft, binary mattes USED-FOR unsupervised segmentation of whole objects\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  24%|██▍       | 120/500 [22:35<3:28:13, 32.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm SRDA FEATURE-OF subspace-based classification\", \"class structures HYPONYM-OF semi-Riemannian manifold\", \"SRDA COMPARE existing algorithms\", \"semi-Riemannian metrics USED-FOR smoothing of discrete functions\", \"class structures PART-OF original samples\", \"proposed framework USED-FOR subspace-based classification\", \"SRDA EVALUATE-FOR recognition\", \"SRDA EVALUATE-FOR classification\", \"semi-Riemannian geometry USED-FOR pattern recognition\", \"class structures USED-FOR subspace-based classification\", \"SRDA COREF algorithm\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  24%|██▍       | 121/500 [22:48<2:49:14, 26.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"3D object categories FEATURE-OF visual models\", \"ensemble of parts PART-OF objects\", \"appearance information and geometric constraints USED-FOR learning visual models\", \"parts consistent under 3D viewpoint transformations HYPONYM-OF coherent ensemble of parts\", \"generative framework USED-FOR learning a model\", \"explicit correspondences of parts ACROSS different viewpoints of the object class USED-FOR our model\", \"detection and classification EVALUATE-FOR position and viewpoint of the model\", \"algorithm TESTED-ON detection task and viewpoint classification task\", \"car category PART-OF Savarese et al. 2007 dataset\", \"car category PART-OF PASCAL VOC 2006 dataset\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  24%|██▍       | 122/500 [23:05<2:30:29, 23.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"automated surveillance systems USED-FOR PTZ cameras\", \"algorithms REQUIRE prior knowledge intrinsic parameters PTZ camera\", \"mapping algorithm PROPOSED\", \"mapping algorithm DERIVES relative positioning and orientation between two PTZ cameras\", \"reduced dependence on knowledge intrinsic parameters PTZ camera and relative positions\", \"experimental results DEMONSTRATE proposed algorithm presents substantially reduced computational complexity and improved flexibility\", \"pixel accuracy DECREASED COMPARED WITH work of Chen and Wang\", \"consistent labeling approaches can COMPENSATE FOR decreased pixel accuracy\", \"application of automated surveillance systems WITH changing configurations and a larger number of PTZ cameras\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  25%|██▍       | 123/500 [23:18<2:09:12, 20.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"proposed detectors FEATURE-OF histogram-based representations\", \"proposed detectors USED-FOR matching textured scenes under blur and illumination changes\", \"extension of our method FEATURE-OF space-time interest point detection\", \"proposed detectors EVALUATE-FOR matching textured scenes under blur and illumination changes\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  25%|██▍       | 124/500 [23:25<1:43:35, 16.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"multi-label classification problems FEATURE-OF computer vision applications\", \"instance ASSIGNED-TO category\", \"hypergraph CAPTURE correlations among categories\", \"vertex REPRESENTS training instance\", \"hyperedge CONTAINS instances belonging to category\", \"Rank-HLapSVM PROPOSED to handle multi-label classification problems\", \"optimization problem SOLVED by dual coordinate descent method\", \"experimental results DEMONSTRATE effectiveness and efficiency of proposed algorithm\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  25%|██▌       | 125/500 [23:39<1:37:39, 15.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"classifier USED-FOR two class problem\", \"objects FEATURE-OF image\", \"approach COMPARE other works\", \"methodology USED-FOR reducing time complexity\", \"classifier FEATURE-OF boosted combination\", \"Random Ferns FEATURE-OF classifier\", \"local histograms of oriented gradients FEATURE-OF Random Ferns\", \"supervised learning FEATURE-OF approach\", \"gradient space FEATURE-OF approach\", \"approach EVALUATE-FOR classification results\", \"databases COREF\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  25%|██▌       | 126/500 [23:49<1:27:39, 14.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"dimensionality reduction USED-FOR classification\", \"supervised dimensionality reduction FEATURE-OF existing methods\", \"data PART-OF neighborhood graph structure\", \"S-KDR COMPARE traditional methods\", \"approach EVALUATE-FOR discrimination of human gesture and motion categories\", \"approach EVALUATE-FOR database of dynamic textures\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  25%|██▌       | 127/500 [23:58<1:17:55, 12.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"graph-cuts optimization USED-FOR vision and graphics problems\", \"BK algorithm COMPARE adaptive bottom-up approach\", \"subgraphs PART-OF graph\", \"algorithm EVALUATE-FOR cache-friendly, balanced workloads, little overhead\", \"2D/3D image segmentations COREF 3D surface fitting\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  26%|██▌       | 128/500 [24:06<1:08:32, 11.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Conditional Random Field models FEATURE-OF low-level computer vision problems\", \"Inference in Conditional Random Field models USED-FOR solving a combinatorial optimization problem\", \"graph cuts COMPARE belief propagation\", \"methods for learning model parameters EVALUATE-FOR computing the partition function\", \"structured learning methods USED-FOR large margin estimation\", \"iterative solutions EVALUATE-FOR solving an inference problem over all the labels\", \"large margin piece-wise learning method FEATURE-OF efficient optimization problem solving\", \"optimization problem PART-OF convex problem\", \"efficient scheme FEATURE-OF solving optimization problem\", \"publicly available standard datasets COREF\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  26%|██▌       | 129/500 [24:18<1:11:31, 11.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method USED-FOR evaluation of object detection cascades\", \"proposed method COMPARE exhaustive procedure\", \"proposed method EVALUATE-FOR fewer evaluations of the classifier functions\", \"ESS procedure FEATURE-OF last stage of our method\", \"our method USED-FOR branch-and-bound object detection\", \"kernel-ized support vector machines HYPONYM-OF nonlinear quality functions\", \"Experiments COMPARE standard cascade evaluation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  26%|██▌       | 130/500 [24:28<1:07:13, 10.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"techniques FAIL motion estimation\", \"techniques FAIL object recognition\", \"reflections PART-OF image sequences\", \"reflection models regions\", \"regions CONTAIN two different layers\", \"layers MOVE over each other\", \"detector BASED-ON weak detectors\", \"priors USED-FOR generating detection maps\", \"detection maps EVALUATE-FOR detection rate\", \"detection maps EVALUATE-FOR rejection to pathological motion\", \"detection maps EVALUATE-FOR rejection to occlusion\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  26%|██▌       | 131/500 [24:43<1:14:50, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach FEATURE-OF Multiple Instance Learning formulation\", \"slave camera PART-OF PTZ cameras\", \"approaches USED-FOR establishing correspondences between static cameras\", \"approach COMPARE previous approaches\", \"our approach EVALUATE-FOR wide-area surveillance scenarios\", \"approach USED-FOR perform camera handoff\", \"approach USED-FOR circumventing the problems faced by previous approaches\", \"approach USED-FOR avoiding the need to perform any model transfer\", \"logistic softmax function COMPARE covariance-based region features\", \"state-of-the-art approaches COMPARE our approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  26%|██▋       | 132/500 [24:56<1:16:20, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method FEATURE-OF estimating relative pose\", \"two calibrated cameras COREF two uncalibrated cameras\", \"moving object USED-FOR estimating relative pose\", \"missing point correspondences EVALUATE-FOR SfM pipelines\", \"surveillance scenarios HYPONYM-OF video surveillance\", \"Quadratic Eigenvalue Problem FEATURE-OF casting problem\", \"nonlinear monomials EVALUATE-FOR Quadratic Eigenvalue Problem\", \"closed-form solution FEATURE-OF Quadratic Eigenvalue Problem\", \"bundle adjustment EVALUATE-FOR closed-form solution\", \"different camera setups COMPARE results\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  27%|██▋       | 133/500 [25:14<1:26:48, 14.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"spatio-temporal video segmentation algorithm USED-FOR recognition\", \"long-range motion cues FEATURE-OF spatio-temporal video segmentation algorithm\", \"clusters of point tracks PART-OF spatio-temporal video segmentation algorithm\", \"occlusion reasoning FEATURE-OF track clustering cost function\", \"depth ordering constraints FEATURE-OF track clustering cost function\", \"motion similarity FEATURE-OF track clustering cost function\", \"proposed approach EVALUATE-FOR challenging set of video sequences\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  27%|██▋       | 134/500 [25:23<1:17:13, 12.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"color constancy COMPARE traditional methods\", \"multi-view color constancy FEATURE-OF object recognition and retrieval applications\", \"correspondences COREF these images\", \"method EVALUATE-FOR estimates of underlying surface reflectance\", \"method EVALUATE-FOR scene illuminants\", \"method EVALUATE-FOR object color\", \"image correspondences USED-FOR joint estimation of surface properties and illuminants\", \"alignment techniques USED-FOR image correspondences\", \"local region features USED-FOR matching\", \"multi-view constraints EVALUATE-FOR estimates of scene illuminants\", \"multi-view constraints EVALUATE-FOR object color\", \"single-view method COMPARE baseline\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  27%|██▋       | 135/500 [25:39<1:22:42, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm USED-FOR camera relative pose estimation\", \"lines FEATURE-OF camera relative pose estimation\", \"relative rotation COMPUTED-FROM lines and images\", \"relative translation COMPUTED-FROM lines and intersection points\", \"lines DETECTED-BY framework\", \"performance EVALUATE-FOR algorithm using synthetic and real data\", \"approach SUITABLE-FOR urban and indoor environments\", \"most lines PARALLEL-OR-ORTHOGONAL\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  27%|██▋       | 136/500 [25:48<1:13:24, 12.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"co-occurrence pattern FEATURE-OF object recognition\", \"co-occurrence pattern FEATURE-OF scene recognition\", \"co-occurrence pattern FEATURE-OF action recognition\", \"conjunction (AND) co-occurrence pattern COMPARE disjunction (OR) co-occurrence pattern\", \"data mining method USED-FOR discovering optimal co-occurrence pattern\", \"mining procedure PART-OF boosting\", \"boosting EVALUATE-FOR generalization ability\", \"boosting COMPARE conventional boosting decision trees\", \"boosting COMPARE boosting decision stumps\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  27%|██▋       | 137/500 [26:05<1:22:35, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"facial expression recognition FEATURE-OF automated facial expression recognition\", \"binary classifiers COMPARE ordinal manifold\", \"Hidden Conditional Ordinal Random Field (H-CORF) framework PART-OF dynamic ordinal regression\", \"facial expressions EVALUATE-FOR simultaneous dynamic recognition and intensity estimation\", \"proposed method USED-FOR deliberate and spontaneous facial affect data\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  28%|██▊       | 138/500 [26:14<1:14:31, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"motion estimation FEATURE-OF segmentation\", \"multi-label representation USED-FOR flow field\", \"label costs FEATURE-OF Potts model\", \"occlusions PART-OF object boundaries\", \"fast primal-dual algorithm USED-FOR motion segmentation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  28%|██▊       | 139/500 [26:21<1:04:28, 10.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"fluorescence FEATURE-OF shape reconstruction\", \"fluorescent materials USED-FOR clothing\", \"fluorescence HYPONYM-OF ideal diffuse reflection\", \"fluorescence COMPARE ideal diffuse reflection\", \"fluorescence EVALUATE-FOR shape estimation\", \"photometric stereo EVALUATE-FOR shape estimation\", \"emission-only images EVALUATE-FOR shape estimation\", \"specular reflection COMPARE fluorescence-based method\", \"fluorescence-based method COMPARE previous methods based on reflection\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  28%|██▊       | 140/500 [26:33<1:06:46, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm USED-FOR estimating broad 3D geometric structure of outdoor video scenes\", \"spatio-temporal video segmentation PART-OF dynamic scene\", \"region-classifiers EVALUATE-FOR predictions\", \"predictions FEATURE-OF geometric classes\", \"homogeneity COMPARE granularity\", \"dataset FEATURE-OF geometric context of video\", \"semi-supervised learning framework USED-FOR expanding pool of labeled data\", \"high confidence predictions EVALUATE-FOR labeled data\", \"system EVALUATE-FOR accurate prediction of geometric context of video\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  28%|██▊       | 141/500 [26:44<1:05:36, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"image set classification algorithm USED-FOR unsupervised clustering\", \"labels FEATURE-OF training and test data\", \"probability distribution USED-FOR similarity measure\", \"sparse spectral clustering algorithm PART-OF iterative algorithm\", \"proximity matrix USED-FOR local subspace structure\", \"clusters PART-OF data structure\", \"class differences COMPARE global scale\", \"image sets PART-OF Grass-mannian manifolds\", \"spectral clustering algorithm PART-OF eigenvector solver\", \"computational cost EVALUATE-FOR spectral clustering\", \"clustering quality EVALUATE-FOR final classification results\", \"comparison COMPARE seven existing techniques\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  28%|██▊       | 142/500 [26:58<1:11:18, 11.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"point cloud matching FEATURE-OF shape matching problem\", \"point clouds COREF each\", \"Schrödinger distance transform representation FEATURE-OF point clouds\", \"Schrödinger equation USED-FOR Schrödinger distance transform representation\", \"Hamilton-Jacobi equation COMPARE Schrödinger equation\", \"SDT representation HYPONYM-OF analytic expression\", \"SDT representation HYPONYM-OF square-root density\", \"square-root density HYPONYM-OF point on unit Hilbert sphere\", \"intrinsic geometry HYPONYM-OF unit Hilbert sphere\", \"Fisher-Rao metric USED-FOR space of densities\", \"geodesic distance EVALUATE-FOR points on sphere\", \"Riemannian framework USED-FOR point cloud matching\", \"point set matching PART-OF point cloud matching\", \"rigid transformations PART-OF point set matching\", \"non-rigid transformations PART-OF point set matching\", \"SDTM EVALUATE-FOR performance of algorithm\", \"synthetic data COMPARE real data\", \"SDTM OUTPERFORMS state-of-the-art algorithms\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  29%|██▊       | 143/500 [27:22<1:33:09, 15.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"object shapes FEATURE-OF visual hull proposals\", \"camera viewpoint USED-FOR rigid structure-from-motion\", \"object projection cone PART-OF visual hull sampling process\", \"similar objects HYPONYM-OF within-class shape similarity assumptions\", \"our method EVALUATE-FOR convincing per-object 3D reconstructions\", \"PASCAL VOC COMPARE once popular geometry-oriented model-based recognition approaches\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  29%|██▉       | 144/500 [27:31<1:20:15, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method FEATURE-OF pipeline\", \"method USED-FOR build personalized parametric model\", \"pipeline USED-FOR build personalized parametric model\", \"scan PART-OF incomplete scan\", \"scan USED-FOR fit incomplete scan\", \"template FEATURE-OF fitting techniques\", \"scan HYPONYM-OF watertight models\", \"pose HYPONYM-OF different poses\", \"model EVALUATE-FOR effectiveness to produce dynamic models\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  29%|██▉       | 145/500 [27:41<1:14:35, 12.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach USED-FOR estimating location information\", \"sparse coding approach USED-FOR discriminating images\", \"geometric prior FEATURE-OF transformations\", \"approach EXTENDED-TO account for heterogeneous data modalities\", \"approach STUDIED-PROBLEM of transferring knowledge\", \"datasets EVALUATED-TO obtain state-of-the-art results\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  29%|██▉       | 146/500 [27:50<1:06:29, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"action proposal generation FORMULATED-AS maximum set coverage problem\", \"appearance cues UTILIZED-TO-MEASURE actionness of video tubes\", \"motion cues UTILIZED-TO-MEASURE actionness of video tubes\", \"action proposals DO-NOT-RELY-ON video segmentation\", \"action proposals GENERATED-IN nearly real-time\", \"experimental results VALIDATE superior performance of our action proposals\", \"competitive results on action detection and search COMPARED-WITH our action proposals\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  29%|██▉       | 147/500 [28:00<1:05:07, 11.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method FEATURE-OF joint embeddings\", \"neural network PART-OF method\", \"linear projections PART-OF neural network\", \"nonlinearities PART-OF neural network\", \"network USED-FOR cross-view ranking constraints\", \"network USED-FOR within-view neighborhood structure preservation constraints\", \"metric learning literature FEATURE-OF within-view neighborhood structure preservation constraints\", \"approach EVALUATE-FOR image-to-text retrieval\", \"approach EVALUATE-FOR text-to-image retrieval\", \"approach USED-FOR phrase localization task\", \"Flickr30K Entities dataset HYPONYM-OF phrase localization task\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  30%|██▉       | 148/500 [28:15<1:10:57, 12.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"animated GIFs FEATURE-OF rich meta-data\", \"new dataset TGIF PART-OF animated GIF understanding\", \"natural language descriptions EVALUATE-FOR image sequence description systems\", \"crowd-workers COREF free-form text input\", \"visual content COMPARE natural language descriptions\", \"existing image and video description datasets COMPARE our dataset\", \"nearest neighbor, statistical machine translation, and recurrent neural networks USED-FOR animated GIF description task\", \"models fine-tuned from our animated GIF description dataset USED-FOR automatic movie description\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  30%|██▉       | 149/500 [28:25<1:07:51, 11.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SIFT FEATURE-OF feature-based matching\", \"RANSAC FEATURE-OF feature-based matching\", \"deep learning-based approach USED-FOR ultra-wide baseline matching\", \"local correspondence EVALUATE-FOR performance\", \"attention mechanism FEATURE-OF probable matches\", \"dataset USED-FOR training models\", \"urban aerial imagery PART-OF dataset\", \"same pairs COREF 'same' pairs\", \"different pairs COREF 'different' pairs\", \"state-of-the-art COMPARE our models\", \"human accuracy COMPARE our models\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  30%|███       | 150/500 [28:37<1:08:11, 11.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"confidence measures FEATURE-OF outlier removal\", \"training data USED-FOR outlier removal and quality improvement\", \"training data GENERATED-FOR learned confidence measures\", \"view points USED-FOR reasoning about contradictions and consistencies\", \"depth maps GENERATED-FOR reasoning about contradictions and consistencies\", \"approach BOOSTED performance of learned confidence measures\", \"approach APPLIED-TO KITTI2012 dataset\", \"laser ground truth data COMPARED-TO automatically generated training data\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  30%|███       | 151/500 [28:48<1:06:34, 11.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"instance-level retrieval EVALUATE-FOR images\", \"finger sketches HYPONYM-OF free-hand sketches\", \"annotated cross-domain sketch-photo datasets PART-OF training\", \"database PART-OF sketch-photo pairs\", \"triplet-ranking model USED-FOR instance-level SBIR\", \"data augmentation FEATURE-OF deep triplet-ranking model\", \"pre-training FEATURE-OF deep triplet-ranking model\", \"insufficient fine-grained training data COMPARE over-fitting avoidance\", \"deep networks COMPARE fine-grained cross-domain ranking tasks\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  30%|███       | 152/500 [28:59<1:06:29, 11.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 152: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9f1cf9f167ccbbfb48ee439789661f1d in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "     \n",
      " In this paper we study a set of problems that are of considerable importance to  Statistical Machine Translation (SMT)  but which have not been addressed satisfactorily by the  SMT research community  . Over the last decade, a variety of  SMT algorithms  have been built and empirically tested whereas little is known about the  computational complexity  of some of the fundamental problems of  SMT  . Our work aims at providing useful insights into the the  computational complexity  of those problems. We prove that while  IBM Models 1-2  are conceptually and computationally simple, computations involving the higher (and more useful)  models  are  hard  . Since it is unlikely that there exists a  polynomial time solution  for any of these  hard problems  (unless  P = NP  and  P#P = P  ), our results highlight and justify the need for developing  polynomial time approximations  for these computations. We also discuss some practical ways of dealing with  complexity  . \n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"SMT algorithms USED-FOR Statistical Machine Translation\", \"computational complexity FEATURE-OF IBM Models 1-2\", \"higher models HYPONYM-OF more useful models\", \"hard problems EVALUATE-FOR need for developing polynomial time approximations\", \"complexity PART-OF computations\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  31%|███       | 153/500 [29:44<2:03:09, 21.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"one sense per collocation observation USED-FOR word sense induction\", \"clustering of word co-occurrences FEATURE-OF WSI\", \"triplets of words USED-FOR one sense per collocation observation\", \"two-step clustering process FEATURE-OF accurate results\", \"sentence co-occurrences PART-OF two-step clustering process\", \"evaluation method FEATURE-OF WSI algorithm\", \"Schutze's idea COMPARE evaluation method\", \"reproducability EVALUATE-FOR evaluation method\", \"independency EVALUATE-FOR evaluation method\", \"automatic parameter optimization EVALUATE-FOR WSI algorithm\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  31%|███       | 154/500 [29:57<1:49:48, 19.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"addressee identification FEATURE-OF four-participants face-to-face meetings\", \"addressee HYPONYM-OF dialogue act\", \"gaze USED-FOR addressee identification\", \"utterance USED-FOR addressee identification\", \"conversational context USED-FOR addressee identification\", \"meeting context EVALUATE-FOR classifiers' performances\", \"classifiers COMPARE conversational context and utterance features\", \"classifiers COMPARE gain from information about meeting context\", \"conversational context PART-OF classifiers' performances\", \"utterance PART-OF classifiers' performances\", \"speaker's gaze information PART-OF classifiers' performances\", \"classifiers PART-OF performances\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  31%|███       | 155/500 [30:12<1:41:13, 17.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"evaluation measure models block reordering USED-FOR edit operation\", \"word-dependent substitution costs FEATURE-OF evaluation measures\", \"new measure COMPARE state-of-the-art approaches\", \"language pairs PART-OF human judgment\", \"automatic evaluation measures EVALUATE-FOR human judgment\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  31%|███       | 156/500 [30:18<1:21:48, 14.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ASR output USED-FOR predicting segment boundaries\", \"human transcription USED-FOR predicting segment boundaries\", \"top-level topic shifts HYPONYM-OF subtopic boundaries\", \"lexical cohesion-based approach FEATURE-OF predicting subtopic boundaries\", \"machine learning approach FEATURE-OF predicting top-level boundaries\", \"lexical-cohesion and conversational features FEATURE-OF predicting top-level boundaries\", \"conversational cues FEATURE-OF predicting top-level boundaries\", \"cue phrases FEATURE-OF conversational cues\", \"overlapping speech FEATURE-OF conversational cues\", \"transcription errors EVALUATE-FOR models that combine lexical-cohesion and conversational features\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  31%|███▏      | 157/500 [30:31<1:19:14, 13.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"data-driven selection FEATURE-OF emphatic facial displays\", \"embodied conversational agent PART-OF dialogue system\", \"corpus PART-OF target dialogue system\", \"facial displays USED-FOR speaker\", \"models EVALUATE-FOR facial displays\", \"context USED-FOR generating facial displays\", \"cross-validation COMPARE user ratings\", \"majority choice FEATURE-OF models\", \"user study COMPARE cross-validation\", \"preference EVALUATE-FOR variation\", \"female subjects COREF\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  32%|███▏      | 158/500 [30:41<1:12:59, 12.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SI-Nets PART-OF operations\", \"operations FEATURE-OF formal language\", \"SI-Nets HYPONYM-OF epistemological objects\", \"processes HYPONYM-OF conceptual system of NL\", \"KL-ONE USED-FOR epistemological level\", \"KL-Conc USED-FOR conceptual level\", \"KL-Conc FEATURE-OF interacting with SI-Nets\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  32%|███▏      | 159/500 [30:51<1:07:38, 11.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"syntactic analyzer PART-OF system\", \"Procedural Systemic Grammar FEATURE-OF syntactic analyzer\", \"semantic analyzer PART-OF system\", \"Conceptual Dependency Theory FEATURE-OF semantic analyzer\", \"dictionary PART-OF system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  32%|███▏      | 160/500 [30:57<57:24, 10.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"analytical inverses FEATURE-OF compositional syntax rules\", \"Definite Clause Grammar techniques USED-FOR parser construction\", \"parser MDCC FEATURE-OF augmented Friedman-Warren algorithm\", \"augmented Friedman-Warren algorithm USED-FOR post referencing\", \"parser MDCC INTERFACE-WITH LILT\", \"reduced IL formulae PART-OF corresponding derivational history\", \"Montague's PTQ ASSUMED-BY basic DCG mechanism\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  32%|███▏      | 161/500 [31:06<55:19,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Systemic grammar USED-FOR AI text generation\", \"implementations tend to be ad hoc or inefficient COREF\", \"approach to systemic text generation FEATURE-OF AI problem solving techniques\", \"AI problem solving techniques USED-FOR systemic grammar\", \"special relationship between systemic grammar and problem solving COMPARE choosing from alternatives\", \"text generation EVALUATE-FOR linguistic theory\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  32%|███▏      | 162/500 [31:15<52:43,  9.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"model FEATURE-OF scheme\", \"communicative context PART-OF structure\", \"interacting partners PART-OF system\", \"dialogue PART-OF system\", \"environment PART-OF system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  33%|███▎      | 163/500 [31:20<46:22,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"formalisms FEATURE-OF grammatical formalisms\", \"LFG HYPONYM-OF context-free phrase-structure grammar\", \"PATR-II HYPONYM-OF context-free phrase-structure grammar\", \"processing FEATURE-OF formalisms\", \"chart-parsing framework PART-OF processing\", \"declarative character EVALUATE-FOR optimal control strategy\", \"rule-invocation strategy EVALUATE-FOR processing efficiency\", \"rules USED-FOR processing efficiency\", \"rule-invocation strategies COMPARE fundamental rule-invocation strategies\", \"context-free chart parsing HYPONYM-OF chart-parsing framework\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  33%|███▎      | 164/500 [31:32<52:34,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 164: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0509f6b457353c88e7c924b980849f7a in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    \n",
      "The  verb forms  are often claimed to convey two kinds of  information  : 1. whether the  event  described in a  sentence  is  present ,  past  or  future  (=  deictic information ) 2. whether the  event  described in a  sentence  is presented as completed, going on, just starting or being finished (=  aspectual information ). It will be demonstrated in this paper that one has to add a third component to the analysis of  verb form meanings , namely whether or not they express  habituality . The framework of the analysis is  model-theoretic semantics . \n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"event described FEATURE-OF sentence\", \"event described EVALUATE-FOR habituality\", \"event described EVALUATE-FOR aspectual information\", \"event described EVALUATE-FOR deictic information\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  33%|███▎      | 165/500 [32:13<1:44:43, 18.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"theory of tenses FEATURE-OF Discourse Representation Theory\", \"IMS PART-OF proposal\", \"Reichenbachian point of view FEATURE-OF tenses\", \"tenses CONTRIBUTION-TO integration of events\", \"system of relevant times USED-FOR choice of anchors\", \"system of relevant times USED-FOR updating temporal coordinates\", \"choice COMPARE approach of Kamp and Rohrer\", \"meaning FIXED-BY resolution component\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  33%|███▎      | 166/500 [32:21<1:27:24, 15.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approaches EVALUATE-FOR Natural Language systems\", \"systems PART-OF approaches\", \"task EVALUATE-FOR data retrieval\", \"validity FEATURE-OF approaches\", \"study USED-FOR identify NL requirements\", \"Wizard of Oz technique USED-FOR identify NL requirements\", \"task dialogues EVALUATE-FOR prototype Natural Language system\", \"requirements FEATURE-OF task dialogues\", \"operators specific to task EVALUATE-FOR database access\", \"contextual reference FEATURE-OF complex reference\", \"reference PART-OF structure of information source\", \"requirements EVALUATE-FOR future Natural Language systems\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  33%|███▎      | 167/500 [32:36<1:24:43, 15.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"anaphoric component PART-OF Mimo formalism\", \"translation EVALUATE-FOR anaphoric relations\", \"anaphoric relations HYPONYM-OF linguistic phenomena\", \"wh-movement FEATURE-OF anaphoric component\", \"passive FEATURE-OF anaphoric component\", \"binding of reflexives and pronouns FEATURE-OF anaphoric component\", \"wh-movement COMPARE passive\", \"wh-movement COMPARE binding of reflexives and pronouns\", \"anaphoric component COREF component\", \"Mimo formalism COREF formalism\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  34%|███▎      | 168/500 [32:49<1:21:32, 14.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"LR-parsers GENERALIZATION-OF recursive descent parser\", \"time-complexity of parser CUBIC non-LR grammars\", \"functions MEMO-FUNCTIONS parser\", \"memo-functions FACILITATE construction of compact representation of parse forest\", \"algorithm RELATED-TO recursive ascent parsers for LR(0) grammars\", \"Extended CF grammars PARSED-WITH modification of LR-parser for normal CF grammars\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  34%|███▍      | 169/500 [33:02<1:18:33, 14.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"model FEATURE-OF grammatical processing\", \"parsing PART-OF model\", \"generation PART-OF model\", \"parametrized deduction process USED-FOR parsing, generation\", \"view EVALUATE-FOR flexible and efficient natural language processing\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  34%|███▍      | 170/500 [33:08<1:04:00, 11.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Unification USED-FOR expressing relations\", \"declarative formalism FEATURE-OF feature structure\", \"mappings EVALUATE-FOR application\", \"feature structure PART-OF representations\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  34%|███▍      | 171/500 [33:13<53:02,  9.67s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 171: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cf599987cbd566b89dc5a9627af0b2ed in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    \n",
      "In this paper we introduce a  modal language LT for imposing  constraints  on  trees , and an extension  LT (LF)  for imposing  constraints  on  trees decorated with feature structures . The motivation for introducing these  languages  is to provide tools for formalising  grammatical frameworks  perspicuously, and the paper illustrates this by showing how the leading ideas of  GPSG  can be captured in  LT (LF) . In addition, the role of  modal languages  (and in particular, what we have called as  constraint formalisms  for linguistic theorising is discussed in some detail.\n",
      "\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"modal language LT FEATURE-OF trees\", \"extension LT (LF) FEATURE-OF trees decorated with feature structures\", \"grammatical frameworks PART-OF LT (LF)\", \"constraint formalisms FEATURE-OF linguistic theorising\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  34%|███▍      | 172/500 [33:54<1:44:05, 19.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"MORPA USED-FOR text-to-speech conversion system\", \"MORPA FEATURE-OF probabilistic context-free grammar\", \"morphological parsing EVALUATE-FOR PCFG\", \"morphological grammar PART-OF PCFG\", \"successful parse HYPONYM-OF grammatical segmentation\", \"remaining analyses COMPARE plausibility\", \"parser COREF MORPA\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  35%|███▍      | 173/500 [34:03<1:26:53, 15.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ellipsis resolution FEATURE-OF discourse copying algorithm\", \"identity-of-relations analyses HYPONYM-OF discourse copying algorithm\", \"full NPs HYPONYM-OF referential elements\", \"referential elements COREF full NPs\", \"predictions EVALUATE-FOR problematic examples of ellipsis\", \"ellipsis COMPARE other discourse copying phenomena\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  35%|███▍      | 174/500 [34:11<1:14:13, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"morphological component FEATURE-OF system\", \"two-level morphology FEATURE-OF system\", \"word grammar FEATURE-OF system\", \"hierarchical lexicon FEATURE-OF word grammar\", \"Polymorphemic stems PART-OF hierarchical lexicon\", \"compositional interpretation USED-FOR polymorphemic stems\", \"derived words HYPONYM-OF polymorphemic stems\", \"redundancy EVALUATE-FOR lexicon\", \"ad-hoc words COMPARE derived words\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  35%|███▌      | 175/500 [34:22<1:10:25, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Turkish word structures PART-OF description\", \"description USED-FOR implementation\", \"implementation USED-FOR Turkish word structures\", \"PC-KIMMO environment PART-OF implementation\", \"root word lexicon PART-OF description\", \"phonological and morphological rules FEATURE-OF special cases and exceptions\", \"Turkish HYPONYM-OF agglutinative language\", \"word structures PART-OF Turkish\", \"productive affixations FEATURE-OF word structures\", \"derivational and inflectional suffixes FEATURE-OF affixations\", \"morphotactics FEATURE-OF Turkish\", \"morphemes PART-OF word\", \"nominal FEATURE-OF word structure\", \"verbal FEATURE-OF word structure\", \"adverbial constructs FEATURE-OF word structure\", \"surface realizations FEATURE-OF morphological constructions\", \"phonetic rules FEATURE-OF surface realizations\", \"vowel harmony FEATURE-OF phonetic rules\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  35%|███▌      | 176/500 [34:42<1:20:45, 14.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"part-of-speech tagging COMPARE statistical and constraint-based disambiguation\", \"French EVALUATE-FOR part-of-speech tagging\", \"constraint system PART-OF experiment\", \"statistical model USED-FOR part-of-speech tagging\", \"accuracy COMPARE taggers for English\", \"constraint-based tagger COMPARE statistical method\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  35%|███▌      | 177/500 [34:50<1:09:54, 12.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"anaphora resolution FEATURE-OF criteria\", \"dependency-based grammar model FEATURE-OF unified account\", \"GB's binding theory HYPONYM-OF major concepts\", \"text-level anaphora FEATURE-OF criteria\", \"Grosz-Sidner-style focus model FEATURE-OF adapted version\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  36%|███▌      | 178/500 [34:58<1:00:50, 11.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"quantification USED-FOR events\", \"temporal connective FEATURE-OF quantified sentences\", \"truth-conditions EVALUATE-FOR quantified sentences\", \"temporal connective PART-OF subordinate clause\", \"proportion problem HYPONYM-OF instance\", \"solution FEATURE-OF proportion problem\", \"reference time HYPONYM-OF notions\", \"solution FEATURE-OF problem\", \"temporal anaphora phenomena PART-OF quantified sentences\", \"temporal anaphora COREF anaphora\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  36%|███▌      | 179/500 [35:09<1:00:57, 11.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach suitable FOR Information Extraction\", \"Sequences analyze text\", \"rules deterministically analyze text\", \"basic chunks analyzed\", \"argumental relations recognized\", \"modifier attachment performed\", \"global parse tree built\", \"approach proven to work FOR three languages and different domains\", \"implemented in IE module of FACILE\", \"FACILE EU project for multilingual text classification and IE\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  36%|███▌      | 180/500 [35:18<55:54, 10.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"automatic abstracting systems USED-FOR training resources\", \"annotation scheme FEATURE-OF scientific articles\", \"scheme PART-OF resource\", \"rhetorical moves HYPONYM-OF argumentation\", \"scheme EVALUATE-FOR building training resources\", \"scheme COMPARE rhetorical moves\", \"experimental results COREF\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  36%|███▌      | 181/500 [35:25<51:09,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Ramshaw and Marcus USED-FOR data representation\", \"chunking FEATURE-OF preprocessing step\", \"data representation FEATURE-OF chunking\", \"data representation EVALUATE-FOR chunking performance\", \"memory-based learning chunker USED-FOR chunking results\", \"standard data set HYPONYM-OF data set\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  36%|███▋      | 182/500 [35:33<47:54,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Tree Adjoining Grammars USED-FOR extended domain of locality\", \"feature structure unification EVALUATE-FOR parsing\", \"LEXSYS COMPARE XTAG\", \"grammars HYPONYM-OF Tree Adjoining Grammars\", \"grammars FEATURE-OF English\", \"EDOL FEATURE-OF Tree Adjoining Grammars\", \"EDOL USED-FOR limit for feature structure unification\", \"grammars PART-OF LEXSYS\", \"grammars PART-OF XTAG\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  37%|███▋      | 183/500 [35:44<51:46,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"co-occurrence similarities USED-FOR separating query terms\", \"useful terms FEATURE-OF query terms\", \"term similarities EVALUATE-FOR determining useful query terms\", \"weights OF query terms\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  37%|███▋      | 184/500 [35:50<45:23,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"focus FEATURE-OF operable definition\", \"determination process PART-OF file card model\", \"determination process PART-OF knowledge store\", \"determination process USED-FOR FDA\", \"focus USED-FOR speech synthesis systems\", \"focus USED-FOR concept-to-speech systems\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  37%|███▋      | 185/500 [35:57<42:39,  8.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"motion field FEATURE-OF exchange, growth, and transport processes\", \"performance OPTIMIZATION low-level motion estimators\", \"tensor method yields reliable and dense displacement vector fields\", \"accuracy of tensor method verified with computer-generated sequences and calibrated image sequence\", \"imperfections in CCD sensors LIMIT motion estimation\", \"spatial nonuniformity IN responsivity\", \"two-point calibration EFFICIENTLY suppresses effects of imperfections in CCD sensors\", \"application of techniques to analysis of plant growth, ocean surface microturbulence in IR image sequences, and sediment transport demonstrated\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  37%|███▋      | 186/500 [36:11<50:49,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"photometric model USED-FOR image formation\", \"statistical model FEATURE-OF face appearance variation\", \"geodesically local appearance manifold structure FEATURE-OF smoothness\", \"same-identity likelihood USED-FOR achieving invariance to unseen head poses\", \"video sequence reillumination algorithm USED-FOR achieving robustness to face motion patterns in video\", \"recognition system EVALUATE-FOR challenging data set\", \"state-of-the-art commercial software COMPARE proposed method\", \"methods from the literature COMPARE proposed method\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  37%|███▋      | 187/500 [36:22<53:51, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"non-sequential tracking approaches FEATURE-OF reduced drift and increased robustness\", \"tree HYPONYM-OF input sequences\", \"tree PART-OF non-sequential tracking\", \"optimisation EVALUATE-FOR non-sequential tracking\", \"cluster tree USED-FOR optimal alignment of non-rigid surfaces\", \"tree COMPARE previous sequential and non-sequential tracking approaches\", \"it COREF non-sequential tracking approaches\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  38%|███▊      | 188/500 [36:32<52:15, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"motion reconstruction USED-FOR 2D point correspondences\", \"smooth motion FEATURE-OF trajectory basis\", \"trajectory basis EVALUATE-FOR smooth motion\", \"dynamic programming approach FEATURE-OF linear scaling\", \"filter interactions PART-OF dynamic programming approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  38%|███▊      | 189/500 [36:39<48:18,  9.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"patches FEATURE-OF mid-level visual representation\", \"patches DISCRIMINATIVE-FOR rest of visual world\", \"patches COMPARE visual words\", \"patches USED-FOR scene classification\", \"MIT Indoor-67 dataset PART-OF supervised regime\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  38%|███▊      | 190/500 [36:45<42:36,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"KAZE features FEATURE-OF multiscale 2D feature detection and description algorithm\", \"Gaussian blurring PART-OF Gaussian scale space\", \"nonlinear diffusion filtering PART-OF nonlinear scale space\", \"AOS techniques PART-OF building nonlinear scale space\", \"variable conductance diffusion PART-OF building nonlinear scale space\", \"our features COMPARE SURF\", \"our features COMPARE SIFT\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  38%|███▊      | 191/500 [36:55<44:42,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 191: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e3fc87efc6af2a96f2a04557b6c30dee in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    The problem of predicting image or video interestingness from their low-level feature representations has received increasing interest. As a highly subjective visual attribute, annotating the interesting-ness value of training data for learning a prediction model is challenging. To make the annotation less subjective and more reliable, recent studies employ crowdsourcing tools to collect pairwise comparisons â€“ relying on majority voting to prune the annotation outliers/errors. In this paper, we propose a more principled way to identify annotation outliers by formulating the interestingness prediction task as a unified robust learning to rank problem, tackling both the outlier detection and interestingness prediction tasks jointly. Extensive experiments on both image and video interestingness benchmark datasets demonstrate that our new approach significantly outperforms state-of-the-art alternatives.\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"interestingness prediction task USED-FOR outlier detection task\", \"outlier detection FEATURE-OF interestingness prediction task\", \"crowdsourcing tools USED-FOR collect pairwise comparisons\", \"majority voting EVALUATE-FOR prune annotation outliers/errors\", \"annotation outliers/errors COMPARE state-of-the-art alternatives\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  38%|███▊      | 192/500 [37:37<1:36:08, 18.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"intrinsic textures FEATURE-OF pixel-resolution surface textures\", \"method USED-FOR relighting of free-viewpoint rendering\", \"approach DOES-NOT-ASSUME regions of uniform albedo\", \"method USED-FOR refine shading estimate\", \"global lighting reconstruction PART-OF initial shading estimate\", \"method EVALUATE-FOR resolving inherent global ambiguity in shading\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  39%|███▊      | 193/500 [37:45<1:19:47, 15.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach learning visual representation FEATURE-OF raw spatiotemporal signals\", \"representation learned without supervision\", \"method unsupervised sequential verification task\", \"sequence of frames PART-OF video\", \"visual representation USED-FOR pre-training action recognition\", \"method gives significant gains COMPARE learning without external data\", \"method sensitivity to human pose\", \"results for pose estimation EVALUATE-FOR approaches using significantly more supervision\", \"method combined with supervised representations to provide additional boost\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  39%|███▉      | 194/500 [37:57<1:13:21, 14.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Diagrams FEATURE-OF tools\", \"Diagrams REPRESENT relationships and events\", \"natural images COMPARE diagram\", \"computer vision EVALUATE-FOR natural images\", \"diagram understanding EVALUATE-FOR little attention\", \"DPG REPRESENT structure of diagrams\", \"syntactic parsing EVALUATE-FOR DPGs\", \"syntactic parsing EVALUATE-FOR diagrams\", \"semantic interpretation EVALUATE-FOR diagram question answering\", \"LSTM-based method USED-FOR syntactic parsing\", \"DPG-based attention model USED-FOR diagram question answering\", \"dataset COMPARE models\", \"constituents COREF their relationships\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  39%|███▉      | 195/500 [38:11<1:12:35, 14.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach FEATURE-OF creating pixel-accurate semantic label maps\", \"datasets USED-FOR training high-capacity models\", \"human effort REQUIRED-FOR creating large datasets\", \"pixel-level labels REQUIRED-FOR creating large datasets\", \"images PART-OF semantic label maps\", \"computer vision EVALUATE-FOR creating pixel-accurate semantic label maps\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  39%|███▉      | 196/500 [38:19<1:02:55, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"person re-identification COMPARE many problems in computer vision\", \"WARCA USED-FOR metric learning formulation\", \"stochastic gradient descent algorithm EVALUATE-FOR learning problem\", \"kernel trick FEATURE-OF non-linear extension of WARCA\", \"data dimension PART-OF training and prediction costs\", \"matrix rank degeneration & non-isolated minima PART-OF low-rank matrix optimization\", \"regularizer EVALUATE-FOR matrix optimization\", \"nine standard person re-identification datasets COREF them\", \"Market-1501 dataset PART-OF person re-identification datasets\", \"CUHK03 dataset PART-OF person re-identification datasets\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  39%|███▉      | 197/500 [38:33<1:05:21, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Template-based methods FEATURE-OF poorly-textured surfaces\", \"Non-rigid Structure from Motion techniques FEATURE-OF points being tracked throughout a video sequence\", \"template-free approach USED-FOR reconstructing a poorly-textured, deformable surface\", \"surface isometry PART-OF 3D reconstruction\", \"non-rigid image registration COMPARE depth estimation\", \"our approach EVALUATE-FOR much more accurate 3D reconstructions than state-of-the-art techniques\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  40%|███▉      | 198/500 [38:43<59:45, 11.87s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 198: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4397f982149111848ca7ad47e0dea3b6 in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    Person re-identification is challenging due to the large variations of pose, illumination, occlusion and camera view. Owing to these variations, the pedestrian data is distributed as highly-curved manifolds in the feature space, despite the current convolutional neural networks (CNN)'s capability of feature extraction. However, the distribution is unknown, so it is difficult to use the geodesic distance when comparing two samples. In practice, the current deep embedding methods use the Euclidean distance for the training and test. On the other hand, the manifold learning methods suggest to use the Euclidean distance in the local range, combining with the graphical relationship between samples , for approximating the geodesic distance. From this point of view, selecting suitable positive (i.e. intra-class) training samples within a local range is critical for training the CNN embedding, especially when the data has large intra-class variations. In this paper, we propose a novel moderate positive sample mining method to train robust CNN for person re-identification, dealing with the problem of large variation. In addition, we improve the learning by a metric weight constraint, so that the learned metric has a better generalization ability. Experiments show that these two strategies are effective in learning robust deep metrics for person re-identification, and accordingly our deep model significantly outperforms the state-of-the-art methods on several benchmarks of person re-identification. Therefore, the study presented in this paper may be useful in inspiring new designs of deep models for person re-identification.\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"person re-identification FEATURE-OF challenging task\", \"pedestrian data DISTRIBUTED-AS highly-curved manifolds in feature space\", \"geodesic distance DIFFICULT-TO-USE when comparing two samples\", \"deep embedding methods USE Euclidean distance for training and test\", \"manifold learning methods SUGGEST to use Euclidean distance in local range for approximating geodesic distance\", \"positive training samples CRITICAL-FOR training CNN embedding\", \"data HAS large intra-class variations\", \"positive sample mining method PROPOSED-FOR training robust CNN for person re-identification\", \"metric weight constraint IMPROVES learning\", \"learned metric HAS better generalization ability\", \"deep model OUTPERFORMS state-of-the-art methods on several benchmarks of person re-identification\", \"study MAY BE USEFUL in inspiring new designs of deep models for person re-identification\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  40%|███▉      | 199/500 [39:34<1:58:51, 23.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"joint filter FEATURE-OF image filters\", \"joint filter USED-FOR suppressing noise or enhancing spatial resolution\", \"existing methods COMPARE proposed learning-based approach\", \"model EVALUATE-FOR generalizes well for other modalities\", \"RGB images COMPARE depth images\", \"RGB images COMPARE Flash/Non-Flash images\", \"RGB images COMPARE NIR images\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  40%|████      | 200/500 [39:43<1:35:55, 19.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"action type FEATURE-OF online action detection\", \"action positions PART-OF streaming skeleton data\", \"multi-task end-to-end Joint Classification-Regression Recurrent Neural Network USED-FOR online action detection\", \"start points PART-OF actions\", \"end points PART-OF actions\", \"Long Short-Term Memory FEATURE-OF proposed model\", \"temporal dynamics FEATURE-OF proposed model\", \"sliding window COMPARE proposed model\", \"regression optimization EVALUATE-FOR action\", \"streaming video dataset PART-OF proposed model\", \"annotations PART-OF streaming video dataset\", \"experimental results COMPARE promising performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  40%|████      | 201/500 [39:56<1:27:15, 17.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"oral communication USED-FOR documentation\", \"storage media and networks USED-FOR recording conversation\", \"conversation PART-OF documentation\", \"information retrieval techniques USED-FOR document representation\", \"keywords FEATURE-OF histogram\", \"oral communication FEATURE-OF document representation\", \"indices FEATURE-OF oral communication\", \"time indices FEATURE-OF oral communication\", \"place indices FEATURE-OF oral communication\", \"attendance indices FEATURE-OF oral communication\", \"activity indices FEATURE-OF oral communication\", \"automatic detection EVALUATE-FOR activity detection\", \"TV shows PART-OF larger database\", \"emotions FEATURE-OF indices\", \"dominance distribution FEATURE-OF indices\", \"databases PART-OF effectiveness of indices\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  40%|████      | 202/500 [40:11<1:23:06, 16.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"DARPA Communicator program USED-FOR development of distributed message-passing infrastructure\", \"distributed message-passing infrastructure PART-OF dialogue systems\", \"software infrastructure FEATURE-OF useful infrastructure\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  41%|████      | 203/500 [40:18<1:08:18, 13.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"information extraction systems USED-FOR access to text collections\", \"named entity annotations PART-OF information extraction systems\", \"scenario templates PART-OF information extraction systems\", \"prototype system FEATURE-OF access to pharmaceutical news archive\", \"information workers EVALUATE-FOR access to pharmaceutical news archive\", \"industry watch function FEATURE-OF access to pharmaceutical news archive\", \"user evaluation EVALUATE-FOR system\", \"interface PART-OF system\", \"users EVALUATE-FOR increased potential of IE-enhanced text browsers\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  41%|████      | 204/500 [40:29<1:04:12, 13.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"CCLINC Korean-to-English translation system COREF system\", \"language understanding module PART-OF CCLINC Korean-to-English translation system\", \"generation modules PART-OF CCLINC Korean-to-English translation system\", \"semantic frame FEATURE-OF language neutral meaning representation\", \"parsing USED-FOR Korean\", \"word sense disambiguation USED-FOR translation\", \"word order generation USED-FOR target language\", \"knowledge-based automated acquisition of grammars USED-FOR rapid system development\", \"Korean newspaper articles EVALUATE-FOR training of system\", \"translation output EVALUATE-FOR content understanding of original document\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  41%|████      | 205/500 [40:42<1:03:38, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"automated evaluation techniques FEATURE-OF human language learners\", \"automated evaluation techniques EVALUATE-FOR machine translation systems\", \"MT output USED-FOR language learning experiment\", \"assessors COREF assessors\", \"native language essays HYPONYM-OF non-native language essays\", \"extracts COMPARE expert human translations\", \"extracts COMPARE machine translation outputs\", \"subjects EVALUATE-FOR sample output\", \"word PART-OF decision\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  41%|████      | 206/500 [40:52<58:28, 11.93s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"spoken language understanding system PART-OF LCS\", \"intelligent mobile agents PART-OF LCS\", \"users COREF Requestors\", \"information sources PART-OF LCS\", \"LCS-Marine USED-FOR tactical personnel\", \"mobile, intelligent agent USED-FOR execution at appropriate database\", \"status of request EVALUATE-FOR requestors\", \"requestors COREF users\", \"requestors EVALUATE-FOR system notification\", \"request PART-OF supply or information request\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  41%|████▏     | 207/500 [41:02<56:18, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Automatic Speech Recognition technology FEATURE-OF dialog systems\", \"speech recognition FEATURE-OF dialog systems\", \"dialog systems EVALUATE-FOR system response\", \"natural language generation community FEATURE-OF system response\", \"generation FEATURE-OF dialog systems\", \"knowledge-based generation systems COMPARE machine learning techniques\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  42%|████▏     | 208/500 [41:09<49:32, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"language models HYPONYM-OF interpolation methods\", \"interpolation methods FEATURE-OF simple interpolation methods\", \"performance EVALUATE-FOR dynamic language model combination\", \"oracle COREF dynamic combiner\", \"reference word string PART-OF oracle\", \"word string PART-OF reference word string\", \"semantic error rate PART-OF word strings\", \"LMs PART-OF word strings\", \"method FEATURE-OF neural network\", \"method FEATURE-OF decision tree\", \"LMs FEATURE-OF hypothesis\", \"confidence measures FEATURE-OF LMs\", \"best hypothesis EVALUATE-FOR LM\", \"LMs EVALUATE-FOR best hypothesis\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  42%|████▏     | 209/500 [41:21<51:23, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"n-gram models FEATURE-OF Thai key prediction\", \"n-gram models FEATURE-OF Thai-English language identification\", \"error-correction rules USED-FOR Thai key prediction\", \"error-correction rules USED-FOR Thai-English language identification\", \"rule-reduction algorithm FEATURE-OF error-correction rules\", \"mutual information FEATURE-OF rule-reduction algorithm\", \"language identification EVALUATE-FOR accuracy\", \"key prediction EVALUATE-FOR accuracy\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  42%|████▏     | 210/500 [41:31<50:19, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"information redundancy USED-FOR correct errors in machine translation\", \"quality of multilingual summaries EVALUATE-FOR improve\", \"multi-document summarization PART-OF input documents\", \"summary PART-OF input documents\", \"summary PART-OF lexical-syntactic forms\", \"machine translation systems USED-FOR redundancy\", \"information PART-OF English\", \"machine translations EVALUATE-FOR errors\", \"redundancy USED-FOR generate noun phrases\", \"noun phrases PART-OF redundancy\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  42%|████▏     | 211/500 [41:41<49:47, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 211: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cfe2c8bd71037628d8dca0228e55d18b in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "     This paper presents a  maximum entropy word alignment algorithm  for  Arabic-English  based on  supervised training data  . We demonstrate that it is feasible to create  training material  for problems in  machine translation  and that a mixture of  supervised and unsupervised methods  yields superior  performance  . The  probabilistic model  used in the  alignment  directly models the  link decisions  . Significant improvement over traditional  word alignment techniques  is shown as well as improvement on several  machine translation tests  . Performance of the algorithm is contrasted with  human annotation performance  . \n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"maximum entropy word alignment algorithm FEATURE-OF probabilistic model\", \"Arabic-English HYPONYM-OF machine translation\", \"supervised training data FEATURE-OF maximum entropy word alignment algorithm\", \"supervised methods COMPARE unsupervised methods\", \"word alignment techniques COMPARE human annotation performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  42%|████▏     | 212/500 [42:23<1:35:54, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"practically unsupervised learning method USED-FOR single-snippet answers\", \"definition questions FEATURE-OF single-snippet answers\", \"question answering systems USED-FOR single-snippet answers\", \"Web search engines COMPARE on-line encyclopedias and dictionaries\", \"positive and negative definition examples PART-OF svm\", \"proposed method EVALUATE-FOR search engine handling definition questions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  43%|████▎     | 213/500 [42:32<1:19:29, 16.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"conditional log-linear model USED-FOR representation of NLP structures\", \"hidden variables FEATURE-OF conditional log-linear model\", \"lexical items PART-OF hidden variables\", \"word clusters PART-OF hidden variables\", \"word senses PART-OF hidden variables\", \"model EVALUATE-FOR F-measure improvement\", \"base parser COMPARE Collins (2000) reranker\", \"techniques DESCRIBED generalize to NLP structures\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  43%|████▎     | 214/500 [42:42<1:09:58, 14.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 214: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID be88538ad836e789e3ce313ca9b16219 in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "     This paper presents a  phrase-based statistical machine translation method  , based on  non-contiguous phrases  , i.e.  phrases  with gaps. A method for producing such  phrases  from a  word-aligned corpora  is proposed. A  statistical translation model  is also presented that deals such  phrases  , as well as a  training method  based on the maximization of  translation accuracy  , as measured with the  NIST evaluation metric  .  Translations  are produced by means of a  beam-search decoder  . Experimental results are presented, that demonstrate how the proposed method allows to better generalize from the  training data  . \n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"phrase-based statistical machine translation method FEATURE-OF statistical translation model\", \"non-contiguous phrases HYPONYM-OF phrases\", \"word-aligned corpora PART-OF producing phrases\", \"statistical translation model USED-FOR phrases\", \"training method USED-FOR maximization of translation accuracy\", \"NIST evaluation metric EVALUATE-FOR translation accuracy\", \"translations PRODUCED-BY beam-search decoder\", \"proposed method ALLOWS-TO better generalize from training data\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  43%|████▎     | 215/500 [43:28<1:54:09, 24.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"probabilistic translation models FEATURE-OF computational problems\", \"probabilistic translation models HYPONYM-OF probabilistic context-free grammars\", \"probabilistic context-free grammars PART-OF synchronous way\", \"NP EVALUATE-FOR hardness results\", \"algorithms COMPARE exponential time lower-bound\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  43%|████▎     | 216/500 [43:37<1:31:28, 19.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"question-focused sentence retrieval FEATURE-OF news articles\", \"questions FEATURE-OF story corpus\", \"stories PART-OF questions\", \"questions EVALUATE-FOR sentences\", \"stochastic, graph-based method USED-FOR sentence retrieval problem\", \"textual units COMPARE importance\", \"topic-sensitive version HYPONYM-OF method\", \"method COMPARE baseline\", \"similarity COMPARE IDF-weighted word overlap\", \"method EVALUATE-FOR TRDR score\", \"baseline EVALUATE-FOR TRDR score\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  43%|████▎     | 217/500 [43:47<1:18:16, 16.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"automatic evaluation FEATURE-OF machine translation\", \"automatic evaluation FEATURE-OF document summarization\", \"POURPRE EVALUATE-FOR automatically evaluating answers to definition questions\", \"automatic methods PART-OF scoring system output\", \"TREC 2003 COMPARE TREC 2004 QA tracks\", \"rankings COMPARE official rankings\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  44%|████▎     | 218/500 [43:57<1:09:25, 14.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"part-of-speech tag sequences FEATURE-OF method\", \"analysis FEATURE-OF diagnostic tool\", \"diagnostic tool USED-FOR developers of machine translation systems\", \"application EVALUATE-FOR developers to explore patterns in machine translation output\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  44%|████▍     | 219/500 [44:03<56:34, 12.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"project DEVELOP SUMMIT\", \"SUMMIT FEATURE-OF spoken language understanding system\", \"approach EXPRESS speech knowledge\", \"speech knowledge FEATURE-OF formal framework\", \"features DISCOVERED using speech data\", \"decision strategies DISCOVERED using speech data\", \"system DESCRIBED\", \"performance DOCUMENTED\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  44%|████▍     | 220/500 [44:10<49:35, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Comparator USED-FOR evaluating Spoken Language Systems\", \"Common Answer Specification FEATURE-OF answer expressions\", \"SLS HYPONYM-OF Spoken Language Systems\", \"canonical answer PART-OF answer\", \"CAS PART-OF Common Answer Specification\", \"syntax FEATURE-OF answer expressions\", \"content FEATURE-OF answer expressions\", \"data EVALUATE-FOR test corpora\", \"procedures EVALUATE-FOR Comparator\", \"CAS COMPARE Comparator software\", \"CAS COMPARE CAS approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  44%|████▍     | 221/500 [44:22<50:26, 10.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"spoken language system USED-FOR interactive problem solving\", \"voice input FEATURE-OF spoken language system\", \"multiple speakers PART-OF spoken language system\", \"speech recognition USED-FOR speech understanding\", \"natural language processing USED-FOR speech understanding\", \"application domain EVALUATE-FOR usefulness of spoken language system\", \"segment-based approach FEATURE-OF phonetic recognition\", \"recognition system PART-OF speech recognition system\", \"natural language processing USED-FOR spoken language understanding\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  44%|████▍     | 222/500 [44:32<49:05, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"unification-based parsing UTILIZES recent advances in classification-based knowledge representation\", \"unification-based grammatical frameworks SHARE many properties with KL-ONE-like knowledge representation systems\", \"classification-based representation techniques can be APPLIED TO unification-based linguistic descriptions\", \"semantic and syntactic information INTEGRATED INTO same system\", \"efficient parsing EXPECTED DUE TO increased organization of knowledge\", \"KL-ONE style representation USED FOR parsing and semantic interpretation in PSI-KLONE system\", \"parsing CHARACTERIZED AS incremental description refinement in PSI-KLONE system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  45%|████▍     | 223/500 [44:42<48:08, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Spoken Language System PART-OF natural language system\", \"N-Best sentence hypotheses FEATURE-OF algorithms\", \"grammar coverage problems EVALUATE-FOR fully-connected first-order statistical class grammar\", \"speech-search algorithm FEATURE-OF board\", \"Intel i860 chip FEATURE-OF board\", \"board PART-OF VME bus\", \"VME bus PART-OF SUN4\", \"natural language system PART-OF application back end\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  45%|████▍     | 224/500 [44:51<45:57,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"speech USED-FOR large vocabulary continuous speech recognition\", \"speaker-independent training USED-FOR hidden Markov models\", \"speech FEATURE-OF speaker-independent training\", \"speaker FEATURE-OF speech\", \"training speakers FEATURE-OF statistics\", \"independently trained models FEATURE-OF statistics\", \"speech data FEATURE-OF training\", \"training speakers PART-OF SI recognition\", \"word error rate EVALUATE-FOR SI recognition\", \"grammar FEATURE-OF test set\", \"test set PART-OF DARPA Resource Management corpus\", \"performance COMPARE best condition\", \"training speakers COMPARE SI corpus\", \"speaker adaptation USED-FOR SI corpus\", \"probabilistic spectral mapping USED-FOR speaker adaptation\", \"reference model HYPONYM-OF probabilistic spectral mapping\", \"target speaker HYPONYM-OF probabilistic spectral mapping\", \"reference model TRANSFORMED-TO space of target speaker\", \"reference model FEATURE-OF speaker adaptation\", \"target speaker FEATURE-OF speaker adaptation\", \"utterances FEATURE-OF target speaker\", \"error rate EVALUATE-FOR adaptation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  45%|████▌     | 225/500 [45:10<58:03, 12.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Lincoln CSR system PART-OF semiphone modeling\", \"duration model FEATURE-OF triphone and semiphone systems\", \"training strategy USED-FOR rapid adaptation technique\", \"recognizer FEATURE-OF bigram back-off language models\", \"RM task PART-OF system\", \"ATIS CSR task PART-OF system\", \"RM task COMPARE ATIS CSR task\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  45%|████▌     | 226/500 [45:18<51:46, 11.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"tagged text corpus PART-OF program\", \"verb USED-FOR subcategorization frames\", \"completeness EVALUATE-FOR output list\", \"occurrences FEATURE-OF verb\", \"training corpus PART-OF completeness\", \"False positive rates FEATURE-OF output list\", \"subcategorization frames COMPARE subcategorization dictionary\", \"NLP community COREF dictionaries\", \"specific corpora PART-OF dictionaries\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  45%|████▌     | 227/500 [45:28<49:42, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"WordNet FEATURE-OF method\", \"semantic relations PART-OF WordNet\", \"synonymy HYPONYM-OF semantic relations\", \"antonymy HYPONYM-OF semantic relations\", \"hyponymy HYPONYM-OF semantic relations\", \"meronymy HYPONYM-OF semantic relations\", \"causal entailment HYPONYM-OF semantic relations\", \"troponymic entailment HYPONYM-OF semantic relations\", \"semantically related words FEATURE-OF WordNet\", \"sense resolution USED-FOR text processing\", \"polysemous word COREF alternative senses\", \"words RELATED-TO alternative senses\", \"derived strings USED-FOR sense resolution\", \"textual corpus EVALUATE-FOR derived strings\", \"sense EVALUATE-FOR derived string\", \"context USED-FOR sense resolution\", \"corpus EVALUATE-FOR context\", \"semantic distance EVALUATE-FOR alternative senses\", \"information retrieval USED-FOR sense resolution\", \"mechanical translation USED-FOR sense resolution\", \"intelligent tutoring systems USED-FOR sense resolution\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  46%|████▌     | 228/500 [45:50<1:04:44, 14.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"spoken language corpus FEATURE-OF ATIS domain\", \"data collection effort USED-FOR multi-site common evaluation of speech, natural language and spoken language\", \"MADCOW PART-OF implementation of multi-site data collection paradigm\", \"MADCOW USED-FOR monitoring collection and distribution of utterances\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  46%|████▌     | 229/500 [45:57<54:25, 12.05s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"LIMSI research CONJUNCTION speech processing\", \"Human-Machine Communication FEATURE-OF Natural Language Processing\", \"Natural Language Processing PART-OF Human-Machine Communication\", \"Non Verbal and Multimodal Communication PART-OF Human-Machine Communication\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  46%|████▌     | 230/500 [46:02<45:41, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Paramax spoken language understanding system PART-OF non-monotonic reasoning\", \"implicit reference resolution FEATURE-OF Paramax spoken language understanding system\", \"database query paraphrase FEATURE-OF Paramax spoken language understanding system\", \"February 1992 ATIS benchmark tests EVALUATE-FOR progress\", \"n-best speech/language integration architecture USED-FOR OCR accuracy\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  46%|████▌     | 231/500 [46:10<41:49,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"generative probabilistic model USED-FOR natural language ambiguity\", \"HBG model COMPARE P-CFG model\", \"lexical information PART-OF HBG model\", \"syntactic information PART-OF HBG model\", \"semantic information PART-OF HBG model\", \"structural information PART-OF HBG model\", \"parse tree PART-OF HBG model\", \"disambiguation process EVALUATE-FOR parse\", \"corpus of bracketed sentences PART-OF Treebank\", \"decision tree building USED-FOR parse tree\", \"grammar FEATURE-OF parsing models\", \"linguistic introspection USED-FOR grammar tailoring\", \"HBG model EVALUATE-FOR parsing accuracy rate\", \"P-CFG model EVALUATE-FOR parsing accuracy rate\", \"error COREF reduction\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  46%|████▋     | 232/500 [46:26<50:21, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"CDHMM FEATURE-OF MLE reestimation algorithms\", \"forward-backward algorithm PART-OF CDHMM\", \"segmental k-means algorithm PART-OF CDHMM\", \"HMM WITH Gaussian mixture observation densities HYPONYM-OF CDHMM\", \"Bayesian learning USED-FOR parameter smoothing\", \"Bayesian learning USED-FOR speaker adaptation\", \"Bayesian learning USED-FOR speaker group modeling\", \"Bayesian learning USED-FOR corrective training\", \"MAP estimation approach FEATURE-OF Bayesian learning\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  47%|████▋     | 233/500 [46:36<49:07, 11.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"polysemous word COREF sentence\", \"word-sense disambiguation systems USED-FOR improving performance\", \"bilingual material USED-FOR one of the word-sense disambiguation systems\", \"monolingual material USED-FOR one of the word-sense disambiguation systems\", \"discourse effect EVALUATE-FOR word-sense disambiguation algorithm\", \"polysemous word PART-OF well-written discourse\", \"sense HYPONYM-OF meaning\", \"experiment COMPARE hypothesis\", \"discourse CONJUNCTION constraint\", \"disambiguation algorithms EVALUATE-FOR discourse constraint\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  47%|████▋     | 234/500 [46:55<59:40, 13.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"speech and text-image recognition COREF recognition technology\", \"systems USED-FOR text processing functionality\", \"text processors HYPONYM-OF audio and scanned image data\", \"speech and text-image recognition USED-FOR retrieve arbitrary information\", \"documents PART-OF signal content\", \"text-image editor FEATURE-OF document processing functionality\", \"wordspotter USED-FOR voice editing and indexing\", \"decoding framework USED-FOR scanned-document content retrieval\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  47%|████▋     | 235/500 [47:04<53:20, 12.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"LIMSI recognizer EVALUATE-FOR ARPA NOV93 CSR test\", \"WSJ corpus PART-OF word recognition experiments\", \"BREF corpus PART-OF word recognition experiments\", \"vocabularies FEATURE-OF word recognition experiments\", \"continuous density HMM FEATURE-OF recognizer\", \"Gaussian mixture FEATURE-OF acoustic modeling\", \"n-gram statistics FEATURE-OF language modeling\", \"newspaper texts FEATURE-OF language modeling\", \"time-synchronous graph-search strategy FEATURE-OF recognizer\", \"bigram back-off language models FEATURE-OF time-synchronous graph-search strategy\", \"forward pass FEATURE-OF recognizer\", \"word graph FEATURE-OF forward pass\", \"trigram language model FEATURE-OF forward pass\", \"cepstrum-based features FEATURE-OF acoustic modeling\", \"context-dependent phone models FEATURE-OF acoustic modeling\", \"phone duration models FEATURE-OF acoustic modeling\", \"sex-dependent models FEATURE-OF acoustic modeling\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  47%|████▋     | 236/500 [47:24<1:03:41, 14.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"continuous speech recognition techniques FEATURE-OF Spoken Language Systems\", \"speech recognition and understanding systems FEATURE-OF spoken language technology\", \"CSR USED-FOR mobile military command and control\", \"acoustic modelling FEATURE-OF robust large-vocabulary CSR\", \"search FEATURE-OF robust large-vocabulary CSR\", \"adaptation techniques FEATURE-OF robust large-vocabulary CSR\", \"ARPA large-vocabulary CSR corpora PART-OF recognition-time adaptation techniques\", \"military application tasks EVALUATE-FOR robust large-vocabulary CSR\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  47%|████▋     | 237/500 [47:35<58:09, 13.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ILIMP USED-FOR anaphora resolution system\", \"pronoun il COREF il\", \"ILIMP FEATURE-OF modular syntactic analysis system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  48%|████▊     | 238/500 [47:40<47:39, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Automatic evaluation metrics FEATURE-OF Machine Translation systems\", \"BLEU USED-FOR word n-grams\", \"BLEU COMPARE its application at the character level\", \"word segmentation problem EVALUATE-FOR assessment of language pairs like English-Chinese or English-Japanese\", \"BLEU USED-FOR character level\", \"word segmentation problem PART-OF use of BLEU at the character level\", \"commercial systems outputting unsegmented texts COMPARE statistical MT systems\", \"outputs PART-OF statistical MT systems\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  48%|████▊     | 239/500 [47:51<47:15, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SMT models EVALUATE-FOR WSD accuracy\", \"SMT models COMPARE dedicated WSD models\", \"SMT models FEATURE-OF translation\", \"WSD models FEATURE-OF word sense disambiguation models\", \"BLEU scores FEATURE-OF statistical machine translation\", \"Senseval series FEATURE-OF workshops\", \"datasets FEATURE-OF Senseval-3 Chinese lexical sample task\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  48%|████▊     | 240/500 [47:59<43:55, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"natural language processing USED-FOR trend survey\", \"Japanese natural language processing studies PART-OF trend survey\", \"number of papers published FEATURE-OF research organization and research area\", \"relationship between research organizations and research areas\", \"Japanese NLP USED-FOR recognizing trends\", \"method of supporting trend surveys EVALUATE-FOR constructing\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  48%|████▊     | 241/500 [48:06<39:14,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ambiguity resolution FEATURE-OF right-side dependencies\", \"dependency parsing USED-FOR sentences\", \"shift-reduce dependency parsers COMPARE two-phase shift-reduce dependency parser\", \"left-side dependents PART-OF two-phase shift-reduce dependency parser\", \"right-side nominal dependents PART-OF two-phase shift-reduce dependency parser\", \"right-side verbal dependents PART-OF two-phase shift-reduce dependency parser\", \"proposed method EVALUATE-FOR dependency accuracy\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  48%|████▊     | 242/500 [48:15<38:40,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SMT gives competitive results COMPARE rule-based translation systems\", \"translation systems USED-FOR language pairs, domains\", \"SMT system PART-OF translation system\", \"STTK FEATURE-OF statistical machine translation tool kit\", \"STTK USED-FOR translation system\", \"STTK USED-FOR CMU's SMT system\", \"multi engine machine translation system HYPONYM-OF rule-based and example based machine translation modules\", \"tool kit PART-OF STTK\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  49%|████▊     | 243/500 [48:24<39:27,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"word segmentation system FEATURE-OF France Telecom R&D Beijing\", \"word breaking PART-OF word segmentation system\", \"OOV identification PART-OF word segmentation system\", \"output FEATURE-OF system\", \"segmentation standards EVALUATE-FOR output\", \"system USED-FOR segmentation bakeoff\", \"PK-open COMPARE MSR-open\", \"PK-closed COMPARE MSR-close\", \"AS-open COREF AS-closed\", \"HK-open COREF HK-closed\", \"MSR-open HYPONYM-OF state-of-the-art performance\", \"MSR-close HYPONYM-OF state-of-the-art performance\", \"system PART-OF scores\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  49%|████▉     | 244/500 [48:37<44:06, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Taiwan Child Language Corpus FEATURE-OF scripts\", \"scripts PART-OF Taiwan Child Language Corpus\", \"Southern Min Chinese HYPONYM-OF Chinese speaking families\", \"corpus USED-FOR applications\", \"data collection FEATURE-OF corpus\", \"transcription FEATURE-OF corpus\", \"word segmentation FEATURE-OF corpus\", \"part-of-speech annotation FEATURE-OF corpus\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  49%|████▉     | 245/500 [48:46<41:09,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"English-Chinese bitexts FEATURE-OF laws of Hong Kong\", \"numbering system USED-FOR aligning English-Chinese bitexts\", \"bilingual corpus EVALUATE-FOR empirical MT research\", \"English-Chinese bitexts USED-FOR empirical MT research\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  49%|████▉     | 246/500 [48:52<37:28,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"machine translation evaluation RELATED-TO sentence-level semantic equivalence classification\", \"MT evaluation methods USED-FOR building classifiers\", \"BLEU USED-FOR building classifiers\", \"NIST USED-FOR building classifiers\", \"WER USED-FOR building classifiers\", \"PER USED-FOR building classifiers\", \"classification method BASED-ON PER\", \"part of speech information FEATURE-OF words\", \"words PART-OF word matches and non-matches\", \"MT evaluation techniques USED-FOR paraphrase classification\", \"features EVALUATE-FOR paraphrase classification\", \"entailment EVALUATE-FOR MT evaluation techniques\", \"technique USED-FOR paraphrase classification accuracy improvement\", \"models COMPARE technique\", \"experiments COMPARE technique\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  49%|████▉     | 247/500 [49:06<42:57, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"class-oriented framework USED-FOR collecting paraphrase examples\", \"sentential paraphrases PART-OF paraphrase class\", \"automatic candidate generation USED-FOR collecting sentential paraphrases\", \"manual judgement USED-FOR collecting sentential paraphrases\", \"paraphrase corpus EVALUATE-FOR cost-efficiency\", \"paraphrase corpus EVALUATE-FOR exhaustiveness\", \"paraphrase corpus EVALUATE-FOR reliability\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  50%|████▉     | 248/500 [49:15<41:47,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method USED-FOR machine translation evaluation measures\", \"paraphrase sets FEATURE-OF reference sets\", \"paraphrases EVALUATE-FOR MT evaluation\", \"paraphrases COMPARE hand-produced sets\", \"paraphrases PART-OF paraphrase sets\", \"method EVALUATE-FOR paraphrase quality\", \"grammaticality FEATURE-OF sentences\", \"equivalence in meaning FEATURE-OF paraphrases\", \"internal lexical and syntactical variation FEATURE-OF paraphrase sets\", \"method COREF sets\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  50%|████▉     | 249/500 [49:27<43:40, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"latent variable model EVALUATE-FOR paraphrases\", \"context FEATURE-OF sentence\", \"latent variable PART-OF model\", \"paraphrase USED-FOR context\", \"proposed method COMPARE two models\", \"accuracy EVALUATE-FOR paraphrases\", \"topic FEATURE-OF latent variable\", \"accuracy EVALUATE-FOR method\", \"topic FEATURE-OF method\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  50%|█████     | 250/500 [49:34<39:42,  9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"corpus-based investigations FEATURE-OF quantifying noun groups\", \"information other than grammar sensu stricto USED-FOR treebank integration\", \"annotation PART-OF treebank\", \"stochastic parsers EVALUATE-FOR treebank\", \"grammars INDUCED-FROM treebank\", \"treebank SOURCE-OF data for theoretical linguistic investigations\", \"corpus research USED-FOR proposed analyses\", \"SILVA FEATURE-OF parsing and extraction tool\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  50%|█████     | 251/500 [49:43<38:27,  9.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"honorifics FEATURE-OF annotating scheme\", \"social relationship FEATURE-OF honorifics\", \"referential information USED-FOR resolving zero pronouns\", \"referential information EVALUATE-FOR improving machine translation outputs\", \"predicate PART-OF honorifics\", \"ranks FEATURE-OF referents\", \"ranks CALIBRATES referents\", \"referents CONNECTS predicates\", \"zero pronouns COREF\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  50%|█████     | 252/500 [49:53<39:58,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"significance FEATURE-OF words\", \"ASR performance EVALUATE-FOR IR\", \"WWER USED-FOR weighted word error rate\", \"WER COMPARE WWER\", \"decoding strategy FEATURE-OF WWER minimization\", \"errors PART-OF ASR\", \"errors PART-OF IR\", \"automatic estimation method FEATURE-OF word significance\", \"weights FEATURE-OF word significance\", \"evaluation measures COREF ASR\", \"evaluation measures COREF IR\", \"proposed method USED-FOR speech-based information retrieval system\", \"IR PART-OF speech-based information retrieval system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  51%|█████     | 253/500 [50:04<41:18, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"paraphrasing method USED-FOR disambiguating sense of phrase\", \"paraphrasing method USED-FOR obtaining interchangeable paraphrases\", \"method USED-FOR acquiring generalized translation knowledge\", \"paraphrasing method FEATURE-OF method\", \"bilingual dependency relations FEATURE-OF paraphrasing method\", \"monolingual dependency parse PART-OF bilingual dependency relations\", \"statistical alignment techniques FEATURE-OF bilingual dependency relations\", \"bilingual context EVALUATE-FOR disambiguating sense of phrase\", \"paraphrases EVALUATE-FOR generalized translation knowledge\", \"paraphrases USED-FOR extracting translation knowledge\", \"paraphrases COMPARE precision of 94.3% for Korean and 84.6% for English\", \"bilingual corpora USED-FOR extracting translation knowledge\", \"paraphrases USED-FOR successful generalization of translation knowledge\", \"Korean-English translation EVALUATE-FOR acquiring generalized translation knowledge\", \"parallel corpora PART-OF Korean and English language pairs\", \"compression ratio FEATURE-OF successful generalization of translation knowledge\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  51%|█████     | 254/500 [50:25<54:27, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ASR System USED-FOR Utterance Verification\", \"Confidence tests FEATURE-OF decoded string hypotheses\", \"Word Spotting PART-OF ASR system\", \"Noise Spotting PART-OF ASR system\", \"UV procedure EVALUATE-FOR recognition errors\", \"Confidence tests COMPARE acoustic measures\", \"Confidence tests COMPARE linguistic information\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  51%|█████     | 255/500 [50:33<47:56, 11.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"nonstationary chaotic behavior FEATURE-OF practical interest\", \"nonstationary events EVALUATE-FOR capture\", \"signal PART-OF periods\", \"biological signals COMPARE ocean waves\", \"biological signals COMPARE traffic flow\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  51%|█████     | 256/500 [50:39<40:34,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"LPC based speech coders USED-FOR synthetic speech\", \"buzzy artefacts FEATURE-OF LPC based speech coders\", \"metallic artefacts FEATURE-OF LPC based speech coders\", \"simplifying assumptions MADE-ABOUT excitation source\", \"excitation source REQUIRED-TO maintain low bit rates\", \"new LPC vocoder PRESENTED\", \"LPC excitation SPLIT-INTO two frequency bands\", \"lower band RESPONSIBLE-FOR representing voiced parts of speech\", \"upper band REPRESENTS unvoiced speech\", \"coder's performance GREATLY-IMPROVED\", \"mixed voicing speech EVALUATE-FOR coder's performance\", \"speech containing acoustic noise EVALUATE-FOR coder's performance\", \"soft natural sounding speech FEATURE-OF improved coder's performance\", \"new parameter determination techniques DESCRIBED\", \"quantisation techniques DESCRIBED\", \"operation of this coder at low bit rates MADE-POSSIBLE\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  51%|█████▏    | 257/500 [50:58<51:16, 12.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"GNSS/INS coupling USED-FOR localization\", \"interference FEATURE-OF GNSS measurement noise\", \"GNSS noise inflation FEATURE-OF covariance of EKF outputs\", \"least square estimate USED-FOR potential variance jumps\", \"estimation USED-FOR Bayesian test\", \"interference EVALUATE-FOR corrupting GNSS signal\", \"impaired measurements PART-OF navigation solution\", \"proposed approach COMPARE simulated data\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  52%|█████▏    | 258/500 [51:08<47:42, 11.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"estimation problem USED-FOR maximum likelihood estimation problem\", \"gear scale factors PART-OF motorized vehicle\", \"estimation method FEATURE-OF functionality\", \"speed measurements COREF measurements\", \"measurements of the signal COREF measurements\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  52%|█████▏    | 259/500 [51:14<40:01,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Dau measure EVALUATE-FOR intelligibility prediction\", \"glimpse proportion EVALUATE-FOR intelligibility prediction\", \"Speech Intelligibility Index (SII) EVALUATE-FOR intelligibility prediction\", \"Perceptual Evaluation of Speech Quality (PESQ) EVALUATE-FOR quality measure\", \"HMM-based speech synthesis system USED-FOR generation of synthesized speech\", \"additive noises PART-OF noisy conditions\", \"Dau measure COMPARE glimpse measures\", \"Dau measure COMPARE Speech Intelligibility Index (SII)\", \"Dau measure COMPARE subjective scores\", \"glimpse proportion COMPARE Speech Intelligibility Index (SII)\", \"glimpse proportion COMPARE subjective scores\", \"Speech Intelligibility Index (SII) COMPARE subjective scores\", \"synthetic speech COMPARE natural speech\", \"ideal binary mask USED-FOR processed synthesized speech\", \"Glimpse measure EVALUATE-FOR intelligibility predictions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  52%|█████▏    | 260/500 [51:34<52:25, 13.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"blind separation FEATURE-OF underdetermined instantaneous mixtures of independent signals\", \"signals PART-OF epochs\", \"autoregressive model COMPARE i.i.d.\", \"model USED-FOR blind separation of natural speech signals\", \"separation method EVALUATE-FOR separation accuracy\", \"method USED-FOR blind separation of natural speech signals\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  52%|█████▏    | 261/500 [51:42<46:14, 11.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"speaker DOA estimation accuracy FEATURE-OF mobile speech application\", \"AVS USED-FOR size\", \"DOA estimation algorithm USED-FOR accuracy\", \"NSI deteriorates DOA estimation algorithm\", \"inter-sensor data ratio model PART-OF AVS\", \"BISDR EVALUATE-FOR robust speaker DOA estimation algorithm\", \"bispectrum FEATURE-OF reliable bispectrum mask\", \"speaker DOA cues EVALUATE-FOR robustness to NSI\", \"speech sparsity COMPARE large bispectrum amplitude of the captured signals\", \"proposed algorithm COMPARE DOA estimation algorithm\", \"NSI conditions COMPARE various NSI conditions\", \"SIR COMPARE 0dB\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  52%|█████▏    | 262/500 [51:55<47:46, 12.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"MFCC features COMPARE DOCC features\", \"MFCC features EVALUATE-FOR depression prediction\", \"DOCC features EVALUATE-FOR depression prediction\", \"higher-order cepstral coefficients FEATURE-OF cepstral coefficients\", \"neural networks COMPARE support vector regression\", \"spontaneous speech COMPARE read speech\", \"DOCCs USED-FOR noise and reverberation robustness\", \"MFCCs USED-FOR depression prediction\", \"DOCCs USED-FOR depression prediction\", \"DOCCs USED-FOR noise and reverberation robustness\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  53%|█████▎    | 263/500 [52:08<48:17, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"HFOs USED-FOR biomarker of epileptic brain tissue and activity\", \"dimensionality reduction FEATURE-OF HFO analysis\", \"linear manifold COMPARE global manifold\", \"linear methods EVALUATE-FOR appropriateness\", \"manifold consistency EVALUATE-FOR time, space, and patients\", \"Bayes classification error EVALUATE-FOR distinction between two classes of HFOs\", \"seizures COREF other processes\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  53%|█████▎    | 264/500 [52:17<44:25, 11.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Wallflower COMPARE 8 other background subtraction algorithms\", \"pixel-level component USED-FOR probabilistic predictions\", \"region-level component USED-FOR filling in homogeneous regions\", \"frame-level component USED-FOR detecting sudden, global changes\", \"Wallflower OUTPERFORM previous algorithms\", \"background PART-OF video surveillance systems\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  53%|█████▎    | 265/500 [52:25<40:23, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"3-D stereo reconstruction scheme USED-FOR cope with cases where image information alone is not sufficient to accurately recover 3-D shape\", \"anisotropic meshing FEATURE-OF satisfactory reconstruction results using triangulations with few vertices\", \"numerical constraints EVALUATE-FOR reconstruction results\", \"structural constraints EVALUATE-FOR reconstruction results\", \"constrained optimization scheme USED-FOR adding structural or numerical constraints locally to the reconstruction process\", \"differential features FEATURE-OF strong description and modeling properties\", \"they useful tools COMPARE constraints for 3-D reconstruction\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  53%|█████▎    | 266/500 [52:38<43:22, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"model space USED-FOR search space\", \"tracked points COREF their correct locations\", \"face metrics FEATURE-OF face geometry\", \"algorithm COMPARE existing ones\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  53%|█████▎    | 267/500 [52:43<35:58,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"highlight pixels FEATURE-OF guiding the inpainting process\", \"illumination constraints USED-FOR better recovery of shading and textures\", \"pixel colors EVALUATE-FOR estimation of the underlying diffuse color\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  54%|█████▎    | 268/500 [52:48<31:31,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"video streams USED-FOR novel view generation\", \"two cameras PART-OF computer monitor\", \"proposed algorithm SYNTHESIZES images\", \"virtual camera FEATURE-OF novel view synthesis\", \"dynamic-programming algorithm USED-FOR efficient novel-view generation\", \"three-plane graph USED-FOR dense-stereo dynamic-programming\", \"occlusion labeling FEATURE-OF three-plane graph\", \"geometric derivation USED-FOR novel-view synthesis\", \"minimum-cost surface FEATURE-OF novel-view synthesis\", \"background model USED-FOR temporal maintenance\", \"cost aggregation algorithm USED-FOR three-dimensional matching cost space\", \"long stereo video streams COMPARE spatial and temporal artefacts\", \"cyclopean views EVALUATE-FOR extended conversational sequences\", \"virtual camera USED-FOR novel view synthesis\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  54%|█████▍    | 269/500 [53:05<40:46, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm computes optical flow, shape, motion, lighting, and albedo FROM image sequence\", \"problem formulated IN manner that subsumes structure from motion, multi-view stereo, and photo-metric stereo AS special cases\", \"algorithm utilizes spatial and temporal intensity variation AS cues\", \"former constrains flow AND latter constrains surface orientation\", \"combining both cues enables dense reconstruction OF textured AND texture-less surfaces\", \"algorithm works BY iteratively estimating affine camera parameters, illumination, shape, AND albedo IN alternating fashion\", \"results demonstrated ON videos OF hand-held objects moving IN front OF fixed light AND camera\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  54%|█████▍    | 270/500 [53:16<41:41, 10.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"transparent objects HYPONYM-OF hard problem\", \"features FEATURE-OF transparent objects\", \"features FEATURE-OF objects rigidly attached to scene\", \"model-based approach USED-FOR recover shapes and poses of transparent objects\", \"transparent objects PART-OF objects composed of multiple layers\", \"refractive indices FEATURE-OF layers of transparent objects\", \"simulations EVALUATE-FOR practical feasibility of algorithm\", \"algorithm USED-FOR recover shapes of transparent objects\", \"shapes COREF objects\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  54%|█████▍    | 271/500 [53:27<40:52, 10.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"face recognition systems USED-FOR live CCTV camera input\", \"Bayesian framework USED-FOR multi-modal face image super-resolution\", \"low-resolution face image PART-OF multi-modal variations\", \"training tensor FEATURE-OF factor interactions\", \"high-resolution reconstructions PART-OF super-resolution\", \"super-resolution and recognition EVALUATE-FOR maximum likelihood identity parameter vector\", \"multi-modal super-resolution COMPARE standard tensorface and eigenface representations\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  54%|█████▍    | 272/500 [53:35<38:10, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach FEATURE-OF object category recognition\", \"datasets USED-FOR training images\", \"approach EVALUATE-FOR performance\", \"model FEATURE-OF TSI-pLSA\", \"pLSA COMPARE TSI-pLSA\", \"spatial information PART-OF TSI-pLSA\", \"intra-class variability FEATURE-OF images\", \"images USED-FOR search engines\", \"models EVALUATE-FOR performance\", \"methods COMPARE approach\", \"datasets COMPARE test sets\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  55%|█████▍    | 273/500 [53:45<38:20, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"technique FEATURE-OF robust estimation algorithm\", \"uncertainty FEATURE-OF estimation procedure\", \"solution FEATURE-OF non-randomness\", \"combination FEATURE-OF strategies\", \"algorithm EVALUATE-FOR speed-up\", \"algorithm EVALUATE-FOR RANSAC techniques\", \"algorithm EVALUATE-FOR samples\", \"algorithm EVALUATE-FOR standard RANSAC\", \"algorithm EVALUATE-FOR theoretical predictions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  55%|█████▍    | 274/500 [53:55<37:18,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method USED-FOR detecting 3D objects\", \"image and dense depth map FEATURE-OF object information\", \"representation of templates PART-OF method\", \"approach COMPARE state-of-the-art methods\", \"our approach EVALUATE-FOR significantly outperforms state-of-the-art methods\", \"it WORKS-IN real-time\", \"it can HANDLE untextured objects\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  55%|█████▌    | 275/500 [54:04<36:07,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"behaviours USED-FOR security domain\", \"behaviours HYPONYM-OF rare behaviours of interest\", \"training examples EVALUATE-FOR behaviours\", \"algorithm FEATURE-OF weakly supervised\", \"algorithm EVALUATE-FOR detection of abnormal behaviours\", \"context FEATURE-OF global context\", \"detection EVALUATE-FOR abnormal behaviours\", \"aspects CONJUNCTION pragmatic aspects\", \"parameter tuning EVALUATE-FOR pragmatic aspects\", \"performance EVALUATE-FOR real time performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  55%|█████▌    | 276/500 [54:15<37:43, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"our method FEATURE-OF subpixel accuracy\", \"gray-level band-pass white noise patterns FEATURE-OF robustness\", \"our method EVALUATE-FOR scene geometry recovery\", \"our method COMPARE mi-cro phase shifting\", \"our method COMPARE modulated phase shifting\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  55%|█████▌    | 277/500 [54:21<33:26,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"energy minimization strategy USED-FOR semantic video segmentation\", \"hierarchical abstraction PART-OF supervoxel graph\", \"energy minimization algorithm COMPARE graph cuts and belief propagation\", \"strategy strength speedups EVALUATE-FOR datasets with spatio-temporal continuity\", \"our strategy COREF existing hierarchical approaches\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  56%|█████▌    | 278/500 [54:29<31:33,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"functional objects FEATURE-OF people's trajectories\", \"functional objects USED-FOR satisfying certain needs\", \"Bayesian framework EVALUATE-FOR probabilistically model\", \"La-grangian mechanics USED-FOR extending\", \"people COREF particle-agents\", \"video footage COREF the video\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  56%|█████▌    | 279/500 [54:35<28:58,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"example image PART-OF its semantic components\", \"tiling GENERATED-FROM example image\", \"novel tilings CREATED-FROM example image\", \"facade textures GENERATED-FROM tilings\", \"occluded parts PART-OF facade textures\", \"genetic algorithm GUIDES novel facades\", \"genetic algorithm GUIDES inpainted parts\", \"novel facades CONSISTENT-WITH example\", \"inpainted parts CONSISTENT-WITH example\", \"method EVALUATE-FOR efficient creation of city models\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  56%|█████▌    | 280/500 [54:45<31:20,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"light fields FEATURE-OF image-based representations\", \"3D lines PART-OF ray space\", \"triangulation USED-FOR light field super-resolution\", \"light field space FEATURE-OF bilinear subspaces\", \"triangulation COMPARE direct triangulation\", \"bilinear subspaces HYPONYM-OF line constraints\", \"Constrained Delaunay Triangulation USED-FOR bilinear subspaces\", \"line constraints FEATURE-OF light field stereo matching\", \"our triangulation EVALUATE-FOR state-of-the-art solutions\", \"LAGC algorithm USED-FOR light field stereo matching\", \"our algorithms EVALUATE-FOR accuracy and visual quality\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  56%|█████▌    | 281/500 [54:59<36:43, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"techniques USED-FOR people counting\", \"data annotation FEATURE-OF model training\", \"informative frames FEATURE-OF annotation\", \"unlabelled data USED-FOR learning\", \"Labelled data USED-FOR data annotation\", \"ideas PART-OF unified active and semi-supervised regression framework\", \"ability EVALUATE-FOR transfer learning\", \"geometric structure FEATURE-OF crowd patterns\", \"manifold analysis USED-FOR exploiting geometric structure\", \"approach EVALUATE-FOR effectiveness\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  56%|█████▋    | 282/500 [55:09<36:28, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 282: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d6613f6be54376eb6f74a676d977f959 in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    In this paper, we propose a new approach to generate oriented object proposals (OOPs) to reduce the detection error caused by various orientations of the object. To this end, we propose to efficiently locate object regions according to pixelwise object probability, rather than measuring the objectness from a set of sampled windows. We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes (i.e., sizes and orientations) can be produced by locating the local maximum likelihoods. The new approach has three main advantages. First, it helps the object detector handle objects of different orientations. Second, as the shapes of the proposals may vary to fit the objects, the resulting proposals are tighter than the sampling windows with fixed sizes. Third, it avoids massive window sampling, and thereby reducing the number of proposals while maintaining a high recall. Experiments on the PASCAL VOC 2007 dataset show that the proposed OOP outperforms the state-of-the-art fast methods. Further experiments show that the rotation invariant property helps a class-specific object detector achieve better performance than the state-of-the-art proposal generation methods in either object rotation scenarios or general scenarios. Generating OOPs is very fast and takes only 0.5s per image.\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"object proposals PART-OF proposal generation problem\", \"object regions EVALUATE-FOR object detector\", \"object proposals FEATURE-OF generative probabilistic model\", \"object proposals HYPONYM-OF sampling windows\", \"object proposals USED-FOR object detection\", \"proposals PART-OF objects\", \"proposals COMPARE sampling windows\", \"proposals COMPARE fixed sizes\", \"proposals COMPARE massive window sampling\", \"proposals EVALUATE-FOR object detector\", \"proposals EVALUATE-FOR object rotation scenarios\", \"proposals EVALUATE-FOR general scenarios\", \"rotation invariant property FEATURE-OF class-specific object detector\", \"OOP USED-FOR object detection\", \"OOP OUTPERFORMS state-of-the-art fast methods\", \"PASCAL VOC 2007 dataset PART-OF experiments\", \"generating OOPs USED-FOR reducing detection error\", \"generating OOPs USED-FOR object orientation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  57%|█████▋    | 283/500 [56:12<1:33:34, 25.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Expected-IoU (EIoU) HYPONYM-OF Expected-Intersection-over-Expected-Union (EIoEU)\", \"new methods FEATURE-OF EIoEU approximation\", \"high quality candidate solutions FEATURE-OF new methods\", \"new approaches EVALUATE-FOR improved performance\", \"image segmentation tasks COREF both tasks\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  57%|█████▋    | 284/500 [56:20<1:13:43, 20.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Hough voting USED-FOR spatial verification\", \"adaptive dither voting USED-FOR robust spatial verification\", \"correspondence PART-OF multiple dithered transformations\", \"method EVALUATE-FOR losing correspondences\", \"method EVALUATE-FOR mismatches\", \"Hough histogram FEATURE-OF spatial similarity\", \"exploiting non-uniformity of Hough histogram FEATURE-OF spatial similarity\", \"method COMPARE state-of-the-art counterparts\", \"method COMPARE accuracy\", \"method COMPARE scalability\", \"retrieval of small, rotated objects COREF it\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  57%|█████▋    | 285/500 [56:33<1:05:53, 18.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"set of age-group specific dictionaries FEATURE-OF aging faces\", \"dictionary bases PART-OF aging process pattern\", \"linear combination USED-FOR personalized aging process\", \"personalized facial characteristics FEATURE-OF subject\", \"coupled reconstruction loss EVALUATE-FOR dictionary learning\", \"face pairs COMPARE neighboring age groups\", \"proposed solution COMPARE state-of-the-arts\", \"cross-age face verification EVALUATE-FOR synthesizing aging faces\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  57%|█████▋    | 286/500 [56:43<56:04, 15.72s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"camera relocation USED-FOR detection sensitivity and accuracy\", \"group of images FEATURE-OF observation\", \"fine-grained change detection HYPONYM-OF change detection\", \"camera geometry correction flow PART-OF joint optimization problem\", \"real scene change mask PART-OF joint optimization problem\", \"our approach COMPARE state-of-the-art change detection methods\", \"real scene changes COREF false ones caused by lighting variations\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  57%|█████▋    | 287/500 [56:53<49:55, 14.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Ant-Q algorithms COMPARE Q-learning\", \"Ant-Q algorithms USED-FOR TSP solution\", \"AS HYPONYM-OF Ant-Q family\", \"Ant-Q family PART-OF AS\", \"results EVALUATE-FOR entity quality\", \"neural networks COMPARE Ant-Q algorithms\", \"local search COMPARE Ant-Q algorithms\", \"Ant-Q algorithms USED-FOR asymmetric TSP solution\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  58%|█████▊    | 288/500 [57:02<44:05, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"agent learns action models USED-FOR planning systems\", \"agent learns action models FROM own experience\", \"agent learns action models FROM observation of domain expert\", \"action model formalism FEATURE-OF re-active agent\", \"noise-handling mechanisms FEATURE-OF successful implementation\", \"Training instances GENERATED-FROM experience\", \"Training instances GENERATED-FROM observation\", \"GOLEM USED-FOR learn action models\", \"learning system EVALUATE-FOR simulated construction domains\", \"learning system EVALUATE-FOR simulated ooce domains\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  58%|█████▊    | 289/500 [57:13<42:36, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"boosting methods FEATURE-OF classifiers\", \"Schapire et al. COREF they\", \"phenomenon EVALUATE-FOR overfitting\", \"margins theory COMPARE base-classifier complexity\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  58%|█████▊    | 290/500 [57:18<35:34, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"multiclass Perceptron USED-FOR multiclass categorization\", \"unique hypothesis FEATURE-OF class\", \"single common hypothesis FEATURE-OF all classes\", \"number of classes EVALUATE-FOR online learning process\", \"our approach COMPARE previous methods\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  58%|█████▊    | 291/500 [57:25<31:58,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"learning to predict moves FEATURE-OF board game of Go\", \"probability distribution USED-FOR stand-alone Go player, move selector, move sorter, training tool for Go players\", \"pattern extraction scheme USED-FOR harvesting patterns from expert game records\", \"Bayesian learning algorithm USED-FOR learning a distribution over the values of a move given a board position\", \"system TRAINED-ON 181,000 expert games\", \"prediction performance EVALUATE-FOR ability to perfectly predict the moves made by professional Go players in 34% of test positions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  58%|█████▊    | 292/500 [57:36<33:02,  9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"model-based policy search approach USED-FOR reinforcement learning\", \"algorithm returns policy that works in simulation but not in real-life COMPARE model-free RL\", \"hybrid algorithm EVALUATE-FOR near-optimal performance\", \"approximate model USED-FOR hybrid algorithm\", \"real-life trials USED-FOR hybrid algorithm\", \"policy evaluations PART-OF hybrid algorithm\", \"approximate model SUGGEST local changes\", \"algorithm achieves near-optimal performance EVALUATE-FOR real system\", \"model HYPONYM-OF Markov decision process\", \"real-life trials EVALUATE-FOR near-optimal performance\", \"crude model USED-FOR algorithm\", \"small number of real-life trials USED-FOR algorithm\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  59%|█████▊    | 293/500 [57:50<37:32, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"sampling probabilities EVALUATE-FOR records\", \"loss COMPARE inverse proportional to regressed-to values\", \"regularization FEATURE-OF Empirical Risk Minimization algorithm\", \"uniform sampling COMPARE standard stratified sampling\", \"hard budget constraints PART-OF cost zero solution\", \"this problem HYPONYM-OF specialized regression problem\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  59%|█████▉    | 294/500 [57:58<34:11,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"robust PCA FEATURE-OF machine learning applications\", \"low rank matrix PART-OF data matrix\", \"side information EVALUATE-FOR robust PCA\", \"prior structure FEATURE-OF entities\", \"features FEATURE-OF entities\", \"proposed method COMPARE standard robust PCA\", \"low rank matrices COMPARE standard robust PCA\", \"our method COMPARE standard robust PCA\", \"features EVALUATE-FOR robust PCA\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  59%|█████▉    | 295/500 [58:07<33:09,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"object category recognition USED-FOR deep learning methods\", \"object pose estimation FEATURE-OF object representation\", \"CNN architectures USED-FOR object recognition and pose estimation task\", \"layers of distributed representations PART-OF CNNs\", \"object pose information COMPARE object category representations\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  59%|█████▉    | 296/500 [58:12<28:49,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"our method FEATURE-OF limited-memory stochastic block BFGS update\", \"inverse Hessian matrix FEATURE-OF estimate\", \"estimate USED-FOR inverse Hessian matrix\", \"sketch FEATURE-OF Hessian\", \"quasi-Newton method FEATURE-OF stochastic block BFGS updates\", \"stochastic block BFGS updates USED-FOR stochastic approximation methods\", \"SVRG EVALUATE-FOR batch stochastic gradients\", \"our method COMPARE current state-of-the-art methods\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  59%|█████▉    | 297/500 [58:28<35:52, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"perceptual sound organization FEATURE-OF scene analysis problem\", \"model CONSISTS-OF processing modules\", \"model CONSISTS-OF hypothesis network\", \"processing module RISES-TO input information\", \"module WRITES output information\", \"information INTEGRATED hypothesis network\", \"model CONSTRUCTED internal model of perceptual sounds\", \"music scene analysis system DEVELOPED acoustic signals\", \"system RECOGNIZES rhythm\", \"system RECOGNIZES chords\", \"system RECOGNIZES source-separated musical notes\", \"experimental results SHOW method has permitted autonomous, stable and effective information integration\", \"information INTEGRATION CONJUNCTION construction of internal model\", \"perceptual sounds COREF it\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  60%|█████▉    | 298/500 [58:42<39:32, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm MINPATH USED-FOR wireless web navigation\", \"MINPATH models FEATURE-OF predictive models\", \"shortcut links PART-OF deep link structures\", \"MINPATH EVALUATE-FOR navigational effort\", \"Naive Bayes mixture models COMPARE mixtures of Markov models\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  60%|█████▉    | 299/500 [58:50<35:19, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm USED-FOR three dimensional container packing problem\", \"new algorithm COMPARE traditional approach\", \"new algorithm EVALUATE-FOR average packing utilization\", \"results COMPARE results reported in literature\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  60%|██████    | 300/500 [58:55<29:44,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"KANAL USED-FOR authoring and checking process models\", \"KANAL FEATURE-OF system\", \"KANAL PART-OF interdependency models\", \"process models EVALUATE-FOR errors\", \"interdependency models EVALUATE-FOR finding errors and proposing fixes\", \"pieces of information COMPARE pieces of input\", \"KANAL COREF our system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  60%|██████    | 301/500 [59:02<27:51,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"DLs combine knowledge representation on an abstract, logical level with an interface to 'concrete' domains such as numbers and strings\", \"DLs extend with key constraints\", \"US citizens uniquely identified by their social security number EVALUATE-FOR expression\", \"natural DLs introduced\", \"un)decidability results presented\", \"NEx-PTlME complexity bounds tight\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  60%|██████    | 302/500 [59:12<28:41,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"conjugate priors FEATURE-OF Bayesian machine learning\", \"conjugate priors COMPARE Bregman divergence\", \"hyperparameters EVALUATE-FOR effective sample points\", \"generative and discriminative components PART-OF hybrid model\", \"semi-supervised learning USED-FOR hybrid model\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  61%|██████    | 303/500 [59:20<27:43,  8.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"training USED-FOR document classification\", \"training methods FEATURE-OF linear classification\", \"data PART-OF computer memory\", \"data PART-OF disk\", \"block minimization framework USED-FOR data larger than memory size\", \"block minimization framework EVALUATE-FOR primal and dual SVMs\", \"design considerations COMPARE traditional algorithms\", \"data sets COMPARE memory\", \"proposed method EVALUATE-FOR effectiveness\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  61%|██████    | 304/500 [59:30<29:13,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Interval Algebra (IA) FEATURE-OF qualitative temporal relations\", \"Region Connection Calculus (RCC)-8 FEATURE-OF topological relations\", \"Qualitative Constraint Network (QCN) PART-OF MLP\", \"chordal QCNs FEATURE-OF feasible base relations\", \"partial consistency EVALUATE-FOR feasible base relations\", \"patchwork property FEATURE-OF tractable subclasses of relations\", \"IA COMPARE RCC-8\", \"QCNs COMPARE MLP\", \"proposed algorithm COMPARE previous approaches\", \"experimentations COREF this new approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  61%|██████    | 305/500 [59:42<32:51, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  61%|██████    | 306/500 [59:44<24:12,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"constraint propagation FEATURE-OF constraint programming\", \"short supports USED-FOR inferring support for variables and values\", \"SHORTSTR2 COMPARE SHORTGAC and HAGGISGAC\", \"constraint USED-FOR short supports\", \"SHORTSTR2 PART-OF Simple Tabular Reduction algorithm\", \"short support set COMPARE full-length support set\", \"SHORTSTR2 USED-FOR propagating many constraints\", \"algorithm EVALUATE-FOR identifying short supports from full-length supports\", \"SHORTSTR2 COMPARE STR2+\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  61%|██████▏   | 307/500 [59:56<28:23,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"hash-tag recommendation task FEATURE-OF microblogs\", \"CNNs USED-FOR hashtag recommendation problem\", \"trigger words EVALUATE-FOR effectiveness\", \"proposed model COMPARE state-of-the-art methods\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  62%|██████▏   | 308/500 [1:00:01<24:54,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"government auction OFF spectrum FROM public safety network HYPONYM-OF auction domains\", \"combinatorial auctions perform poorly EVALUATE-FOR violations of individual rationality\", \"combinatorial auctions perform poorly EVALUATE-FOR low efficiency\", \"design of core-selecting payment rules FEATURE-OF new domain\", \"payment rule does not exist in new domain COMPARE ex-post core-selecting\", \"designing rules that are execution-contingent USED-FOR reducing IR violations\", \"charging payments CONDITIONED-ON realization of availability of goods USED-FOR reducing IR violations\", \"design two core-selecting rules FEATURE-OF reducing IR violations\", \"perform computational Bayes-Nash equilibrium analysis USED-FOR studying performance of rules\", \"new rules have better incentives COMPARE standard core-selecting rules\", \"new rules have higher efficiency COMPARE standard core-selecting rules\", \"new rules have lower rate of ex-post IR violations COMPARE standard core-selecting rules\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  62%|██████▏   | 309/500 [1:00:19<34:11, 10.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Coupled Marginalized Denoising Auto-encoders framework USED-FOR cross-domain learning\", \"domain divergence PART-OF cross-domain learning\", \"intermediate domain FEATURE-OF Coupled Marginalized Denoising Auto-encoders framework\", \"feature mapping USED-FOR transfer knowledge\", \"maximum margin criterion EVALUATE-FOR discriminative features\", \"state-of-the-art methods COMPARE our method\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  62%|██████▏   | 310/500 [1:00:28<32:08, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"video frame PART-OF video\", \"adjacent frames HYPONYM-OF local temporal relationship\", \"deep representations FEATURE-OF adjacent frames\", \"graph structure FEATURE-OF video\", \"inherent correlations FEATURE-OF video frames\", \"our approach EVALUATE-FOR video recognition tasks\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  62%|██████▏   | 311/500 [1:00:34<28:34,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Maximum Entropy Model USED-FOR automatic image annotation\", \"visual vocabulary PART-OF image content\", \"blob-tokens FEATURE-OF visual vocabulary\", \"statistical relationship MODELED-BY Maximum Entropy Model\", \"blob-tokens COMPARE traditional annotation methods\", \"Maximum Entropy Model EVALUATE-FOR annotation performance\", \"this method COREF Maximum Entropy Model\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  62%|██████▏   | 312/500 [1:00:43<28:11,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"WSJ data USED-FOR train recognizer\", \"recognizer ADAPTED-EVALUATED-IN Phonebook domain\", \"two corpora DIFFER-IN microphone vs. telephone channel, continuous speech vs. isolated words, mismatch IN speaking rate\", \"adaptation data NECESSARY-TO achieve reasonable recognition performance\", \"out-of-domain training data USED-TO improve recognition performance of Phonebook-trained baseline acoustic model\", \"adaptation and normalization techniques USED-TO bridge the mismatch between two corpora\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  63%|██████▎   | 313/500 [1:00:54<30:19,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"N-gram models FEATURE-OF statistical language modeling\", \"neural network COMPARE standard statistical methods\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  63%|██████▎   | 314/500 [1:00:57<23:52,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"multimodal dialog system FEATURE-OF SmartKom\", \"speech input USED-FOR spontaneous speech understanding\", \"gesture input USED-FOR video-based recognition of natural gestures\", \"computational methods USED-FOR seamless integration and mutual disambiguation of multimodal input and output\", \"dialog paradigm FEATURE-OF SmartKom\", \"user DELEGATE-TASK-TO virtual communication assistant\", \"virtual communication assistant VISUALIZED-AS lifelike character\", \"XML-based markup language USED-FOR multimodal content\", \"SmartKom demonstrator PART-OF SmartKom architecture\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  63%|██████▎   | 315/500 [1:01:09<27:25,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"speaker verification system USED-FOR access control\", \"access control PART-OF test implementation\", \"user evaluation EVALUATE-FOR system\", \"speech data PART-OF data base\", \"data base USED-FOR simulation experiments\", \"Hidden Markov Models FEATURE-OF recent experiments\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  63%|██████▎   | 316/500 [1:01:16<25:32,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"proposed algorithm FEATURE-OF statistical model\", \"algorithm USED-FOR estimation of reverberation times\", \"speech utterance PART-OF reverberant room\", \"estimation method EVALUATE-FOR robust automatic speech recognition\", \"reverberation time USED-FOR model selection\", \"acoustic model PART-OF library of models\", \"library of models COMPARE standard channel normalization techniques\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  63%|██████▎   | 317/500 [1:01:24<25:18,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"language model FEATURE-OF word list\", \"raw corpus PART-OF segmented corpus\", \"annotator EVALUATE-FOR productivity\", \"word HYPONYM-OF correction unit\", \"method COMPARE sentence-by-sentence error correction method\", \"method USED-FOR capturing statistical behavior\", \"segmented corpus COMPARE language models\", \"our method USED-FOR speech recognition accuracies\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  64%|██████▎   | 318/500 [1:01:33<25:25,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 318: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 99033fbb7cd25a8035070a595993eb22 in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    We investigated whether automatic phonetic transcriptions (APTs) can replace manually verified phonetic transcriptions (MPTs) in a large corpus-based study on pronunciation variation. To this end, we compared the performance of both transcription types in a classification experiment aimed at establishing the direct influence of a particular situational setting on pronunciation variation. We trained classifiers on the speech processes extracted from the alignments of an APT and an MPT with a canonical transcription. We tested whether the classifiers were equally good at verifying whether unknown transcriptions represent read speech or telephone dialogues, and whether the same speech processes were identified to distinguish between transcriptions of the two situational settings. Our results not only show that similar distinguishing speech processes were identified; our APT-based classifier yielded better classification accuracy than the MPT-based classifier whilst using fewer classification features.\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"automatic phonetic transcriptions USED-FOR manually verified phonetic transcriptions\", \"classifiers trained on speech processes FEATURE-OF alignments\", \"canonical transcription PART-OF speech processes\", \"classifiers EVALUATE-FOR verification of unknown transcriptions\", \"read speech COMPARE telephone dialogues\", \"speech processes IDENTIFY transcriptions of situational settings\", \"APT-based classifier COMPARE MPT-based classifier\", \"APT-based classifier EVALUATE-FOR classification accuracy\", \"APT-based classifier EVALUATE-FOR fewer classification features\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  64%|██████▍   | 319/500 [1:02:18<58:45, 19.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"PASCAL challenge ORGANIZED TO design algorithm\", \"algorithm SEGMENTS words\", \"words SMALLEST meaning-bearing units\", \"units SUITABLE FOR tasks\", \"tasks SUCH AS speech understanding, text understanding, machine translation, information retrieval, statistical language modeling\", \"research groups PARTICIPATED IN challenge\", \"groups SUBMITTED segmentation results\", \"segmentation results OBTAINED BY algorithms\", \"application OF segmentation algorithms TO speech recognition\", \"language models BASED ON word segments\", \"experiments DONE FOR Finnish and Turkish\", \"segmentations COMBINED TO improve performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  64%|██████▍   | 320/500 [1:02:31<52:39, 17.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"N-best candidates USED-FOR system performance\", \"incorporation USED-FOR system performance\", \"contextual information USED-FOR system performance\", \"system FEATURE-OF dialogue management\", \"selection FEATURE-OF optimization\", \"minimization of Bayes risk EVALUATE-FOR optimization\", \"reward EVALUATE-FOR optimization\", \"penalty EVALUATE-FOR optimization\", \"spoken dialogue system COREF Dialogue Navigator for Kyoto City\", \"question-answering capability FEATURE-OF Dialogue Navigator for Kyoto City\", \"proposed framework FEATURE-OF effectiveness\", \"success rate EVALUATE-FOR proposed framework\", \"average number of turns EVALUATE-FOR information access\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  64%|██████▍   | 321/500 [1:02:47<50:49, 17.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 321: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 599058f5f606da68017f07f5549e9f12 in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    Conventional HMMs have weak duration constraints. In noisy conditions, the mismatch between corrupted speech signals and models trained on clean speech may cause the decoder to produce word matches with unrealistic durations. This paper presents a simple way to incorporate word duration constraints by unrolling HMMs to form a lattice where word duration probabilities can be applied directly to state transitions. The expanded HMMs are compatible with conventional Viterbi decoding. Experiments on connected-digit recognition show that when using explicit duration constraints the decoder generates word matches with more reasonable durations, and word error rates are significantly reduced across a broad range of noise conditions .\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"HMMs PART-OF conventional Viterbi decoding\", \"word duration constraints FEATURE-OF state transitions\", \"decoder EVALUATE-FOR word matches\", \"word error rates EVALUATE-FOR noise conditions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  64%|██████▍   | 322/500 [1:04:05<1:45:07, 35.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"recognition process PART-OF ELVIRCOS\", \"approach USED-FOR large vocabulary speech recognition\", \"word graph composition FEATURE-OF continuous speech recognition\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  65%|██████▍   | 323/500 [1:04:10<1:16:57, 26.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"HMM-based TTS system USED-FOR German speech\", \"results COMPARE over three different choices of context features\", \"system ADAPT-TO football announcements\", \"expressivity PARTIALLY-CAPTURED football dataset\", \"HMMs ABLE-TO produce highly intelligible neutral German speech\", \"quality STABLE\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  65%|██████▍   | 324/500 [1:04:17<59:33, 20.30s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"information extraction annotations FEATURE-OF document retrieval\", \"distillation queries USED-FOR annotation elements\", \"ACE events USED-FOR constrain document set\", \"information retrieval engine EVALUATE-FOR precision\", \"ACE events EVALUATE-FOR precision\", \"distillation queries COREF annotation elements\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  65%|██████▌   | 325/500 [1:04:24<47:35, 16.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"IEMOCAP database USED-FOR emotional assessments\", \"self-assessments EVALUATE-FOR intended emotions\", \"speakers COMPARE naÂ¨Ä±ve listeners\", \"expression PART-OF speech communication\", \"perception PART-OF emotion\", \"speakers EVALUATE-FOR specific emotional categories\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  65%|██████▌   | 326/500 [1:04:31<39:23, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Czech talking head system USED-FOR visual speech animation\", \"3D animation model FEATURE-OF pseudo-muscular animation schema\", \"animation schema FEATURE-OF visual speech animation\", \"lip area PART-OF visual speech\", \"labial coarticulation effects HYPONYM-OF forming articulatory trajectories\", \"articulatory targets COMPARE interpolation technique\", \"it EVALUATE-FOR synthesis method\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  65%|██████▌   | 327/500 [1:04:43<37:58, 13.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"inner hair cell synapse PART-OF pool models\", \"OA model FEATURE-OF phase locking\", \"OA model USED-FOR ANF-based features\", \"OA model USED-FOR ON-based auditory features\", \"GMMs COMPARE MLPs\", \"MSG auditory features COMPARE ANF-based features\", \"AN COREF ANF\", \"ON COREF onset neurons\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  66%|██████▌   | 328/500 [1:04:52<33:47, 11.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"model EVALUATE-FOR sparse selectional preferences\", \"data LABEL-FOR hand-crafted rules\", \"Bayesian inference COMBINE rules\", \"English newspaper texts COREF Czech newspaper texts\", \"English newspaper texts COMPARE French broadcast news transcriptions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  66%|██████▌   | 329/500 [1:04:57<28:29, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SMT-style stochastic transduction grammar USED-FOR hip hop lyrics\", \"challenge-response system EVALUATE-FOR rhyming lyrics\", \"approach FEATURE-OF hip hop lyrics domain\", \"model COMPARE phrase-based SMT models\", \"it COREF approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  66%|██████▌   | 330/500 [1:05:05<26:15,  9.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"real-time VC USED-FOR silent speech enhancement\", \"silent speech interface FOCUS-OF non-audible murmur\", \"electrolaryngeal speech PART-OF alaryngeal speech\", \"VC PROMISING-APPROACH address lack of naturalness\", \"real-time VC IMPLEMENTATION-OF DSP\", \"NAM to whispered voice CONVERSION-OF speech enhancement system\", \"electrolaryngeal speech to natural voice CONVERSION-OF speech enhancement system\", \"computational cost REDUCED-FOR preserving conversion accuracy\", \"real-time VC CAPABLE-OF running on DSP\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  66%|██████▌   | 331/500 [1:05:18<29:08, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"multilingual feature-level data sharing FEATURE-OF Deep Neural Network\", \"DNN stacked bottleneck features PART-OF multilingual feature-level data sharing\", \"language identification USED-FOR efficient use of multilingual resources\", \"source languages COMPARE target language\", \"bottleneck features trained on most similar source language EVALUATE-FOR better performance\", \"data similar to target language USED-FOR multilingual training\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  66%|██████▋   | 332/500 [1:05:26<27:19,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"singing voice conversion USED-FOR convert singing voice characteristics\", \"source singer COREF source singer\", \"target singer COREF target singer\", \"speech quality EVALUATE-FOR converted singing voice\", \"analysis errors COMPARE modeling errors\", \"differential spectral feature FEATURE-OF differential Gaussian mixture model\", \"conversion model PART-OF conventional SVC\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  67%|██████▋   | 333/500 [1:05:34<25:19,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"i-vector challenge USED-FOR participants from outside the audio processing field\", \"i-vectors FEATURE-OF fixed-length feature vectors\", \"i-vector challenge COMPARE SRE series\", \"number of participants COMPARE number of systems submitted for evaluation\", \"leading system EVALUATE-FOR approximate 37% improvement relative to baseline system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  67%|██████▋   | 334/500 [1:05:43<24:54,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Fujisaki-model parameters FEATURE-OF sequence\", \"model FEATURE-OF algorithm\", \"model USED-FOR estimating Fujisaki-model parameters\", \"model PART-OF statistical learning\", \"present model FEATURE-OF parameter training algorithm\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  67%|██████▋   | 335/500 [1:05:48<22:08,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Neural Network classifier FEATURE-OF SAE structure\", \"ASR system USED-FOR error detection\", \"positive examples EVALUATE-FOR training a binary classifier\", \"classifiers COMPARE different types\", \"SAE classifier EVALUATE-FOR ASR error detection\", \"performance EVALUATE-FOR each investigated classifier\", \"receiving operating curve COMPARE mean absolute error\", \"classifier based on SAE COMPARE other classification methods\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  67%|██████▋   | 336/500 [1:05:57<22:23,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"text data USED-FOR Automatic Speech Recognition\", \"text data USED-FOR Keyword Search\", \"blogs FEATURE-OF language models\", \"movie subtitles FEATURE-OF language models\", \"web data EVALUATE-FOR Term Error Rate Performance\", \"web data EVALUATE-FOR Maximum Term-Weighted Value in Keyword Search\", \"out-of-vocabulary items PART-OF reductions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  67%|██████▋   | 337/500 [1:06:04<21:25,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"probabilistic parser USED-FOR candidate parses\", \"probabilities FEATURE-OF candidate parses\", \"model USED-FOR reranking task\", \"tree FEATURE-OF features\", \"reranking task FEATURE-OF parsing\", \"Wall Street Journal treebank FEATURE-OF parsing\", \"log-likelihood FEATURE-OF baseline model\", \"features FEATURE-OF parse trees\", \"model EVALUATE-FOR F-measure\", \"baseline model COMPARE new model\", \"algorithm FEATURE-OF boosting approach\", \"feature selection methods COMPARE boosting approach\", \"NLP COMPARE speech recognition\", \"NLP COMPARE machine translation\", \"NLP COMPARE natural language generation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  68%|██████▊   | 338/500 [1:06:17<25:06,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method FEATURE-OF discovering parallel sentences\", \"maximum entropy classifier USED-FOR determining translations\", \"parallel data PART-OF Chinese, Arabic, and English non-parallel newspaper corpora\", \"quality EVALUATE-FOR performance of a state-of-the-art statistical machine translation system\", \"MT system USED-FOR building from scratch\", \"parallel corpus PART-OF MT system\", \"non-parallel corpus USED-FOR building MT system\", \"language pairs EVALUATE-FOR scarce resources\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  68%|██████▊   | 339/500 [1:06:27<25:34,  9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Fragment-and-Compose paradigm USED-FOR creating natural language text\", \"KDS FEATURE-OF Fragment-and-Compose paradigm\", \"propositional units PART-OF knowledge to be expressed in text\", \"text FEATURE-OF propositional units\", \"KDS PART-OF distinct parts\", \"propositional units PART-OF combinations of units\", \"combinations of units EVALUATE-FOR potential sentences\", \"combinations of units COMPARE competing combinations\", \"final text FEATURE-OF best among competing combinations\", \"computational methods FEATURE-OF KDS\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  68%|██████▊   | 340/500 [1:06:38<26:35,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"natural language question answering system FEATURE-OF Chat-80\", \"Chat-80 USED-FOR variety of applications\", \"Prolog FEATURE-OF programming language\", \"extraposition grammars FEATURE-OF logic-based grammar formalism\", \"English questions FEATURE-OF logical expression\", \"logical expression USED-FOR planning algorithm\", \"planning algorithm USED-FOR query optimization\", \"Prolog form USED-FOR answer\", \"relational database FEATURE-OF query optimization\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  68%|██████▊   | 341/500 [1:06:48<26:25,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"error correction DONE-BY parsing\", \"dialogue patterns USED-FOR predict new inputs\", \"parsing BIASED-TOWARD expected meanings\", \"dialogue acquisition algorithm FEATURE-OF voice interactive system\", \"implementation PART-OF voice interactive system\", \"error correction methodology POWER-OF stereotypic dialogue\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  68%|██████▊   | 342/500 [1:06:54<23:42,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"linguistic structure PART-OF discourse\", \"intentional structure FEATURE-OF linguistic segments\", \"attentional state FEATURE-OF focus of attention\", \"discourse-relevant purposes FEATURE-OF linguistic segments\", \"relationships among intentions FEATURE-OF intentional structure\", \"cue phrases FEATURE-OF discourse phenomena\", \"referring expressions FEATURE-OF discourse phenomena\", \"interruptions FEATURE-OF discourse phenomena\", \"theory COREF framework\", \"discourse processing EVALUATE-FOR recognizing intentions and relationships among intentions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  69%|██████▊   | 343/500 [1:07:05<24:40,  9.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"speaker COREF listener\", \"speaker COREF utterance\", \"listener COREF speaker\", \"reference failures FEATURE-OF miscommunication\", \"miscommunications PART-OF communication\", \"miscommunications PART-OF miscommunication\", \"reference problems FEATURE-OF miscommunication\", \"speaker USED-FOR utterance\", \"utterance EVALUATE-FOR task\", \"utterance EVALUATE-FOR conversational vehicle\", \"extensional reference HYPONYM-OF reference\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  69%|██████▉   | 344/500 [1:07:14<24:13,  9.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"grammatical number FEATURE-OF nouns\", \"grammatical number FEATURE-OF reflexive pronouns\", \"grammatical number COMPARE grammatical gender\", \"Interchange Lemma USED-FOR formal proof\", \"respectively CONJUNCTION coordinate phrases\", \"conjuncts PART-OF coordinate phrases\", \"arguments EVALUATE-FOR constructions with unequal numbers of conjuncts\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  69%|██████▉   | 345/500 [1:07:22<22:52,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"dictionary word sense definitions FEATURE-OF phrasal patterns\", \"experimental system USED-FOR processing definitions\", \"restricted vocabulary FEATURE-OF word sense definitions\", \"classification EVALUATE-FOR new word senses\", \"senses PART-OF words\", \"phrasal analysis rules PART-OF analysis process\", \"patterns HYPONYM-OF phrasal analysis rules\", \"incomplete analyses FEATURE-OF definitions\", \"robust analysis mechanism FEATURE-OF analysis process\", \"robustness problems EVALUATE-FOR natural language processing systems\", \"incomplete lexicon COMPARE incomplete knowledge of phrasal constructions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  69%|██████▉   | 346/500 [1:07:33<24:48,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"intelligent interactive systems COREF humans\", \"user modeling USED-FOR intelligent interactive systems\", \"user model FEATURE-OF types of information\", \"user model PART-OF user\", \"user model PART-OF user modeling\", \"user model PART-OF user modeling component\", \"user modeling EVALUATE-FOR benefits and costs\", \"user modeling COMPARE current state of research\", \"user modeling COMPARE future research topics\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  69%|██████▉   | 347/500 [1:07:43<24:30,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"model CHARACTERIZE class of languages\", \"reduplication ADD-TO context-free languages\", \"model AUGMENTED-WITH ability to check reduplication\", \"pushdown automaton AUGMENTED-WITH ability to check reduplication\", \"class of languages STRICTLY-BETWEEN context-free languages and indexed languages\", \"reduplications OBSERVED-TO-OCCUR in natural languages\", \"formal models PERMITTED unnatural constructions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  70%|██████▉   | 348/500 [1:07:52<24:06,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"editor USED-FOR dictionary\", \"lexicologists EVALUATE-FOR dictionary\", \"linguistic theory FEATURE-OF dictionary\", \"lexicons USED-FOR natural language processing\", \"grammars USED-FOR natural language processing\", \"linguistic databases FEATURE-OF natural language processing\", \"coherence rules PART-OF editor\", \"lexical entries PART-OF editor\", \"interface FEATURE-OF editor\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  70%|██████▉   | 349/500 [1:08:01<23:47,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"explanation system USED-FOR selecting information, organizing information, realizing discourse plans\", \"discourse plans FEATURE-OF explanation system\", \"explanation generation FEATURE-OF knowledge bases\", \"robust explanation system FEATURE-OF explanation generation\", \"multi-sentential explanations FEATURE-OF robust explanation system\", \"multi-paragraph explanations FEATURE-OF robust explanation system\", \"large-scale knowledge base PART-OF explanation system\", \"evaluation methodology FEATURE-OF explanation system\", \"performance EVALUATE-FOR assessment methodology\", \"performance COMPARE domain experts' performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  70%|███████   | 350/500 [1:08:13<25:35, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Prague Dependency Treebank FEATURE-OF syntactically motivated relations\", \"Penn Discourse Treebank FEATURE-OF syntactically motivated relations\", \"Prague Dependency Treebank PART-OF sentence-boundary-crossing representation\", \"Prague Dependency Treebank USED-FOR discourse level annotation\", \"Praguian dependency-based approach COMPARE Penn discourse annotation\", \"discourse connectives FEATURE-OF Penn discourse annotation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  70%|███████   | 351/500 [1:08:23<24:49, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"unsupervised automatic acquisition FEATURE-OF Italian and English verb subcategorization frames\", \"proposed technique USED-FOR syntactically shallow-parsed corpora\", \"search heuristics FEATURE-OF limited number\", \"lexico-syntactic knowledge FEATURE-OF SCFs\", \"reported results COMPARE state-of-the-art lexical acquisition systems\", \"verbs sharing similar SCFs distributions COMPARE similar semantic properties\", \"verbs COREF frames\", \"Minimum Description Length Principle USED-FOR clustering verbs with the same distribution\", \"Italian verbs EVALUATE-FOR encouraging results\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  70%|███████   | 352/500 [1:08:34<25:22, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"hypotheses graph PART-OF translation hypotheses\", \"nodes FEATURE-OF vectors\", \"vectors FEATURE-OF morpho-syntactic properties\", \"feature functions FEATURE-OF vector components\", \"feature functions EVALUATE-FOR best M translation paths\", \"CMU toolkit COMPARE SRI toolkit\", \"word-lemma based feature function models COMPARE token-based models\", \"PoS-tag feature function FEATURE-OF word-lemma model\", \"weights USED-FOR lexical translations\", \"training material COMPARE texts\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  71%|███████   | 353/500 [1:08:44<25:04, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"term extraction BASED-ON delimiters\", \"term candidates EXTRACTED-BY existing techniques\", \"features LEAD-TO conflicts\", \"proposed approach NOT-SENSITIVE-TO term frequency\", \"proposed approach APPLIED-TO different domains\", \"proposed approach USEFUL-FOR resource-limited domains\", \"evaluations SHOW improvements OVER existing techniques\", \"proposed approach EFFECTIVE-TOOL for domain lexicon expansion\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  71%|███████   | 354/500 [1:08:54<24:28, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"computer-assisted acquisition USED-FOR morpho-syntactic description\", \"verb-noun collocations FEATURE-OF SyntLex\", \"dictionary-based acquisition USED-FOR collocation lexicon\", \"corpus-based lexicon enlargement USED-FOR collocation description\", \"corpus-based approach USED-FOR triple size\", \"verb-noun collocation dictionary PART-OF SyntLex Dictionary of Collocations\", \"future research COREF separate project continuation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  71%|███████   | 355/500 [1:09:04<24:16, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"MWEs PART-OF lexical units\", \"MWEs FEATURE-OF domains\", \"MWEs COMPARE corpus data\", \"MWEs EVALUATE-FOR tagging and lemmatization\", \"Word Sketch Engine USED-FOR statistical parameters\", \"database USED-FOR tagging and lemmatization\", \"MWEs EVALUATE-FOR tagging and lemmatization\", \"MWEs COREF them\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  71%|███████   | 356/500 [1:09:12<22:56,  9.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"PAKTUS PART-OF tools\", \"core English lexicon PART-OF PAKTUS\", \"grammar PART-OF PAKTUS\", \"concept representations PART-OF PAKTUS\", \"PAKTUS USED-FOR building NLP systems\", \"NLP system USED-FOR generating input to knowledge based systems or data base systems\", \"electronic message stream FEATURE-OF input to NLP system\", \"JINTACCS messages HYPONYM-OF sublanguage\", \"RAINFORM messages HYPONYM-OF sublanguage\", \"news reports HYPONYM-OF sublanguage\", \"sublanguage FEATURE-OF domain-specific grammar\", \"domain-specific grammar FEATURE-OF PAKTUS adaptation\", \"words FEATURE-OF PAKTUS adaptation\", \"conceptual mappings FEATURE-OF PAKTUS adaptation\", \"discourse patterns FEATURE-OF PAKTUS adaptation\", \"system EVALUATE-FOR processing relatively long discourses\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  71%|███████▏  | 357/500 [1:09:29<28:13, 11.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SPoT FEATURE-OF sentence planner\", \"SPG FEATURE-OF sentence plans\", \"SPR FEATURE-OF ranking rules\", \"SPR EVALUATE-FOR sentence plan selection\", \"human judges EVALUATE-FOR SPR training data\", \"sentence planning PART-OF text planning\", \"sentence scoping PART-OF sentence planning\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  72%|███████▏  | 358/500 [1:09:37<24:54, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"utterance classification FEATURE-OF acoustic models\", \"classifiers FEATURE-OF utterance classification performance\", \"word-trigram recognition COMPARE manual transcription\", \"unsupervised training USED-FOR phone n-gram model\", \"phone n-gram model FEATURE-OF recognition\", \"phone-string classifier USED-FOR recognition\", \"method EVALUATE-FOR classification accuracy\", \"spoken language system domains PART-OF evaluation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  72%|███████▏  | 359/500 [1:09:45<23:28,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ensemble methods FEATURE-OF machine learning\", \"multi-strategy approach USED-FOR question answering\", \"multi-source approach USED-FOR question answering\", \"answering agents PART-OF multi-level answer resolution algorithm\", \"knowledge-based mechanisms FEATURE-OF answering agents\", \"statistical techniques FEATURE-OF answering agents\", \"multi-level answer resolution algorithm FEATURE-OF answer resolution algorithm\", \"answer resolution algorithm EVALUATE-FOR questions correctly answered\", \"answer resolution algorithm EVALUATE-FOR average precision metric\", \"baseline system COMPARE answer resolution algorithm\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  72%|███████▏  | 360/500 [1:09:56<23:59, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ONTOSCORE FEATURE-OF system\", \"ONTOSCORE USED-FOR scoring sets of concepts\", \"ONTOSCORE USED-FOR scoring SRH\", \"semantic coherence EVALUATE-FOR speech recognition hypotheses\", \"annotation experiment PART-OF ONTOSCORE\", \"human annotators COREF annotators\", \"speech recognition hypotheses PART-OF annotated data\", \"73.2% COMPARE baseline\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  72%|███████▏  | 361/500 [1:10:04<22:05,  9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 361: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3fa0b58c8bfdd64416ddb75d9efade5a in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "     We propose a new  phrase-based translation model  and  decoding algorithm  that enables us to evaluate and compare several, previously proposed  phrase-based translation models  . Within our framework, we carry out a large number of experiments to understand better and explain why  phrase-based models  outperform  word-based models  . Our empirical results, which hold for all examined  language pairs  , suggest that the highest levels of performance can be obtained through relatively simple means:  heuristic learning  of  phrase translations  from  word-based alignments  and  lexical weighting  of  phrase translations  . Surprisingly, learning  phrases  longer than three  words  and learning  phrases  from  high-accuracy word-level alignment models  does not have a strong impact on performance. Learning only  syntactically motivated phrases  degrades the performance of our systems. \n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"phrase-based translation model FEATURE-OF decoding algorithm\", \"phrase-based translation models COMPARE previously proposed phrase-based translation models\", \"phrase-based models OUTPERFORM word-based models\", \"empirical results HOLD-FOR all examined language pairs\", \"heuristic learning USED-FOR phrase translations\", \"word-based alignments USED-FOR heuristic learning of phrase translations\", \"lexical weighting USED-FOR phrase translations\", \"learning phrases longer than three words EVALUATE-FOR performance\", \"learning phrases from high-accuracy word-level alignment models EVALUATE-FOR performance\", \"syntactically motivated phrases EVALUATE-FOR performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  72%|███████▏  | 362/500 [1:10:52<48:05, 20.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"generative probabilistic OCR model USED-FOR error correction\", \"model FEATURE-OF end-to-end process\", \"true text HYPONYM-OF noisy output\", \"OCR system PART-OF noisy channel framework\", \"output PART-OF OCR systems\", \"model EVALUATE-FOR NLP tasks\", \"finite-state models FEATURE-OF implementation\", \"character error rate COMPARE word error rate\", \"translation lexicons EVALUATE-FOR printed text\", \"OCR system COREF model\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  73%|███████▎  | 363/500 [1:11:02<40:44, 17.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"application of ambiguity packing and stochastic disambiguation techniques USED-FOR sentence condensation\", \"linguistic parser/generator FEATURE-OF LFG\", \"transfer component USED-FOR parse reduction\", \"packed parse forests PART-OF transfer component\", \"maximum-entropy model USED-FOR stochastic output selection\", \"parser evaluation methods EVALUATE-FOR summarization quality\", \"experimental evaluation EVALUATE-FOR summarization quality\", \"automatic parse-based evaluation COMPARE manual evaluation\", \"proposed system COREF system\", \"constraint-based parser/generator FEATURE-OF system output\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  73%|███████▎  | 364/500 [1:11:13<35:22, 15.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"part-of-speech tagger FEATURE-OF explicit use\", \"part-of-speech tagger FEATURE-OF broad use\", \"part-of-speech tagger FEATURE-OF effective use\", \"part-of-speech tagger FEATURE-OF fine-grained modeling\", \"tag contexts USED-FOR dependency network representation\", \"lexical features USED-FOR conditioning on multiple consecutive words\", \"priors USED-FOR conditional loglinear models\", \"tagger EVALUATE-FOR accuracy\", \"error reduction COMPARE best previous single automatically learned tagging result\", \"tagger COREF tagger\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  73%|███████▎  | 365/500 [1:11:23<31:50, 14.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"training data USED-FOR language modeling\", \"training data FEATURE-OF conversational speech\", \"training data PART-OF class-dependent interpolation\", \"N-grams PART-OF class-dependent interpolation\", \"web FEATURE-OF text\", \"web FEATURE-OF style\", \"web FEATURE-OF topic\", \"text FEATURE-OF recognition task\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  73%|███████▎  | 366/500 [1:11:31<27:06, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"EBMT system USED-FOR translation quality\", \"out-of-domain bilingual corpus USED-FOR EBMT\", \"out-of-domain bilingual corpus USED-FOR bilingual corpus\", \"language model FEATURE-OF EBMT system\", \"in-domain monolingual corpus FEATURE-OF language model\", \"BLEU score EVALUATE-FOR translation quality\", \"NIST score EVALUATE-FOR translation quality\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  73%|███████▎  | 367/500 [1:11:39<24:16, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"unsupervised technique USED-FOR learning morphology\", \"node FEATURE-OF graph\", \"word-trie PART-OF minimal DFA\", \"hubs HYPONYM-OF node\", \"hubs PART-OF boundary between root and suffix\", \"performance EVALUATE-FOR achieving similar performance to more complex mixtures of techniques\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  74%|███████▎  | 368/500 [1:11:45<20:59,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"syntax-based constraint FEATURE-OF word alignment\", \"cohesion constraint FEATURE-OF word alignment\", \"English phrases PART-OF cohesion constraint\", \"French sentence PART-OF cohesion constraint\", \"cohesion constraint EVALUATE-FOR alignment quality\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  74%|███████▍  | 369/500 [1:11:51<18:25,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Named Entity (NE) TAGGING HYPONYM-OF parsing-based NE rules\", \"bootstrapping approach USED-FOR training two successive learners\", \"common noun SEEDS FEATURE-OF concept\", \"pronoun SEEDS FEATURE-OF concept\", \"PERSON NE PART-OF targeted NE concept\", \"decision list USED-FOR parsing-based NE rules\", \"Hidden Markov Model USED-FOR corpus automatically tagged by first learner\", \"NE system EVALUATE-FOR supervised NE performance for some NE types\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  74%|███████▍  | 370/500 [1:12:01<19:14,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"phrase-based unigram model USED-FOR statistical machine translation\", \"model parameters FEATURE-OF phrase-based models\", \"units of translation PART-OF blocks\", \"blocks PART-OF pairs of phrases\", \"block unigram model USED-FOR decoding\", \"word-based trigram language model USED-FOR decoding\", \"blocks USED-FOR training\", \"source interval projections USED-FOR learning blocks\", \"word alignment FEATURE-OF learning blocks\", \"block selection criteria EVALUATE-FOR experimental results\", \"unigram counts COMPARE phrase length\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  74%|███████▍  | 371/500 [1:12:12<20:24,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Cooperative Model FEATURE-OF natural language understanding\", \"Cooperative Model FEATURE-OF dialogue system\", \"FSM USED-FOR language understanding\", \"FSM EVALUATE-FOR accuracy\", \"Statistical approach EVALUATE-FOR robustness\", \"Cooperative Model COMPARE FSM\", \"Cooperative Model COMPARE Statistical approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  74%|███████▍  | 372/500 [1:12:19<18:53,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"TAP-XL Automated Analyst's Assistant USED-FOR topical report\", \"multilingual, multimedia data PART-OF TAP-XL Automated Analyst's Assistant\", \"human language technology FEATURE-OF TAP-XL Automated Analyst's Assistant\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  75%|███████▍  | 373/500 [1:12:25<16:51,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"JAVELIN system USED-FOR open-domain question answering capability\", \"JAVELIN system processes questions\", \"answer candidates PART-OF text corpus\", \"system creates data objects during each question answering session\", \"system explained in depth through browsing repository of data objects\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  75%|███████▍  | 374/500 [1:12:31<15:30,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Question Answering system EVALUATE-FOR FAQ-like questions and answers\", \"noisy-channel architecture FEATURE-OF system\", \"language model FEATURE-OF answers\", \"transformation model FEATURE-OF answer/question terms\", \"corpus PART-OF system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  75%|███████▌  | 375/500 [1:12:37<14:26,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"MBR decoding USED-FOR statistical machine translation\", \"expected loss EVALUATE-FOR translation errors\", \"loss functions FEATURE-OF MBR decoders\", \"linguistic information PART-OF loss functions\", \"word-to-word alignments PART-OF loss functions\", \"syntactic structure PART-OF loss functions\", \"MBR decoders FEATURE-OF statistical MT performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  75%|███████▌  | 376/500 [1:12:45<14:53,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"CriterionSM Online Essay Evaluation Service USED-FOR labeling sentences with essay-based discourse elements\", \"new system EVALUATE-FOR coherence in essays\", \"semantic similarity measures FEATURE-OF sentences\", \"discourse structure FEATURE-OF sentences\", \"support vector machine USED-FOR capturing breakdowns in coherence\", \"relatedness to essay question COMPARE relatedness between discourse elements\", \"intra-sentential quality EVALUATE-FOR rule-based heuristics\", \"system yields higher performance COMPARE baseline\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  75%|███████▌  | 377/500 [1:12:56<16:54,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"English text USED-FOR American Sign Language animation\", \"MT architectural designs FEATURE-OF translation\", \"semantic representation FEATURE-OF virtual reality 3D scene modeling software\", \"classifier predicates PART-OF spatially complex ASL phenomena\", \"model PART-OF interlingua\", \"multi-pathway MT architecture design FEATURE-OF system\", \"transfer APPROACH-OF multi-pathway MT architecture design\", \"direct APPROACH-OF multi-pathway MT architecture design\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  76%|███████▌  | 378/500 [1:13:06<17:54,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"information extraction system FEATURE-OF linear-chain conditional random field\", \"linear-chain conditional random field FEATURE-OF probabilistic model\", \"probabilistic model FEATURE-OF information extraction tasks\", \"Markov model FEATURE-OF linear-chain conditional random field\", \"confidence EVALUATE-FOR extracted fields\", \"confidence EVALUATE-FOR multi-field records\", \"average precision EVALUATE-FOR retrieving correct fields\", \"average precision EVALUATE-FOR multi-field records\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  76%|███████▌  | 379/500 [1:13:16<18:45,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"entailment acquisition COMPARE paraphrases acquisition\", \"verb entailment USED-FOR local structure of coherent text\", \"method models discourse relations\", \"verb entailment PART-OF coherent text\", \"method models verb entailment\", \"mapping EVALUATE-FOR verb entailment\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  76%|███████▌  | 380/500 [1:13:23<16:51,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"temporal expressions FEATURE-OF constraint-based representation\", \"temporal expressions HYPONYM-OF under-specified nature\", \"work COMPARE closely related work\", \"TEA EVALUATE-FOR performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  76%|███████▌  | 381/500 [1:13:28<14:49,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"convolution kernel USED-FOR modeling syntactic structure information\", \"syntactic structure features FEATURE-OF parse tree\", \"convolution tree kernel USED-FOR capturing syntactic structure features\", \"evaluation EVALUATE-FOR achieving comparable performance with previous best-reported feature-based methods\", \"convolution kernel COMPARE dependency tree kernels\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  76%|███████▋  | 382/500 [1:13:35<14:36,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"QA systems USED-FOR information need\", \"preferred language FEATURE-OF information need\", \"MT-based paraphrasing technique USED-FOR paraphrased questions\", \"QA system EVALUATE-FOR performance on paraphrased questions\", \"MRR EVALUATE-FOR QA system performance\", \"question COREF question\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  77%|███████▋  | 383/500 [1:13:42<14:02,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"information extraction FEATURE-OF token classification task\", \"tagging strategies PART-OF token\", \"tagging strategies EVALUATE-FOR relative performances\", \"Begin/After tagging COMPARE other strategies\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  77%|███████▋  | 384/500 [1:13:47<12:41,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"InfoMagnets USED-FOR exploratory corpus analysis\", \"research context COREF InfoMagnets\", \"language PART-OF behavioral patterns\", \"tutorial dialogue COMPARE on-line communities\", \"educational tool USED-FOR protocol analysis\", \"InfoMagnets USED-FOR Educational Research Methods course\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  77%|███████▋  | 385/500 [1:13:53<12:11,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"TD COMPARE step-size and eligibility trace parameters\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  77%|███████▋  | 386/500 [1:13:55<09:57,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"function f\", \"neural network USED-FOR computing function f\", \"hidden layers REQUIRED-BY neural network\", \"Gibson's assumptions\", \"multiple intersection point\", \"restriction of f\", \"neighborhood of multiple intersection point\", \"neighborhood of infinity\", \"locally computable WITH one hidden layer\", \"global computability WITH one hidden layer\", \"new non-local configuration\", \"critical cycle\", \"f not computable WITH one hidden layer\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  77%|███████▋  | 387/500 [1:14:05<12:03,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"neuronal population vector NPV HYPONYM-OF coordinated action of neurons\", \"model FEATURE-OF cortical motor command\", \"visual information PART-OF self-organizing neural network\", \"motor babbling USED-FOR training network\", \"movement direction EVALUATE-FOR angular motor commands\", \"actual trajectory COMPARE desired trajectory\", \"NPV COMPARE actual trajectory\", \"NPV COMPARE desired trajectory\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  78%|███████▊  | 388/500 [1:14:13<12:59,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"new variant of AdaBoost USED-FOR training simple classifiers\", \"cascade of simple classifiers USED-FOR final detector\", \"high detection rates FEATURE-OF final detector\", \"low false positive rates FEATURE-OF final detector\", \"fast performance FEATURE-OF final detector\", \"experimental results EVALUATE-FOR performance over conventional AdaBoost\", \"final face detection system PART-OF cascade of simple classifiers\", \"false positive rate EVALUATE-FOR final face detection system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  78%|███████▊  | 389/500 [1:14:23<14:26,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"high-density analog array PART-OF mixed-signal paradigm\", \"binary-binary partial matrix-vector multiplication USED-FOR high-resolution parallel inner-product computation\", \"random statistics FEATURE-OF full digital resolution\", \"random modulation scheme FEATURE-OF near-Bernoulli statistics\", \"experimental results COMPARE real image data\", \"CID/DRAM analog array prototype EVALUATE-FOR efficient implementation of kernels in image processing\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  78%|███████▊  | 390/500 [1:14:31<14:50,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"factor analysis USED-FOR modeling linear relationships\", \"factor analysis USED-FOR mapping high-dimensional data\", \"observations MODELED-AS linear combination hidden variables\", \"product analysis HYPONYM-OF nonlinear factor analysis\", \"observed variables MODELED-AS linear combination products hidden variables\", \"mapping between data and hidden space NONLINEAR\", \"variational technique USED-FOR inference and learning\", \"product analysis COMPARE factor analysis\", \"product analysis FINDS higher data likelihood than factor analysis\", \"results GIVEN ON pattern recognition\", \"results GIVEN ON illumination-invariant image clustering\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  78%|███████▊  | 391/500 [1:14:43<16:51,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"sparsity FEATURE-OF sources\", \"multi scale transforms FEATURE-OF signals\", \"local features PART-OF signals\", \"best subsets EVALUATE-FOR separation\", \"algorithm COMPARE previously reported results\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  78%|███████▊  | 392/500 [1:14:49<14:51,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"citation matching COMPARE current algorithms\", \"identity uncertainty EVALUATE-FOR citation matching\", \"Markov chain Monte Carlo USED-FOR inference\", \"relational probability model USED-FOR generative model\", \"author names COREF author names\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  79%|███████▊  | 393/500 [1:14:55<13:30,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"study of clustering FEATURE-OF goal\", \"unified framework EVALUATE-FOR reasoning\", \"approaches COMPARE clustering techniques\", \"properties COREF Relaxations\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  79%|███████▉  | 394/500 [1:15:00<11:45,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 394: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 83ac94deb1162b740336943b9349c87c in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    A bio-inspired model for an analog programmable array processor (APAP), based on studies on the vertebrate retina, has permitted the realization of complex programmable spatio-temporal dynamics in VLSI. This model mimics the way in which images are processed in the visual pathway, rendering a feasible alternative for the implementation of early vision applications in standard technologies. A prototype chip has been designed and fabricated in a 0.5Âµm standard CMOS process. Computing power per area and power consumption is amongst the highest reported for a single chip. Design challenges, trade-offs and some experimental results are presented in this paper.\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"model FEATURE-OF APAP\", \"model HYPONYM-OF bio-inspired model\", \"model PART-OF VLSI\", \"prototype chip PART-OF chip\", \"computing power EVALUATE-FOR area\", \"computing power EVALUATE-FOR power consumption\", \"trade-offs COMPARE design challenges\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  79%|███████▉  | 395/500 [1:15:43<30:55, 17.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"gender judgment EVALUATE-FOR classification task\", \"hyperplane algorithms USED-FOR classification\", \"human classification COREF brain\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  79%|███████▉  | 396/500 [1:15:47<23:31, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm models shape motion AS rigid component combined with non-rigid deformation\", \"reconstruction ILL-POSED if arbitrary deformations are allowed\", \"algorithm ESTIMATES 3D shape and motion for each time frame\", \"algorithm LEARNS parameters of Gaussian\", \"algorithm FILLS-IN missing data points ROBUSTLY\", \"algorithm MODELS temporal smoothness in object shape\", \"missing data COREF severe cases\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  79%|███████▉  | 397/500 [1:15:54<19:59, 11.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Kikuchi approximation USED-FOR estimating log partition function\", \"reweighted version USED-FOR Kikuchi approximation\", \"weight assignments FEATURE-OF Kikuchi expansion\", \"sum product algorithm USED-FOR Kikuchi region graph\", \"global optima EVALUATE-FOR Kikuchi approximation\", \"region graph PART-OF product distribution\", \"region graph PART-OF Bethe approximation\", \"sufficient conditions FOR concavity\", \"cycle structure FEATURE-OF region graph\", \"reweighted Kikuchi approach USED-FOR simulations\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  80%|███████▉  | 398/500 [1:16:04<18:46, 11.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"weighted expert voting FEATURE-OF decision-theoretic problem\", \"weighted majority USED-FOR expert voting\", \"competence levels UNKNOWN\", \"competence levels EVALUATE-FOR empirically estimated\", \"proof techniques OF independent interest\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  80%|███████▉  | 399/500 [1:16:11<16:19,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"low-level features CANNOT-ADEQUATELY-CHARACTERIZE rich spatial-temporal structures\", \"actions BASED-ON attributes\", \"humans GENERATE one type of action attributes\", \"data-driven attributes LEARNED-FROM data\", \"attribute-based representation MAY-EXHIBIT high variance\", \"subset of discriminative attributes SELECTED-FROM large attribute set\", \"proposed attribute-based representation CAN-SIGNIFICANTLY-BOOST performance of action recognition algorithms\", \"most recently proposed recognition approaches COMPARED\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  80%|████████  | 400/500 [1:16:23<17:37, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SVRG USED-FOR stochastic optimization algorithms\", \"SDCA USED-FOR stochastic optimization algorithms\", \"local smoothness FEATURE-OF loss functions\", \"penalized empirical risk minimization problems PART-OF family\", \"local smoothness EVALUATE-FOR convergence guarantees\", \"local smoothness COMPARE global smoothness\", \"algorithms CONJUNCTION local smoothness\", \"our theory COREF our bounds\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  80%|████████  | 401/500 [1:16:32<16:37, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"DNA sequence PART-OF practical modeling problems\", \"children's names PART-OF practical modeling problems\", \"text documents PART-OF practical modeling problems\", \"nucleotide HYPONYM-OF multinomial distributions\", \"children's names EVALUATE-FOR correlation from year to year\", \"topics EVALUATE-FOR correlation and dynamic\", \"Dirichlet-multinomial formulation COMPARE logistic stick-breaking representation\", \"latent variables FEATURE-OF logistic stick-breaking representation\", \"Gaussian likelihoods FEATURE-OF latent variables\", \"Bayesian inference techniques USED-FOR Gaussian models\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  80%|████████  | 402/500 [1:16:45<18:04, 11.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"convolutional neural networks FEATURE-OF success\", \"stochastic attention-based models USED-FOR computational efficiency\", \"Wake-Sleep Recurrent Attention Model FEATURE-OF method\", \"training deep generative models COMPARE Wake-Sleep Recurrent Attention Model\", \"stochastic attention networks EVALUATE-FOR training time\", \"image classification PART-OF Wake-Sleep Recurrent Attention Model\", \"caption generation PART-OF Wake-Sleep Recurrent Attention Model\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  81%|████████  | 403/500 [1:16:55<17:06, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"set M' USED-FOR noise perturbed versions of the matrices in M\", \"matrices in M' PART-OF set M\", \"approximate joint triangularizer EVALUATE-FOR exact joint triangularizer\", \"existing bounds COMPARE our bound\", \"this HYPONYM-OF joint matrix decomposition\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  81%|████████  | 404/500 [1:17:02<15:29,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach FEATURE-OF NN search\", \"embedding PART-OF points\", \"methodology EVALUATE-FOR correctness\", \"methodology COMPARE available alternatives\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  81%|████████  | 405/500 [1:17:06<12:33,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"segment order COMPARE segmentation\", \"segment order COMPARE segment contiguity\", \"retrieval performance EVALUATE-FOR translation memory system\", \"bag-of-words methods COMPARE segment order-sensitive methods\", \"retrieval accuracy EVALUATE-FOR bag-of-words methods\", \"retrieval accuracy EVALUATE-FOR segment order-sensitive methods\", \"character bigrams FEATURE-OF indexing\", \"word N-gram models HYPONYM-OF local segment contiguity models\", \"character-segmented data PART-OF indexing\", \"word-segmented data PART-OF indexing\", \"N-grams FEATURE-OF local segment contiguity models\", \"datasets COREF\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  81%|████████  | 406/500 [1:17:21<15:46, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"RCL can be parsed USED-FOR NLP\", \"grammatical formalisms translated HYPONYM-OF RCGs\", \"tree adjoining grammar HYPONYM-OF RCG\", \"parsing technique EVALUATE-FOR practical efficiency of RCL parsers\", \"non-deterministic parsing choices FEATURE-OF main parser\", \"guide USED-FOR directing parsing choices\", \"shared derivation forest FEATURE-OF guide\", \"RCL parser COMPARE prior RCL parser\", \"results of practical evaluation COREF this method\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  81%|████████▏ | 407/500 [1:17:32<15:41, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"paraphrases FEATURE-OF interpretation\", \"paraphrases FEATURE-OF generation\", \"systems USE manual methods\", \"systems USE semi-automatic methods\", \"unsupervised learning algorithm EVALUATE-FOR identification of paraphrases\", \"corpus PART-OF identification of paraphrases\", \"English translations HYPONYM-OF source text\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  82%|████████▏ | 408/500 [1:17:40<14:34,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"alternative markers FEATURE-OF dialog\", \"natural language search engines EVALUATE-FOR queries\", \"search engine PART-OF natural language applications\", \"operational semantics FEATURE-OF natural language applications\", \"operational semantics COMPARE larger improvements\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  82%|████████▏ | 409/500 [1:17:45<12:29,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Minimalist grammars FEATURE-OF Stabler's formalization\", \"Minimalist grammars HYPONYM-OF Chomsky's minimalist program\", \"logical definition FEATURE-OF Minimalist grammars\", \"logical definition FEATURE-OF categorial grammar\", \"logical definition EVALUATE-FOR Montague semantics\", \"parsing-as-deduction FEATURE-OF resource sensitive logic\", \"learning algorithm FEATURE-OF structured data\", \"learning algorithm FEATURE-OF typing-algorithm\", \"learning algorithm FEATURE-OF type-unification\", \"Montague semantics HYPONYM-OF formal computation\", \"logical form PART-OF Montague semantics\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  82%|████████▏ | 410/500 [1:17:59<14:47,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"trainable sentence planner EVALUATE-FOR subjective human judgments\", \"trainable sentence planner COMPARE rule-based systems\", \"trainable sentence planner COMPARE baselines\", \"trainable sentence planner COMPARE hand-crafted system\", \"hand-crafted template-based generation component FEATURE-OF utterances produced with trainable components\", \"rule-based sentence planners COMPARE baseline sentence planners\", \"trainable sentence planner PART-OF spoken dialogue system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  82%|████████▏ | 411/500 [1:18:07<14:03,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"supervised machine learning experiments FEATURE-OF construction\", \"statistical models FEATURE-OF WH-questions\", \"models USED-FOR predict target variables\", \"user's informational goals PART-OF target variables\", \"predictive performance EVALUATE-FOR target variables\", \"training and testing factors PART-OF predictive performance\", \"target variables COMPARE target variables\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  82%|████████▏ | 412/500 [1:18:15<13:17,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"LM size REDUCED-FOR realistic applications\", \"three measures STUDIED-FOR LM pruning\", \"probability FEATURE-OF pruning criteria\", \"rank FEATURE-OF pruning criteria\", \"entropy FEATURE-OF pruning criteria\", \"rank COMPARE probability\", \"rank EVALUATE-FOR character error rate\", \"combined criterion USED-FOR model pruning\", \"two criteria CONJUNCTION model pruning\", \"combined criterion EVALUATE-FOR smaller models\", \"probability COMPARE rank\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  83%|████████▎ | 413/500 [1:18:25<13:25,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"supervised learning FEATURE-OF summarization\", \"unsupervised learning FEATURE-OF summarization\", \"probabilistic decision tree USED-FOR clustering framework\", \"human created summaries PART-OF corpus\", \"newspaper corpus PART-OF corpus\", \"probabilistic decision trees FEATURE-OF clustering framework\", \"mixture of the two paradigms EVALUATE-FOR performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  83%|████████▎ | 414/500 [1:18:34<12:56,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"HMM-based chunk tagger FEATURE-OF NER system\", \"NER problem EVALUATE-FOR effective resolution\", \"system EVALUATE-FOR F-measures\", \"MUC-6 English NE tasks PART-OF evaluation\", \"MUC-7 English NE tasks PART-OF evaluation\", \"machine-learning system COMPARE handcrafted rules\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  83%|████████▎ | 415/500 [1:18:41<12:06,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"predicate-argument structures FEATURE-OF IE results\", \"predicate-argument structures USED-FOR IE paradigm\", \"predicate-argument structures PART-OF IE paradigm\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  83%|████████▎ | 416/500 [1:18:45<09:59,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"HDAG Kernel FEATURE-OF structured natural language data\", \"HDAG Kernel EVALUATE-FOR question classification\", \"HDAG Kernel EVALUATE-FOR sentence alignment tasks\", \"HDAG Kernel EVALUATE-FOR similarity measure\", \"HDAG Kernel EVALUATE-FOR kernel function\", \"HDAG Kernel COMPARE other kernel functions\", \"HDAG Kernel COMPARE baseline methods\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  83%|████████▎ | 417/500 [1:18:53<10:27,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 417: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6263b8dbd6fed2cab7d48fbac2c691d0 in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "     Previous research has demonstrated the utility of  clustering  in inducing  semantic verb classes  from undisambiguated  corpus data  . We describe a new approach which involves clustering  subcategorization frame (SCF)  distributions using the  Information Bottleneck  and  nearest neighbour  methods. In contrast to previous work, we particularly focus on clustering  polysemic verbs  . A novel  evaluation scheme  is proposed which accounts for the effect of  polysemy  on the  clusters  , offering us a good insight into the potential and limitations of  semantically classifying   undisambiguated SCF data  . \n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"clustering USED-FOR inducing semantic verb classes\", \"subcategorization frame distributions PART-OF clustering\", \"polysemic verbs HYPONYM-OF semantic verb classes\", \"evaluation scheme FEATURE-OF clustering\", \"polysemy EVALUATE-FOR clusters\", \"undisambiguated SCF data COREF\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  84%|████████▎ | 418/500 [1:19:35<24:23, 17.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"pronoun resolution PART-OF spoken dialogue\", \"system COMPARE Byron's manually tuned system\", \"pronouns COREF NP- and non-NP-antecedents\", \"features USED-FOR pronoun resolution\", \"features EVALUATE-FOR pronoun resolution\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  84%|████████▍ | 419/500 [1:19:42<19:39, 14.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Link detection FEATURE-OF core technology\", \"Topic Detection and Tracking tasks PART-OF new event detection\", \"story link detection HYPONYM-OF new event detection\", \"story link detection FEATURE-OF information retrieval task\", \"new event detection FEATURE-OF information retrieval task\", \"precision EVALUATE-FOR story link detection\", \"recall EVALUATE-FOR story link detection\", \"precision EVALUATE-FOR new event detection\", \"recall EVALUATE-FOR new event detection\", \"part of speech tagging FEATURE-OF performance enhancing techniques\", \"similarity measures FEATURE-OF performance enhancing techniques\", \"stop lists FEATURE-OF performance enhancing techniques\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  84%|████████▍ | 420/500 [1:19:54<18:31, 13.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"discourse understanding process FEATURE-OF spoken dialogue systems\", \"system USED-FOR understand user utterances\", \"context PART-OF dialogue\", \"candidates PART-OF understanding result\", \"ambiguity PART-OF speech understanding\", \"understanding result EVALUATE-FOR user utterance\", \"candidates PART-OF understanding results\", \"ambiguity PART-OF dialogue\", \"discourse understanding accuracy EVALUATE-FOR ambiguity\", \"ambiguity FEATURE-OF statistical information\", \"dialogue corpora PART-OF statistical information\", \"hand-crafted rules COMPARE proposed method\", \"discourse understanding process FEATURE-OF proposed method\", \"system USED-FOR exploits proposed method\", \"candidates PART-OF understanding results\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  84%|████████▍ | 421/500 [1:20:10<19:01, 14.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"user model PROPOSE Kyoto city bus information system FEATURE-OF dialogue strategies\", \"user modeling USED-FOR cooperative responses\", \"skill level PART-OF user models\", \"knowledge level PART-OF user models\", \"degree of hastiness PART-OF user models\", \"models EVALUATE-FOR classification accuracy\", \"cooperative responses EVALUATE-FOR novice users\", \"cooperative responses EVALUATE-FOR individual users\", \"dialogue duration EVALUATE-FOR skilled users\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  84%|████████▍ | 422/500 [1:20:21<17:23, 13.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"NLG systems HAVE-GROWN increasingly complex\", \"architectural modules WERE-ADDED to support language functionalities\", \"referring expressions FEATURE-OF language functionalities\", \"lexical choice FEATURE-OF language functionalities\", \"revision FEATURE-OF language functionalities\", \"discourse markers FEATURE-OF multi-paragraph text\", \"discourse marker insertion algorithm USED-FOR multi-paragraph text\", \"discourse marker insertion algorithm PART-OF pipelined NLG architecture\", \"approach TIE-TO revision component\", \"approach EVALUATE-FOR multi-page system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  85%|████████▍ | 423/500 [1:20:33<16:36, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"unsupervised learning approach USED-FOR building non-English stemmer\", \"stemming model FEATURE-OF statistical machine translation\", \"stemming model USED-FOR affix removal\", \"English stemmer PART-OF stemming model\", \"parallel corpus PART-OF stemming model\", \"parallel text NOT-NEEDED-AFTER training phase\", \"monolingual unannotated text USED-FOR improving stemmer\", \"stemmer ADAPTS-TO desired domain or genre\", \"resource-frugal approach USED-FOR building Arabic stemmer\", \"unsupervised component USED-FOR building proprietary Arabic stemmer\", \"task-based evaluation EVALUATE-FOR Arabic information retrieval\", \"improvement COMPARE unstemmed text\", \"performance COMPARE proprietary stemmer\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  85%|████████▍ | 424/500 [1:20:49<17:27, 13.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"word sense disambiguation USED-FOR supervised learning\", \"approach USED-FOR acquire sense-tagged training data\", \"English-Chinese parallel corpora USED-FOR sense-tagged training data\", \"method of acquiring sense-tagged data FEATURE-OF promising\", \"SENSEVAL-2 English lexical sample task EVALUATE-FOR disambiguating nouns\", \"accuracy COMPARE difference between two approaches\", \"manually sense-tagged data FEATURE-OF sense coverage\", \"domain dependence EVALUATE-FOR WSD programs\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  85%|████████▌ | 425/500 [1:20:59<16:00, 12.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"large-scale acquisition FEATURE-OF domain-independent lexica\", \"semantic roles PART-OF annotation\", \"annotated data EVALUATE-FOR project stage\", \"vagueness PROBLEM-OF semantic annotation\", \"ambiguity PROBLEM-OF semantic annotation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  85%|████████▌ | 426/500 [1:21:06<13:38, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"embodied conversational agents FEATURE-OF design\", \"signals USED-FOR establish common ground\", \"eye gaze PART-OF nonverbal behaviors\", \"head nods PART-OF nonverbal behaviors\", \"attentional focus PART-OF nonverbal behaviors\", \"nonverbal behaviors FEATURE-OF grounding\", \"dialogue move HYPONYM-OF direction-giving task\", \"nonverbal behaviors COMPARE negative feedback\", \"ECA USED-FOR update dialogue state\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  85%|████████▌ | 427/500 [1:21:17<13:24, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approximation of HPSG FEATURE-OF CFG filter\", \"LTAG HYPONYM-OF CFG filter\", \"approximation of HPSG COMPARE LTAG\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  86%|████████▌ | 428/500 [1:21:22<10:57,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"head-driven statistical parsing model FEATURE-OF simultaneous language model\", \"head-driven statistical parsing model FEATURE-OF parser\", \"parser USED-FOR large-vocabulary speech recognition\", \"model ADAPTED-TO chart-parser\", \"chart-parser PART-OF word lattices\", \"parser USES structural dependencies\", \"parser USES lexical dependencies\", \"n-gram models COMPARE parser\", \"Wall Street Journal treebank PART-OF experiments\", \"lattice corpora PART-OF experiments\", \"word error rates EVALUATE-FOR speech understanding\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  86%|████████▌ | 429/500 [1:21:35<12:07, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"English topic signatures FEATURE-OF concept\", \"topic signatures USED-FOR NLP applications\", \"Word Sense Disambiguation (WSD) EVALUATE-FOR topic signatures\", \"word senses PART-OF topic signatures\", \"Chinese text FEATURE-OF corpora\", \"topic signatures EVALUATE-FOR WSD task\", \"second-order vector cooccurrence algorithm USED-FOR WSD datasets\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  86%|████████▌ | 430/500 [1:21:44<11:35,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ensemble learning approach USED-FOR resolving German pronouns\", \"Boosting FEATURE-OF method\", \"classifiers PART-OF hypotheses\", \"ensemble learning approach COMPARE decision-tree classifier\", \"standalone system EVALUATE-FOR resolving pronouns in unannotated text\", \"preprocessing modules PART-OF standalone system\", \"manual annotation process HYPONYM-OF preprocessing modules\", \"textual domain FEATURE-OF system\", \"open-domain question answering CONJUNCTION text summarisation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  86%|████████▌ | 431/500 [1:21:55<11:52, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"generative probabilistic model HYPONYM-OF parse trees\", \"PCFG-LA model FEATURE-OF non-terminal symbols\", \"CFG rules FEATURE-OF parsed corpus\", \"PCFG-LA model USED-FOR training\", \"parsing EVALUATE-FOR performance\", \"PCFG parser COMPARE PCFG-LA model\", \"Penn WSJ corpus PART-OF experiments\", \"automatically trained model EVALUATE-FOR performance\", \"F1 EVALUATE-FOR sentences\", \"unlexicalized PCFG parser COMPARE PCFG-LA model\", \"extensive manual feature selection PART-OF unlexicalized PCFG parser\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  86%|████████▋ | 432/500 [1:22:09<12:55, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"entity-based representation FEATURE-OF discourse\", \"coherence assessment USED-FOR ranking learning problem\", \"discourse representation FEATURE-OF coherence assessment\", \"induced model COMPARE state-of-the-art coherence model\", \"accuracy EVALUATE-FOR induced model\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  87%|████████▋ | 433/500 [1:22:16<11:05,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"captions FEATURE-OF information graphic\", \"graphic interpretation system USED-FOR communicative signals\", \"shallow processing EVALUATE-FOR system's success\", \"larger project PART-OF work\", \"sight-impaired users COREF they\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  87%|████████▋ | 434/500 [1:22:22<09:40,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"phrase translations FEATURE-OF suffix array-based data structure\", \"sampling USED-FOR reduction of retrieval time\", \"retrieval time EVALUATE-FOR translation quality\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  87%|████████▋ | 435/500 [1:22:26<08:07,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"statistical machine translation FEATURE-OF approach\", \"syntactic information FEATURE-OF source language\", \"phrasal translation FEATURE-OF recent advances\", \"source-language dependency parser PART-OF method\", \"target language word segmentation PART-OF method\", \"unsupervised word alignment component PART-OF method\", \"parallel corpus PART-OF method\", \"source dependency parse PART-OF sentence\", \"dependency treelet translation pairs PART-OF method\", \"tree-based ordering model FEATURE-OF method\", \"tree-based models USED-FOR SMT models\", \"phrasal SMT FEATURE-OF power\", \"linguistic generality FEATURE-OF parser\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  87%|████████▋ | 436/500 [1:22:40<09:55,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"unlexicalized parser USED-FOR German\", \"smoothing USED-FOR unlexicalized parser\", \"suffix analysis USED-FOR unlexicalized parser\", \"labelled bracket F-score EVALUATE-FOR NEGRA corpus\", \"accuracy FEATURE-OF model\", \"smoothing FEATURE-OF unlexicalized parser\", \"smoothing COMPARE parsing results\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  87%|████████▋ | 437/500 [1:22:48<09:23,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"hidden Markov models FEATURE-OF generative model\", \"unsupervised HMM learning EVALUATE-FOR useful structure\", \"prior knowledge USED-FOR effective models\", \"unsupervised methods COMPARE supervised methods\", \"labeled data PART-OF small amounts\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  88%|████████▊ | 438/500 [1:22:55<08:40,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"word sense disambiguation USED-FOR translation candidates\", \"word sense disambiguation EVALUATE-FOR translation quality\", \"statistical machine translation system COMPARE word sense disambiguation\", \"statistical machine translation system PART-OF IBM statistical MT system\", \"statistical MT architectures FEATURE-OF inherent limitations\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  88%|████████▊ | 439/500 [1:23:02<08:05,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 439: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f955eade7f1d23b54d2f894110aeb3ab in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    \n",
      " Sentence boundary detection  in  speech  is important for enriching  speech recognition  output, making it easier for humans to read and downstream modules to process. In previous work, we have developed  hidden Markov model (HMM) and maximum entropy (Maxent) classifiers  that integrate textual and prosodic  knowledge sources  for detecting  sentence boundaries . In this paper, we evaluate the use of a  conditional random field (CRF)  for this task and relate results with this model to our prior work. We evaluate across two corpora (conversational  telephone speech  and  broadcast news speech ) on both  human transcriptions  and  speech recognition  output. In general, our  CRF  model yields a lower error rate than the  HMM and Max-ent models  on the  NIST sentence boundary detection task  in  speech , although it is interesting to note that the best results are achieved by  three-way voting  among the  classifiers . This probably occurs because each  model  has different strengths and weaknesses for modeling the  knowledge sources .\n",
      "\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"sentence boundary detection USED-FOR speech recognition output\", \"HMM classifiers FEATURE-OF textual and prosodic knowledge sources\", \"Maxent classifiers FEATURE-OF textual and prosodic knowledge sources\", \"CRF USED-FOR sentence boundary detection task\", \"CRF COMPARE HMM classifiers\", \"CRF COMPARE Max-ent classifiers\", \"three-way voting CONJUNCTION classifiers\", \"model COMPARE model\", \"knowledge sources COMPARE knowledge sources\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  88%|████████▊ | 440/500 [1:24:30<32:00, 32.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"word alignment FEATURE-OF framework\", \"knowledge sources FEATURE-OF feature functions\", \"source language sentence PART-OF feature functions\", \"target language sentence PART-OF feature functions\", \"log-linear models FEATURE-OF statistical alignment models\", \"syntactic information FEATURE-OF log-linear models\", \"IBM Model 3 alignment probabilities FEATURE-OF log-linear models\", \"POS correspondence FEATURE-OF log-linear models\", \"bilingual dictionary coverage FEATURE-OF log-linear models\", \"IBM translation models COMPARE log-linear models\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  88%|████████▊ | 441/500 [1:24:42<25:37, 26.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"alignment adaptation approach USED-FOR improve domain-specific word alignment\", \"out-of-domain corpus USED-FOR improve in-domain word alignment results\", \"statistical word alignment models FEATURE-OF experimental results\", \"out-of-domain corpus COMPARE in-domain corpus\", \"precision EVALUATE-FOR domain-specific word alignment\", \"recall EVALUATE-FOR domain-specific word alignment\", \"relative error rate reduction FEATURE-OF state-of-the-art technologies\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  88%|████████▊ | 442/500 [1:24:52<20:20, 21.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"syntax-based statistical machine translation system FEATURE-OF probabilistic synchronous dependency insertion grammar\", \"synchronous dependency insertion grammars HYPONYM-OF synchronous grammars\", \"parallel corpora PART-OF inducing grammar\", \"graphical model EVALUATE-FOR machine translation task\", \"stochastic tree-to-tree transducer HYPONYM-OF graphical model\", \"polynomial time decoding algorithm FEATURE-OF model\", \"MT system USED-FOR machine translation task\", \"NIST automatic MT evaluation software COMPARE Bleu automatic MT evaluation software\", \"baseline system COMPARE our system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  89%|████████▊ | 443/500 [1:25:03<17:18, 18.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"training method FOR localized phrase-based prediction model\", \"model PREDICTS blocks\", \"blocks WITH orientation\", \"local phrase re-ordering FEATURE-OF model\", \"maximum likelihood criterion USED-FOR training log-linear block bigram model\", \"real-valued features FEATURE-OF log-linear block bigram model\", \"binary features FEATURE-OF log-linear block bigram model\", \"block bigram features FEATURE-OF binary features\", \"training algorithm USED-FOR handling millions of features\", \"best system EVALUATE-FOR 18.6% improvement over baseline\", \"Arabic-English translation task PART-OF standard\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  89%|████████▉ | 444/500 [1:25:16<15:24, 16.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"semantic role labeling USED-FOR accurate\", \"previous work USED-FOR independent classifiers\", \"label sequence models FEATURE-OF core argument frame\", \"core argument frame HYPONYM-OF joint structure\", \"dependencies FEATURE-OF core argument frame\", \"joint model USED-FOR argument frames\", \"features FEATURE-OF joint model\", \"interactions FEATURE-OF features\", \"discriminative log-linear models FEATURE-OF joint model\", \"error reduction EVALUATE-FOR all arguments\", \"error reduction EVALUATE-FOR core arguments\", \"independent classifier COMPARE state-of-the art independent classifier\", \"gold-standard parse trees COMPARE state-of-the art independent classifier\", \"PropBank PART-OF gold-standard parse trees\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  89%|████████▉ | 445/500 [1:25:31<14:54, 16.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"monolingual parallel corpora USED-FOR extract and generate paraphrases\", \"bilingual parallel corpora USED-FOR extract and generate paraphrases\", \"alignment techniques FEATURE-OF phrase-based statistical machine translation\", \"paraphrases PART-OF bilingual parallel corpus\", \"paraphrase probability EVALUATE-FOR rank paraphrases using translation probabilities\", \"paraphrase probability EVALUATE-FOR refine using contextual information\", \"paraphrase extraction and ranking methods USED-FOR extract and rank paraphrases\", \"quality COMPARE paraphrases extracted from manual alignments\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  89%|████████▉ | 446/500 [1:25:44<13:40, 15.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"system incorporates decision-tree classifier USED-FOR testing for presence of grammatical relations\", \"pattern-matching language FEATURE-OF classifying grammatical relations into frames\", \"experiments EVALUATE-FOR precision and recall rate\", \"tool INTRODUCED-FOR linguistic annotation of subcategorization frames\", \"subcategorization acquisition HYPONYM-OF linguistic annotation\", \"system COREF system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  89%|████████▉ | 447/500 [1:25:56<12:35, 14.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Sentiment Classification seeks to identify a piece of text according to its author's general feeling toward their subject\", \"machine learning techniques have been applied to this problem with reasonable success\", \"training and test data HAVE good match with respect to topic\", \"match with respect to domain and time is also important\", \"preliminary experiments with training data labeled with emoticons\", \"training data has the potential of being independent of domain, topic and time\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  90%|████████▉ | 448/500 [1:26:09<12:01, 13.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 448: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 141d2cd10750287c598e9adfd943891f in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    \n",
      "This paper presents the results of automatically inducing a  Combinatory Categorial Grammar (CCG) lexicon  from a  Turkish dependency treebank . The fact that  Turkish  is an  agglutinating free word order language  presents a challenge for  language theories . We explored possible ways to obtain a  compact lexicon , consistent with  CCG principles , from a  treebank  which is an order of magnitude smaller than  Penn WSJ .\n",
      "\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"Turkish agglutinating free word order language FEATURE-OF language theories\", \"CCG lexicon FEATURE-OF compact lexicon\", \"Turkish dependency treebank PART-OF CCG lexicon\", \"treebank PART-OF lexicon\", \"Turkish agglutinating free word order language HYPONYM-OF order language\", \"Turkish dependency treebank USED-FOR inducing CCG lexicon\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  90%|████████▉ | 449/500 [1:26:54<19:35, 23.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Czech-English statistical machine translation system USED-FOR tree-to-tree translation of dependency structures\", \"bilingual resource PART-OF sentence-aligned parallel corpus\", \"resources PART-OF monolingual\", \"evaluation method FEATURE-OF system's output\", \"system's output COMPARE benchmark system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  90%|█████████ | 450/500 [1:27:00<15:07, 18.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"dialogue system USED-FOR object identification\", \"modular architecture FEATURE-OF contributions\", \"reversible processes PART-OF modular architecture\", \"information-state model FEATURE-OF contributions\", \"links PART-OF contributions\", \"semantics CONJUNCTION collaborative problem solving\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  90%|█████████ | 451/500 [1:27:06<11:52, 14.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method allows user EXPLORE model\", \"model STRENGTHS-AND-WEAKNESSES other MT systems\", \"visualization method FIND-AND-ADDRESS problems MT system\", \"users DRIVE syntax-based decoder\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  90%|█████████ | 452/500 [1:27:13<09:37, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"reading materials PART-OF vocabulary learning\", \"target corpus PART-OF method\", \"target vocabulary FEATURE-OF reading texts\", \"target vocabulary FEATURE-OF specialized vocabulary\", \"English certification test USED-FOR specialized vocabulary\", \"English Wikipedia USED-FOR target corpus\", \"organized reading materials EVALUATE-FOR learners\", \"target vocabulary EVALUATE-FOR vocabulary learning\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  91%|█████████ | 453/500 [1:27:22<08:42, 11.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"sense priors FEATURE-OF word\", \"WSD systems USED-FOR domains\", \"sense priors EVALUATE-FOR WSD accuracy\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  91%|█████████ | 454/500 [1:27:26<06:53,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"system combination FEATURE-OF improving system performance\", \"system combination EVALUATE-FOR unsupervised WSD\", \"voting-based combination strategies COMPARE arbiter-based combination strategies\", \"combination methods FEATURE-OF predominant senses\", \"raw text PART-OF predominant senses\", \"SemCor COREF Senseval-3\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  91%|█████████ | 455/500 [1:27:33<06:20,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"mathematical formalism FEATURE-OF combination\", \"strings PART-OF mathematical formalism\", \"trees PART-OF mathematical formalism\", \"dags PART-OF mathematical formalism\", \"graphs PART-OF mathematical formalism\", \"polarization USED-FOR saturation\", \"elementary structures PART-OF polarization\", \"final structure FEATURE-OF saturation\", \"formalism COMPARE grammar formalisms\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  91%|█████████ | 456/500 [1:27:41<06:15,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"underspecified semantic representation USED-FOR scope ambiguity\", \"underspecified chart representations FEATURE-OF dominance graphs\", \"USRs EVALUATE-FOR ambiguity\", \"algorithm EVALUATE-FOR degree of ambiguity\", \"algorithm EVALUATE-FOR runtime\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  91%|█████████▏| 457/500 [1:27:48<05:40,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"syntactic priming FEATURE-OF incremental probabilistic parser\", \"priming USED-FOR rules\", \"rules HYPONYM-OF syntactic priming\", \"sentences CONJUNCTION coordinate structures\", \"parallel structures EVALUATE-FOR reading time advantage\", \"human data COREF data\", \"models COMPARE parsing accuracy\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  92%|█████████▏| 458/500 [1:27:56<05:35,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"pos tagging USED-FOR newspaper text\", \"parser EVALUATE-FOR performance\", \"parser PART-OF grammar formalisms\", \"pos tagging EVALUATE-FOR ccg supertagging\", \"multi-tagging approach USED-FOR ccg parsing\", \"multi-tagging approach PART-OF pos level\", \"pos tags FEATURE-OF errors\", \"pos tag ambiguity FEATURE-OF language processing pipeline\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  92%|█████████▏| 459/500 [1:28:05<05:41,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"dependency relation paths FEATURE-OF candidate answers\", \"dependency relations COMPARE relations in question\", \"question phrases COREF mapped question phrases\", \"approximate phrase mapping algorithm USED-FOR correlation measure\", \"mapping score FEATURE-OF correlation measure\", \"correlations FEATURE-OF Maximum Entropy-based ranking model\", \"path weights FEATURE-OF Maximum Entropy-based ranking model\", \"syntactic relation-based methods COMPARE our method\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  92%|█████████▏| 460/500 [1:28:15<05:46,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"machine learning techniques USED-FOR comma checker\", \"comma checker PART-OF grammar checker\", \"Basque FEATURE-OF grammar checker\", \"corpus USED-FOR system training\", \"system EVALUATE-FOR comma placement precision\", \"system EVALUATE-FOR comma placement recall\", \"corpus EVALUATE-FOR system performance improvement\", \"corpus PART-OF author\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  92%|█████████▏| 461/500 [1:28:25<05:53,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"unsupervised learning approach USED-FOR disambiguate various relations\", \"named entities COREF contexts\", \"lexical and syntactic features FEATURE-OF contexts\", \"eigenvectors OF adjacency graph\", \"submanifold PART-OF high dimensionality space\", \"cluster number estimation EVALUATE-FOR eigenvectors\", \"spectral clustering based approach COMPARE other clustering methods\", \"ACE corpora PART-OF experiment results\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  92%|█████████▏| 462/500 [1:28:35<05:54,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method FEATURE-OF building polarity-tagged corpus\", \"method USED-FOR HTML documents\", \"method PART-OF layout structures\", \"method PART-OF linguistic pattern\", \"sentences PART-OF corpus\", \"sentences EVALUATE-FOR opinion\", \"corpus PART-OF experiment\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  93%|█████████▎| 463/500 [1:28:42<05:18,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Bikel's parser COMPARE current technology\", \"subcategorization cues EVALUATE-FOR spoken language\", \"subcategorization frames USED-FOR spoken language\", \"punctuation USED-FOR parsing\", \"punctuation USED-FOR extraction\", \"spoken corpora PART-OF parsers\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  93%|█████████▎| 464/500 [1:28:49<05:00,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"word vectors FEATURE-OF similarity\", \"LSA-based word vectors COMPARE cooccurrence-based word vectors\", \"dictionary-based word vectors EVALUATE-FOR taxonomic similarity\", \"LSA-based word vectors COMPARE cooccurrence-based word vectors\", \"dictionary-based word vectors FEATURE-OF taxonomic similarity\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  93%|█████████▎| 465/500 [1:28:58<04:52,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[event terms FEATURE-OF events, associated event elements PART-OF event terms, independent approach USED-FOR identifying important contents, frequency COMPARE PageRank algorithm, event map PART-OF documents, relevant approach USED-FOR identifying important contents, PageRank algorithm EVALUATE-FOR event map]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  93%|█████████▎| 466/500 [1:29:05<04:31,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 466: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f5390640884463c7dc26fdedb6987bdb in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    \n",
      "Both  rhetorical structure  and  punctuation  have been helpful in  discourse processing . Based on a  corpus annotation project , this paper reports the  discursive usage  of 6  Chinese punctuation marks  in  news commentary texts :  Colon ,  Dash ,  Ellipsis ,  Exclamation Mark ,  Question Mark , and  Semicolon . The  rhetorical patterns  of these marks are compared against  patterns  around  cue phrases  in general. Results show that these  Chinese punctuation marks , though fewer in number than  cue phrases , are easy to identify, have strong correlation with certain relations, and can be used as distinctive indicators of nuclearity in  Chinese texts .\n",
      "\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"Chinese punctuation marks FEATURE-OF cue phrases\", \"Chinese punctuation marks COMPARE cue phrases\", \"Chinese punctuation marks PART-OF Chinese texts\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  93%|█████████▎| 467/500 [1:29:44<09:32, 17.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"FERRET interactive question-answering system\", \"automatic Q/A applications PART-OF real-world environments\", \"predictive questioning FEATURE-OF Q/A\", \"users EVALUATE-FOR questions and answers\", \"user PART-OF system\", \"information EVALUATE-FOR particular scenario\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  94%|█████████▎| 468/500 [1:29:51<07:32, 14.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method introduces computational analysis MOVE structures\", \"sentences analyzed and labeled with MOVE in light of rhetorical functions\", \"abstracts automatically gathered from Web USED-FOR building language model\", \"prototype concordancer CARE FEATURE-OF move-tagged abstracts\", \"system provides promising approach to Web-based computer-assisted academic writing EVALUATE-FOR\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  94%|█████████▍| 469/500 [1:29:59<06:20, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"LOGON MT demonstrator USED-FOR machine translation pipeline\", \"output quality FEATURE-OF machine translation pipeline\", \"hand-built symbolic resources PART-OF LOGON MT demonstrator\", \"stochastic processes PART-OF LOGON MT demonstrator\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  94%|█████████▍| 470/500 [1:30:05<05:14, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"topical blog post retrieval USED-FOR ranking blog posts\", \"textual credibility indicators FEATURE-OF retrieval approach\", \"post level indicators EVALUATE-FOR retrieval effectiveness\", \"blog level indicators EVALUATE-FOR retrieval effectiveness\", \"credibility indicators COMPARE retrieval effectiveness\", \"language models FEATURE-OF retrieval approach\", \"TREC Blog track test set PART-OF experiments\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  94%|█████████▍| 471/500 [1:30:13<04:39,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"vector space model (VSM)-based text classification approach INEFFECTIVE\", \"words CONTRIBUTING LITTLE TO sentiment\", \"Nouns and verbs AMBIGUOUS for sentiment\", \"Negations and modifiers CONTRIBUTING TO sentiment\", \"sentiment vector space model (s-VSM) PROPOSED to represent song lyric document\", \"s-VSM model OUTPERFORMS VSM model in lyric-based song sentiment classification task\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  94%|█████████▍| 472/500 [1:30:21<04:23,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"metaphor interpretation REDUCED-TO recognition task\", \"generalized metaphor CONTAINS recognition network\", \"generalized metaphor CONTAINS basic mapping\", \"generalized metaphor CONTAINS transfer mappings\", \"generalized metaphor CONTAINS implicit intention component\", \"method BASED-ON existence of generalized metaphor mappings\", \"method REDUCES metaphor interpretation TO recognition task\", \"implications towards automating certain aspects of language learning DISCUSSED\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  95%|█████████▍| 473/500 [1:30:30<04:11,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"natural language interfaces FEATURE-OF input\", \"non-literal aspects of communication FEATURE-OF communication procedures\", \"personal computers USED-FOR non-literal aspects of communication\", \"interfaces BASED-ON mixture of techniques and methods\", \"natural language interfaces COMPARE personal computers\", \"natural language interfaces COMPARE traditional natural language interfaces\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  95%|█████████▍| 474/500 [1:30:38<03:45,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"natural language FEATURE-OF human listeners\", \"computer system USED-FOR natural language input\", \"users COREF their\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  95%|█████████▌| 475/500 [1:30:41<02:59,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"single-strategy parsers COMPARE multi-strategy approach\", \"parsing algorithm PART-OF parsing strategies\", \"case-frame instantiation FEATURE-OF parsing strategies\", \"parsing strategies USED-FOR processing conjunctions\", \"parsing strategies USED-FOR fragmentary input\", \"parsing strategies USED-FOR ungrammatical structures\", \"parsing strategies USED-FOR grammatically correct input\", \"heuristics EVALUATE-FOR ungrammatical input\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  95%|█████████▌| 476/500 [1:30:51<03:08,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"parser FEATURE-OF flexible parser\", \"correction USED-FOR deviant input\", \"ambiguity EVALUATE-FOR resolution\", \"user EVALUATE-FOR ambiguity resolution\", \"interaction FEATURE-OF focused interaction\", \"approach FEATURE-OF construction-specific approach\", \"parsing techniques FEATURE-OF specialized parsing techniques\", \"construction PART-OF specialized ambiguity representations\", \"construction PART-OF flexible parsing\", \"language definition PART-OF task-specific language development\", \"language definition HYPONYM-OF uniform grammar formalism\", \"testing EVALUATE-FOR changes to language definition\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  95%|█████████▌| 477/500 [1:31:03<03:31,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"extension PROPOSED-FOR GPSG grammatical formalism\", \"non-terminals CONSIST-OF finite sequences of category labels\", \"schematic variables RANGE-OVER sequences\", \"grammar STRONGLY-ADEQUATE FOR crossed serial dependencies\", \"Dutch subordinate clauses HYPONYM-OF crossed serial dependencies\", \"structures INDUCED-FOR constructions\", \"constructions FEATURE-OF data involving conjunction\", \"extension PARSEABLE-BY parsing method for GPSG\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  96%|█████████▌| 478/500 [1:31:13<03:28,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"MPS grammars FEATURE-OF metagrammatical formalisms\", \"MPS grammars PART-OF unconstrained MPS grammars\", \"proposals EVALUATE-FOR computational tractability\", \"proposals EVALUATE-FOR explanatory adequacy\", \"none of them COMPARE new directions for research on alternative metagrammatical formalisms\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  96%|█████████▌| 479/500 [1:31:25<03:33, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"natural language system USED-FOR computer aided second language learning\", \"principles of the system USED-FOR other areas\", \"general mechanism FEATURE-OF natural language system\", \"it PART-OF computer aided second language learning\", \"the aim EVALUATE-FOR assessing developments of the system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  96%|█████████▌| 480/500 [1:31:32<03:01,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"entity-oriented approach FEATURE-OF restricted-domain parsing\", \"definitions FEATURE-OF structure\", \"definitions FEATURE-OF surface representation\", \"semantic grammar COMPARE entity-oriented approach\", \"fragmentary recognition EVALUATE-FOR robust recognition of extra-grammatical input\", \"entity-oriented language definition FEATURE-OF representative samples\", \"control structure FEATURE-OF entity-oriented parser\", \"parsing strategies FEATURE-OF control structure\", \"worked examples COREF parses\", \"parser USED-FOR implementation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  96%|█████████▌| 481/500 [1:31:42<02:57,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"computer text generation system USED-FOR cohesive text\", \"lexical substitutions FEATURE-OF Paul\", \"pronominalization PART-OF lexical substitutions\", \"superordinate substitution PART-OF lexical substitutions\", \"definite noun phrase reiteration PART-OF lexical substitutions\", \"antecedence recovery EVALUATE-FOR lexical substitutions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  96%|█████████▋| 482/500 [1:31:48<02:30,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Plume approach USED-FOR parsing\", \"Plume approach BASED-ON semantic caseframe instantiation\", \"Plume approach ADVANTAGES efficiency on grammatical input\", \"Plume approach ADVANTAGES robustness in the face of ungrammatical input\", \"Plume handles passives in an AD-HOC manner\", \"Plume handles relative clauses in an AD-HOC manner\", \"Plume handles interrogatives in an AD-HOC manner\", \"Plume OUTLINES as it currently exists\", \"Plume EXTENDING to handle passives\", \"Plume EXTENDING to handle relative clauses\", \"Plume EXTENDING to handle interrogatives\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  97%|█████████▋| 483/500 [1:32:01<02:46,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Tree Adjoining Grammars HYPONYM-OF grammatical formalisms\", \"Head Grammars HYPONYM-OF grammatical formalisms\", \"weak equivalence COMPARE linguistic expressiveness\", \"Tree Adjoining Grammars COREF formalisms\", \"Head Grammars COREF formalisms\", \"linguistic expressiveness FEATURE-OF formalisms\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  97%|█████████▋| 484/500 [1:32:09<02:28,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"terminology structuring FEATURE-OF much work\", \"terms extracted FROM corpora\", \"hierarchical relations PART-OF terms\", \"terminology structuring EVALUATE-FOR lexical methods\", \"terms matched ON basis OF content words\", \"morphological variants USED-FOR matching terms\", \"lexically-induced relations COMPARE MeSH relations\", \"quantitative evaluation EVALUATE-FOR congruence\", \"qualitative analysis EVALUATE-FOR new relations\", \"MeSH designers COREF their\", \"ontological commitments FEATURE-OF automatic structuring\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  97%|█████████▋| 485/500 [1:32:18<02:20,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method OVERCOMES limitations statistical methods REQUIRE large corpora\", \"sentence-aligned corpus USED-FOR translation equivalences\", \"frequency profiles FEATURE-OF parallel concordances\", \"algorithm EVALUATE-FOR precision and recall\", \"translation lexicon PART-OF legal terminology\", \"bilingual dictionaries COMPARE lexical approaches\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  97%|█████████▋| 486/500 [1:32:25<02:01,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"UNL graphs FEATURE-OF interlingual form\", \"naive users COREF they\", \"text USED-FOR improvement sharing\", \"versions PART-OF original multilingual document\", \"liaisons ESTABLISHED-BETWEEN text and graph\", \"LO-English HYPONYM-OF L0-UNL dictionary\", \"canonical graph2tree transformation FEATURE-OF lattice\", \"pivot MT COMPARE interactive MT\", \"multilingual text authoring FEATURE-OF research\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  97%|█████████▋| 487/500 [1:32:36<01:58,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"unsupervised learning method FEATURE-OF Expectation-Maximization algorithm\", \"unsupervised learning method EVALUATE-FOR word sense disambiguation problems\", \"EM algorithm PART-OF unsupervised learning method\", \"optimum iteration number PART-OF EM algorithm\", \"two methods EVALUATE-FOR optimum iteration number\", \"50 noun WSD problems EVALUATE-FOR Japanese Dictionary Task\", \"our method COMPARE best public score\", \"our methods EVALUATE-FOR verb WSD problems\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  98%|█████████▊| 488/500 [1:32:46<01:54,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"model USED-FOR unsupervised learning of POS tags in English\", \"morphology USED-FOR providing better clues to a word's category than word order\", \"computational model FEATURE-OF POS learning\", \"Bulgarian HYPONYM-OF Slavic language\", \"word order COMPARE morphology\", \"we COREF authors\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  98%|█████████▊| 489/500 [1:32:54<01:38,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"computational model OF word segmentation FEATURE-OF statistical learning mechanisms\", \"statistical learning mechanisms FEATURE-OF cognitive psychology\", \"statistical learning mechanisms FEATURE-OF linguistics\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  98%|█████████▊| 490/500 [1:32:58<01:14,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"transfer dictionary FEATURE-OF machine translation system\", \"dictionary PART-OF machine translation system\", \"algorithm USED-FOR dictionary construction\", \"linguistic resources PART-OF dictionary\", \"language pairs PART-OF algorithm\", \"Korean-to-Japanese dictionary FEATURE-OF algorithm\", \"pivot FEATURE-OF Korean-to-Japanese dictionary\", \"one-time look up method USED-FOR automatic construction\", \"Korean-to-English dictionary PART-OF one-time look up method\", \"Japanese-to-English dictionary PART-OF one-time look up method\", \"overlapping constraint USED-FOR automatic construction\", \"Korean-to-English dictionary PART-OF overlapping constraint\", \"English-to-Japanese dictionary PART-OF overlapping constraint\", \"English-to-Korean dictionary USED-FOR automatic construction\", \"English-to-Japanese dictionary USED-FOR automatic construction\", \"first method COMPARE second method\", \"first method COMPARE third method\", \"best result EVALUATE-FOR combining the three methods\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  98%|█████████▊| 491/500 [1:33:15<01:32, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"PDTB USED-FOR extraction of syntactic and semantic features\", \"PDTB PART-OF Penn TreeBank\", \"PDTB PART-OF Propbank\", \"discourse connectives FEATURE-OF discourse structure\", \"inter-annotator agreement EVALUATE-FOR development and evaluation of practical algorithms\", \"inter-annotator agreement COMPARE inter-annotator variation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  98%|█████████▊| 492/500 [1:33:23<01:17,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"IntEx system USED-FOR gene and protein interactions\", \"approach BASED-ON splitting complex sentences into simple clausal structures\", \"biological entities TAGGED-WITH biomedical and linguistic ontologies\", \"complete interactions EXTRACTED-BY analyzing matching contents of syntactic roles\", \"extraction system HANDLES complex sentences\", \"multiple and nested interactions EXTRACTED\", \"IntEx system OUTPERFORMS two other extraction systems in performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  99%|█████████▊| 493/500 [1:33:32<01:05,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"categories FEATURE-OF coarse-grained concepts\", \"concept-concept matrix PART-OF distance values\", \"concept-distance measures COMPARE distributional word-distance measures\", \"WordNet-based measures COMPARE distributional concept-distance measures\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  99%|█████████▉| 494/500 [1:33:37<00:49,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"NLP tasks FEATURE-OF graph transformations\", \"identification of non-local dependencies EVALUATE-FOR Penn Treebank data\", \"semantic role labeling EVALUATE-FOR Proposition Bank data\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  99%|█████████▉| 495/500 [1:33:41<00:35,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"CoNLL 2008 shared task COREF challenge\", \"generative history-based latent variable model USED-FOR prediction of synchronous dependency parser derivation\", \"syntactic dependencies LAS FEATURE-OF joint task\", \"semantic dependencies F1 FEATURE-OF joint task\", \"larger model EVALUATE-FOR macro-average F1 improvement\", \"syntactic dependencies LAS EVALUATE-FOR improvement\", \"semantic dependencies F1 EVALUATE-FOR improvement\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  99%|█████████▉| 496/500 [1:33:51<00:31,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ICICLE system USED-FOR language tutoring application\", \"model FEATURE-OF language proficiency\", \"model DESIGNED-FOR writing analysis\", \"model DESIGNED-FOR feedback production\", \"model USED-FOR language assessment/correction application\", \"model PROVIDES information base\", \"user proficiency FEATURE-OF model\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  99%|█████████▉| 497/500 [1:33:58<00:22,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"TIPSTER Architecture USED-FOR text applications\", \"text processing modules PART-OF TIPSTER Architecture\", \"user interfaces EVALUATE-FOR particular applications\", \"user interface styles or conventions COMPARE TIPSTER Architecture specification\", \"GUIs FEATURE-OF TIPSTER applications\", \"TUIT FEATURE-OF multilingual TIPSTER user interfaces\", \"TUIT PART-OF CRL's work to integrate TIPSTER modules\", \"TUIT USED-FOR Oleada and Temple demonstration projects\", \"TUIT COMPARE TIPSTER User Interface Toolkit\", \"TUIT HYPONYM-OF software library\", \"TIPSTER applications PART-OF common set of configurable GUI functions\", \"CRL COREF TUIT\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses: 100%|█████████▉| 498/500 [1:34:12<00:18,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 498: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 16d379e8061999a1f64a6724ff246ed5 in your message.)\n",
      "Query: Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\n",
      "    ###\n",
      "    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of each type of relationship that may be detected:\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [rel1, rel2, rel3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    \n",
      " Recognition of proper nouns  in  Japanese text  has been studied as a part of the more general problem of  morphological analysis  in  Japanese text processing  ([1] [2]). It has also been studied in the framework of  Japanese information extraction  ([3]) in recent years. Our approach to the Multi-lingual Evaluation Task (MET) for  Japanese text  is to consider the given task as a  morphological analysis problem  in  Japanese . Our  morphological analyzer  has done all the necessary work for the  recognition and classification of proper names, numerical and temporal expressions, i.e. Named Entity (NE) items  in the  Japanese text . The  analyzer  is called \"Amorph\". Amorph recognizes  NE items  in two stages:  dictionary lookup  and  rule application . First, it uses several kinds of  dictionaries  to segment and tag  Japanese character strings . Second, based on the information resulting from the  dictionary lookup stage , a set of  rules  is applied to the  segmented strings  in order to identify  NE items . When a  segment  is found to be an  NE item , this information is added to the  segment  and it is used to generate the final output.\n",
      "\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"proper nouns FEATURE-OF morphological analysis\", \"Japanese text USED-FOR morphological analysis problem\", \"Japanese information extraction FEATURE-OF Japanese text processing\", \"MET EVALUATE-FOR Japanese text\", \"morphological analyzer PART-OF recognition and classification of NE items\", \"NE items PART-OF Japanese text\", \"Amorph PART-OF morphological analyzer\", \"NE items USED-FOR dictionary lookup\", \"dictionaries PART-OF Japanese character strings\", \"rules USED-FOR segmented strings\", \"NE items PART-OF segment\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses: 100%|█████████▉| 499/500 [1:34:58<00:20, 20.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"automatic summarization FEATURE-OF Internet services\", \"MUC USED-FOR next generation Internet\", \"SUMMAC USED-FOR next generation Internet\", \"automatic summarization USED-FOR summary generation\", \"positive feature vectors FEATURE-OF generic summaries\", \"negative feature vectors FEATURE-OF generic summaries\", \"text model FEATURE-OF relationship between nouns and verbs\", \"relationship between nouns and verbs FEATURE-OF text model\", \"discourse segment PART-OF text model\", \"sentences EVALUATE-FOR user-directed summaries\", \"NormF EVALUATE-FOR best summary\", \"NormF EVALUATE-FOR fixed summary\", \"system COMPARE average system\", \"categorization task USED-FOR summary generation\", \"adhoc task USED-FOR summary generation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses: 100%|██████████| 500/500 [1:35:13<00:00, 11.43s/it]\n"
     ]
    }
   ],
   "source": [
    "generate_responses(scierc_full_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9172e7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "      <th>prompt</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Generic', 'Start Offset': 26, 'End Offset': 32, 'Annotated Text': 'system'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 37, 'End Offset': 63, 'Annotated Text': 'categorizing unknown words'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'Generic', 'Start Offset': 71, 'End Offset': 77, 'Annotated Text': 'system'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Method', 'Start Offset': 94, 'End Offset': 122, 'Annotated Text': 'multi-component architecture'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 136, 'End Offset': 145, 'Annotated Text': 'component'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'OtherScientificTerm', 'Start Offset': 192, 'End Offset': 205, 'Annotated Text': 'unknown words'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'Generic', 'Start Offset': 240, 'End Offset': 250, 'Annotated Text': 'components'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'OtherScientificTerm', 'Start Offset': 267, 'End Offset': 272, 'Annotated Text': 'names'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'OtherScientificTerm', 'Start Offset': 279, 'End Offset': 294, 'Annotated Text': 'spelling errors'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'Generic', 'Start Offset': 303, 'End Offset': 312, 'Annotated Text': 'component'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Method', 'Start Offset': 322, 'End Offset': 348, 'Annotated Text': 'decision tree architecture'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'OtherScientificTerm', 'Start Offset': 401, 'End Offset': 413, 'Annotated Text': 'unknown word'}, 'T13': {'Annotation ID': 'T13', 'Entity': 'Generic', 'Start Offset': 421, 'End Offset': 427, 'Annotated Text': 'system'}, 'T14': {'Annotation ID': 'T14', 'Entity': 'Material', 'Start Offset': 459, 'End Offset': 479, 'Annotated Text': 'live closed captions'}, 'T15': {'Annotation ID': 'T15', 'Entity': 'OtherScientificTerm', 'Start Offset': 523, 'End Offset': 536, 'Annotated Text': 'unknown words'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED-FOR', 'Arg1': 'T4', 'Arg2': 'T3'}, 'R2': {'Relationship ID': 'R2', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T8'}, 'R3': {'Relationship ID': 'R3', 'Type': 'USED-FOR', 'Arg1': 'T11', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'PART-OF', 'Arg1': 'T5', 'Arg2': 'T4'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T9'}, 'R6': {'Relationship ID': 'R6', 'Type': 'HYPONYM-OF', 'Arg1': 'T7', 'Arg2': 'T5'}, 'R7': {'Relationship ID': 'R7', 'Type': 'COREF', 'Arg1': 'T13', 'Arg2': 'T3'}, 'R8': {'Relationship ID': 'R8', 'Type': 'USED-FOR', 'Arg1': 'T5', 'Arg2': 'T6'}, 'R9': {'Relationship ID': 'R9', 'Type': 'EVALUATE-FOR', 'Arg1': 'T14', 'Arg2': 'T13'}, 'R10': {'Relationship ID': 'R10', 'Type': 'CONJUNCTION', 'Arg1': 'T8', 'Arg2': 'T9'}, 'R11': {'Relationship ID': 'R11', 'Type': 'COREF', 'Arg1': 'T10', 'Arg2': 'T7'}, 'R12': {'Relationship ID': 'R12', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R13': {'Relationship ID': 'R13', 'Type': 'COREF', 'Arg1': 'T1', 'Arg2': 'T3'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi-component architecture USED-FOR system'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'components USED-FOR names'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'decision tree architecture USED-FOR component'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'component PART-OF multi-component architecture'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'components USED-FOR spelling errors'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'components HYPONYM-OF component'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'system COREF system'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'component USED-FOR unknown words'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'live closed captions EVALUATE-FOR system'}, 'R10': {'Relationship ID': 'R10', 'Rel': 'names CONJUNCTION spelling errors'}, 'R11': {'Relationship ID': 'R11', 'Rel': 'component COREF components'}, 'R12': {'Relationship ID': 'R12', 'Rel': 'system USED-FOR categorizing unknown words'}, 'R13': {'Relationship ID': 'R13', 'Rel': 'system COREF system'}}</td>\n",
       "      <td>[multi-component architecture USED-FOR system, components USED-FOR names, decision tree architecture USED-FOR component, component PART-OF multi-component architecture, components USED-FOR spelling errors, components HYPONYM-OF component, system COREF system, component USED-FOR unknown words, live closed captions EVALUATE-FOR system, names CONJUNCTION spelling errors, component COREF components, system USED-FOR categorizing unknown words, system COREF system]</td>\n",
       "      <td>13</td>\n",
       "      <td>Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n\\n    ###\\n</td>\n",
       "      <td>[\"system PART-OF multi-component architecture\", \"component USED-FOR identifying unknown words\", \"names COREF spelling errors\", \"component FEATURE-OF decision tree architecture\", \"system EVALUATE-FOR live closed captions\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>\\nThis paper presents a new approach to  statistical sentence generation  in which alternative  phrases  are represented as packed sets of  trees , or  forests , and then ranked statistically to choose the best one. This representation offers advantages in compactness and in the ability to represent  syntactic information . It also facilitates more efficient  statistical ranking  than a previous approach to  statistical generation . An efficient  ranking algorithm  is described, together with experimental results showing significant improvements over simple enumeration or a  lattice-based approach .\\n</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Generic', 'Start Offset': 27, 'End Offset': 35, 'Annotated Text': 'approach'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 40, 'End Offset': 71, 'Annotated Text': 'statistical sentence generation'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 139, 'End Offset': 144, 'Annotated Text': 'trees'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'OtherScientificTerm', 'Start Offset': 151, 'End Offset': 158, 'Annotated Text': 'forests'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 220, 'End Offset': 234, 'Annotated Text': 'representation'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'OtherScientificTerm', 'Start Offset': 301, 'End Offset': 322, 'Annotated Text': 'syntactic information'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'Generic', 'Start Offset': 325, 'End Offset': 327, 'Annotated Text': 'It'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'Method', 'Start Offset': 361, 'End Offset': 380, 'Annotated Text': 'statistical ranking'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'Generic', 'Start Offset': 398, 'End Offset': 406, 'Annotated Text': 'approach'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'Task', 'Start Offset': 411, 'End Offset': 433, 'Annotated Text': 'statistical generation'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Method', 'Start Offset': 450, 'End Offset': 467, 'Annotated Text': 'ranking algorithm'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'Method', 'Start Offset': 563, 'End Offset': 574, 'Annotated Text': 'enumeration'}, 'T13': {'Annotation ID': 'T13', 'Entity': 'Method', 'Start Offset': 581, 'End Offset': 603, 'Annotated Text': 'lattice-based approach'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMPARE', 'Arg1': 'T11', 'Arg2': 'T13'}, 'R2': {'Relationship ID': 'R2', 'Type': 'COMPARE', 'Arg1': 'T11', 'Arg2': 'T12'}, 'R3': {'Relationship ID': 'R3', 'Type': 'USED-FOR', 'Arg1': 'T9', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'COREF', 'Arg1': 'T7', 'Arg2': 'T5'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R6': {'Relationship ID': 'R6', 'Type': 'COREF', 'Arg1': 'T5', 'Arg2': 'T1'}, 'R7': {'Relationship ID': 'R7', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T8'}, 'R8': {'Relationship ID': 'R8', 'Type': 'COMPARE', 'Arg1': 'T7', 'Arg2': 'T9'}, 'R9': {'Relationship ID': 'R9', 'Type': 'CONJUNCTION', 'Arg1': 'T12', 'Arg2': 'T13'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'ranking algorithm COMPARE lattice-based approach'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'ranking algorithm COMPARE enumeration'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'approach USED-FOR statistical generation'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'It COREF representation'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'approach USED-FOR statistical sentence generation'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'representation COREF approach'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'It USED-FOR statistical ranking'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'It COMPARE approach'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'enumeration CONJUNCTION lattice-based approach'}}</td>\n",
       "      <td>[ranking algorithm COMPARE lattice-based approach, ranking algorithm COMPARE enumeration, approach USED-FOR statistical generation, It COREF representation, approach USED-FOR statistical sentence generation, representation COREF approach, It USED-FOR statistical ranking, It COMPARE approach, enumeration CONJUNCTION lattice-based approach]</td>\n",
       "      <td>9</td>\n",
       "      <td>Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nThis paper presents a new approach to  statistical sentence generation  in which alternative  phrases  are represented as packed sets of  trees , or  forests , and then ranked statistically to choose the best one. This representation offers advantages in compactness and in the ability to represent  syntactic information . It also facilitates more efficient  statistical ranking  than a previous approach to  statistical generation . An efficient  ranking algorithm  is described, together with experimental results showing significant improvements over simple enumeration or a  lattice-based approach .\\n\\n    ###\\n</td>\n",
       "      <td>[\"approach FEATURE-OF statistical sentence generation\", \"alternative phrases PART-OF packed sets\", \"alternative phrases PART-OF forests\", \"representation FEATURE-OF advantages\", \"representation FEATURE-OF ability to represent syntactic information\", \"ranking algorithm FEATURE-OF efficient statistical ranking\", \"experimental results EVALUATE-FOR improvements over simple enumeration\", \"experimental results EVALUATE-FOR lattice-based approach\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>\\n This paper describes a domain independent strategy for the  multimedia articulation of answers  elicited by a  natural language interface  to  database query applications  .  Multimedia answers  include  videodisc images  and heuristically-produced complete  sentences  in  text  or  text-to-speech form  .  Deictic reference  and  feedback  about the  discourse  are enabled. The  interface  thus presents the application as cooperative and conversational.</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Method', 'Start Offset': 26, 'End Offset': 53, 'Annotated Text': 'domain independent strategy'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 63, 'End Offset': 97, 'Annotated Text': 'multimedia articulation of answers'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 114, 'End Offset': 140, 'Annotated Text': 'natural language interface'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Task', 'Start Offset': 146, 'End Offset': 173, 'Annotated Text': 'database query applications'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Material', 'Start Offset': 178, 'End Offset': 196, 'Annotated Text': 'Multimedia answers'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'Material', 'Start Offset': 207, 'End Offset': 223, 'Annotated Text': 'videodisc images'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'OtherScientificTerm', 'Start Offset': 287, 'End Offset': 306, 'Annotated Text': 'text-to-speech form'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'OtherScientificTerm', 'Start Offset': 311, 'End Offset': 328, 'Annotated Text': 'Deictic reference'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'OtherScientificTerm', 'Start Offset': 335, 'End Offset': 343, 'Annotated Text': 'feedback'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'OtherScientificTerm', 'Start Offset': 356, 'End Offset': 365, 'Annotated Text': 'discourse'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Generic', 'Start Offset': 385, 'End Offset': 394, 'Annotated Text': 'interface'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'Generic', 'Start Offset': 414, 'End Offset': 425, 'Annotated Text': 'application'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEATURE-OF', 'Arg1': 'T9', 'Arg2': 'T10'}, 'R2': {'Relationship ID': 'R2', 'Type': 'PART-OF', 'Arg1': 'T6', 'Arg2': 'T5'}, 'R3': {'Relationship ID': 'R3', 'Type': 'FEATURE-OF', 'Arg1': 'T8', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'COREF', 'Arg1': 'T11', 'Arg2': 'T3'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R6': {'Relationship ID': 'R6', 'Type': 'USED-FOR', 'Arg1': 'T3', 'Arg2': 'T4'}, 'R7': {'Relationship ID': 'R7', 'Type': 'COREF', 'Arg1': 'T12', 'Arg2': 'T4'}, 'R8': {'Relationship ID': 'R8', 'Type': 'CONJUNCTION', 'Arg1': 'T8', 'Arg2': 'T9'}, 'R9': {'Relationship ID': 'R9', 'Type': 'USED-FOR', 'Arg1': 'T2', 'Arg2': 'T3'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'feedback FEATURE-OF discourse'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'videodisc images PART-OF Multimedia answers'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'Deictic reference FEATURE-OF discourse'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'interface COREF natural language interface'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'domain independent strategy USED-FOR multimedia articulation of answers'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'natural language interface USED-FOR database query applications'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'application COREF database query applications'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'Deictic reference CONJUNCTION feedback'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'multimedia articulation of answers USED-FOR natural language interface'}}</td>\n",
       "      <td>[feedback FEATURE-OF discourse, videodisc images PART-OF Multimedia answers, Deictic reference FEATURE-OF discourse, interface COREF natural language interface, domain independent strategy USED-FOR multimedia articulation of answers, natural language interface USED-FOR database query applications, application COREF database query applications, Deictic reference CONJUNCTION feedback, multimedia articulation of answers USED-FOR natural language interface]</td>\n",
       "      <td>9</td>\n",
       "      <td>Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n     \\n This paper describes a domain independent strategy for the  multimedia articulation of answers  elicited by a  natural language interface  to  database query applications  .  Multimedia answers  include  videodisc images  and heuristically-produced complete  sentences  in  text  or  text-to-speech form  .  Deictic reference  and  feedback  about the  discourse  are enabled. The  interface  thus presents the application as cooperative and conversational. \\n    ###\\n</td>\n",
       "      <td>[\"natural language interface USED-FOR database query applications\", \"multimedia answers FEATURE-OF videodisc images, complete sentences\", \"text-to-speech form FEATURE-OF heuristically-produced sentences\", \"Deictic reference PART-OF multimedia answers\", \"feedback PART-OF discourse\", \"interface PRESENTS application as cooperative and conversational\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>\\n In this paper, we describe the  pronominal anaphora resolution module  of  Lucy  , a portable  English understanding system  . The design of this module was motivated by the observation that, although there exist many theories of  anaphora resolution  , no one of these theories is complete. Thus we have implemented a  blackboard-like architecture  in which individual  partial theories  can be encoded as separate modules that can interact to propose candidate  antecedents  and to evaluate each other's proposals.</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Method', 'Start Offset': 35, 'End Offset': 72, 'Annotated Text': 'pronominal anaphora resolution module'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Method', 'Start Offset': 78, 'End Offset': 82, 'Annotated Text': 'Lucy'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'Method', 'Start Offset': 98, 'End Offset': 126, 'Annotated Text': 'English understanding system'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Generic', 'Start Offset': 149, 'End Offset': 155, 'Annotated Text': 'module'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Task', 'Start Offset': 234, 'End Offset': 253, 'Annotated Text': 'anaphora resolution'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'Method', 'Start Offset': 323, 'End Offset': 351, 'Annotated Text': 'blackboard-like architecture'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART-OF', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R2': {'Relationship ID': 'R2', 'Type': 'COREF', 'Arg1': 'T4', 'Arg2': 'T1'}, 'R3': {'Relationship ID': 'R3', 'Type': 'HYPONYM-OF', 'Arg1': 'T2', 'Arg2': 'T3'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'pronominal anaphora resolution module PART-OF Lucy'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'module COREF pronominal anaphora resolution module'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'Lucy HYPONYM-OF English understanding system'}}</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF Lucy, module COREF pronominal anaphora resolution module, Lucy HYPONYM-OF English understanding system]</td>\n",
       "      <td>3</td>\n",
       "      <td>Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n     \\n In this paper, we describe the  pronominal anaphora resolution module  of  Lucy  , a portable  English understanding system  . The design of this module was motivated by the observation that, although there exist many theories of  anaphora resolution  , no one of these theories is complete. Thus we have implemented a  blackboard-like architecture  in which individual  partial theories  can be encoded as separate modules that can interact to propose candidate  antecedents  and to evaluate each other's proposals. \\n    ###\\n</td>\n",
       "      <td>[\"pronominal anaphora resolution module PART-OF Lucy\", \"anaphora resolution HYPONYM-OF theories\", \"blackboard-like architecture FEATURE-OF module design\", \"partial theories PART-OF blackboard-like architecture\", \"antecedents USED-FOR candidate proposals\", \"modules EVALUATE-FOR proposals\", \"proposals COMPARE each other's proposals\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>\\nIn our current research into the design of  cognitively well-motivated interfaces  relying primarily on the  display of graphical information , we have observed that  graphical information  alone does not provide sufficient support to users - particularly when situations arise that do not simply conform to the users' expectations. This can occur due to too much  information  being requested, too little,  information  of the wrong kind, etc. To solve this problem, we are working towards the integration of  natural language generation  to augment the  interaction</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task', 'Start Offset': 45, 'End Offset': 82, 'Annotated Text': 'cognitively well-motivated interfaces'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'OtherScientificTerm', 'Start Offset': 110, 'End Offset': 142, 'Annotated Text': 'display of graphical information'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 168, 'End Offset': 189, 'Annotated Text': 'graphical information'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Task', 'Start Offset': 512, 'End Offset': 539, 'Annotated Text': 'natural language generation'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 557, 'End Offset': 568, 'Annotated Text': 'interaction'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED-FOR', 'Arg1': 'T2', 'Arg2': 'T1'}, 'R2': {'Relationship ID': 'R2', 'Type': 'USED-FOR', 'Arg1': 'T4', 'Arg2': 'T5'}, 'R3': {'Relationship ID': 'R3', 'Type': 'COREF', 'Arg1': 'T3', 'Arg2': 'T2'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'display of graphical information USED-FOR cognitively well-motivated interfaces'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'natural language generation USED-FOR interaction'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'graphical information COREF display of graphical information'}}</td>\n",
       "      <td>[display of graphical information USED-FOR cognitively well-motivated interfaces, natural language generation USED-FOR interaction, graphical information COREF display of graphical information]</td>\n",
       "      <td>3</td>\n",
       "      <td>Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nIn our current research into the design of  cognitively well-motivated interfaces  relying primarily on the  display of graphical information , we have observed that  graphical information  alone does not provide sufficient support to users - particularly when situations arise that do not simply conform to the users' expectations. This can occur due to too much  information  being requested, too little,  information  of the wrong kind, etc. To solve this problem, we are working towards the integration of  natural language generation  to augment the  interaction \\n    ###\\n</td>\n",
       "      <td>[\"natural language generation USED-FOR interaction\", \"graphical information FEATURE-OF cognitively well-motivated interfaces\", \"information EVALUATE-FOR user support\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 entities                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               relationships                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             populated_rels                                                                                                                                                                                                                                                                                                                                                                                                                                                        simplified_populated_rels  rel_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 prompt                                                                                                                                                                                                                                                                                                                                                                                                                                                      responses\n",
       "0    A00-1024                                                                     \\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n  {'T1': {'Annotation ID': 'T1', 'Entity': 'Generic', 'Start Offset': 26, 'End Offset': 32, 'Annotated Text': 'system'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 37, 'End Offset': 63, 'Annotated Text': 'categorizing unknown words'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'Generic', 'Start Offset': 71, 'End Offset': 77, 'Annotated Text': 'system'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Method', 'Start Offset': 94, 'End Offset': 122, 'Annotated Text': 'multi-component architecture'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 136, 'End Offset': 145, 'Annotated Text': 'component'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'OtherScientificTerm', 'Start Offset': 192, 'End Offset': 205, 'Annotated Text': 'unknown words'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'Generic', 'Start Offset': 240, 'End Offset': 250, 'Annotated Text': 'components'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'OtherScientificTerm', 'Start Offset': 267, 'End Offset': 272, 'Annotated Text': 'names'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'OtherScientificTerm', 'Start Offset': 279, 'End Offset': 294, 'Annotated Text': 'spelling errors'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'Generic', 'Start Offset': 303, 'End Offset': 312, 'Annotated Text': 'component'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Method', 'Start Offset': 322, 'End Offset': 348, 'Annotated Text': 'decision tree architecture'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'OtherScientificTerm', 'Start Offset': 401, 'End Offset': 413, 'Annotated Text': 'unknown word'}, 'T13': {'Annotation ID': 'T13', 'Entity': 'Generic', 'Start Offset': 421, 'End Offset': 427, 'Annotated Text': 'system'}, 'T14': {'Annotation ID': 'T14', 'Entity': 'Material', 'Start Offset': 459, 'End Offset': 479, 'Annotated Text': 'live closed captions'}, 'T15': {'Annotation ID': 'T15', 'Entity': 'OtherScientificTerm', 'Start Offset': 523, 'End Offset': 536, 'Annotated Text': 'unknown words'}}  {'R1': {'Relationship ID': 'R1', 'Type': 'USED-FOR', 'Arg1': 'T4', 'Arg2': 'T3'}, 'R2': {'Relationship ID': 'R2', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T8'}, 'R3': {'Relationship ID': 'R3', 'Type': 'USED-FOR', 'Arg1': 'T11', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'PART-OF', 'Arg1': 'T5', 'Arg2': 'T4'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T9'}, 'R6': {'Relationship ID': 'R6', 'Type': 'HYPONYM-OF', 'Arg1': 'T7', 'Arg2': 'T5'}, 'R7': {'Relationship ID': 'R7', 'Type': 'COREF', 'Arg1': 'T13', 'Arg2': 'T3'}, 'R8': {'Relationship ID': 'R8', 'Type': 'USED-FOR', 'Arg1': 'T5', 'Arg2': 'T6'}, 'R9': {'Relationship ID': 'R9', 'Type': 'EVALUATE-FOR', 'Arg1': 'T14', 'Arg2': 'T13'}, 'R10': {'Relationship ID': 'R10', 'Type': 'CONJUNCTION', 'Arg1': 'T8', 'Arg2': 'T9'}, 'R11': {'Relationship ID': 'R11', 'Type': 'COREF', 'Arg1': 'T10', 'Arg2': 'T7'}, 'R12': {'Relationship ID': 'R12', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R13': {'Relationship ID': 'R13', 'Type': 'COREF', 'Arg1': 'T1', 'Arg2': 'T3'}}  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi-component architecture USED-FOR system'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'components USED-FOR names'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'decision tree architecture USED-FOR component'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'component PART-OF multi-component architecture'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'components USED-FOR spelling errors'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'components HYPONYM-OF component'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'system COREF system'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'component USED-FOR unknown words'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'live closed captions EVALUATE-FOR system'}, 'R10': {'Relationship ID': 'R10', 'Rel': 'names CONJUNCTION spelling errors'}, 'R11': {'Relationship ID': 'R11', 'Rel': 'component COREF components'}, 'R12': {'Relationship ID': 'R12', 'Rel': 'system USED-FOR categorizing unknown words'}, 'R13': {'Relationship ID': 'R13', 'Rel': 'system COREF system'}}  [multi-component architecture USED-FOR system, components USED-FOR names, decision tree architecture USED-FOR component, component PART-OF multi-component architecture, components USED-FOR spelling errors, components HYPONYM-OF component, system COREF system, component USED-FOR unknown words, live closed captions EVALUATE-FOR system, names CONJUNCTION spelling errors, component COREF components, system USED-FOR categorizing unknown words, system COREF system]         13                                                                     Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n\\n    ###\\n                                                                                                                                                                                                                                      [\"system PART-OF multi-component architecture\", \"component USED-FOR identifying unknown words\", \"names COREF spelling errors\", \"component FEATURE-OF decision tree architecture\", \"system EVALUATE-FOR live closed captions\"]\n",
       "1    A00-2023  \\nThis paper presents a new approach to  statistical sentence generation  in which alternative  phrases  are represented as packed sets of  trees , or  forests , and then ranked statistically to choose the best one. This representation offers advantages in compactness and in the ability to represent  syntactic information . It also facilitates more efficient  statistical ranking  than a previous approach to  statistical generation . An efficient  ranking algorithm  is described, together with experimental results showing significant improvements over simple enumeration or a  lattice-based approach .\\n                                                                                                                                                                                                                                                                                      {'T1': {'Annotation ID': 'T1', 'Entity': 'Generic', 'Start Offset': 27, 'End Offset': 35, 'Annotated Text': 'approach'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 40, 'End Offset': 71, 'Annotated Text': 'statistical sentence generation'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 139, 'End Offset': 144, 'Annotated Text': 'trees'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'OtherScientificTerm', 'Start Offset': 151, 'End Offset': 158, 'Annotated Text': 'forests'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 220, 'End Offset': 234, 'Annotated Text': 'representation'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'OtherScientificTerm', 'Start Offset': 301, 'End Offset': 322, 'Annotated Text': 'syntactic information'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'Generic', 'Start Offset': 325, 'End Offset': 327, 'Annotated Text': 'It'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'Method', 'Start Offset': 361, 'End Offset': 380, 'Annotated Text': 'statistical ranking'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'Generic', 'Start Offset': 398, 'End Offset': 406, 'Annotated Text': 'approach'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'Task', 'Start Offset': 411, 'End Offset': 433, 'Annotated Text': 'statistical generation'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Method', 'Start Offset': 450, 'End Offset': 467, 'Annotated Text': 'ranking algorithm'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'Method', 'Start Offset': 563, 'End Offset': 574, 'Annotated Text': 'enumeration'}, 'T13': {'Annotation ID': 'T13', 'Entity': 'Method', 'Start Offset': 581, 'End Offset': 603, 'Annotated Text': 'lattice-based approach'}}                                                                                                                                                                                                                                                                                                                                                  {'R1': {'Relationship ID': 'R1', 'Type': 'COMPARE', 'Arg1': 'T11', 'Arg2': 'T13'}, 'R2': {'Relationship ID': 'R2', 'Type': 'COMPARE', 'Arg1': 'T11', 'Arg2': 'T12'}, 'R3': {'Relationship ID': 'R3', 'Type': 'USED-FOR', 'Arg1': 'T9', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'COREF', 'Arg1': 'T7', 'Arg2': 'T5'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R6': {'Relationship ID': 'R6', 'Type': 'COREF', 'Arg1': 'T5', 'Arg2': 'T1'}, 'R7': {'Relationship ID': 'R7', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T8'}, 'R8': {'Relationship ID': 'R8', 'Type': 'COMPARE', 'Arg1': 'T7', 'Arg2': 'T9'}, 'R9': {'Relationship ID': 'R9', 'Type': 'CONJUNCTION', 'Arg1': 'T12', 'Arg2': 'T13'}}                                                                                                                                                                                                                                                                                                             {'R1': {'Relationship ID': 'R1', 'Rel': 'ranking algorithm COMPARE lattice-based approach'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'ranking algorithm COMPARE enumeration'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'approach USED-FOR statistical generation'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'It COREF representation'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'approach USED-FOR statistical sentence generation'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'representation COREF approach'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'It USED-FOR statistical ranking'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'It COMPARE approach'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'enumeration CONJUNCTION lattice-based approach'}}                                                                                                                             [ranking algorithm COMPARE lattice-based approach, ranking algorithm COMPARE enumeration, approach USED-FOR statistical generation, It COREF representation, approach USED-FOR statistical sentence generation, representation COREF approach, It USED-FOR statistical ranking, It COMPARE approach, enumeration CONJUNCTION lattice-based approach]          9  Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nThis paper presents a new approach to  statistical sentence generation  in which alternative  phrases  are represented as packed sets of  trees , or  forests , and then ranked statistically to choose the best one. This representation offers advantages in compactness and in the ability to represent  syntactic information . It also facilitates more efficient  statistical ranking  than a previous approach to  statistical generation . An efficient  ranking algorithm  is described, together with experimental results showing significant improvements over simple enumeration or a  lattice-based approach .\\n\\n    ###\\n      [\"approach FEATURE-OF statistical sentence generation\", \"alternative phrases PART-OF packed sets\", \"alternative phrases PART-OF forests\", \"representation FEATURE-OF advantages\", \"representation FEATURE-OF ability to represent syntactic information\", \"ranking algorithm FEATURE-OF efficient statistical ranking\", \"experimental results EVALUATE-FOR improvements over simple enumeration\", \"experimental results EVALUATE-FOR lattice-based approach\"]\n",
       "2    A88-1001                                                                                                                                                     \\n This paper describes a domain independent strategy for the  multimedia articulation of answers  elicited by a  natural language interface  to  database query applications  .  Multimedia answers  include  videodisc images  and heuristically-produced complete  sentences  in  text  or  text-to-speech form  .  Deictic reference  and  feedback  about the  discourse  are enabled. The  interface  thus presents the application as cooperative and conversational.                                                                                                                                                                                                                                                                                                                                            {'T1': {'Annotation ID': 'T1', 'Entity': 'Method', 'Start Offset': 26, 'End Offset': 53, 'Annotated Text': 'domain independent strategy'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 63, 'End Offset': 97, 'Annotated Text': 'multimedia articulation of answers'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 114, 'End Offset': 140, 'Annotated Text': 'natural language interface'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Task', 'Start Offset': 146, 'End Offset': 173, 'Annotated Text': 'database query applications'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Material', 'Start Offset': 178, 'End Offset': 196, 'Annotated Text': 'Multimedia answers'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'Material', 'Start Offset': 207, 'End Offset': 223, 'Annotated Text': 'videodisc images'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'OtherScientificTerm', 'Start Offset': 287, 'End Offset': 306, 'Annotated Text': 'text-to-speech form'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'OtherScientificTerm', 'Start Offset': 311, 'End Offset': 328, 'Annotated Text': 'Deictic reference'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'OtherScientificTerm', 'Start Offset': 335, 'End Offset': 343, 'Annotated Text': 'feedback'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'OtherScientificTerm', 'Start Offset': 356, 'End Offset': 365, 'Annotated Text': 'discourse'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Generic', 'Start Offset': 385, 'End Offset': 394, 'Annotated Text': 'interface'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'Generic', 'Start Offset': 414, 'End Offset': 425, 'Annotated Text': 'application'}}                                                                                                                                                                                                                                                                                                                                               {'R1': {'Relationship ID': 'R1', 'Type': 'FEATURE-OF', 'Arg1': 'T9', 'Arg2': 'T10'}, 'R2': {'Relationship ID': 'R2', 'Type': 'PART-OF', 'Arg1': 'T6', 'Arg2': 'T5'}, 'R3': {'Relationship ID': 'R3', 'Type': 'FEATURE-OF', 'Arg1': 'T8', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'COREF', 'Arg1': 'T11', 'Arg2': 'T3'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R6': {'Relationship ID': 'R6', 'Type': 'USED-FOR', 'Arg1': 'T3', 'Arg2': 'T4'}, 'R7': {'Relationship ID': 'R7', 'Type': 'COREF', 'Arg1': 'T12', 'Arg2': 'T4'}, 'R8': {'Relationship ID': 'R8', 'Type': 'CONJUNCTION', 'Arg1': 'T8', 'Arg2': 'T9'}, 'R9': {'Relationship ID': 'R9', 'Type': 'USED-FOR', 'Arg1': 'T2', 'Arg2': 'T3'}}                                                                                                                                                                                        {'R1': {'Relationship ID': 'R1', 'Rel': 'feedback FEATURE-OF discourse'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'videodisc images PART-OF Multimedia answers'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'Deictic reference FEATURE-OF discourse'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'interface COREF natural language interface'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'domain independent strategy USED-FOR multimedia articulation of answers'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'natural language interface USED-FOR database query applications'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'application COREF database query applications'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'Deictic reference CONJUNCTION feedback'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'multimedia articulation of answers USED-FOR natural language interface'}}        [feedback FEATURE-OF discourse, videodisc images PART-OF Multimedia answers, Deictic reference FEATURE-OF discourse, interface COREF natural language interface, domain independent strategy USED-FOR multimedia articulation of answers, natural language interface USED-FOR database query applications, application COREF database query applications, Deictic reference CONJUNCTION feedback, multimedia articulation of answers USED-FOR natural language interface]          9                                                                                                                                                    Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n     \\n This paper describes a domain independent strategy for the  multimedia articulation of answers  elicited by a  natural language interface  to  database query applications  .  Multimedia answers  include  videodisc images  and heuristically-produced complete  sentences  in  text  or  text-to-speech form  .  Deictic reference  and  feedback  about the  discourse  are enabled. The  interface  thus presents the application as cooperative and conversational. \\n    ###\\n                                                                                                     [\"natural language interface USED-FOR database query applications\", \"multimedia answers FEATURE-OF videodisc images, complete sentences\", \"text-to-speech form FEATURE-OF heuristically-produced sentences\", \"Deictic reference PART-OF multimedia answers\", \"feedback PART-OF discourse\", \"interface PRESENTS application as cooperative and conversational\"]\n",
       "3    A88-1003                                                                                          \\n In this paper, we describe the  pronominal anaphora resolution module  of  Lucy  , a portable  English understanding system  . The design of this module was motivated by the observation that, although there exist many theories of  anaphora resolution  , no one of these theories is complete. Thus we have implemented a  blackboard-like architecture  in which individual  partial theories  can be encoded as separate modules that can interact to propose candidate  antecedents  and to evaluate each other's proposals.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                {'T1': {'Annotation ID': 'T1', 'Entity': 'Method', 'Start Offset': 35, 'End Offset': 72, 'Annotated Text': 'pronominal anaphora resolution module'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Method', 'Start Offset': 78, 'End Offset': 82, 'Annotated Text': 'Lucy'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'Method', 'Start Offset': 98, 'End Offset': 126, 'Annotated Text': 'English understanding system'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Generic', 'Start Offset': 149, 'End Offset': 155, 'Annotated Text': 'module'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Task', 'Start Offset': 234, 'End Offset': 253, 'Annotated Text': 'anaphora resolution'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'Method', 'Start Offset': 323, 'End Offset': 351, 'Annotated Text': 'blackboard-like architecture'}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {'R1': {'Relationship ID': 'R1', 'Type': 'PART-OF', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R2': {'Relationship ID': 'R2', 'Type': 'COREF', 'Arg1': 'T4', 'Arg2': 'T1'}, 'R3': {'Relationship ID': 'R3', 'Type': 'HYPONYM-OF', 'Arg1': 'T2', 'Arg2': 'T3'}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       {'R1': {'Relationship ID': 'R1', 'Rel': 'pronominal anaphora resolution module PART-OF Lucy'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'module COREF pronominal anaphora resolution module'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'Lucy HYPONYM-OF English understanding system'}}                                                                                                                                                                                                                                                                                                                           [pronominal anaphora resolution module PART-OF Lucy, module COREF pronominal anaphora resolution module, Lucy HYPONYM-OF English understanding system]          3                                                                                         Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n     \\n In this paper, we describe the  pronominal anaphora resolution module  of  Lucy  , a portable  English understanding system  . The design of this module was motivated by the observation that, although there exist many theories of  anaphora resolution  , no one of these theories is complete. Thus we have implemented a  blackboard-like architecture  in which individual  partial theories  can be encoded as separate modules that can interact to propose candidate  antecedents  and to evaluate each other's proposals. \\n    ###\\n                                                                                                                      [\"pronominal anaphora resolution module PART-OF Lucy\", \"anaphora resolution HYPONYM-OF theories\", \"blackboard-like architecture FEATURE-OF module design\", \"partial theories PART-OF blackboard-like architecture\", \"antecedents USED-FOR candidate proposals\", \"modules EVALUATE-FOR proposals\", \"proposals COMPARE each other's proposals\"]\n",
       "4    A92-1010                                        \\nIn our current research into the design of  cognitively well-motivated interfaces  relying primarily on the  display of graphical information , we have observed that  graphical information  alone does not provide sufficient support to users - particularly when situations arise that do not simply conform to the users' expectations. This can occur due to too much  information  being requested, too little,  information  of the wrong kind, etc. To solve this problem, we are working towards the integration of  natural language generation  to augment the  interaction                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                {'T1': {'Annotation ID': 'T1', 'Entity': 'Task', 'Start Offset': 45, 'End Offset': 82, 'Annotated Text': 'cognitively well-motivated interfaces'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'OtherScientificTerm', 'Start Offset': 110, 'End Offset': 142, 'Annotated Text': 'display of graphical information'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 168, 'End Offset': 189, 'Annotated Text': 'graphical information'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Task', 'Start Offset': 512, 'End Offset': 539, 'Annotated Text': 'natural language generation'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 557, 'End Offset': 568, 'Annotated Text': 'interaction'}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            {'R1': {'Relationship ID': 'R1', 'Type': 'USED-FOR', 'Arg1': 'T2', 'Arg2': 'T1'}, 'R2': {'Relationship ID': 'R2', 'Type': 'USED-FOR', 'Arg1': 'T4', 'Arg2': 'T5'}, 'R3': {'Relationship ID': 'R3', 'Type': 'COREF', 'Arg1': 'T3', 'Arg2': 'T2'}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            {'R1': {'Relationship ID': 'R1', 'Rel': 'display of graphical information USED-FOR cognitively well-motivated interfaces'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'natural language generation USED-FOR interaction'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'graphical information COREF display of graphical information'}}                                                                                                                                                                                                                                                                                [display of graphical information USED-FOR cognitively well-motivated interfaces, natural language generation USED-FOR interaction, graphical information COREF display of graphical information]          3                                        Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nIn our current research into the design of  cognitively well-motivated interfaces  relying primarily on the  display of graphical information , we have observed that  graphical information  alone does not provide sufficient support to users - particularly when situations arise that do not simply conform to the users' expectations. This can occur due to too much  information  being requested, too little,  information  of the wrong kind, etc. To solve this problem, we are working towards the integration of  natural language generation  to augment the  interaction \\n    ###\\n                                                                                                                                                                                                                                                                                            [\"natural language generation USED-FOR interaction\", \"graphical information FEATURE-OF cognitively well-motivated interfaces\", \"information EVALUATE-FOR user support\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scierc_full_responses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4403399d",
   "metadata": {},
   "source": [
    "## Compare count of rels found to annotated count.\n",
    "* Very unlikely to get a hard match of the entire list of rels between simplified_populated_rels and responses.\n",
    "* Also unlikely to get items to match across lists.\n",
    "\n",
    "* Can analyse count of rels combined with manual evaluation.\n",
    "\n",
    "* seems to have formed new rel outside of restricted rel list: OFFERS-ADVANTAGES-IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "992641b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "      <th>prompt</th>\n",
       "      <th>responses</th>\n",
       "      <th>responses_rels_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Generic', 'Start Offset': 26, 'End Offset': 32, 'Annotated Text': 'system'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 37, 'End Offset': 63, 'Annotated Text': 'categorizing unknown words'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'Generic', 'Start Offset': 71, 'End Offset': 77, 'Annotated Text': 'system'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Method', 'Start Offset': 94, 'End Offset': 122, 'Annotated Text': 'multi-component architecture'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 136, 'End Offset': 145, 'Annotated Text': 'component'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'OtherScientificTerm', 'Start Offset': 192, 'End Offset': 205, 'Annotated Text': 'unknown words'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'Generic', 'Start Offset': 240, 'End Offset': 250, 'Annotated Text': 'components'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'OtherScientificTerm', 'Start Offset': 267, 'End Offset': 272, 'Annotated Text': 'names'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'OtherScientificTerm', 'Start Offset': 279, 'End Offset': 294, 'Annotated Text': 'spelling errors'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'Generic', 'Start Offset': 303, 'End Offset': 312, 'Annotated Text': 'component'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Method', 'Start Offset': 322, 'End Offset': 348, 'Annotated Text': 'decision tree architecture'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'OtherScientificTerm', 'Start Offset': 401, 'End Offset': 413, 'Annotated Text': 'unknown word'}, 'T13': {'Annotation ID': 'T13', 'Entity': 'Generic', 'Start Offset': 421, 'End Offset': 427, 'Annotated Text': 'system'}, 'T14': {'Annotation ID': 'T14', 'Entity': 'Material', 'Start Offset': 459, 'End Offset': 479, 'Annotated Text': 'live closed captions'}, 'T15': {'Annotation ID': 'T15', 'Entity': 'OtherScientificTerm', 'Start Offset': 523, 'End Offset': 536, 'Annotated Text': 'unknown words'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED-FOR', 'Arg1': 'T4', 'Arg2': 'T3'}, 'R2': {'Relationship ID': 'R2', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T8'}, 'R3': {'Relationship ID': 'R3', 'Type': 'USED-FOR', 'Arg1': 'T11', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'PART-OF', 'Arg1': 'T5', 'Arg2': 'T4'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T9'}, 'R6': {'Relationship ID': 'R6', 'Type': 'HYPONYM-OF', 'Arg1': 'T7', 'Arg2': 'T5'}, 'R7': {'Relationship ID': 'R7', 'Type': 'COREF', 'Arg1': 'T13', 'Arg2': 'T3'}, 'R8': {'Relationship ID': 'R8', 'Type': 'USED-FOR', 'Arg1': 'T5', 'Arg2': 'T6'}, 'R9': {'Relationship ID': 'R9', 'Type': 'EVALUATE-FOR', 'Arg1': 'T14', 'Arg2': 'T13'}, 'R10': {'Relationship ID': 'R10', 'Type': 'CONJUNCTION', 'Arg1': 'T8', 'Arg2': 'T9'}, 'R11': {'Relationship ID': 'R11', 'Type': 'COREF', 'Arg1': 'T10', 'Arg2': 'T7'}, 'R12': {'Relationship ID': 'R12', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R13': {'Relationship ID': 'R13', 'Type': 'COREF', 'Arg1': 'T1', 'Arg2': 'T3'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi-component architecture USED-FOR system'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'components USED-FOR names'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'decision tree architecture USED-FOR component'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'component PART-OF multi-component architecture'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'components USED-FOR spelling errors'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'components HYPONYM-OF component'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'system COREF system'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'component USED-FOR unknown words'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'live closed captions EVALUATE-FOR system'}, 'R10': {'Relationship ID': 'R10', 'Rel': 'names CONJUNCTION spelling errors'}, 'R11': {'Relationship ID': 'R11', 'Rel': 'component COREF components'}, 'R12': {'Relationship ID': 'R12', 'Rel': 'system USED-FOR categorizing unknown words'}, 'R13': {'Relationship ID': 'R13', 'Rel': 'system COREF system'}}</td>\n",
       "      <td>[multi-component architecture USED-FOR system, components USED-FOR names, decision tree architecture USED-FOR component, component PART-OF multi-component architecture, components USED-FOR spelling errors, components HYPONYM-OF component, system COREF system, component USED-FOR unknown words, live closed captions EVALUATE-FOR system, names CONJUNCTION spelling errors, component COREF components, system USED-FOR categorizing unknown words, system COREF system]</td>\n",
       "      <td>13</td>\n",
       "      <td>Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n\\n    ###\\n</td>\n",
       "      <td>[\"system PART-OF multi-component architecture\", \"component USED-FOR identifying unknown words\", \"names COREF spelling errors\", \"component FEATURE-OF decision tree architecture\", \"system EVALUATE-FOR live closed captions\"]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>\\nThis paper presents a new approach to  statistical sentence generation  in which alternative  phrases  are represented as packed sets of  trees , or  forests , and then ranked statistically to choose the best one. This representation offers advantages in compactness and in the ability to represent  syntactic information . It also facilitates more efficient  statistical ranking  than a previous approach to  statistical generation . An efficient  ranking algorithm  is described, together with experimental results showing significant improvements over simple enumeration or a  lattice-based approach .\\n</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Generic', 'Start Offset': 27, 'End Offset': 35, 'Annotated Text': 'approach'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 40, 'End Offset': 71, 'Annotated Text': 'statistical sentence generation'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 139, 'End Offset': 144, 'Annotated Text': 'trees'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'OtherScientificTerm', 'Start Offset': 151, 'End Offset': 158, 'Annotated Text': 'forests'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 220, 'End Offset': 234, 'Annotated Text': 'representation'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'OtherScientificTerm', 'Start Offset': 301, 'End Offset': 322, 'Annotated Text': 'syntactic information'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'Generic', 'Start Offset': 325, 'End Offset': 327, 'Annotated Text': 'It'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'Method', 'Start Offset': 361, 'End Offset': 380, 'Annotated Text': 'statistical ranking'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'Generic', 'Start Offset': 398, 'End Offset': 406, 'Annotated Text': 'approach'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'Task', 'Start Offset': 411, 'End Offset': 433, 'Annotated Text': 'statistical generation'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Method', 'Start Offset': 450, 'End Offset': 467, 'Annotated Text': 'ranking algorithm'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'Method', 'Start Offset': 563, 'End Offset': 574, 'Annotated Text': 'enumeration'}, 'T13': {'Annotation ID': 'T13', 'Entity': 'Method', 'Start Offset': 581, 'End Offset': 603, 'Annotated Text': 'lattice-based approach'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMPARE', 'Arg1': 'T11', 'Arg2': 'T13'}, 'R2': {'Relationship ID': 'R2', 'Type': 'COMPARE', 'Arg1': 'T11', 'Arg2': 'T12'}, 'R3': {'Relationship ID': 'R3', 'Type': 'USED-FOR', 'Arg1': 'T9', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'COREF', 'Arg1': 'T7', 'Arg2': 'T5'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R6': {'Relationship ID': 'R6', 'Type': 'COREF', 'Arg1': 'T5', 'Arg2': 'T1'}, 'R7': {'Relationship ID': 'R7', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T8'}, 'R8': {'Relationship ID': 'R8', 'Type': 'COMPARE', 'Arg1': 'T7', 'Arg2': 'T9'}, 'R9': {'Relationship ID': 'R9', 'Type': 'CONJUNCTION', 'Arg1': 'T12', 'Arg2': 'T13'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'ranking algorithm COMPARE lattice-based approach'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'ranking algorithm COMPARE enumeration'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'approach USED-FOR statistical generation'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'It COREF representation'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'approach USED-FOR statistical sentence generation'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'representation COREF approach'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'It USED-FOR statistical ranking'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'It COMPARE approach'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'enumeration CONJUNCTION lattice-based approach'}}</td>\n",
       "      <td>[ranking algorithm COMPARE lattice-based approach, ranking algorithm COMPARE enumeration, approach USED-FOR statistical generation, It COREF representation, approach USED-FOR statistical sentence generation, representation COREF approach, It USED-FOR statistical ranking, It COMPARE approach, enumeration CONJUNCTION lattice-based approach]</td>\n",
       "      <td>9</td>\n",
       "      <td>Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nThis paper presents a new approach to  statistical sentence generation  in which alternative  phrases  are represented as packed sets of  trees , or  forests , and then ranked statistically to choose the best one. This representation offers advantages in compactness and in the ability to represent  syntactic information . It also facilitates more efficient  statistical ranking  than a previous approach to  statistical generation . An efficient  ranking algorithm  is described, together with experimental results showing significant improvements over simple enumeration or a  lattice-based approach .\\n\\n    ###\\n</td>\n",
       "      <td>[\"approach FEATURE-OF statistical sentence generation\", \"alternative phrases PART-OF packed sets\", \"alternative phrases PART-OF forests\", \"representation FEATURE-OF advantages\", \"representation FEATURE-OF ability to represent syntactic information\", \"ranking algorithm FEATURE-OF efficient statistical ranking\", \"experimental results EVALUATE-FOR improvements over simple enumeration\", \"experimental results EVALUATE-FOR lattice-based approach\"]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>\\n This paper describes a domain independent strategy for the  multimedia articulation of answers  elicited by a  natural language interface  to  database query applications  .  Multimedia answers  include  videodisc images  and heuristically-produced complete  sentences  in  text  or  text-to-speech form  .  Deictic reference  and  feedback  about the  discourse  are enabled. The  interface  thus presents the application as cooperative and conversational.</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Method', 'Start Offset': 26, 'End Offset': 53, 'Annotated Text': 'domain independent strategy'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 63, 'End Offset': 97, 'Annotated Text': 'multimedia articulation of answers'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 114, 'End Offset': 140, 'Annotated Text': 'natural language interface'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Task', 'Start Offset': 146, 'End Offset': 173, 'Annotated Text': 'database query applications'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Material', 'Start Offset': 178, 'End Offset': 196, 'Annotated Text': 'Multimedia answers'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'Material', 'Start Offset': 207, 'End Offset': 223, 'Annotated Text': 'videodisc images'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'OtherScientificTerm', 'Start Offset': 287, 'End Offset': 306, 'Annotated Text': 'text-to-speech form'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'OtherScientificTerm', 'Start Offset': 311, 'End Offset': 328, 'Annotated Text': 'Deictic reference'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'OtherScientificTerm', 'Start Offset': 335, 'End Offset': 343, 'Annotated Text': 'feedback'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'OtherScientificTerm', 'Start Offset': 356, 'End Offset': 365, 'Annotated Text': 'discourse'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Generic', 'Start Offset': 385, 'End Offset': 394, 'Annotated Text': 'interface'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'Generic', 'Start Offset': 414, 'End Offset': 425, 'Annotated Text': 'application'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEATURE-OF', 'Arg1': 'T9', 'Arg2': 'T10'}, 'R2': {'Relationship ID': 'R2', 'Type': 'PART-OF', 'Arg1': 'T6', 'Arg2': 'T5'}, 'R3': {'Relationship ID': 'R3', 'Type': 'FEATURE-OF', 'Arg1': 'T8', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'COREF', 'Arg1': 'T11', 'Arg2': 'T3'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R6': {'Relationship ID': 'R6', 'Type': 'USED-FOR', 'Arg1': 'T3', 'Arg2': 'T4'}, 'R7': {'Relationship ID': 'R7', 'Type': 'COREF', 'Arg1': 'T12', 'Arg2': 'T4'}, 'R8': {'Relationship ID': 'R8', 'Type': 'CONJUNCTION', 'Arg1': 'T8', 'Arg2': 'T9'}, 'R9': {'Relationship ID': 'R9', 'Type': 'USED-FOR', 'Arg1': 'T2', 'Arg2': 'T3'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'feedback FEATURE-OF discourse'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'videodisc images PART-OF Multimedia answers'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'Deictic reference FEATURE-OF discourse'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'interface COREF natural language interface'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'domain independent strategy USED-FOR multimedia articulation of answers'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'natural language interface USED-FOR database query applications'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'application COREF database query applications'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'Deictic reference CONJUNCTION feedback'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'multimedia articulation of answers USED-FOR natural language interface'}}</td>\n",
       "      <td>[feedback FEATURE-OF discourse, videodisc images PART-OF Multimedia answers, Deictic reference FEATURE-OF discourse, interface COREF natural language interface, domain independent strategy USED-FOR multimedia articulation of answers, natural language interface USED-FOR database query applications, application COREF database query applications, Deictic reference CONJUNCTION feedback, multimedia articulation of answers USED-FOR natural language interface]</td>\n",
       "      <td>9</td>\n",
       "      <td>Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n     \\n This paper describes a domain independent strategy for the  multimedia articulation of answers  elicited by a  natural language interface  to  database query applications  .  Multimedia answers  include  videodisc images  and heuristically-produced complete  sentences  in  text  or  text-to-speech form  .  Deictic reference  and  feedback  about the  discourse  are enabled. The  interface  thus presents the application as cooperative and conversational. \\n    ###\\n</td>\n",
       "      <td>[\"natural language interface USED-FOR database query applications\", \"multimedia answers FEATURE-OF videodisc images, complete sentences\", \"text-to-speech form FEATURE-OF heuristically-produced sentences\", \"Deictic reference PART-OF multimedia answers\", \"feedback PART-OF discourse\", \"interface PRESENTS application as cooperative and conversational\"]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>\\n In this paper, we describe the  pronominal anaphora resolution module  of  Lucy  , a portable  English understanding system  . The design of this module was motivated by the observation that, although there exist many theories of  anaphora resolution  , no one of these theories is complete. Thus we have implemented a  blackboard-like architecture  in which individual  partial theories  can be encoded as separate modules that can interact to propose candidate  antecedents  and to evaluate each other's proposals.</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Method', 'Start Offset': 35, 'End Offset': 72, 'Annotated Text': 'pronominal anaphora resolution module'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Method', 'Start Offset': 78, 'End Offset': 82, 'Annotated Text': 'Lucy'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'Method', 'Start Offset': 98, 'End Offset': 126, 'Annotated Text': 'English understanding system'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Generic', 'Start Offset': 149, 'End Offset': 155, 'Annotated Text': 'module'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Task', 'Start Offset': 234, 'End Offset': 253, 'Annotated Text': 'anaphora resolution'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'Method', 'Start Offset': 323, 'End Offset': 351, 'Annotated Text': 'blackboard-like architecture'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART-OF', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R2': {'Relationship ID': 'R2', 'Type': 'COREF', 'Arg1': 'T4', 'Arg2': 'T1'}, 'R3': {'Relationship ID': 'R3', 'Type': 'HYPONYM-OF', 'Arg1': 'T2', 'Arg2': 'T3'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'pronominal anaphora resolution module PART-OF Lucy'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'module COREF pronominal anaphora resolution module'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'Lucy HYPONYM-OF English understanding system'}}</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF Lucy, module COREF pronominal anaphora resolution module, Lucy HYPONYM-OF English understanding system]</td>\n",
       "      <td>3</td>\n",
       "      <td>Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n     \\n In this paper, we describe the  pronominal anaphora resolution module  of  Lucy  , a portable  English understanding system  . The design of this module was motivated by the observation that, although there exist many theories of  anaphora resolution  , no one of these theories is complete. Thus we have implemented a  blackboard-like architecture  in which individual  partial theories  can be encoded as separate modules that can interact to propose candidate  antecedents  and to evaluate each other's proposals. \\n    ###\\n</td>\n",
       "      <td>[\"pronominal anaphora resolution module PART-OF Lucy\", \"anaphora resolution HYPONYM-OF theories\", \"blackboard-like architecture FEATURE-OF module design\", \"partial theories PART-OF blackboard-like architecture\", \"antecedents USED-FOR candidate proposals\", \"modules EVALUATE-FOR proposals\", \"proposals COMPARE each other's proposals\"]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>\\nIn our current research into the design of  cognitively well-motivated interfaces  relying primarily on the  display of graphical information , we have observed that  graphical information  alone does not provide sufficient support to users - particularly when situations arise that do not simply conform to the users' expectations. This can occur due to too much  information  being requested, too little,  information  of the wrong kind, etc. To solve this problem, we are working towards the integration of  natural language generation  to augment the  interaction</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task', 'Start Offset': 45, 'End Offset': 82, 'Annotated Text': 'cognitively well-motivated interfaces'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'OtherScientificTerm', 'Start Offset': 110, 'End Offset': 142, 'Annotated Text': 'display of graphical information'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 168, 'End Offset': 189, 'Annotated Text': 'graphical information'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Task', 'Start Offset': 512, 'End Offset': 539, 'Annotated Text': 'natural language generation'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 557, 'End Offset': 568, 'Annotated Text': 'interaction'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED-FOR', 'Arg1': 'T2', 'Arg2': 'T1'}, 'R2': {'Relationship ID': 'R2', 'Type': 'USED-FOR', 'Arg1': 'T4', 'Arg2': 'T5'}, 'R3': {'Relationship ID': 'R3', 'Type': 'COREF', 'Arg1': 'T3', 'Arg2': 'T2'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'display of graphical information USED-FOR cognitively well-motivated interfaces'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'natural language generation USED-FOR interaction'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'graphical information COREF display of graphical information'}}</td>\n",
       "      <td>[display of graphical information USED-FOR cognitively well-motivated interfaces, natural language generation USED-FOR interaction, graphical information COREF display of graphical information]</td>\n",
       "      <td>3</td>\n",
       "      <td>Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nIn our current research into the design of  cognitively well-motivated interfaces  relying primarily on the  display of graphical information , we have observed that  graphical information  alone does not provide sufficient support to users - particularly when situations arise that do not simply conform to the users' expectations. This can occur due to too much  information  being requested, too little,  information  of the wrong kind, etc. To solve this problem, we are working towards the integration of  natural language generation  to augment the  interaction \\n    ###\\n</td>\n",
       "      <td>[\"natural language generation USED-FOR interaction\", \"graphical information FEATURE-OF cognitively well-motivated interfaces\", \"information EVALUATE-FOR user support\"]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 entities                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               relationships                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             populated_rels                                                                                                                                                                                                                                                                                                                                                                                                                                                        simplified_populated_rels  rel_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 prompt                                                                                                                                                                                                                                                                                                                                                                                                                                                      responses  responses_rels_detected\n",
       "0    A00-1024                                                                     \\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n  {'T1': {'Annotation ID': 'T1', 'Entity': 'Generic', 'Start Offset': 26, 'End Offset': 32, 'Annotated Text': 'system'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 37, 'End Offset': 63, 'Annotated Text': 'categorizing unknown words'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'Generic', 'Start Offset': 71, 'End Offset': 77, 'Annotated Text': 'system'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Method', 'Start Offset': 94, 'End Offset': 122, 'Annotated Text': 'multi-component architecture'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 136, 'End Offset': 145, 'Annotated Text': 'component'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'OtherScientificTerm', 'Start Offset': 192, 'End Offset': 205, 'Annotated Text': 'unknown words'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'Generic', 'Start Offset': 240, 'End Offset': 250, 'Annotated Text': 'components'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'OtherScientificTerm', 'Start Offset': 267, 'End Offset': 272, 'Annotated Text': 'names'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'OtherScientificTerm', 'Start Offset': 279, 'End Offset': 294, 'Annotated Text': 'spelling errors'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'Generic', 'Start Offset': 303, 'End Offset': 312, 'Annotated Text': 'component'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Method', 'Start Offset': 322, 'End Offset': 348, 'Annotated Text': 'decision tree architecture'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'OtherScientificTerm', 'Start Offset': 401, 'End Offset': 413, 'Annotated Text': 'unknown word'}, 'T13': {'Annotation ID': 'T13', 'Entity': 'Generic', 'Start Offset': 421, 'End Offset': 427, 'Annotated Text': 'system'}, 'T14': {'Annotation ID': 'T14', 'Entity': 'Material', 'Start Offset': 459, 'End Offset': 479, 'Annotated Text': 'live closed captions'}, 'T15': {'Annotation ID': 'T15', 'Entity': 'OtherScientificTerm', 'Start Offset': 523, 'End Offset': 536, 'Annotated Text': 'unknown words'}}  {'R1': {'Relationship ID': 'R1', 'Type': 'USED-FOR', 'Arg1': 'T4', 'Arg2': 'T3'}, 'R2': {'Relationship ID': 'R2', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T8'}, 'R3': {'Relationship ID': 'R3', 'Type': 'USED-FOR', 'Arg1': 'T11', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'PART-OF', 'Arg1': 'T5', 'Arg2': 'T4'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T9'}, 'R6': {'Relationship ID': 'R6', 'Type': 'HYPONYM-OF', 'Arg1': 'T7', 'Arg2': 'T5'}, 'R7': {'Relationship ID': 'R7', 'Type': 'COREF', 'Arg1': 'T13', 'Arg2': 'T3'}, 'R8': {'Relationship ID': 'R8', 'Type': 'USED-FOR', 'Arg1': 'T5', 'Arg2': 'T6'}, 'R9': {'Relationship ID': 'R9', 'Type': 'EVALUATE-FOR', 'Arg1': 'T14', 'Arg2': 'T13'}, 'R10': {'Relationship ID': 'R10', 'Type': 'CONJUNCTION', 'Arg1': 'T8', 'Arg2': 'T9'}, 'R11': {'Relationship ID': 'R11', 'Type': 'COREF', 'Arg1': 'T10', 'Arg2': 'T7'}, 'R12': {'Relationship ID': 'R12', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R13': {'Relationship ID': 'R13', 'Type': 'COREF', 'Arg1': 'T1', 'Arg2': 'T3'}}  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi-component architecture USED-FOR system'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'components USED-FOR names'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'decision tree architecture USED-FOR component'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'component PART-OF multi-component architecture'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'components USED-FOR spelling errors'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'components HYPONYM-OF component'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'system COREF system'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'component USED-FOR unknown words'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'live closed captions EVALUATE-FOR system'}, 'R10': {'Relationship ID': 'R10', 'Rel': 'names CONJUNCTION spelling errors'}, 'R11': {'Relationship ID': 'R11', 'Rel': 'component COREF components'}, 'R12': {'Relationship ID': 'R12', 'Rel': 'system USED-FOR categorizing unknown words'}, 'R13': {'Relationship ID': 'R13', 'Rel': 'system COREF system'}}  [multi-component architecture USED-FOR system, components USED-FOR names, decision tree architecture USED-FOR component, component PART-OF multi-component architecture, components USED-FOR spelling errors, components HYPONYM-OF component, system COREF system, component USED-FOR unknown words, live closed captions EVALUATE-FOR system, names CONJUNCTION spelling errors, component COREF components, system USED-FOR categorizing unknown words, system COREF system]         13                                                                     Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n\\n    ###\\n                                                                                                                                                                                                                                      [\"system PART-OF multi-component architecture\", \"component USED-FOR identifying unknown words\", \"names COREF spelling errors\", \"component FEATURE-OF decision tree architecture\", \"system EVALUATE-FOR live closed captions\"]                        5\n",
       "1    A00-2023  \\nThis paper presents a new approach to  statistical sentence generation  in which alternative  phrases  are represented as packed sets of  trees , or  forests , and then ranked statistically to choose the best one. This representation offers advantages in compactness and in the ability to represent  syntactic information . It also facilitates more efficient  statistical ranking  than a previous approach to  statistical generation . An efficient  ranking algorithm  is described, together with experimental results showing significant improvements over simple enumeration or a  lattice-based approach .\\n                                                                                                                                                                                                                                                                                      {'T1': {'Annotation ID': 'T1', 'Entity': 'Generic', 'Start Offset': 27, 'End Offset': 35, 'Annotated Text': 'approach'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 40, 'End Offset': 71, 'Annotated Text': 'statistical sentence generation'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 139, 'End Offset': 144, 'Annotated Text': 'trees'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'OtherScientificTerm', 'Start Offset': 151, 'End Offset': 158, 'Annotated Text': 'forests'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 220, 'End Offset': 234, 'Annotated Text': 'representation'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'OtherScientificTerm', 'Start Offset': 301, 'End Offset': 322, 'Annotated Text': 'syntactic information'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'Generic', 'Start Offset': 325, 'End Offset': 327, 'Annotated Text': 'It'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'Method', 'Start Offset': 361, 'End Offset': 380, 'Annotated Text': 'statistical ranking'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'Generic', 'Start Offset': 398, 'End Offset': 406, 'Annotated Text': 'approach'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'Task', 'Start Offset': 411, 'End Offset': 433, 'Annotated Text': 'statistical generation'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Method', 'Start Offset': 450, 'End Offset': 467, 'Annotated Text': 'ranking algorithm'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'Method', 'Start Offset': 563, 'End Offset': 574, 'Annotated Text': 'enumeration'}, 'T13': {'Annotation ID': 'T13', 'Entity': 'Method', 'Start Offset': 581, 'End Offset': 603, 'Annotated Text': 'lattice-based approach'}}                                                                                                                                                                                                                                                                                                                                                  {'R1': {'Relationship ID': 'R1', 'Type': 'COMPARE', 'Arg1': 'T11', 'Arg2': 'T13'}, 'R2': {'Relationship ID': 'R2', 'Type': 'COMPARE', 'Arg1': 'T11', 'Arg2': 'T12'}, 'R3': {'Relationship ID': 'R3', 'Type': 'USED-FOR', 'Arg1': 'T9', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'COREF', 'Arg1': 'T7', 'Arg2': 'T5'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R6': {'Relationship ID': 'R6', 'Type': 'COREF', 'Arg1': 'T5', 'Arg2': 'T1'}, 'R7': {'Relationship ID': 'R7', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T8'}, 'R8': {'Relationship ID': 'R8', 'Type': 'COMPARE', 'Arg1': 'T7', 'Arg2': 'T9'}, 'R9': {'Relationship ID': 'R9', 'Type': 'CONJUNCTION', 'Arg1': 'T12', 'Arg2': 'T13'}}                                                                                                                                                                                                                                                                                                             {'R1': {'Relationship ID': 'R1', 'Rel': 'ranking algorithm COMPARE lattice-based approach'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'ranking algorithm COMPARE enumeration'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'approach USED-FOR statistical generation'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'It COREF representation'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'approach USED-FOR statistical sentence generation'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'representation COREF approach'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'It USED-FOR statistical ranking'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'It COMPARE approach'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'enumeration CONJUNCTION lattice-based approach'}}                                                                                                                             [ranking algorithm COMPARE lattice-based approach, ranking algorithm COMPARE enumeration, approach USED-FOR statistical generation, It COREF representation, approach USED-FOR statistical sentence generation, representation COREF approach, It USED-FOR statistical ranking, It COMPARE approach, enumeration CONJUNCTION lattice-based approach]          9  Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nThis paper presents a new approach to  statistical sentence generation  in which alternative  phrases  are represented as packed sets of  trees , or  forests , and then ranked statistically to choose the best one. This representation offers advantages in compactness and in the ability to represent  syntactic information . It also facilitates more efficient  statistical ranking  than a previous approach to  statistical generation . An efficient  ranking algorithm  is described, together with experimental results showing significant improvements over simple enumeration or a  lattice-based approach .\\n\\n    ###\\n      [\"approach FEATURE-OF statistical sentence generation\", \"alternative phrases PART-OF packed sets\", \"alternative phrases PART-OF forests\", \"representation FEATURE-OF advantages\", \"representation FEATURE-OF ability to represent syntactic information\", \"ranking algorithm FEATURE-OF efficient statistical ranking\", \"experimental results EVALUATE-FOR improvements over simple enumeration\", \"experimental results EVALUATE-FOR lattice-based approach\"]                        8\n",
       "2    A88-1001                                                                                                                                                     \\n This paper describes a domain independent strategy for the  multimedia articulation of answers  elicited by a  natural language interface  to  database query applications  .  Multimedia answers  include  videodisc images  and heuristically-produced complete  sentences  in  text  or  text-to-speech form  .  Deictic reference  and  feedback  about the  discourse  are enabled. The  interface  thus presents the application as cooperative and conversational.                                                                                                                                                                                                                                                                                                                                            {'T1': {'Annotation ID': 'T1', 'Entity': 'Method', 'Start Offset': 26, 'End Offset': 53, 'Annotated Text': 'domain independent strategy'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 63, 'End Offset': 97, 'Annotated Text': 'multimedia articulation of answers'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 114, 'End Offset': 140, 'Annotated Text': 'natural language interface'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Task', 'Start Offset': 146, 'End Offset': 173, 'Annotated Text': 'database query applications'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Material', 'Start Offset': 178, 'End Offset': 196, 'Annotated Text': 'Multimedia answers'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'Material', 'Start Offset': 207, 'End Offset': 223, 'Annotated Text': 'videodisc images'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'OtherScientificTerm', 'Start Offset': 287, 'End Offset': 306, 'Annotated Text': 'text-to-speech form'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'OtherScientificTerm', 'Start Offset': 311, 'End Offset': 328, 'Annotated Text': 'Deictic reference'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'OtherScientificTerm', 'Start Offset': 335, 'End Offset': 343, 'Annotated Text': 'feedback'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'OtherScientificTerm', 'Start Offset': 356, 'End Offset': 365, 'Annotated Text': 'discourse'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Generic', 'Start Offset': 385, 'End Offset': 394, 'Annotated Text': 'interface'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'Generic', 'Start Offset': 414, 'End Offset': 425, 'Annotated Text': 'application'}}                                                                                                                                                                                                                                                                                                                                               {'R1': {'Relationship ID': 'R1', 'Type': 'FEATURE-OF', 'Arg1': 'T9', 'Arg2': 'T10'}, 'R2': {'Relationship ID': 'R2', 'Type': 'PART-OF', 'Arg1': 'T6', 'Arg2': 'T5'}, 'R3': {'Relationship ID': 'R3', 'Type': 'FEATURE-OF', 'Arg1': 'T8', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'COREF', 'Arg1': 'T11', 'Arg2': 'T3'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R6': {'Relationship ID': 'R6', 'Type': 'USED-FOR', 'Arg1': 'T3', 'Arg2': 'T4'}, 'R7': {'Relationship ID': 'R7', 'Type': 'COREF', 'Arg1': 'T12', 'Arg2': 'T4'}, 'R8': {'Relationship ID': 'R8', 'Type': 'CONJUNCTION', 'Arg1': 'T8', 'Arg2': 'T9'}, 'R9': {'Relationship ID': 'R9', 'Type': 'USED-FOR', 'Arg1': 'T2', 'Arg2': 'T3'}}                                                                                                                                                                                        {'R1': {'Relationship ID': 'R1', 'Rel': 'feedback FEATURE-OF discourse'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'videodisc images PART-OF Multimedia answers'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'Deictic reference FEATURE-OF discourse'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'interface COREF natural language interface'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'domain independent strategy USED-FOR multimedia articulation of answers'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'natural language interface USED-FOR database query applications'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'application COREF database query applications'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'Deictic reference CONJUNCTION feedback'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'multimedia articulation of answers USED-FOR natural language interface'}}        [feedback FEATURE-OF discourse, videodisc images PART-OF Multimedia answers, Deictic reference FEATURE-OF discourse, interface COREF natural language interface, domain independent strategy USED-FOR multimedia articulation of answers, natural language interface USED-FOR database query applications, application COREF database query applications, Deictic reference CONJUNCTION feedback, multimedia articulation of answers USED-FOR natural language interface]          9                                                                                                                                                    Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n     \\n This paper describes a domain independent strategy for the  multimedia articulation of answers  elicited by a  natural language interface  to  database query applications  .  Multimedia answers  include  videodisc images  and heuristically-produced complete  sentences  in  text  or  text-to-speech form  .  Deictic reference  and  feedback  about the  discourse  are enabled. The  interface  thus presents the application as cooperative and conversational. \\n    ###\\n                                                                                                     [\"natural language interface USED-FOR database query applications\", \"multimedia answers FEATURE-OF videodisc images, complete sentences\", \"text-to-speech form FEATURE-OF heuristically-produced sentences\", \"Deictic reference PART-OF multimedia answers\", \"feedback PART-OF discourse\", \"interface PRESENTS application as cooperative and conversational\"]                        7\n",
       "3    A88-1003                                                                                          \\n In this paper, we describe the  pronominal anaphora resolution module  of  Lucy  , a portable  English understanding system  . The design of this module was motivated by the observation that, although there exist many theories of  anaphora resolution  , no one of these theories is complete. Thus we have implemented a  blackboard-like architecture  in which individual  partial theories  can be encoded as separate modules that can interact to propose candidate  antecedents  and to evaluate each other's proposals.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                {'T1': {'Annotation ID': 'T1', 'Entity': 'Method', 'Start Offset': 35, 'End Offset': 72, 'Annotated Text': 'pronominal anaphora resolution module'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Method', 'Start Offset': 78, 'End Offset': 82, 'Annotated Text': 'Lucy'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'Method', 'Start Offset': 98, 'End Offset': 126, 'Annotated Text': 'English understanding system'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Generic', 'Start Offset': 149, 'End Offset': 155, 'Annotated Text': 'module'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Task', 'Start Offset': 234, 'End Offset': 253, 'Annotated Text': 'anaphora resolution'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'Method', 'Start Offset': 323, 'End Offset': 351, 'Annotated Text': 'blackboard-like architecture'}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {'R1': {'Relationship ID': 'R1', 'Type': 'PART-OF', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R2': {'Relationship ID': 'R2', 'Type': 'COREF', 'Arg1': 'T4', 'Arg2': 'T1'}, 'R3': {'Relationship ID': 'R3', 'Type': 'HYPONYM-OF', 'Arg1': 'T2', 'Arg2': 'T3'}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       {'R1': {'Relationship ID': 'R1', 'Rel': 'pronominal anaphora resolution module PART-OF Lucy'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'module COREF pronominal anaphora resolution module'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'Lucy HYPONYM-OF English understanding system'}}                                                                                                                                                                                                                                                                                                                           [pronominal anaphora resolution module PART-OF Lucy, module COREF pronominal anaphora resolution module, Lucy HYPONYM-OF English understanding system]          3                                                                                         Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n     \\n In this paper, we describe the  pronominal anaphora resolution module  of  Lucy  , a portable  English understanding system  . The design of this module was motivated by the observation that, although there exist many theories of  anaphora resolution  , no one of these theories is complete. Thus we have implemented a  blackboard-like architecture  in which individual  partial theories  can be encoded as separate modules that can interact to propose candidate  antecedents  and to evaluate each other's proposals. \\n    ###\\n                                                                                                                      [\"pronominal anaphora resolution module PART-OF Lucy\", \"anaphora resolution HYPONYM-OF theories\", \"blackboard-like architecture FEATURE-OF module design\", \"partial theories PART-OF blackboard-like architecture\", \"antecedents USED-FOR candidate proposals\", \"modules EVALUATE-FOR proposals\", \"proposals COMPARE each other's proposals\"]                        7\n",
       "4    A92-1010                                        \\nIn our current research into the design of  cognitively well-motivated interfaces  relying primarily on the  display of graphical information , we have observed that  graphical information  alone does not provide sufficient support to users - particularly when situations arise that do not simply conform to the users' expectations. This can occur due to too much  information  being requested, too little,  information  of the wrong kind, etc. To solve this problem, we are working towards the integration of  natural language generation  to augment the  interaction                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                {'T1': {'Annotation ID': 'T1', 'Entity': 'Task', 'Start Offset': 45, 'End Offset': 82, 'Annotated Text': 'cognitively well-motivated interfaces'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'OtherScientificTerm', 'Start Offset': 110, 'End Offset': 142, 'Annotated Text': 'display of graphical information'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 168, 'End Offset': 189, 'Annotated Text': 'graphical information'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Task', 'Start Offset': 512, 'End Offset': 539, 'Annotated Text': 'natural language generation'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 557, 'End Offset': 568, 'Annotated Text': 'interaction'}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            {'R1': {'Relationship ID': 'R1', 'Type': 'USED-FOR', 'Arg1': 'T2', 'Arg2': 'T1'}, 'R2': {'Relationship ID': 'R2', 'Type': 'USED-FOR', 'Arg1': 'T4', 'Arg2': 'T5'}, 'R3': {'Relationship ID': 'R3', 'Type': 'COREF', 'Arg1': 'T3', 'Arg2': 'T2'}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            {'R1': {'Relationship ID': 'R1', 'Rel': 'display of graphical information USED-FOR cognitively well-motivated interfaces'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'natural language generation USED-FOR interaction'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'graphical information COREF display of graphical information'}}                                                                                                                                                                                                                                                                                [display of graphical information USED-FOR cognitively well-motivated interfaces, natural language generation USED-FOR interaction, graphical information COREF display of graphical information]          3                                        Give me a comma-separated list of relationships and coreferences detected in the provided abstract, as long as they are in this list of restricted relationship types:\\n    ###\\n    [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of each type of relationship that may be detected:\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [rel1, rel2, rel3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nIn our current research into the design of  cognitively well-motivated interfaces  relying primarily on the  display of graphical information , we have observed that  graphical information  alone does not provide sufficient support to users - particularly when situations arise that do not simply conform to the users' expectations. This can occur due to too much  information  being requested, too little,  information  of the wrong kind, etc. To solve this problem, we are working towards the integration of  natural language generation  to augment the  interaction \\n    ###\\n                                                                                                                                                                                                                                                                                            [\"natural language generation USED-FOR interaction\", \"graphical information FEATURE-OF cognitively well-motivated interfaces\", \"information EVALUATE-FOR user support\"]                        3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scierc_full_responses['responses_rels_detected'] = scierc_full_responses['responses'].apply(lambda x: len(x.split(',')))\n",
    "scierc_full_responses.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f88b16d",
   "metadata": {},
   "source": [
    "### Quantitative comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36b2d6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of rel_count: 6394\n",
      "Sum of responses_rels_detected: 3958\n"
     ]
    }
   ],
   "source": [
    "rel_count_sum = scierc_full_responses['rel_count'].sum()\n",
    "responses_rels_detected_sum = scierc_full_responses['responses_rels_detected'].sum()\n",
    "\n",
    "print(\"Sum of rel_count:\", rel_count_sum)\n",
    "print(\"Sum of responses_rels_detected:\", responses_rels_detected_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1f630e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'USED-FOR': 712, 'FEATURE-OF': 902, 'HYPONYM-OF': 158, 'PART-OF': 583, 'EVALUATE-FOR': 574, 'COMPARE': 404, 'CONJUNCTION': 15, 'COREF': 136}\n",
      "Sum of Values: 3484\n"
     ]
    }
   ],
   "source": [
    "# Define the target texts\n",
    "target_texts = ['USED-FOR', 'FEATURE-OF', 'HYPONYM-OF', 'PART-OF', 'EVALUATE-FOR', 'COMPARE', 'CONJUNCTION', 'COREF']\n",
    "\n",
    "# Initialize the dictionary\n",
    "rel_summary = {text: 0 for text in target_texts}\n",
    "\n",
    "# Count the occurrences of each target text\n",
    "for row in scierc_full_responses['responses']:\n",
    "    phrases = row.split(', ')\n",
    "    for text in target_texts:\n",
    "        for phrase in phrases:\n",
    "            if text in phrase:\n",
    "                rel_summary[text] += 1\n",
    "\n",
    "# Print the summary statistics\n",
    "print(rel_summary)\n",
    "\n",
    "# Print the sum of values\n",
    "print(\"Sum of Values:\", sum(rel_summary.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59fd2487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above implies that there are some rels generated outside of the restricted options;\n",
    "# Or, may be slight mis-matches with letter-casing, lack of hyphen, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520ce1ec",
   "metadata": {},
   "source": [
    "# Final export for manual verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15e819d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export to excel for manual verification:\n",
    "# scierc_full_responses.to_excel(\"./benchmarking/results/scierc_rel_detection_responses.xlsx\")\n",
    "\n",
    "# # export to pickle in case of future use.\n",
    "# scierc_full_responses.to_pickle(\"./benchmarking/results/scierc_rel_detection_responses.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4109a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c06dd8c6",
   "metadata": {},
   "source": [
    "# Re-import pickle file for exploratory analysis\n",
    "* Used in V2 COPY (used when writing dissertation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b6812ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "      <th>prompt</th>\n",
       "      <th>responses</th>\n",
       "      <th>responses_rels_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categori...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "      <td>[\"system PART-OF multi-component architecture\"...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "\n",
       "                                                text  \\\n",
       "0  \\nThis paper introduces a  system for categori...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "\n",
       "                                      populated_rels  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...   \n",
       "\n",
       "                           simplified_populated_rels  \\\n",
       "0  [multi-component architecture USED-FOR system,...   \n",
       "\n",
       "   rel_count  \\\n",
       "0         13   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Give me a comma-separated list of relationship...   \n",
       "\n",
       "                                           responses  \\\n",
       "0  [\"system PART-OF multi-component architecture\"...   \n",
       "\n",
       "   responses_rels_detected  \n",
       "0                        5  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pickle file\n",
    "reimport_scierc_results = pd.read_pickle(\"./benchmarking/results/scierc_rel_detection_responses.pkl\")\n",
    "print(len(reimport_scierc_results))\n",
    "reimport_scierc_results.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d83682",
   "metadata": {},
   "source": [
    "### remove rows where abstract ID had missing annotation file (C88-2132), or no rels detected (other 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0ccad673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "      <th>prompt</th>\n",
       "      <th>responses</th>\n",
       "      <th>responses_rels_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categori...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "      <td>[\"system PART-OF multi-component architecture\"...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "\n",
       "                                                text  \\\n",
       "0  \\nThis paper introduces a  system for categori...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "\n",
       "                                      populated_rels  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...   \n",
       "\n",
       "                           simplified_populated_rels  \\\n",
       "0  [multi-component architecture USED-FOR system,...   \n",
       "\n",
       "   rel_count  \\\n",
       "0         13   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Give me a comma-separated list of relationship...   \n",
       "\n",
       "                                           responses  \\\n",
       "0  [\"system PART-OF multi-component architecture\"...   \n",
       "\n",
       "   responses_rels_detected  \n",
       "0                        5  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# List of abstract values to be excluded\n",
    "excluded_abstracts = ['IJCAI_2013_4_abs', 'AAAI_2008_262_abs', 'C88-2132']\n",
    "\n",
    "# Filter out rows with excluded abstract values\n",
    "reimport_scierc_results = reimport_scierc_results[~reimport_scierc_results['abstract_id'].isin(excluded_abstracts)]\n",
    "print(len(reimport_scierc_results))\n",
    "reimport_scierc_results.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6823d6b7",
   "metadata": {},
   "source": [
    "## Add comparison cols:\n",
    "1) exact rel in annotated but not in responses.\n",
    "2) corresponding count of rels.\n",
    "3) exact rel in responses but not in annotated.\n",
    "4) corresponding count of rels. \n",
    "5) exact rel in responses and annotations.\n",
    "6) corresponding count of rels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "58e33b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "      <th>prompt</th>\n",
       "      <th>responses</th>\n",
       "      <th>responses_rels_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categori...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "      <td>system PART-OF multi-component architecture, c...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "\n",
       "                                                text  \\\n",
       "0  \\nThis paper introduces a  system for categori...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "\n",
       "                                      populated_rels  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...   \n",
       "\n",
       "                           simplified_populated_rels  \\\n",
       "0  [multi-component architecture USED-FOR system,...   \n",
       "\n",
       "   rel_count  \\\n",
       "0         13   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Give me a comma-separated list of relationship...   \n",
       "\n",
       "                                           responses  \\\n",
       "0  system PART-OF multi-component architecture, c...   \n",
       "\n",
       "   responses_rels_detected  \n",
       "0                        5  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation contained in most responses\n",
    "reimport_scierc_results['responses'] = reimport_scierc_results['responses'].str.replace('[\\[\\]\"]', '', regex=True)\n",
    "\n",
    "# Trim leading and trailing spaces/newlines\n",
    "# reimport_scierc_results['responses'] = reimport_scierc_results['responses'].apply(lambda x: [item.strip() for item in x])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "reimport_scierc_results.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1db8b3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'simplified_populated_rels' column contains a list of items.\n",
      "The 'responses' column contains strings.\n"
     ]
    }
   ],
   "source": [
    "# determine if comparison cols are list of items or string.\n",
    "# Assuming the column name is 'col_name'\n",
    "col_names = ('simplified_populated_rels', 'responses')\n",
    "\n",
    "for col in col_names:\n",
    "    col_name = col\n",
    "    # Check the type of values in the column\n",
    "    value_type = type(reimport_scierc_results.loc[0, col_name])\n",
    "\n",
    "    # Check if the column contains a list\n",
    "    if value_type == list:\n",
    "        print(f\"The '{col_name}' column contains a list of items.\")\n",
    "    else:\n",
    "        print(f\"The '{col_name}' column contains strings.\")\n",
    "\n",
    "# output must be same format for accurate comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "da739fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'responses' column has been converted to a list of items.\n"
     ]
    }
   ],
   "source": [
    "# Assuming the column name is 'responses'\n",
    "col_name = 'responses'\n",
    "\n",
    "# Convert the string to a list of items\n",
    "reimport_scierc_results[col_name] = reimport_scierc_results[col_name].str.split(',')\n",
    "\n",
    "# Check the updated type of values in the column\n",
    "value_type = type(reimport_scierc_results.loc[0, col_name])\n",
    "\n",
    "# Check if the column contains a list\n",
    "if value_type == list:\n",
    "    print(f\"The '{col_name}' column has been converted to a list of items.\")\n",
    "else:\n",
    "    print(f\"Error: The '{col_name}' column could not be converted to a list.\")\n",
    "reimport_scierc_results.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "05ec5fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip\n",
    "reimport_scierc_results['responses'] = reimport_scierc_results['responses'].apply(lambda x: [item.strip() for item in x])\n",
    "reimport_scierc_results.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4263b4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create 'rel_annotated_but_not_detected' column\n",
    "reimport_scierc_results['rel_annotated_but_not_detected'] = reimport_scierc_results.apply(lambda row: [rel for rel in row['simplified_populated_rels'] if rel not in row['responses']], axis=1)\n",
    "reimport_scierc_results['rel_annotated_but_not_detected_count'] = reimport_scierc_results['rel_annotated_but_not_detected'].apply(len)\n",
    "\n",
    "# Step 3: Create 'rel_detected_but_not_annotated' column\n",
    "reimport_scierc_results['rel_detected_but_not_annotated'] = reimport_scierc_results.apply(lambda row: [rel for rel in row['responses'] if rel not in row['simplified_populated_rels']], axis=1)\n",
    "reimport_scierc_results['rel_detected_but_not_annotated_count'] = reimport_scierc_results['rel_detected_but_not_annotated'].apply(len)\n",
    "\n",
    "# Step 4: Create 'annotated_rel_detected' column\n",
    "reimport_scierc_results['annotated_rel_detected'] = reimport_scierc_results.apply(lambda row: [rel for rel in row['responses'] if rel in row['simplified_populated_rels']], axis=1)\n",
    "reimport_scierc_results['annotated_rel_detected_count'] = reimport_scierc_results['annotated_rel_detected'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "68acf057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "      <th>prompt</th>\n",
       "      <th>responses</th>\n",
       "      <th>responses_rels_detected</th>\n",
       "      <th>rel_annotated_but_not_detected</th>\n",
       "      <th>rel_annotated_but_not_detected_count</th>\n",
       "      <th>rel_detected_but_not_annotated</th>\n",
       "      <th>rel_detected_but_not_annotated_count</th>\n",
       "      <th>annotated_rel_detected</th>\n",
       "      <th>annotated_rel_detected_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categori...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "      <td>[system PART-OF multi-component architecture, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "      <td>[system PART-OF multi-component architecture, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>\\nThis paper presents a new approach to  stati...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMP...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...</td>\n",
       "      <td>[ranking algorithm COMPARE lattice-based appro...</td>\n",
       "      <td>9</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "      <td>[approach FEATURE-OF statistical sentence gene...</td>\n",
       "      <td>8</td>\n",
       "      <td>[ranking algorithm COMPARE lattice-based appro...</td>\n",
       "      <td>9</td>\n",
       "      <td>[approach FEATURE-OF statistical sentence gene...</td>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>\\n This paper describes a domain independent ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...</td>\n",
       "      <td>[feedback FEATURE-OF discourse, videodisc imag...</td>\n",
       "      <td>9</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "      <td>[natural language interface USED-FOR database ...</td>\n",
       "      <td>7</td>\n",
       "      <td>[feedback FEATURE-OF discourse, videodisc imag...</td>\n",
       "      <td>8</td>\n",
       "      <td>[multimedia answers FEATURE-OF videodisc image...</td>\n",
       "      <td>6</td>\n",
       "      <td>[natural language interface USED-FOR database ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>\\n In this paper, we describe the  pronominal...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'prono...</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF...</td>\n",
       "      <td>3</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF...</td>\n",
       "      <td>7</td>\n",
       "      <td>[module COREF pronominal anaphora resolution m...</td>\n",
       "      <td>2</td>\n",
       "      <td>[anaphora resolution HYPONYM-OF theories, blac...</td>\n",
       "      <td>6</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>\\nIn our current research into the design of  ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'displ...</td>\n",
       "      <td>[display of graphical information USED-FOR cog...</td>\n",
       "      <td>3</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "      <td>[natural language generation USED-FOR interact...</td>\n",
       "      <td>3</td>\n",
       "      <td>[display of graphical information USED-FOR cog...</td>\n",
       "      <td>2</td>\n",
       "      <td>[graphical information FEATURE-OF cognitively ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[natural language generation USED-FOR interact...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "1    A00-2023   \n",
       "2    A88-1001   \n",
       "3    A88-1003   \n",
       "4    A92-1010   \n",
       "\n",
       "                                                text  \\\n",
       "0  \\nThis paper introduces a  system for categori...   \n",
       "1  \\nThis paper presents a new approach to  stati...   \n",
       "2   \\n This paper describes a domain independent ...   \n",
       "3   \\n In this paper, we describe the  pronominal...   \n",
       "4  \\nIn our current research into the design of  ...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "1  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "2  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "3  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "4  {'T1': {'Annotation ID': 'T1', 'Entity': 'Task...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Type': 'COMP...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Type': 'PART...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "\n",
       "                                      populated_rels  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Rel': 'prono...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Rel': 'displ...   \n",
       "\n",
       "                           simplified_populated_rels  \\\n",
       "0  [multi-component architecture USED-FOR system,...   \n",
       "1  [ranking algorithm COMPARE lattice-based appro...   \n",
       "2  [feedback FEATURE-OF discourse, videodisc imag...   \n",
       "3  [pronominal anaphora resolution module PART-OF...   \n",
       "4  [display of graphical information USED-FOR cog...   \n",
       "\n",
       "   rel_count  \\\n",
       "0         13   \n",
       "1          9   \n",
       "2          9   \n",
       "3          3   \n",
       "4          3   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Give me a comma-separated list of relationship...   \n",
       "1  Give me a comma-separated list of relationship...   \n",
       "2  Give me a comma-separated list of relationship...   \n",
       "3  Give me a comma-separated list of relationship...   \n",
       "4  Give me a comma-separated list of relationship...   \n",
       "\n",
       "                                           responses  \\\n",
       "0  [system PART-OF multi-component architecture, ...   \n",
       "1  [approach FEATURE-OF statistical sentence gene...   \n",
       "2  [natural language interface USED-FOR database ...   \n",
       "3  [pronominal anaphora resolution module PART-OF...   \n",
       "4  [natural language generation USED-FOR interact...   \n",
       "\n",
       "   responses_rels_detected  \\\n",
       "0                        5   \n",
       "1                        8   \n",
       "2                        7   \n",
       "3                        7   \n",
       "4                        3   \n",
       "\n",
       "                      rel_annotated_but_not_detected  \\\n",
       "0  [multi-component architecture USED-FOR system,...   \n",
       "1  [ranking algorithm COMPARE lattice-based appro...   \n",
       "2  [feedback FEATURE-OF discourse, videodisc imag...   \n",
       "3  [module COREF pronominal anaphora resolution m...   \n",
       "4  [display of graphical information USED-FOR cog...   \n",
       "\n",
       "   rel_annotated_but_not_detected_count  \\\n",
       "0                                    13   \n",
       "1                                     9   \n",
       "2                                     8   \n",
       "3                                     2   \n",
       "4                                     2   \n",
       "\n",
       "                      rel_detected_but_not_annotated  \\\n",
       "0  [system PART-OF multi-component architecture, ...   \n",
       "1  [approach FEATURE-OF statistical sentence gene...   \n",
       "2  [multimedia answers FEATURE-OF videodisc image...   \n",
       "3  [anaphora resolution HYPONYM-OF theories, blac...   \n",
       "4  [graphical information FEATURE-OF cognitively ...   \n",
       "\n",
       "   rel_detected_but_not_annotated_count  \\\n",
       "0                                     5   \n",
       "1                                     8   \n",
       "2                                     6   \n",
       "3                                     6   \n",
       "4                                     2   \n",
       "\n",
       "                              annotated_rel_detected  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [natural language interface USED-FOR database ...   \n",
       "3  [pronominal anaphora resolution module PART-OF...   \n",
       "4  [natural language generation USED-FOR interact...   \n",
       "\n",
       "   annotated_rel_detected_count  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             1  \n",
       "3                             1  \n",
       "4                             1  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reimport_scierc_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0d1279",
   "metadata": {},
   "source": [
    "### Export scierc_full_responses with additional analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7897294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reimport_scierc_results.to_excel(\"./benchmarking/results/V2_scierc_rel_detection_responses.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d39050",
   "metadata": {},
   "source": [
    "## iterate over input annotations to get distribution of relation types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9e5f50b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'reimport_scierc_results' is your DataFrame\n",
    "simplified_populated_rels_list = [str(item) for item in reimport_scierc_results['simplified_populated_rels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "284ce299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'USED-FOR': 2437, 'FEATURE-OF': 264, 'HYPONYM-OF': 477, 'PART-OF': 270, 'EVALUATE-FOR': 454, 'COMPARE': 234, 'CONJUNCTION': 583, 'COREF': 1675}\n",
      "Sum of Values: 6394\n"
     ]
    }
   ],
   "source": [
    "# Define the target texts\n",
    "target_texts = ['USED-FOR', 'FEATURE-OF', 'HYPONYM-OF', 'PART-OF', 'EVALUATE-FOR', 'COMPARE', 'CONJUNCTION', 'COREF']\n",
    "\n",
    "# Initialize the dictionary\n",
    "rel_summary = {text: 0 for text in target_texts}\n",
    "\n",
    "# Count the occurrences of each target text\n",
    "for row in simplified_populated_rels_list:\n",
    "    phrases = row.split(', ')\n",
    "    for text in target_texts:\n",
    "        for phrase in phrases:\n",
    "            if text in phrase:\n",
    "                rel_summary[text] += 1\n",
    "\n",
    "# Print the summary statistics\n",
    "print(rel_summary)\n",
    "\n",
    "# Print the sum of values\n",
    "print(\"Sum of Values:\", sum(rel_summary.values()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67cb6a7",
   "metadata": {},
   "source": [
    "## Explore 10 randomly selected samples where ChatGPT detected more rels than was annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "722d10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seedset = 3409578\n",
    "\n",
    "# Filter the DataFrame based on the condition\n",
    "responses_more_than_annotated = reimport_scierc_results[reimport_scierc_results['responses_rels_detected'] > reimport_scierc_results['rel_count']]\n",
    "responses_less_than_annotated = reimport_scierc_results[reimport_scierc_results['responses_rels_detected'] < reimport_scierc_results['rel_count']]\n",
    "\n",
    "\n",
    "# Randomly select 10 samples from the filtered DataFrame\n",
    "CGPT_detected_more = responses_more_than_annotated.sample(n=10, random_state=random.seed(seedset))\n",
    "CGPT_detected_less = responses_less_than_annotated.sample(n=10, random_state=random.seed(seedset))\n",
    "\n",
    "# Export the DataFrames to an Excel file with two sheets\n",
    "with pd.ExcelWriter('./benchmarking/results/qual_analysis_scierc.xlsx') as writer:\n",
    "    CGPT_detected_more.to_excel(writer, sheet_name='CGPT_detected_more')\n",
    "    CGPT_detected_less.to_excel(writer, sheet_name='CGPT_detected_less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9807871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "426.649px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "316.84px",
    "left": "1543.99px",
    "right": "20px",
    "top": "120px",
    "width": "316.997px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
