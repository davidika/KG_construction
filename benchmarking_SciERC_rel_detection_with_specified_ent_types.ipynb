{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "207471af",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5b97276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using conda library 'ontogpt_fork'; naming irrelevant as this was previously going to be used to work on a different project.\n",
    "\n",
    "# increase cell-width\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm # progress bar tracking\n",
    "\n",
    "# API keys:\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 50)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "import json\n",
    "import jsonschema\n",
    "from jsonschema import validate\n",
    "\n",
    "# prompts for OpenAI\n",
    "\n",
    "import openai_secret_manager\n",
    "import openai\n",
    "import time\n",
    "import random\n",
    "\n",
    "import tiktoken\n",
    "from typing import List, Tuple\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f615246d",
   "metadata": {},
   "source": [
    "# Load SciERC dataset\n",
    "* http://nlp.cs.washington.edu/sciIE/\n",
    "* annotation guideline: http://nlp.cs.washington.edu/sciIE/annotation_guideline.pdf\n",
    "\n",
    "* SciERC is an annotated dataset of 500 scientific abstracts (multi-sentence).\n",
    "* Each article has 3 files:\n",
    "    * .txt being the raw text.\n",
    "    * .xml being the post-processed article.\n",
    "    * .ann being the annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b5abb2",
   "metadata": {},
   "source": [
    "## Annotation guideline\n",
    "\n",
    "Relation link can not go beyond sentence boundary.\n",
    "\n",
    "We define 4 asymmetric relation types (Used-for, Feature-of, Hyponym-of, Part-of), together with 2 symmetric relation types (Compare, Conjunction).\n",
    "B always points to A for asymmetric relations.\n",
    "\n",
    "* Used-for: B is used for A, B models A, A is trained on B, B exploits A, A is based on B. E.g.\n",
    "    * The TISPER system has been designed to enable many text applications.\n",
    "    * Our method models user proficiency.\n",
    "    * Our algorithms exploits local soothness.\n",
    "\n",
    "* Feature-of: B belongs to A, B is a feature of A, B is under A domain. E.g.\n",
    "    * prior knowledge of the model\n",
    "    * genre-specific regularities of discourse structure\n",
    "    * English text in science domain\n",
    "\n",
    "* Hyponym-of: B is a hyponym of A, B is a type of A. E.g.\n",
    "    * TUIT is a software library\n",
    "    * NLP applications such as machine translation and language generation\n",
    "\n",
    "* Part-of: B is a part of A... E.g.\n",
    "    * The system includes two models: speech recognition and natural language understanding\n",
    "    * We incorporate NLU module to the system.\n",
    "\n",
    "* Compare: Symmetric relation (use blue to denote entity). Opposite of conjunction, compare two models/methods, or listing two opposing entities. E.g.\n",
    "    * Unlike the quantitative prior, the qualitative prior is often ignored...\n",
    "\n",
    "* Conjunction: Symmetric relation (use blue to denote entity). Function as similar role or use/incorporate\n",
    "with. E.g.\n",
    "    * obtained from human expert or knowledge base\n",
    "    * NLP applications such as machine translation and language generation\n",
    "\n",
    "Coreference:\n",
    "* Anaphora and Cataphora:\n",
    "    * We introduce a machine reading system... The system...\n",
    "    * The prior knowledge include...Such knowledge can be applied to...\n",
    "\n",
    "* Coreferring noun phrase:\n",
    "    * We develop a part-of-speech tagging system...The POS tagger..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b338a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2308ae0e",
   "metadata": {},
   "source": [
    "## Explore .ann files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1924b4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\A00-1024.ann\n",
      "T1\tGeneric 26 32\tsystem\n",
      "T2\tTask 37 63\tcategorizing unknown words\n",
      "T3\tGeneric 71 77\tsystem\n",
      "T4\tMethod 94 122\tmulti-component architecture\n",
      "T5\tGeneric 136 145\tcomponent\n",
      "T6\tOtherScientificTerm 192 205\tunknown words\n",
      "T7\tGeneric 240 250\tcomponents\n",
      "T8\tOtherScientificTerm 267 272\tnames\n",
      "T9\tOtherScientificTerm 279 294\tspelling errors\n",
      "T10\tGeneric 303 312\tcomponent\n",
      "T11\tMethod 322 348\tdecision tree architecture\n",
      "T12\tOtherScientificTerm 401 413\tunknown word\n",
      "T13\tGeneric 421 427\tsystem\n",
      "T14\tMaterial 459 479\tlive closed captions\n",
      "T15\tOtherScientificTerm 523 536\tunknown words\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R4\tPART-OF Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R6\tHYPONYM-OF Arg1:T7 Arg2:T5\n",
      "R7\tCOREF Arg1:T13 Arg2:T3\n",
      "R8\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R9\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R10\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R11\tCOREF Arg1:T10 Arg2:T7\n",
      "R12\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R13\tCOREF Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A00-2023.ann\n",
      "T1\tGeneric 27 35\tapproach\n",
      "T2\tTask 40 71\tstatistical sentence generation\n",
      "T3\tOtherScientificTerm 139 144\ttrees\n",
      "T4\tOtherScientificTerm 151 158\tforests\n",
      "T5\tGeneric 220 234\trepresentation\n",
      "T6\tOtherScientificTerm 301 322\tsyntactic information\n",
      "T7\tGeneric 325 327\tIt\n",
      "T8\tMethod 361 380\tstatistical ranking\n",
      "T9\tGeneric 398 406\tapproach\n",
      "T10\tTask 411 433\tstatistical generation\n",
      "T11\tMethod 450 467\tranking algorithm\n",
      "T12\tMethod 563 574\tenumeration\n",
      "T13\tMethod 581 603\tlattice-based approach\n",
      "R1\tCOMPARE Arg1:T11 Arg2:T13\n",
      "R2\tCOMPARE Arg1:T11 Arg2:T12\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R4\tCOREF Arg1:T7 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tCOREF Arg1:T5 Arg2:T1\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R8\tCOMPARE Arg1:T7 Arg2:T9\n",
      "R9\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A88-1001.ann\n",
      "T1\tMethod 26 53\tdomain independent strategy\n",
      "T2\tTask 63 97\tmultimedia articulation of answers\n",
      "T3\tOtherScientificTerm 114 140\tnatural language interface\n",
      "T4\tTask 146 173\tdatabase query applications\n",
      "T5\tMaterial 178 196\tMultimedia answers\n",
      "T6\tMaterial 207 223\tvideodisc images\n",
      "T7\tOtherScientificTerm 287 306\ttext-to-speech form\n",
      "T8\tOtherScientificTerm 311 328\tDeictic reference\n",
      "T9\tOtherScientificTerm 335 343\tfeedback\n",
      "T10\tOtherScientificTerm 356 365\tdiscourse\n",
      "T11\tGeneric 385 394\tinterface\n",
      "T12\tGeneric 414 425\tapplication\n",
      "R1\tFEATURE-OF Arg1:T9 Arg2:T10\n",
      "R2\tPART-OF Arg1:T6 Arg2:T5\n",
      "R3\tFEATURE-OF Arg1:T8 Arg2:T10\n",
      "R4\tCOREF Arg1:T11 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R7\tCOREF Arg1:T12 Arg2:T4\n",
      "R8\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R9\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A88-1003.ann\n",
      "T1\tMethod 35 72\tpronominal anaphora resolution module\n",
      "T2\tMethod 78 82\tLucy\n",
      "T3\tMethod 98 126\tEnglish understanding system\n",
      "T4\tGeneric 149 155\tmodule\n",
      "T5\tTask 234 253\tanaphora resolution\n",
      "T6\tMethod 323 351\tblackboard-like architecture\n",
      "R1\tPART-OF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T4 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T2 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A92-1010.ann\n",
      "T1\tTask 45 82\tcognitively well-motivated interfaces\n",
      "T2\tOtherScientificTerm 110 142\tdisplay of graphical information\n",
      "T3\tOtherScientificTerm 168 189\tgraphical information\n",
      "T4\tTask 512 539\tnatural language generation\n",
      "T5\tGeneric 557 568\tinteraction\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tCOREF Arg1:T3 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A92-1023.ann\n",
      "T1\tTask 14 36\tevaluation methodology\n",
      "T2\tTask 151 161\tEvaluation\n",
      "T3\tGeneric 244 254\tapproaches\n",
      "T4\tTask 271 294\tspeech recognition (SR)\n",
      "T5\tGeneric 313 337\tevaluation methodologies\n",
      "T6\tOtherScientificTerm 448 480\tnatural language (NL) interfaces\n",
      "T7\tTask 501 526\tspeech understanding (SU)\n",
      "T8\tGeneric 723 734\tmethodology\n",
      "T9\tTask 751 777\tevaluation of  SLS systems\n",
      "T10\tMethod 766 777\tSLS systems\n",
      "T11\tGeneric 789 800\tmethodology\n",
      "T12\tMethod 875 886\tSLS systems\n",
      "T13\tGeneric 895 906\tevaluations\n",
      "T14\tTask 930 944\tNL evaluations\n",
      "T15\tMaterial 972 1005\tMessage Understanding Conferences\n",
      "T16\tMetric 1278 1301\t\"black-box\" methodology\n",
      "T17\tTask 1307 1361\tautomatic evaluation of  question-answering NL systems\n",
      "T18\tGeneric 1467 1478\tmethodology\n",
      "T19\tGeneric 1506 1508\tit\n",
      "T20\tOtherScientificTerm 1534 1554\tspeech or text input\n",
      "T21\tGeneric 1595 1603\tapproach\n",
      "R1\tCOREF Arg1:T12 Arg2:T10\n",
      "R2\tCOREF Arg1:T18 Arg2:T16\n",
      "R3\tCOREF Arg1:T21 Arg2:T18\n",
      "R4\tCOREF Arg1:T11 Arg2:T8\n",
      "R5\tEVALUATE-FOR Arg1:T11 Arg2:T12\n",
      "R6\tHYPONYM-OF Arg1:T13 Arg2:T14\n",
      "R7\tCOREF Arg1:T2 Arg2:T1\n",
      "R8\tCOREF Arg1:T2 Arg2:T5\n",
      "R9\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R10\tEVALUATE-FOR Arg1:T8 Arg2:T9\n",
      "R11\tCOREF Arg1:T9 Arg2:T13\n",
      "R12\tCONJUNCTION Arg1:T13 Arg2:T15\n",
      "R13\tCOREF Arg1:T18 Arg2:T19\n",
      "R14\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R15\tEVALUATE-FOR Arg1:T16 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A92-1026.ann\n",
      "T1\tTask 34 61\tnatural language processing\n",
      "T2\tMethod 197 204\tTACITUS\n",
      "T3\tMetric 227 243\tMUC-3 evaluation\n",
      "T4\tGeneric 273 283\ttechniques\n",
      "T5\tTask 289 321\tsyntactic and pragmatic analysis\n",
      "T6\tGeneric 345 352\tmethods\n",
      "T7\tMetric 367 377\trobustness\n",
      "T8\tGeneric 391 407\tthree techniques\n",
      "T9\tTask 420 438\tsyntactic analysis\n",
      "T10\tMethod 458 488\tagenda-based scheduling parser\n",
      "T11\tMethod 495 513\trecovery technique\n",
      "T12\tOtherScientificTerm 518 531\tfailed parses\n",
      "T13\tGeneric 545 554\ttechnique\n",
      "T14\tMethod 563 589\tterminal substring parsing\n",
      "T15\tTask 598 619\tpragmatics processing\n",
      "T16\tMethod 654 673\tabductive inference\n",
      "T17\tOtherScientificTerm 783 798\tworld knowledge\n",
      "T18\tGeneric 843 859\tthese techniques\n",
      "R1\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R2\tHYPONYM-OF Arg1:T15 Arg2:T5\n",
      "R3\tHYPONYM-OF Arg1:T9 Arg2:T5\n",
      "R4\tHYPONYM-OF Arg1:T10 Arg2:T8\n",
      "R5\tHYPONYM-OF Arg1:T8 Arg2:T18\n",
      "R6\tHYPONYM-OF Arg1:T16 Arg2:T18\n",
      "R7\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R8\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R9\tCOREF Arg1:T14 Arg2:T13\n",
      "R10\tHYPONYM-OF Arg1:T13 Arg2:T8\n",
      "R11\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R12\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R13\tCONJUNCTION Arg1:T11 Arg2:T13\n",
      "R14\tHYPONYM-OF Arg1:T11 Arg2:T8\n",
      "R15\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R16\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A92-1027.ann\n",
      "T1\tGeneric 27 36\talgorithm\n",
      "T2\tTask 42 78\tchart-based phrase structure parsing\n",
      "T3\tMaterial 84 100\tnatural language\n",
      "T4\tMethod 288 294\tparser\n",
      "T5\tOtherScientificTerm 355 367\tsearch space\n",
      "T6\tOtherScientificTerm 384 388\tedge\n",
      "T7\tOtherScientificTerm 407 412\tchart\n",
      "T8\tOtherScientificTerm 462 467\tedges\n",
      "T9\tOtherScientificTerm 507 512\tedges\n",
      "T10\tOtherScientificTerm 560 574\tspanning edges\n",
      "T11\tOtherScientificTerm 656 661\tedges\n",
      "T12\tMethod 789 815\tphrase boundary heuristics\n",
      "T13\tOtherScientificTerm 844 858\tfunction words\n",
      "T14\tMethod 870 885\theuristic rules\n",
      "T15\tOtherScientificTerm 965 978\tunknown words\n",
      "T16\tOtherScientificTerm 993 1022\treduction in the search space\n",
      "T17\tOtherScientificTerm 1046 1054\tsemantic\n",
      "T18\tOtherScientificTerm 1069 1089\tsyntactic categories\n",
      "T19\tOtherScientificTerm 1099 1130\tterminal and non-terminal edges\n",
      "T20\tOtherScientificTerm 1201 1206\tedges\n",
      "T21\tOtherScientificTerm 1222 1227\tedges\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R3\tCOMPARE Arg1:T17 Arg2:T18\n",
      "R4\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tCOREF Arg1:T4 Arg2:T1\n",
      "R7\tFEATURE-OF Arg1:T18 Arg2:T19\n",
      "R8\tFEATURE-OF Arg1:T17 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A94-1037.ann\n",
      "T1\tGeneric 1 8\tMethods\n",
      "T2\tTask 24 43\tspelling correction\n",
      "T3\tOtherScientificTerm 50 59\tlanguages\n",
      "T4\tOtherScientificTerm 67 74\tEnglish\n",
      "T5\tOtherScientificTerm 149 172\tagglutinative languages\n",
      "T6\tGeneric 199 207\tapproach\n",
      "T7\tTask 212 231\tspelling correction\n",
      "T8\tOtherScientificTerm 237 260\tagglutinative languages\n",
      "T9\tOtherScientificTerm 280 300\ttwo-level morphology\n",
      "T10\tMethod 309 351\tdynamic-programming based search algorithm\n",
      "T11\tGeneric 379 387\tapproach\n",
      "T12\tTask 431 450\tspelling correction\n",
      "T13\tOtherScientificTerm 456 463\tTurkish\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R4\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R5\tCOREF Arg1:T7 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R9\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R10\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R11\tCOREF Arg1:T11 Arg2:T6\n",
      "R12\tCOREF Arg1:T7 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A97-1020.ann\n",
      "T1\tMethod 2 9\tGLOSSER\n",
      "T2\tTask 34 54\treading and learning\n",
      "T3\tGeneric 104 118\tlanguage pairs\n",
      "T4\tMethod 144 151\tGLOSSER\n",
      "T5\tMaterial 155 172\tEnglish-Bulgarian\n",
      "T6\tMaterial 176 192\tEnglish-Estonian\n",
      "T7\tMaterial 196 213\tEnglish-Hungarian\n",
      "T8\tMaterial 220 232\tFrench-Dutch\n",
      "T9\tGeneric 239 246\tprogram\n",
      "T10\tOtherScientificTerm 265 295\tUNIX and Windows '95 platforms\n",
      "T11\tOtherScientificTerm 323 333\tuser-study\n",
      "T12\tTask 366 401\tApplied Natural Language Processing\n",
      "T13\tGeneric 414 424\tcomponents\n",
      "T14\tTask 457 517\tintelligent computer-assisted morphological analysis (ICALL)\n",
      "T15\tMethod 531 567\tdisambiguated morphological analysis\n",
      "T16\tMethod 574 593\tlemmatized indexing\n",
      "T17\tMaterial 603 627\taligned bilingual corpus\n",
      "R1\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R2\tCOREF Arg1:T4 Arg2:T1\n",
      "R3\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R4\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R5\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R6\tCOREF Arg1:T9 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R8\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R9\tHYPONYM-OF Arg1:T6 Arg2:T3\n",
      "R10\tHYPONYM-OF Arg1:T7 Arg2:T3\n",
      "R11\tHYPONYM-OF Arg1:T8 Arg2:T3\n",
      "R12\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R13\tHYPONYM-OF Arg1:T15 Arg2:T13\n",
      "R14\tHYPONYM-OF Arg1:T16 Arg2:T13\n",
      "R15\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R16\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R17\tUSED-FOR Arg1:T15 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A97-1021.ann\n",
      "T1\tMethod 62 112\tlexical conceptual structure (LCS) representations\n",
      "T2\tOtherScientificTerm 229 251\tbroad semantic classes\n",
      "T3\tMethod 258 280\tLCS meaning components\n",
      "T4\tMethod 288 320\tacquisition program - LEXICALL -\n",
      "T5\tTask 371 390\tverb classification\n",
      "T6\tTask 397 418\tthematic grid tagging\n",
      "T7\tMethod 434 453\tLCS representations\n",
      "T8\tGeneric 489 504\trepresentations\n",
      "T9\tOtherScientificTerm 529 565\tEnglish, Arabic and Spanish lexicons\n",
      "T10\tGeneric 642 650\tlexicons\n",
      "T11\tTask 659 696\toperational foreign language tutoring\n",
      "T12\tTask 703 722\tmachine translation\n",
      "R1\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R3\tCOREF Arg1:T8 Arg2:T7\n",
      "R4\tCOREF Arg1:T10 Arg2:T9\n",
      "R5\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R8\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R9\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R10\tCOREF Arg1:T7 Arg2:T1\n",
      "R11\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R12\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A97-1027.ann\n",
      "T1\tMethod 41 64\tmorphological component\n",
      "T2\tMethod 82 144\tNLP-system for Dutch (Dutch Medical Language Processor - DMLP)\n",
      "T3\tMethod 220 248\tlanguage independent modules\n",
      "T4\tMethod 258 329\tLSP-MLP system (Linguistic String Project - Medical Language Processor)\n",
      "T5\tGeneric 363 369\tformer\n",
      "T6\tGeneric 439 445\tlatter\n",
      "T7\tOtherScientificTerm 466 480\tidiosyncrasies\n",
      "T8\tMaterial 487 492\tDutch\n",
      "T9\tGeneric 552 563\tapplication\n",
      "T10\tTask 576 612\thighlighting of relevant information\n",
      "T11\tGeneric 592 612\trelevant information\n",
      "T12\tOtherScientificTerm 619 650\tpatient discharge summary (PDS)\n",
      "T13\tMethod 672 716\tHyperText Mark-Up Language (HTML) technology\n",
      "T14\tGeneric 727 738\tapplication\n",
      "T15\tTask 757 788\tmedical administrative purposes\n",
      "R1\tPART-OF Arg1:T1 Arg2:T2\n",
      "R2\tPART-OF Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R5\tCOREF Arg1:T14 Arg2:T9\n",
      "R6\tCOREF Arg1:T5 Arg2:T1\n",
      "R7\tCOREF Arg1:T6 Arg2:T3\n",
      "R8\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R9\tCOREF Arg1:T9 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T13 Arg2:T10\n",
      "R11\tPART-OF Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A97-1028.ann\n",
      "T1\tGeneric 29 48\tstatistical profile\n",
      "T2\tTask 58 75\tNamed Entity task\n",
      "T3\tTask 90 117\tinformation extraction task\n",
      "T4\tMethod 205 225\tstatistical analysis\n",
      "T5\tGeneric 243 252\talgorithm\n",
      "T6\tMethod 259 281\tlower bound estimation\n",
      "T7\tMaterial 288 308\tNamed Entity corpora\n",
      "T8\tGeneric 391 399\tanalysis\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tHYPONYM-OF Arg1:T2 Arg2:T3\n",
      "R4\tCOREF Arg1:T8 Arg2:T4\n",
      "R5\tCOREF Arg1:T4 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A97-1042.ann\n",
      "T1\tMethod 169 192\tOptimal Position Policy\n",
      "T2\tGeneric 197 203\tmethod\n",
      "T3\tOtherScientificTerm 227 264\tpositions of  topic-bearing sentences\n",
      "T4\tOtherScientificTerm 276 328\tgenre-specific regularities  of  discourse structure\n",
      "T5\tGeneric 336 342\tmethod\n",
      "T6\tGeneric 358 370\tapplications\n",
      "T7\tTask 380 401\tinformation retrieval\n",
      "T8\tTask 405 412\trouting\n",
      "T9\tTask 420 438\ttext summarization\n",
      "R1\tCOREF Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T5 Arg2:T2\n",
      "R3\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R4\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R5\tHYPONYM-OF Arg1:T7 Arg2:T6\n",
      "R6\tHYPONYM-OF Arg1:T8 Arg2:T6\n",
      "R7\tHYPONYM-OF Arg1:T9 Arg2:T6\n",
      "R8\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R9\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R10\tUSED-FOR Arg1:T4 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A97-1050.ann\n",
      "T1\tGeneric 35 44\talgorithm\n",
      "T2\tTask 49 88\ttranslation lexicon acquisition (SABLE)\n",
      "T3\tOtherScientificTerm 143 172\tgeneral  translation lexicons\n",
      "T4\tGeneric 186 195\talgorithm\n",
      "T5\tOtherScientificTerm 262 298\tdomain-specific translation lexicons\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\A97-1052.ann\n",
      "T1\tGeneric 47 53\tsystem\n",
      "T2\tOtherScientificTerm 74 102\tsubcategorization dictionary\n",
      "T3\tMaterial 110 125\ttextual corpora\n",
      "T4\tOtherScientificTerm 165 197\trelative frequency of occurrence\n",
      "T5\tOtherScientificTerm 564 592\tsubcategorization dictionary\n",
      "T6\tGeneric 609 615\tsystem\n",
      "T7\tMetric 630 638\taccuracy\n",
      "T8\tMethod 646 652\tparser\n",
      "R1\tEVALUATE-FOR Arg1:T8 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T6 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R5\tEVALUATE-FOR Arg1:T7 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\AAAI_1993_70_abs.ann\n",
      "T1\tMethod 4 29\tRete and Treat algorithms\n",
      "T2\tMethod 64 89\timplementation techniques\n",
      "T3\tTask 94 123\tForward Chaining rule systems\n",
      "T4\tGeneric 131 141\talgorithms\n",
      "T5\tMethod 152 188\tlanguage of limited expressive power\n",
      "T6\tOtherScientificTerm 190 200\tAssertions\n",
      "T7\tOtherScientificTerm 228 237\tvariables\n",
      "T8\tOtherScientificTerm 246 270\tuniversal quantification\n",
      "T9\tOtherScientificTerm 305 309\trule\n",
      "T10\tTask 348 364\tfull unification\n",
      "T11\tGeneric 374 384\talgorithms\n",
      "T12\tTask 416 432\tfull unification\n",
      "T13\tTask 444 460\tFull unification\n",
      "T14\tMetric 502 514\tcompile time\n",
      "T15\tMetric 519 527\trun time\n",
      "T16\tTask 554 570\tfull unification\n",
      "T17\tTask 638 654\tfull unification\n",
      "T18\tGeneric 703 705\tit\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tCOREF Arg1:T11 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R6\tCOREF Arg1:T17 Arg2:T16\n",
      "R7\tCOREF Arg1:T16 Arg2:T13\n",
      "R8\tCOREF Arg1:T13 Arg2:T12\n",
      "R9\tCOREF Arg1:T18 Arg2:T17\n",
      "R10\tCOREF Arg1:T12 Arg2:T10\n",
      "R11\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R12\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R13\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R14\tEVALUATE-FOR Arg1:T14 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\AAAI_1993_71_abs.ann\n",
      "T1\tTask 40 70\tlogical properties of contexts\n",
      "T2\tOtherScientificTerm 93 99\tsyntax\n",
      "T3\tOtherScientificTerm 104 113\tsemantics\n",
      "T4\tOtherScientificTerm 127 160\tpropositional language of context\n",
      "T5\tMethod 173 199\tHilbert style proof system\n",
      "T6\tGeneric 209 217\tlanguage\n",
      "T7\tOtherScientificTerm 221 251\tpropositional logic of context\n",
      "T8\tOtherScientificTerm 260 289\tclassical propositional logic\n",
      "T9\tOtherScientificTerm 318 326\tmodality\n",
      "T10\tGeneric 351 353\tIt\n",
      "T11\tMethod 620 646\tHilbert style proof system\n",
      "T12\tOtherScientificTerm 705 726\tcorrespondence theory\n",
      "R1\tCOREF Arg1:T4 Arg2:T6\n",
      "R2\tFEATURE-OF Arg1:T3 Arg2:T4\n",
      "R3\tFEATURE-OF Arg1:T2 Arg2:T4\n",
      "R4\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R5\tCOREF Arg1:T9 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R7\tCOREF Arg1:T5 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\AAAI_2008_254_abs.ann\n",
      "T1\tTask 4 33\tconstruction of causal graphs\n",
      "T2\tMaterial 39 60\tnon-experimental data\n",
      "T3\tOtherScientificTerm 79 90\tconstraints\n",
      "T4\tOtherScientificTerm 100 115\tgraph structure\n",
      "T5\tOtherScientificTerm 131 156\tprobability distributions\n",
      "T6\tOtherScientificTerm 177 182\tgraph\n",
      "T7\tGeneric 190 201\tconstraints\n",
      "T8\tOtherScientificTerm 220 247\tconditional inde-pendencies\n",
      "T9\tOtherScientificTerm 252 273\talgebraic constraints\n",
      "T10\tOtherScientificTerm 303 329\tconditional independencies\n",
      "T11\tMethod 370 397\tcausal induction algorithms\n",
      "T12\tOtherScientificTerm 399 416\tVerma constraints\n",
      "T13\tOtherScientificTerm 511 528\tVerma constraints\n",
      "T14\tGeneric 596 600\tthey\n",
      "T15\tOtherScientificTerm 614 636\tdormant independencies\n",
      "T16\tOtherScientificTerm 648 674\tconditional independencies\n",
      "T17\tOtherScientificTerm 688 716\tinterventional distributions\n",
      "T18\tGeneric 737 746\talgorithm\n",
      "T19\tOtherScientificTerm 768 788\tdormant independence\n",
      "T20\tOtherScientificTerm 809 818\tvariables\n",
      "T21\tOtherScientificTerm 838 850\tcausal graph\n",
      "T22\tOtherScientificTerm 867 879\tindependence\n",
      "T23\tGeneric 916 918\tit\n",
      "T24\tOtherScientificTerm 933 960\tinterventional distribution\n",
      "T25\tOtherScientificTerm 1004 1017\tinterventions\n",
      "T26\tOtherScientificTerm 1053 1075\tdormant independencies\n",
      "T27\tTask 1079 1092\tmodel testing\n",
      "T28\tTask 1097 1106\tinduction\n",
      "T29\tGeneric 1120 1129\talgorithm\n",
      "T30\tGeneric 1140 1151\tconstraints\n",
      "T31\tOtherScientificTerm 1164 1186\tdormant independencies\n",
      "T32\tOtherScientificTerm 1196 1212\textraneous edges\n",
      "T33\tOtherScientificTerm 1226 1238\tcausal graph\n",
      "R1\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R2\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R3\tFEATURE-OF Arg1:T5 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R5\tCOMPARE Arg1:T12 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R7\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R8\tFEATURE-OF Arg1:T16 Arg2:T17\n",
      "R9\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R10\tCOREF Arg1:T22 Arg2:T19\n",
      "R11\tCONJUNCTION Arg1:T27 Arg2:T28\n",
      "R12\tCOREF Arg1:T14 Arg2:T13\n",
      "R13\tCOREF Arg1:T23 Arg2:T22\n",
      "R14\tFEATURE-OF Arg1:T24 Arg2:T23\n",
      "R15\tUSED-FOR Arg1:T26 Arg2:T27\n",
      "R16\tUSED-FOR Arg1:T30 Arg2:T29\n",
      "R17\tPART-OF Arg1:T32 Arg2:T33\n",
      "R18\tCOREF Arg1:T7 Arg2:T3\n",
      "R19\tUSED-FOR Arg1:T26 Arg2:T28\n",
      "R20\tUSED-FOR Arg1:T29 Arg2:T32\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\AAAI_2008_255_abs.ann\n",
      "T1\tMethod 38 54\tbase classifiers\n",
      "T2\tTask 92 100\tensemble\n",
      "T3\tMethod 116 132\tensemble methods\n",
      "T4\tTask 263 284\tensemble construction\n",
      "T5\tTask 288 319\tresampling pairwise constraints\n",
      "T6\tOtherScientificTerm 401 421\tpairwise constraints\n",
      "T7\tTask 426 447\tensemble construction\n",
      "T8\tMethod 511 527\tbase classifiers\n",
      "T9\tOtherScientificTerm 537 565\tsampled pairwise constraints\n",
      "T10\tMethod 668 687\tdata representation\n",
      "T11\tOtherScientificTerm 694 705\tprojections\n",
      "T12\tOtherScientificTerm 718 738\tpairwise constraints\n",
      "T13\tMethod 759 776\tbase clas-sifiers\n",
      "T14\tMethod 790 809\tdata representation\n",
      "T15\tTask 838 869\tresampling pairwise constraints\n",
      "T16\tMethod 893 924\tBagging and Boosting algorithms\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tCOREF Arg1:T4 Arg2:T7\n",
      "R4\tCOREF Arg1:T2 Arg2:T4\n",
      "R5\tCOREF Arg1:T1 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R7\tCOREF Arg1:T8 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R9\tCOREF Arg1:T5 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R11\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R12\tCOREF Arg1:T10 Arg2:T14\n",
      "R13\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\AAAI_2008_262_abs.ann\n",
      "T1\tMethod 12 19\tYoopick\n",
      "T2\tMethod 23 61\tcombinatorial sports prediction market\n",
      "T3\tOtherScientificTerm 80 105\tflexible betting language\n",
      "T4\tTask 131 180\tfine-grained probabilistic estimation of outcomes\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\AAAI_2015_10_abs.ann\n",
      "T1\tTask 0 15\tMachine reading\n",
      "T2\tGeneric 36 41\tfield\n",
      "T3\tMethod 56 73\tcomputer programs\n",
      "T4\tMaterial 91 103\tflowing text\n",
      "T5\tOtherScientificTerm 116 131\tfact assertions\n",
      "T6\tMaterial 149 166\tnarrative content\n",
      "T7\tGeneric 173 177\ttask\n",
      "T8\tMethod 210 243\tnatural language processing (NLP)\n",
      "T9\tTask 248 275\tinformation extraction (IE)\n",
      "T10\tTask 305 327\tmachine reading system\n",
      "T11\tMethod 360 382\tcognitive architecture\n",
      "T12\tOtherScientificTerm 499 518\tcognitive semantics\n",
      "T13\tMethod 523 543\tconstruction grammar\n",
      "T14\tTask 561 570\tprior NLP\n",
      "T15\tTask 575 586\tIE research\n",
      "T16\tGeneric 604 610\tsystem\n",
      "T17\tMaterial 674 693\tidiosyncratic texts\n",
      "T18\tMaterial 701 722\tfamily history domain\n",
      "T19\tGeneric 776 782\tsystem\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R4\tFEATURE-OF Arg1:T5 Arg2:T6\n",
      "R5\tCOREF Arg1:T7 Arg2:T1\n",
      "R6\tPART-OF Arg1:T8 Arg2:T7\n",
      "R7\tPART-OF Arg1:T9 Arg2:T7\n",
      "R8\tFEATURE-OF Arg1:T11 Arg2:T10\n",
      "R9\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R10\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R11\tFEATURE-OF Arg1:T18 Arg2:T17\n",
      "R12\tCOREF Arg1:T16 Arg2:T10\n",
      "R13\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R14\tCOREF Arg1:T19 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\AAAI_2015_11_abs.ann\n",
      "T1\tTask 12 39\tconvex optimization problem\n",
      "T2\tTask 56 82\tsegmenting sequential data\n",
      "T3\tOtherScientificTerm 120 128\toutliers\n",
      "T4\tGeneric 146 156\talgorithms\n",
      "T5\tGeneric 174 181\tproblem\n",
      "T6\tMetric 311 321\tRobustness\n",
      "T7\tOtherScientificTerm 325 333\toutliers\n",
      "T8\tTask 354 370\treal-world tasks\n",
      "T9\tTask 382 401\tspeech segmentation\n",
      "T10\tGeneric 407 417\talgorithms\n",
      "T11\tMethod 429 462\tbaseline seg-mentation algorithms\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T5 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tCOMPARE Arg1:T10 Arg2:T11\n",
      "R5\tCOREF Arg1:T4 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R7\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R8\tEVALUATE-FOR Arg1:T8 Arg2:T6\n",
      "R9\tEVALUATE-FOR Arg1:T9 Arg2:T6\n",
      "R10\tFEATURE-OF Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\AAAI_2015_21_abs.ann\n",
      "T1\tMaterial 0 22\tSemantic Web documents\n",
      "T2\tTask 125 143\tCreating summaries\n",
      "T3\tMaterial 147 177\tlengthy Semantic Web documents\n",
      "T4\tTask 188 230\tidentification of the corresponding entity\n",
      "T5\tMethod 298 333\tautomatic summa-rization techniques\n",
      "T6\tOtherScientificTerm 482 513\tdiversified (faceted) summaries\n",
      "T7\tOtherScientificTerm 545 554\tdiversity\n",
      "T8\tOtherScientificTerm 556 566\tuniqueness\n",
      "T9\tOtherScientificTerm 572 582\tpopularity\n",
      "T10\tMethod 594 639\tdiversity-aware entity summarization approach\n",
      "T11\tMethod 647 685\thuman conceptual clustering techniques\n",
      "T12\tGeneric 868 876\tapproach\n",
      "T13\tGeneric 889 916\tstate-of-the-art techniques\n",
      "T14\tMetric 958 965\tquality\n",
      "T15\tMetric 974 984\tefficiency\n",
      "T16\tTask 988 1008\tentity summarization\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "R3\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R4\tFEATURE-OF Arg1:T8 Arg2:T6\n",
      "R5\tFEATURE-OF Arg1:T9 Arg2:T6\n",
      "R6\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R7\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R8\tCOREF Arg1:T10 Arg2:T12\n",
      "R9\tCOMPARE Arg1:T13 Arg2:T12\n",
      "R10\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R11\tEVALUATE-FOR Arg1:T14 Arg2:T16\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T16\n",
      "R13\tUSED-FOR Arg1:T13 Arg2:T16\n",
      "R14\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C00-1054.ann\n",
      "T1\tTask 2 23\tMultimodal interfaces\n",
      "T2\tMethod 43 50\tparsing\n",
      "T3\tGeneric 170 178\tapproach\n",
      "T4\tTask 204 226\tmultimodal integration\n",
      "T5\tMethod 262 287\tunification-based grammar\n",
      "T6\tMethod 308 337\tmultidimensional chart parser\n",
      "T7\tGeneric 363 371\tapproach\n",
      "T8\tOtherScientificTerm 424 434\tinterfaces\n",
      "T9\tMetric 565 589\tcomputational complexity\n",
      "T10\tGeneric 717 725\tapproach\n",
      "T11\tTask 736 772\tmultimodal parsing and understanding\n",
      "T12\tMethod 796 824\tweighted finite-state device\n",
      "T13\tMaterial 839 865\tspeech and gesture streams\n",
      "T14\tGeneric 922 930\tapproach\n",
      "T15\tTask 990 1014\tmultimodal understanding\n",
      "T16\tTask 1021 1039\tspeech recognition\n",
      "T17\tTask 1094 1125\tmultimodal ambiguity resolution\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R3\tCOREF Arg1:T7 Arg2:T3\n",
      "R4\tCOREF Arg1:T14 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R8\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R9\tCONJUNCTION Arg1:T16 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T17\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C00-2123.ann\n",
      "T1\tGeneric 30 46\tsearch procedure\n",
      "T2\tTask 52 88\tstatistical machine translation (MT)\n",
      "T3\tMethod 100 124\tdynamic programming (DP)\n",
      "T4\tMethod 143 160\tDP-based solution\n",
      "T5\tMethod 168 194\ttraveling salesman problem\n",
      "T6\tGeneric 215 224\ttechnique\n",
      "T7\tOtherScientificTerm 251 266\tword reordering\n",
      "T8\tMethod 338 354\tsearch algorithm\n",
      "T9\tMaterial 509 523\tVerbmobil task\n",
      "T10\tMaterial 526 540\tGerman-English\n",
      "T11\tTask 577 612\tlimited-domain spoken-language task\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tHYPONYM-OF Arg1:T9 Arg2:T11\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C02-1071.ann\n",
      "T1\tTask 38 53\tdeep processing\n",
      "T2\tMethod 73 91\tshallow techniques\n",
      "T3\tMethod 112 122\tNLP system\n",
      "T4\tMethod 144 177\tlinguistic PoS tagger and chunker\n",
      "T5\tMethod 211 262\tbroad coverage unification based grammar of Spanish\n",
      "T6\tGeneric 364 370\tsystem\n",
      "T7\tMetric 386 396\trobustness\n",
      "T8\tTask 406 427\tlinguistic processing\n",
      "T9\tMetric 457 465\taccuracy\n",
      "T10\tMetric 476 485\tprecision\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T6 Arg2:T3\n",
      "R3\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T3\n",
      "R6\tPART-OF Arg1:T4 Arg2:T5\n",
      "R7\tEVALUATE-FOR Arg1:T9 Arg2:T6\n",
      "R8\tEVALUATE-FOR Arg1:T10 Arg2:T6\n",
      "R9\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C02-1120.ann\n",
      "T1\tMethod 26 54\tunsupervised learning method\n",
      "T2\tOtherScientificTerm 61 107\tassociative relationships between verb phrases\n",
      "T3\tTask 153 164\tQ&A systems\n",
      "T4\tTask 283 293\tQ&A system\n",
      "T5\tMaterial 537 557\tlarge-scale database\n",
      "T6\tOtherScientificTerm 578 602\tassociative relationship\n",
      "T7\tMethod 665 693\tunsupervised learning method\n",
      "T8\tOtherScientificTerm 720 744\tassociative relationship\n",
      "T9\tOtherScientificTerm 762 782\tscenario consistency\n",
      "T10\tGeneric 789 795\tmethod\n",
      "T11\tMethod 833 894\texpectation-maximization (EM) based word-clustering algorithm\n",
      "T12\tGeneric 945 951\tmethod\n",
      "T13\tMaterial 959 980\tJapanese verb phrases\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R4\tCOREF Arg1:T10 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R6\tCOREF Arg1:T12 Arg2:T10\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R8\tCOREF Arg1:T8 Arg2:T6\n",
      "R9\tCOREF Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1011.ann\n",
      "T1\tMethod 43 68\tKullback-Leibler distance\n",
      "T2\tMethod 88 104\trelative entropy\n",
      "T3\tMethod 118 152\tprobabilistic context-free grammar\n",
      "T4\tOtherScientificTerm 161 191\tprobabilistic finite automaton\n",
      "T5\tMethod 219 252\tclosed-form (analytical) solution\n",
      "T6\tMethod 275 300\tKullback-Leibler distance\n",
      "T7\tMethod 312 325\tcross-entropy\n",
      "T8\tTask 393 421\tdistributional approximation\n",
      "T9\tMethod 427 462\tprobabilistic context-free grammars\n",
      "T10\tMethod 477 506\tprobabilistic finite automata\n",
      "R1\tCOMPARE Arg1:T3 Arg2:T4\n",
      "R2\tPART-OF Arg1:T7 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R4\tCOREF Arg1:T2 Arg2:T1\n",
      "R5\tCOREF Arg1:T10 Arg2:T4\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R8\tCOREF Arg1:T6 Arg2:T1\n",
      "R9\tFEATURE-OF Arg1:T8 Arg2:T9\n",
      "R10\tCOREF Arg1:T9 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1022.ann\n",
      "T1\tMethod 2 31\tStatistical language modeling\n",
      "T2\tGeneric 55 59\ttask\n",
      "T3\tMaterial 80 110\tmorphologically rich languages\n",
      "T4\tGeneric 127 137\tapproaches\n",
      "T5\tMethod 148 172\tfactored language models\n",
      "T6\tGeneric 226 232\tmodels\n",
      "T7\tOtherScientificTerm 283 305\tconditioning variables\n",
      "T8\tOtherScientificTerm 350 385\tmorphological or syntactic features\n",
      "T9\tOtherScientificTerm 433 449\tmodel parameters\n",
      "T10\tMethod 547 593\tentirely data-driven model selection procedure\n",
      "T11\tMethod 605 619\tgenetic search\n",
      "T12\tMethod 657 704\tknowledge-based and random selection procedures\n",
      "T13\tTask 724 747\tlanguage modeling tasks\n",
      "T14\tMaterial 751 757\tArabic\n",
      "T15\tMaterial 764 771\tTurkish\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R2\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R3\tCOREF Arg1:T6 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R5\tCOMPARE Arg1:T10 Arg2:T12\n",
      "R6\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R7\tHYPONYM-OF Arg1:T14 Arg2:T13\n",
      "R8\tHYPONYM-OF Arg1:T15 Arg2:T13\n",
      "R9\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R10\tCOREF Arg1:T2 Arg2:T1\n",
      "R11\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1024.ann\n",
      "T1\tMethod 15 48\tbit-vector-based CKY-style parser\n",
      "T2\tTask 55 75\tcontext-free parsing\n",
      "T3\tMethod 96 102\tparser\n",
      "T4\tMethod 124 151\tparse forest representation\n",
      "T5\tMethod 199 222\tlarge treebank grammars\n",
      "T6\tMethod 257 263\tparser\n",
      "T7\tMethod 271 292\tbit-vector operations\n",
      "T8\tMethod 346 352\tparser\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R3\tCOREF Arg1:T3 Arg2:T1\n",
      "R4\tCOREF Arg1:T6 Arg2:T3\n",
      "R5\tCOREF Arg1:T8 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1035.ann\n",
      "T1\tMethod 24 49\tmachine learning approach\n",
      "T2\tTask 55 80\tbare slice disambiguation\n",
      "T3\tMaterial 86 94\tdialogue\n",
      "T4\tMethod 118 138\theuristic principles\n",
      "T5\tMaterial 148 167\tcorpus-based sample\n",
      "T6\tOtherScientificTerm 192 218\tprobabilistic Horn clauses\n",
      "T7\tOtherScientificTerm 257 264\tclauses\n",
      "T8\tOtherScientificTerm 286 313\tdomain independent features\n",
      "T9\tMethod 370 397\tmachine learning algorithms\n",
      "T10\tGeneric 401 408\tSLIPPER\n",
      "T11\tMethod 413 442\trule-based learning algorithm\n",
      "T12\tGeneric 449 454\tTiMBL\n",
      "T13\tMethod 459 478\tmemory-based system\n",
      "T14\tMetric 527 540\tsuccess rates\n",
      "T15\tOtherScientificTerm 584 592\tfeatures\n",
      "T16\tMethod 630 650\theuristic principles\n",
      "T17\tOtherScientificTerm 697 702\trules\n",
      "T18\tOtherScientificTerm 731 743\tHorn clauses\n",
      "T19\tOtherScientificTerm 785 793\tfeatures\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tFEATURE-OF Arg1:T6 Arg2:T4\n",
      "R3\tCOMPARE Arg1:T11 Arg2:T13\n",
      "R4\tFEATURE-OF Arg1:T15 Arg2:T16\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R6\tPART-OF Arg1:T11 Arg2:T9\n",
      "R7\tPART-OF Arg1:T13 Arg2:T9\n",
      "R8\tHYPONYM-OF Arg1:T12 Arg2:T13\n",
      "R9\tHYPONYM-OF Arg1:T10 Arg2:T11\n",
      "R10\tCOREF Arg1:T9 Arg2:T1\n",
      "R11\tCOREF Arg1:T16 Arg2:T4\n",
      "R12\tCOREF Arg1:T18 Arg2:T6\n",
      "R13\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R14\tCOREF Arg1:T7 Arg2:T6\n",
      "R15\tCOREF Arg1:T19 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1036.ann\n",
      "T1\tMetric 28 48\tevaluation criterion\n",
      "T2\tMetric 55 79\tword similarity measures\n",
      "T3\tGeneric 90 99\tcriterion\n",
      "T4\tMetric 103 137\tmeaning-entailing substitutability\n",
      "T5\tTask 160 194\tsemantic-oriented NLP applications\n",
      "T6\tMetric 278 293\thuman agreement\n",
      "T7\tMetric 315 333\tsemantic criterion\n",
      "T8\tOtherScientificTerm 372 407\tdistributional word feature vectors\n",
      "T9\tTask 428 443\tword similarity\n",
      "T10\tGeneric 477 484\tmeasure\n",
      "T11\tMetric 501 523\tfeature vector quality\n",
      "T12\tMethod 544 584\tfeature weighting and selection function\n",
      "T13\tOtherScientificTerm 623 638\tfeature vectors\n",
      "T14\tTask 652 667\tword similarity\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tEVALUATE-FOR Arg1:T7 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T3 Arg2:T1\n",
      "R5\tCOREF Arg1:T4 Arg2:T3\n",
      "R6\tCOREF Arg1:T7 Arg2:T3\n",
      "R7\tEVALUATE-FOR Arg1:T6 Arg2:T4\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R9\tEVALUATE-FOR Arg1:T10 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R11\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R12\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1058.ann\n",
      "T1\tMethod 87 98\tclassifiers\n",
      "T2\tMethod 109 136\tmaximum entropy classifiers\n",
      "T3\tMethod 140 148\tboosting\n",
      "T4\tMethod 155 159\tSVMs\n",
      "T5\tTask 177 202\tlanguage processing tasks\n",
      "T6\tMethod 373 400\terror correction mechanisms\n",
      "T7\tGeneric 664 679\tbase classifier\n",
      "T8\tMethod 743 797\tN-fold Templated Piped Correction, or NTPC (\"nitpick\")\n",
      "T9\tMethod 815 830\terror corrector\n",
      "T10\tGeneric 920 922\tit\n",
      "T11\tGeneric 1000 1011\tbase models\n",
      "T12\tMethod 1082 1086\tNTPC\n",
      "T13\tOtherScientificTerm 1129 1151\tOccam's Razor argument\n",
      "R1\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R2\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T4 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T5\n",
      "R5\tHYPONYM-OF Arg1:T8 Arg2:T9\n",
      "R6\tCOREF Arg1:T9 Arg2:T6\n",
      "R7\tCOREF Arg1:T10 Arg2:T8\n",
      "R8\tCOMPARE Arg1:T10 Arg2:T11\n",
      "R9\tCOREF Arg1:T11 Arg2:T7\n",
      "R10\tCOREF Arg1:T12 Arg2:T8\n",
      "R11\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R12\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1068.ann\n",
      "T1\tTask 102 124\telectronic discussions\n",
      "T2\tTask 145 167\thelp-desk applications\n",
      "T3\tOtherScientificTerm 306 314\tfeatures\n",
      "T4\tTask 320 342\telectronic discussions\n",
      "T5\tMethod 364 382\tclustering process\n",
      "T6\tMethod 398 417\tfiltering mechanism\n",
      "T7\tMethod 473 507\tclustering and filtering processes\n",
      "T8\tMaterial 513 545\telectronic newsgroup discussions\n",
      "T9\tGeneric 598 609\texperiments\n",
      "T10\tTask 613 636\tcoarse-level clustering\n",
      "T11\tTask 646 667\tinformation retrieval\n",
      "R1\tEVALUATE-FOR Arg1:T8 Arg2:T7\n",
      "R2\tHYPONYM-OF Arg1:T10 Arg2:T9\n",
      "R3\tHYPONYM-OF Arg1:T11 Arg2:T9\n",
      "R4\tEVALUATE-FOR Arg1:T9 Arg2:T7\n",
      "R5\tCOREF Arg1:T4 Arg2:T1\n",
      "R6\tHYPONYM-OF Arg1:T5 Arg2:T7\n",
      "R7\tHYPONYM-OF Arg1:T6 Arg2:T7\n",
      "R8\tPART-OF Arg1:T1 Arg2:T2\n",
      "R9\tFEATURE-OF Arg1:T3 Arg2:T4\n",
      "R10\tEVALUATE-FOR Arg1:T9 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1080.ann\n",
      "T1\tMethod 18 28\tHMM tagger\n",
      "T2\tGeneric 106 108\tit\n",
      "T3\tTask 122 154\tunsupervised and supervised case\n",
      "T4\tMethod 222 242\tunsupervised methods\n",
      "T5\tTask 247 269\tpart-of-speech tagging\n",
      "T6\tMetric 434 442\taccuracy\n",
      "T7\tGeneric 473 483\talgorithms\n",
      "T8\tMethod 510 522\tHMM training\n",
      "T9\tOtherScientificTerm 569 590\tlexical probabilities\n",
      "T10\tGeneric 635 641\ttagger\n",
      "T11\tTask 682 726\tsupervised, non-training intensive framework\n",
      "R1\tCOREF Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tCOREF Arg1:T10 Arg2:T1\n",
      "R4\tEVALUATE-FOR Arg1:T3 Arg2:T2\n",
      "R5\tCOREF Arg1:T7 Arg2:T4\n",
      "R6\tEVALUATE-FOR Arg1:T11 Arg2:T10\n",
      "R7\tEVALUATE-FOR Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1096.ann\n",
      "T1\tOtherScientificTerm 26 47\treferring expressions\n",
      "T2\tOtherScientificTerm 94 110\tbinary relations\n",
      "T3\tOtherScientificTerm 340 355\tn-ary relations\n",
      "T4\tOtherScientificTerm 521 542\treferring expressions\n",
      "T5\tMethod 577 597\tgeneration algorithm\n",
      "T6\tGeneric 687 693\tmethod\n",
      "T7\tOtherScientificTerm 728 749\treferring expressions\n",
      "R1\tCOREF Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1102.ann\n",
      "T1\tMethod 15 31\tdetection method\n",
      "T2\tOtherScientificTerm 37 58\torthographic variants\n",
      "T3\tTask 70 85\ttransliteration\n",
      "T4\tGeneric 112 118\tmethod\n",
      "T5\tGeneric 132 144\tsimilarities\n",
      "T6\tOtherScientificTerm 155 172\tstring similarity\n",
      "T7\tMethod 184 197\tedit distance\n",
      "T8\tOtherScientificTerm 214 235\tcontextual similarity\n",
      "T9\tMethod 243 261\tvector space model\n",
      "T10\tGeneric 299 305\tmethod\n",
      "T11\tMetric 325 334\tF-measure\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R6\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R7\tHYPONYM-OF Arg1:T8 Arg2:T5\n",
      "R8\tCOREF Arg1:T10 Arg2:T4\n",
      "R9\tEVALUATE-FOR Arg1:T11 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1103.ann\n",
      "T1\tTask 2 46\tMachine transliteration/back-transliteration\n",
      "T2\tTask 81 126\tmultilingual speech and language applications\n",
      "T3\tGeneric 152 161\tframework\n",
      "T4\tTask 167 210\tmachine transliteration/backtransliteration\n",
      "T5\tMethod 241 276\tdirect orthographical mapping (DOM)\n",
      "T6\tGeneric 337 346\tframework\n",
      "T7\tMethod 351 393\tjoint source-channel transliteration model\n",
      "T8\tMethod 409 449\tn-gram transliteration model (n-gram TM)\n",
      "T9\tMethod 486 509\ttransliteration process\n",
      "T10\tGeneric 537 544\tmethods\n",
      "T11\tTask 562 597\ttransliteration/backtransliteration\n",
      "T12\tMaterial 616 667\tEnglish/Chinese and English/Japanese language pairs\n",
      "T13\tGeneric 706 712\tmethod\n",
      "T14\tMetric 794 818\ttransliteration accuracy\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tCOREF Arg1:T8 Arg2:T7\n",
      "R6\tCOREF Arg1:T6 Arg2:T3\n",
      "R7\tCOREF Arg1:T10 Arg2:T8\n",
      "R8\tCOREF Arg1:T13 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R10\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R11\tEVALUATE-FOR Arg1:T11 Arg2:T10\n",
      "R12\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R13\tCOREF Arg1:T11 Arg2:T1\n",
      "R14\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1106.ann\n",
      "T1\tTask 17 40\tanalogies between words\n",
      "T2\tTask 234 261\tanalogies between sentences\n",
      "T3\tMaterial 355 374\tmultilingual corpus\n",
      "T4\tOtherScientificTerm 403 412\tanalogies\n",
      "T5\tOtherScientificTerm 514 521\tanalogy\n",
      "R1\tEVALUATE-FOR Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1112.ann\n",
      "T1\tMethod 30 92\tcorpus-based supervised word sense disambiguation (WSD) system\n",
      "T2\tMaterial 99 104\tDutch\n",
      "T3\tMethod 122 148\tstatistical classification\n",
      "T4\tMethod 152 167\tmaximum entropy\n",
      "T5\tOtherScientificTerm 176 198\tlinguistic information\n",
      "T6\tMethod 233 244\tclassifiers\n",
      "T7\tOtherScientificTerm 251 269\tambiguous wordform\n",
      "T8\tMethod 288 308\tlemma-based approach\n",
      "T9\tGeneric 339 345\tmethod\n",
      "T10\tGeneric 354 356\tit\n",
      "T11\tOtherScientificTerm 371 386\tinflected forms\n",
      "T12\tOtherScientificTerm 395 409\tambiguous word\n",
      "T13\tMethod 419 429\tclassifier\n",
      "T14\tGeneric 495 504\talgorithm\n",
      "T15\tMethod 520 537\tlemma-based model\n",
      "T16\tMaterial 547 573\tDutch Senseval-2 test data\n",
      "T17\tMethod 634 648\twordform model\n",
      "T18\tMethod 662 688\tWSD system based on lemmas\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOMPARE Arg1:T6 Arg2:T8\n",
      "R3\tFEATURE-OF Arg1:T11 Arg2:T12\n",
      "R4\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "R5\tCOREF Arg1:T4 Arg2:T3\n",
      "R6\tCONJUNCTION Arg1:T5 Arg2:T4\n",
      "R7\tPART-OF Arg1:T3 Arg2:T1\n",
      "R8\tPART-OF Arg1:T5 Arg2:T1\n",
      "R9\tPART-OF Arg1:T4 Arg2:T1\n",
      "R10\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R11\tCOREF Arg1:T9 Arg2:T8\n",
      "R12\tCOREF Arg1:T14 Arg2:T9\n",
      "R13\tCOMPARE Arg1:T15 Arg2:T17\n",
      "R14\tCOREF Arg1:T18 Arg2:T15\n",
      "R15\tCOREF Arg1:T15 Arg2:T14\n",
      "R16\tCOREF Arg1:T8 Arg2:T1\n",
      "R17\tCOREF Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1116.ann\n",
      "T1\tMethod 15 33\ttext mining method\n",
      "T2\tOtherScientificTerm 48 70\tsynonymous expressions\n",
      "T3\tOtherScientificTerm 86 111\tdistributional hypothesis\n",
      "T4\tGeneric 171 182\tmethodology\n",
      "T5\tMetric 199 207\taccuracy\n",
      "T6\tMethod 215 238\tterm aggregation system\n",
      "T7\tGeneric 295 303\tapproach\n",
      "T8\tOtherScientificTerm 445 469\tsimilar context features\n",
      "T9\tOtherScientificTerm 513 535\tsynonymous expressions\n",
      "T10\tGeneric 551 557\tmethod\n",
      "T11\tMetric 572 580\taccuracy\n",
      "T12\tMethod 590 613\tterm aggregation system\n",
      "T13\tGeneric 633 641\tapproach\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tCOREF Arg1:T7 Arg2:T4\n",
      "R5\tCOREF Arg1:T10 Arg2:T7\n",
      "R6\tCOREF Arg1:T12 Arg2:T6\n",
      "R7\tEVALUATE-FOR Arg1:T6 Arg2:T4\n",
      "R8\tEVALUATE-FOR Arg1:T12 Arg2:T10\n",
      "R9\tCOREF Arg1:T13 Arg2:T10\n",
      "R10\tEVALUATE-FOR Arg1:T5 Arg2:T6\n",
      "R11\tEVALUATE-FOR Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1128.ann\n",
      "T1\tMethod 8 27\tsentence extraction\n",
      "T2\tTask 48 61\tsummarization\n",
      "T3\tMaterial 163 182\temail communication\n",
      "T4\tMethod 249 268\tsentence extraction\n",
      "T5\tTask 405 440\tdetection of  question-answer pairs\n",
      "T6\tMaterial 449 467\temail conversation\n",
      "T7\tTask 486 505\temail summarization\n",
      "T8\tOtherScientificTerm 530 538\tfeatures\n",
      "T9\tOtherScientificTerm 553 579\tstructure of email-threads\n",
      "T10\tOtherScientificTerm 609 627\tlexical similarity\n",
      "T11\tOtherScientificTerm 633 651\tdiscourse segments\n",
      "T12\tTask 658 681\tquestion-answer pairing\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tFEATURE-OF Arg1:T10 Arg2:T11\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T12\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1147.ann\n",
      "T1\tGeneric 14 23\tframework\n",
      "T2\tTask 32 78\tfast  computation  of  lexical affinity models\n",
      "T3\tGeneric 85 94\tframework\n",
      "T4\tGeneric 118 127\talgorithm\n",
      "T5\tOtherScientificTerm 156 182\tco-occurrence distribution\n",
      "T6\tMethod 214 232\tindependence model\n",
      "T7\tMethod 242 267\tparametric affinity model\n",
      "T8\tGeneric 299 305\tmodels\n",
      "T9\tOtherScientificTerm 355 365\tsimilarity\n",
      "T10\tOtherScientificTerm 391 407\tlexical affinity\n",
      "T11\tMethod 420 437\tsequential models\n",
      "T12\tGeneric 467 473\tmodels\n",
      "T13\tOtherScientificTerm 500 522\tco-occurrence patterns\n",
      "T14\tGeneric 597 606\tframework\n",
      "T15\tGeneric 694 696\tit\n",
      "T16\tMaterial 720 735\tterabyte corpus\n",
      "T17\tTask 748 770\tnatural language tests\n",
      "R1\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tPART-OF Arg1:T4 Arg2:T3\n",
      "R4\tPART-OF Arg1:T6 Arg2:T3\n",
      "R5\tPART-OF Arg1:T7 Arg2:T3\n",
      "R6\tCOMPARE Arg1:T12 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R9\tCOREF Arg1:T14 Arg2:T3\n",
      "R10\tCOREF Arg1:T15 Arg2:T14\n",
      "R11\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "R12\tUSED-FOR Arg1:T15 Arg2:T17\n",
      "R13\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R14\tCONJUNCTION Arg1:T4 Arg2:T6\n",
      "R15\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C04-1192.ann\n",
      "T1\tGeneric 22 28\tmethod\n",
      "T2\tTask 34 59\tword sense disambiguation\n",
      "T3\tMaterial 71 87\tparallel corpora\n",
      "T4\tGeneric 94 100\tmethod\n",
      "T5\tTask 130 144\tword alignment\n",
      "T6\tTask 151 166\tword clustering\n",
      "T7\tTask 178 227\tautomatic extraction  of  translation equivalents\n",
      "T8\tMaterial 262 279\taligned  wordnets\n",
      "T9\tMaterial 323 331\twordnets\n",
      "T10\tMaterial 353 370\tPrinceton Wordnet\n",
      "T11\tMaterial 417 428\tEuroWordNet\n",
      "T12\tMethod 454 464\tWSD system\n",
      "T13\tGeneric 484 490\tmethod\n",
      "T14\tGeneric 550 556\tsystem\n",
      "T15\tOtherScientificTerm 615 668\talignment errors  in  multilingually aligned wordnets\n",
      "T16\tMaterial 637 668\tmultilingually aligned wordnets\n",
      "T17\tMaterial 674 682\tBalkaNet\n",
      "T18\tMaterial 689 700\tEuroWordNet\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T4 Arg2:T1\n",
      "R3\tCOREF Arg1:T12 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R6\tCOREF Arg1:T14 Arg2:T12\n",
      "R7\tHYPONYM-OF Arg1:T17 Arg2:T16\n",
      "R8\tHYPONYM-OF Arg1:T18 Arg2:T16\n",
      "R9\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R10\tUSED-FOR Arg1:T7 Arg2:T4\n",
      "R11\tUSED-FOR Arg1:T8 Arg2:T4\n",
      "R12\tCOREF Arg1:T9 Arg2:T8\n",
      "R13\tCOREF Arg1:T13 Arg2:T4\n",
      "R14\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R15\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R16\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C08-1118.ann\n",
      "T1\tMaterial 86 108\tmedium-length speeches\n",
      "T2\tMaterial 117 132\tEUROPARL corpus\n",
      "T3\tMethod 151 185\tfrequency counts  of  word n-grams\n",
      "T4\tOtherScientificTerm 173 185\tword n-grams\n",
      "T5\tMetric 201 209\taccuracy\n",
      "T6\tMethod 225 246\tclassification method\n",
      "T7\tOtherScientificTerm 291 307\tpositive markers\n",
      "R1\tPART-OF Arg1:T1 Arg2:T2\n",
      "R2\tEVALUATE-FOR Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C08-1128.ann\n",
      "T1\tMaterial 13 25\tChinese text\n",
      "T2\tTask 109 141\tmachine translation (MT) systems\n",
      "T3\tTask 148 150\tMT\n",
      "T4\tMethod 193 215\tChinese word segmenter\n",
      "T5\tMaterial 231 254\tmanually annotated data\n",
      "T6\tMethod 288 305\tword segmentation\n",
      "T7\tTask 339 350\ttranslation\n",
      "T8\tMethod 367 423\tBayesian semi-supervised Chinese word segmentation model\n",
      "T9\tOtherScientificTerm 442 479\tmonolingual and bilingual information\n",
      "T10\tTask 494 506\tsegmentation\n",
      "T11\tTask 522 524\tMT\n",
      "T12\tGeneric 553 559\tmethod\n",
      "T13\tMethod 589 598\tMT system\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R4\tCOREF Arg1:T3 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R6\tCOREF Arg1:T6 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R8\tCOREF Arg1:T7 Arg2:T3\n",
      "R9\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R10\tCOREF Arg1:T12 Arg2:T8\n",
      "R11\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R12\tCOREF Arg1:T11 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C08-2010.ann\n",
      "T1\tMetric 2 27\tLanguage resource quality\n",
      "T2\tTask 44 47\tNLP\n",
      "T3\tTask 134 137\tNLP\n",
      "T4\tTask 170 172\tMT\n",
      "T5\tTask 179 201\treference translations\n",
      "T6\tTask 213 234\tautomatic evaluations\n",
      "T7\tMaterial 242 259\thigh-quality data\n",
      "T8\tGeneric 355 364\tresources\n",
      "T9\tOtherScientificTerm 448 476\tdifferent-quality references\n",
      "T10\tGeneric 482 492\tevaluation\n",
      "T11\tMetric 615 632\tautomatic metrics\n",
      "T12\tTask 647 649\tMT\n",
      "R1\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R2\tEVALUATE-FOR Arg1:T11 Arg2:T12\n",
      "R3\tCOREF Arg1:T10 Arg2:T6\n",
      "R4\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R5\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R6\tCOREF Arg1:T12 Arg2:T4\n",
      "R7\tCOREF Arg1:T3 Arg2:T2\n",
      "R8\tCOREF Arg1:T8 Arg2:T7\n",
      "R9\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R10\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R11\tFEATURE-OF Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C08-3010.ann\n",
      "T1\tMethod 36 47\tsearch tool\n",
      "T2\tOtherScientificTerm 68 74\tngrams\n",
      "T3\tGeneric 81 85\ttool\n",
      "T4\tGeneric 146 148\tIt\n",
      "T5\tGeneric 246 252\tsystem\n",
      "T6\tOtherScientificTerm 301 307\tmemory\n",
      "T7\tOtherScientificTerm 330 340\tdisk space\n",
      "T8\tGeneric 366 372\tsystem\n",
      "T9\tGeneric 394 398\ttool\n",
      "T10\tTask 404 434\tlinguistic knowledge discovery\n",
      "T11\tTask 447 456\tNLP tasks\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T8 Arg2:T5\n",
      "R4\tCOREF Arg1:T9 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R7\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T4 Arg2:T3\n",
      "R9\tCOREF Arg1:T5 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C80-1039.ann\n",
      "T1\tGeneric 147 153\tsystem\n",
      "T2\tMethod 155 160\tFROFF\n",
      "T3\tOtherScientificTerm 361 376\ttyping location\n",
      "T4\tOtherScientificTerm 543 551\tcommands\n",
      "T5\tOtherScientificTerm 556 561\trules\n",
      "T6\tOtherScientificTerm 640 664\tmathematical expressions\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R2\tCOREF Arg1:T2 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R4\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C80-1073.ann\n",
      "T1\tMethod 39 67\tAugmented Transition Network\n",
      "T2\tMethod 86 98\tdialog model\n",
      "T3\tGeneric 129 134\tmodel\n",
      "T4\tGeneric 186 192\tdevice\n",
      "T5\tOtherScientificTerm 228 243\tdialog schemata\n",
      "T6\tMethod 268 289\tconversation analysis\n",
      "T7\tGeneric 298 304\tdevice\n",
      "T8\tGeneric 330 336\tmodels\n",
      "T9\tOtherScientificTerm 340 358\tverbal interaction\n",
      "T10\tGeneric 367 373\tdevice\n",
      "T11\tOtherScientificTerm 401 416\tdialog schemata\n",
      "T12\tOtherScientificTerm 429 447\tverbal interaction\n",
      "T13\tMaterial 471 510\ttask-oriented and goal-directed dialogs\n",
      "T14\tMethod 526 529\tATN\n",
      "T15\tOtherScientificTerm 588 607\tverbal interactions\n",
      "T16\tMaterial 613 634\ttask-oriented dialogs\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tFEATURE-OF Arg1:T15 Arg2:T16\n",
      "R3\tCOREF Arg1:T7 Arg2:T3\n",
      "R4\tCOREF Arg1:T10 Arg2:T3\n",
      "R5\tCOREF Arg1:T14 Arg2:T3\n",
      "R6\tCOREF Arg1:T15 Arg2:T12\n",
      "R7\tCOREF Arg1:T11 Arg2:T5\n",
      "R8\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R9\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R11\tCOREF Arg1:T12 Arg2:T9\n",
      "R12\tCOREF Arg1:T3 Arg2:T1\n",
      "R13\tCOREF Arg1:T3 Arg2:T4\n",
      "R14\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R15\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R16\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C82-1054.ann\n",
      "T1\tMethod 57 86\tleft corner parsing algorithm\n",
      "T2\tMethod 93 114\tcontext-free grammars\n",
      "T3\tGeneric 150 159\talgorithm\n",
      "T4\tMethod 233 239\tparser\n",
      "T5\tTask 252 278\tnatural language interface\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tCOREF Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C86-1021.ann\n",
      "T1\tMethod 6 27\tinterlingual approach\n",
      "T2\tGeneric 31 33\tMT\n",
      "T3\tTask 106 136\tnatural language understanding\n",
      "T4\tTask 148 167\tmachine translation\n",
      "T5\tMethod 384 394\tMu-project\n",
      "T6\tMethod 409 426\ttransfer approach\n",
      "T7\tTask 455 457\tMT\n",
      "T8\tGeneric 515 529\ttransfer phase\n",
      "T9\tGeneric 538 544\tsystem\n",
      "T10\tMaterial 551 559\tJapanese\n",
      "T11\tMaterial 565 572\tEnglish\n",
      "T12\tMethod 649 670\tinterlingual approach\n",
      "T13\tGeneric 709 723\ttransfer phase\n",
      "T14\tGeneric 732 738\tsystem\n",
      "T15\tGeneric 791 801\tprinciples\n",
      "T16\tMethod 858 884\tMultiple Layer of Grammars\n",
      "T17\tMethod 891 918\tMultiple Layer Presentation\n",
      "T18\tMethod 925 950\tLexicon Driven Processing\n",
      "T19\tMethod 957 993\tForm-Oriented Dictionary Description\n",
      "T20\tGeneric 1028 1038\tprinciples\n",
      "T21\tGeneric 1067 1073\tsystem\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T4 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R4\tPART-OF Arg1:T8 Arg2:T9\n",
      "R5\tCOREF Arg1:T9 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R7\tCOREF Arg1:T13 Arg2:T8\n",
      "R8\tCOREF Arg1:T14 Arg2:T9\n",
      "R9\tPART-OF Arg1:T13 Arg2:T14\n",
      "R10\tPART-OF Arg1:T16 Arg2:T15\n",
      "R11\tPART-OF Arg1:T17 Arg2:T15\n",
      "R12\tPART-OF Arg1:T18 Arg2:T15\n",
      "R13\tPART-OF Arg1:T19 Arg2:T15\n",
      "R14\tCOREF Arg1:T21 Arg2:T14\n",
      "R15\tCOREF Arg1:T20 Arg2:T15\n",
      "R16\tPART-OF Arg1:T20 Arg2:T21\n",
      "R17\tCOREF Arg1:T8 Arg2:T6\n",
      "R18\tCOREF Arg1:T12 Arg2:T1\n",
      "R19\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R20\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R21\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C86-1081.ann\n",
      "T1\tMethod 4 15\tDeterminers\n",
      "T2\tMethod 284 295\tdeterminers\n",
      "T3\tOtherScientificTerm 316 325\tambiguity\n",
      "T4\tMethod 357 374\tlogical formalism\n",
      "T5\tTask 435 446\tdeterminers\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tCOREF Arg1:T5 Arg2:T2\n",
      "R4\tCOREF Arg1:T2 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C86-1105.ann\n",
      "T1\tOtherScientificTerm 16 38\thierarchical relations\n",
      "T2\tOtherScientificTerm 46 77\tsuperordinate -hyponym relation\n",
      "T3\tOtherScientificTerm 81 97\tsynonym relation\n",
      "T4\tTask 143 165\tthesaurus construction\n",
      "T5\tGeneric 205 214\trelations\n",
      "T6\tMaterial 248 276\tJapanese language dictionary\n",
      "T7\tOtherScientificTerm 367 375\tfeatures\n",
      "T8\tOtherScientificTerm 384 404\tdefinition sentences\n",
      "T9\tGeneric 414 424\tdictionary\n",
      "T10\tOtherScientificTerm 461 483\thierarchical relations\n",
      "R1\tPART-OF Arg1:T1 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tPART-OF Arg1:T8 Arg2:T9\n",
      "R4\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R5\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R6\tCOREF Arg1:T5 Arg2:T1\n",
      "R7\tCOREF Arg1:T9 Arg2:T6\n",
      "R8\tCOREF Arg1:T10 Arg2:T5\n",
      "R9\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C86-1132.ann\n",
      "T1\tGeneric 26 32\tsystem\n",
      "T2\tMethod 36 42\tRAREAS\n",
      "T3\tTask 64 88\tmarine weather forecasts\n",
      "T4\tMaterial 104 126\tformatted weather data\n",
      "T5\tGeneric 136 145\tsynthesis\n",
      "T6\tMaterial 176 230\tnatural sublanguages  with  stereotyped text structure\n",
      "T7\tMethod 235 241\tRAREAS\n",
      "T8\tOtherScientificTerm 270 309\tlinguistic and non-linguistic knowledge\n",
      "T9\tGeneric 441 449\tapproach\n",
      "T10\tMaterial 487 519\tbilingual or multi-lingual texts\n",
      "R1\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R2\tCOREF Arg1:T2 Arg2:T1\n",
      "R3\tCOREF Arg1:T5 Arg2:T1\n",
      "R4\tCOREF Arg1:T7 Arg2:T5\n",
      "R5\tCOREF Arg1:T9 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R8\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-1007.ann\n",
      "T1\tMethod 44 80\tUnification Categorial Grammar (UCG)\n",
      "T2\tMethod 103 122\tIsomorphic Grammars\n",
      "T3\tTask 129 148\tMachine Translation\n",
      "T4\tMethod 181 209\tIsomorphic Grammars approach\n",
      "T5\tTask 213 215\tMT\n",
      "T6\tOtherScientificTerm 372 392\ttranslation relation\n",
      "T7\tOtherScientificTerm 400 422\tisomorphic derivations\n",
      "T8\tOtherScientificTerm 729 749\ttranslation relation\n",
      "T9\tMethod 771 793\ttextual representation\n",
      "T10\tGeneric 820 828\tapproach\n",
      "T11\tTask 833 850\tMT system  design\n",
      "T12\tTask 871 886\tmonolingual UCG\n",
      "T13\tGeneric 911 914\ttwo\n",
      "T14\tOtherScientificTerm 978 1017\tbi-directional English-Spanish fragment\n",
      "T15\tGeneric 1080 1088\tapproach\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R3\tCOREF Arg1:T15 Arg2:T10\n",
      "R4\tHYPONYM-OF Arg1:T12 Arg2:T13\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tCOREF Arg1:T2 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R8\tCOREF Arg1:T5 Arg2:T3\n",
      "R9\tCOREF Arg1:T4 Arg2:T10\n",
      "R10\tCOREF Arg1:T5 Arg2:T11\n",
      "R11\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R12\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R13\tHYPONYM-OF Arg1:T11 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-1044.ann\n",
      "T1\tOtherScientificTerm 75 100\tdemonstrative expressions\n",
      "T2\tMaterial 106 113\tEnglish\n",
      "T3\tGeneric 129 141\timplications\n",
      "T4\tMethod 155 186\tdiscourse processing algorithms\n",
      "T5\tOtherScientificTerm 259 292\tdemonstrative forms and functions\n",
      "T6\tOtherScientificTerm 361 382\tanaphoric expressions\n",
      "T7\tMethod 436 470\tnatural language generation system\n",
      "R1\tFEATURE-OF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-1066.ann\n",
      "T1\tTask 29 84\tformalism of  Category Cooccurrence Restrictions (CCRs)\n",
      "T2\tOtherScientificTerm 43 84\tCategory Cooccurrence Restrictions (CCRs)\n",
      "T3\tMethod 105 123\tparsing algorithms\n",
      "T4\tGeneric 140 142\tit\n",
      "T5\tOtherScientificTerm 145 149\tCCRs\n",
      "T6\tOtherScientificTerm 156 174\tBoolean conditions\n",
      "T7\tOtherScientificTerm 216 227\tlocal trees\n",
      "T8\tOtherScientificTerm 246 274\tstatement of generalizations\n",
      "T9\tMethod 319 336\tsyntax formalisms\n",
      "T10\tOtherScientificTerm 352 356\tCCRs\n",
      "T11\tOtherScientificTerm 368 390\tsyntactic descriptions\n",
      "T12\tOtherScientificTerm 418 440\trestrictive statements\n",
      "T13\tGeneric 477 487\talgorithms\n",
      "T14\tMaterial 509 531\tcontext free languages\n",
      "T15\tTask 556 569\tCCR formalism\n",
      "T16\tMethod 620 626\tparser\n",
      "T17\tOtherScientificTerm 660 694\tlogical well-formedness conditions\n",
      "T18\tOtherScientificTerm 700 705\ttrees\n",
      "R1\tFEATURE-OF Arg1:T12 Arg2:T11\n",
      "R2\tFEATURE-OF Arg1:T17 Arg2:T18\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T10 Arg2:T5\n",
      "R5\tCOREF Arg1:T5 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R8\tCOREF Arg1:T13 Arg2:T3\n",
      "R9\tCOREF Arg1:T16 Arg2:T13\n",
      "R10\tCOREF Arg1:T15 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-2086.ann\n",
      "T1\tTask 63 95\tnatural language presuppositions\n",
      "T2\tTask 374 406\tnatural language presuppositions\n",
      "T3\tOtherScientificTerm 495 518\tpresuppositional nature\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-2130.ann\n",
      "T1\tGeneric 24 43\tcomputational model\n",
      "T2\tTask 127 141\tdiscourse task\n",
      "T3\tGeneric 200 205\tmodel\n",
      "T4\tGeneric 224 231\tprogram\n",
      "T5\tMethod 234 237\tAPT\n",
      "T6\tMethod 314 353\torganizational and discourse strategies\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tPART-OF Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-2132.ann\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-2160.ann\n",
      "T1\tGeneric 9 17\tapproach\n",
      "T2\tTask 23 54\tInteractive Machine Translation\n",
      "T3\tMethod 278 295\tlinguistic theory\n",
      "T4\tMethod 420 439\ttranslation process\n",
      "T5\tMethod 470 503\tinteractive disambiguation scheme\n",
      "T6\tMethod 519 531\tparaphrasing\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T5 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-2162.ann\n",
      "T1\tGeneric 3 20\tComputer programs\n",
      "T2\tTask 61 81\tlanguage acquisition\n",
      "T3\tMethod 101 121\tlearning methodology\n",
      "T4\tMaterial 138 153\tgeneral domains\n",
      "T5\tMaterial 192 209\tlinguistic domain\n",
      "T6\tMethod 227 252\tlinguistic representation\n",
      "T7\tMethod 263 290\tlanguage processing systems\n",
      "T8\tMethod 343 368\tlinguistic representation\n",
      "T9\tOtherScientificTerm 377 420\tDynamic Hierarchical Phrasal Lexicon (DHPL)\n",
      "T10\tTask 449 469\tlanguage acquisition\n",
      "T11\tMethod 487 510\tlanguage learning model\n",
      "T12\tMethod 544 548\tRINA\n",
      "T13\tOtherScientificTerm 576 593\tlexical hierarchy\n",
      "T14\tOtherScientificTerm 667 686\tlinguistic concepts\n",
      "T15\tGeneric 746 755\thierarchy\n",
      "T16\tOtherScientificTerm 851 868\tlexical hierarchy\n",
      "T17\tOtherScientificTerm 897 916\tlinguistic concepts\n",
      "T18\tGeneric 929 936\tprogram\n",
      "R1\tCOMPARE Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R4\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R6\tPART-OF Arg1:T11 Arg2:T12\n",
      "R7\tPART-OF Arg1:T14 Arg2:T15\n",
      "R8\tCOREF Arg1:T18 Arg2:T1\n",
      "R9\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R11\tCOREF Arg1:T17 Arg2:T14\n",
      "R12\tCOREF Arg1:T10 Arg2:T2\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\C88-2166.ann\n",
      "T1\tMethod 19 42\tnatural language system\n",
      "T2\tOtherScientificTerm 53 74\tcomputational lexicon\n",
      "T3\tGeneric 83 89\tsystem\n",
      "T4\tMethod 344 351\tCOMPLEX\n",
      "T5\tOtherScientificTerm 358 379\tcomputational lexicon\n",
      "T6\tOtherScientificTerm 413 439\tshared lexical information\n",
      "T7\tTask 453 494\tNatural Language Processing (NLP) systems\n",
      "T8\tMaterial 565 602\tmachine-readable dictionaries (MRD's)\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T7\n",
      "R5\tCOREF Arg1:T5 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-1002.ann\n",
      "T1\tMethod 4 24\tdeterministic parser\n",
      "T2\tMethod 94 115\tdeterministic parsers\n",
      "T3\tGeneric 125 127\tit\n",
      "T4\tMethod 143 180\tsymbolic and connectionist components\n",
      "T5\tMethod 187 210\tconnectionist component\n",
      "T6\tOtherScientificTerm 235 243\tpatterns\n",
      "T7\tMethod 263 297\trules  of a  deterministic grammar\n",
      "T8\tMethod 341 360\thybrid architecture\n",
      "T9\tMethod 377 383\tparser\n",
      "T10\tMethod 417 437\tdeterministic parser\n",
      "T11\tMethod 480 499\ttraining techniques\n",
      "T12\tTask 531 546\tdecision-making\n",
      "T13\tMethod 556 579\tconnectionist component\n",
      "T14\tMethod 589 604\tparsing process\n",
      "T15\tGeneric 612 620\tapproach\n",
      "T16\tOtherScientificTerm 664 669\trules\n",
      "T17\tMethod 681 702\tdeterministic parsers\n",
      "T18\tTask 779 786\tparsing\n",
      "T19\tMethod 887 917\tconnectionist (neural) network\n",
      "T20\tOtherScientificTerm 933 949\tlinguistic rules\n",
      "T21\tMaterial 967 999\texpected (grammatical) sentences\n",
      "T22\tMaterial 1023 1071\t(ungrammatical or lexically ambiguous) sentences\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R2\tPART-OF Arg1:T13 Arg2:T14\n",
      "R3\tUSED-FOR Arg1:T19 Arg2:T21\n",
      "R4\tCOREF Arg1:T3 Arg2:T1\n",
      "R5\tPART-OF Arg1:T4 Arg2:T3\n",
      "R6\tHYPONYM-OF Arg1:T5 Arg2:T4\n",
      "R7\tCOREF Arg1:T8 Arg2:T4\n",
      "R8\tCOMPARE Arg1:T9 Arg2:T10\n",
      "R9\tCOREF Arg1:T9 Arg2:T1\n",
      "R10\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R11\tCOREF Arg1:T15 Arg2:T11\n",
      "R12\tCOREF Arg1:T17 Arg2:T10\n",
      "R13\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R14\tCOMPARE Arg1:T1 Arg2:T2\n",
      "R15\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R16\tUSED-FOR Arg1:T19 Arg2:T22\n",
      "R17\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "R18\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R19\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-1013.ann\n",
      "T1\tMethod 30 69\tbidirectional grammar generation system\n",
      "T2\tMethod 79 116\tfeature structure-directed generation\n",
      "T3\tTask 137 164\tdialogue translation system\n",
      "T4\tGeneric 172 178\tsystem\n",
      "T5\tOtherScientificTerm 189 213\ttyped feature structures\n",
      "T6\tOtherScientificTerm 231 250\ttop-down derivation\n",
      "T7\tMethod 280 297\tgeneration system\n",
      "T8\tOtherScientificTerm 310 340\tdisjunctive feature structures\n",
      "T9\tOtherScientificTerm 381 396\tderivation tree\n",
      "T10\tMethod 405 412\tgrammar\n",
      "T11\tGeneric 424 433\tgenerator\n",
      "T12\tOtherScientificTerm 473 492\tspeaker's intention\n",
      "T13\tOtherScientificTerm 500 518\ttelephone dialogue\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R5\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R7\tCOREF Arg1:T4 Arg2:T2\n",
      "R8\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R9\tCOREF Arg1:T7 Arg2:T4\n",
      "R10\tCOREF Arg1:T11 Arg2:T7\n",
      "R11\tFEATURE-OF Arg1:T13 Arg2:T12\n",
      "R12\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R13\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-2032.ann\n",
      "T1\tMethod 24 63\tdocument oriented preference sets(DoPS)\n",
      "T2\tTask 73 116\tdisambiguation of the  dependency structure\n",
      "T3\tMethod 140 151\tDoPS system\n",
      "T4\tOtherScientificTerm 245 265\tSentence ambiguities\n",
      "T5\tOtherScientificTerm 292 328\tdomain targeted preference knowledge\n",
      "T6\tMaterial 362 376\tknowledgebases\n",
      "T7\tOtherScientificTerm 460 481\tdependency structures\n",
      "T8\tMaterial 487 518\tJapanese patent claim sentences\n",
      "R1\tFEATURE-OF Arg1:T7 Arg2:T8\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R4\tCOMPARE Arg1:T5 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-3007.ann\n",
      "T1\tOtherScientificTerm 40 74\tfeature-based partial descriptions\n",
      "T2\tMethod 93 121\tHalliday's systemic networks\n",
      "T3\tMethod 163 183\tconsistency checking\n",
      "T4\tGeneric 194 206\tdescriptions\n",
      "R1\tCOREF Arg1:T4 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-3014.ann\n",
      "T1\tTask 44 85\tKorean phonological knowledge base system\n",
      "T2\tMethod 98 133\tunification-based grammar formalism\n",
      "T3\tMethod 138 179\tKorean Phonology Structure Grammar (KPSG)\n",
      "T4\tGeneric 187 195\tapproach\n",
      "T5\tMethod 200 204\tKPSG\n",
      "T6\tTask 279 298\tphonological system\n",
      "T7\tTask 303 344\tspeech recognition  and  synthesis system\n",
      "T8\tGeneric 374 382\tapproach\n",
      "T9\tGeneric 414 424\tapproaches\n",
      "T10\tGeneric 433 438\tthose\n",
      "T11\tMethod 464 496\tgenerative phonological approach\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tCOREF Arg1:T5 Arg2:T3\n",
      "R4\tCOMPARE Arg1:T8 Arg2:T9\n",
      "R5\tCOREF Arg1:T8 Arg2:T4\n",
      "R6\tCOREF Arg1:T10 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R8\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R9\tCOREF Arg1:T7 Arg2:T6\n",
      "R10\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-3045.ann\n",
      "T1\tMethod 29 58\ttree-adjoining grammars (TAG)\n",
      "T2\tMethod 104 108\tTAGs\n",
      "T3\tOtherScientificTerm 142 148\tsyntax\n",
      "T4\tTask 182 205\tsemantic interpretation\n",
      "T5\tTask 211 252\tautomatic translation of natural language\n",
      "T6\tMethod 269 285\tvariant of  TAGs\n",
      "T7\tMethod 281 285\tTAGs\n",
      "T8\tMethod 297 313\tsynchronous TAGs\n",
      "T9\tOtherScientificTerm 419 451\texpressions of natural languages\n",
      "T10\tOtherScientificTerm 474 483\tsemantics\n",
      "T11\tOtherScientificTerm 503 524\tlogical form language\n",
      "T12\tOtherScientificTerm 565 581\tnatural language\n",
      "T13\tMethod 620 624\tTAGs\n",
      "T14\tOtherScientificTerm 659 672\tsyntax proper\n",
      "T15\tMethod 707 723\tsynchronous TAGs\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R2\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R3\tCOREF Arg1:T2 Arg2:T1\n",
      "R4\tCOREF Arg1:T7 Arg2:T2\n",
      "R5\tCOREF Arg1:T13 Arg2:T7\n",
      "R6\tCOREF Arg1:T15 Arg2:T8\n",
      "R7\tCOREF Arg1:T8 Arg2:T6\n",
      "R8\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "R9\tUSED-FOR Arg1:T2 Arg2:T5\n",
      "R10\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-3046.ann\n",
      "T1\tTask 29 46\tsentence analysis\n",
      "T2\tMethod 70 90\tdefeasible reasoning\n",
      "T3\tGeneric 114 123\ttreatment\n",
      "T4\tTask 129 155\tJapanese sentence analyses\n",
      "T5\tMethod 167 187\targumentation system\n",
      "T6\tMethod 214 253\tformalization  of  defeasible reasoning\n",
      "T7\tMethod 233 253\tdefeasible reasoning\n",
      "T8\tOtherScientificTerm 272 281\targuments\n",
      "T9\tOtherScientificTerm 288 300\tdefeat rules\n",
      "T10\tOtherScientificTerm 316 329\tdefeasibility\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "R3\tCOREF Arg1:T7 Arg2:T2\n",
      "R4\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R5\tCOREF Arg1:T3 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R8\tFEATURE-OF Arg1:T10 Arg2:T8\n",
      "R9\tPART-OF Arg1:T8 Arg2:T6\n",
      "R10\tPART-OF Arg1:T9 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-3063.ann\n",
      "T1\tTask 2 46\tManual acquisition  of  semantic constraints\n",
      "T2\tOtherScientificTerm 154 175\tcooccurrence patterns\n",
      "T3\tOtherScientificTerm 243 263\tsemantic constraints\n",
      "T4\tOtherScientificTerm 300 319\tanaphora references\n",
      "T5\tOtherScientificTerm 326 347\tsyntactic ambiguities\n",
      "T6\tMethod 424 440\tlinguistic tools\n",
      "T7\tOtherScientificTerm 644 667\tcooccurrence statistics\n",
      "T8\tOtherScientificTerm 689 709\tsemantic constraints\n",
      "T9\tMethod 750 769\tdisambiguation tool\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R4\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C90-3072.ann\n",
      "T1\tTask 4 21\tSpelling-checkers\n",
      "T2\tTask 61 85\ttext processing software\n",
      "T3\tGeneric 157 161\tthey\n",
      "T4\tOtherScientificTerm 184 210\tdictionaries of word forms\n",
      "T5\tGeneric 238 246\tapproach\n",
      "T6\tMaterial 265 274\tlanguages\n",
      "T7\tOtherScientificTerm 288 298\tinflection\n",
      "T8\tMaterial 309 316\tEnglish\n",
      "T9\tMaterial 335 362\thighly inflective languages\n",
      "T10\tMaterial 373 378\tCzech\n",
      "T11\tMaterial 383 390\tRussian\n",
      "T12\tMaterial 395 401\tSlovak\n",
      "T13\tMaterial 413 431\tSlavonic languages\n",
      "T14\tGeneric 463 469\tmethod\n",
      "T15\tOtherScientificTerm 486 496\tinflection\n",
      "T16\tTask 527 544\tspelling-checkers\n",
      "T17\tGeneric 555 564\tlanguages\n",
      "T18\tGeneric 593 600\tprogram\n",
      "T19\tMethod 656 673\tspelling-checkers\n",
      "T20\tMaterial 680 687\tEnglish\n",
      "T21\tMaterial 824 829\tCzech\n",
      "T22\tGeneric 853 859\tmethod\n",
      "T23\tTask 889 908\tword classification\n",
      "R1\tPART-OF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R3\tCOREF Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R5\tCOREF Arg1:T5 Arg2:T4\n",
      "R6\tHYPONYM-OF Arg1:T8 Arg2:T6\n",
      "R7\tHYPONYM-OF Arg1:T10 Arg2:T9\n",
      "R8\tHYPONYM-OF Arg1:T11 Arg2:T9\n",
      "R9\tHYPONYM-OF Arg1:T12 Arg2:T9\n",
      "R10\tHYPONYM-OF Arg1:T13 Arg2:T9\n",
      "R11\tCOREF Arg1:T16 Arg2:T3\n",
      "R12\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R13\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R14\tCOREF Arg1:T17 Arg2:T9\n",
      "R15\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R16\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R17\tCOREF Arg1:T18 Arg2:T14\n",
      "R18\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R19\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R20\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R21\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R22\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C92-1052.ann\n",
      "T1\tOtherScientificTerm 18 36\tdiscourse segments\n",
      "T2\tGeneric 56 62\tmethod\n",
      "T3\tTask 68 90\tdiscourse segmentation\n",
      "T4\tTask 112 145\tabduction  of  temporal relations\n",
      "T5\tGeneric 184 190\tmethod\n",
      "T6\tTask 283 311\ttemporal anaphora resolution\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tCOREF Arg1:T5 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C92-1055.ann\n",
      "T1\tMethod 60 87\tadaptive learning procedure\n",
      "T2\tTask 127 157\tsyntactic ambiguity resolution\n",
      "T3\tOtherScientificTerm 186 212\tinsufficient training data\n",
      "T4\tOtherScientificTerm 219 238\tapproximation error\n",
      "T5\tMethod 259 273\tlanguage model\n",
      "T6\tMethod 290 312\tstatistical approaches\n",
      "T7\tOtherScientificTerm 331 342\tambiguities\n",
      "T8\tMethod 380 405\tmaximum likelihood method\n",
      "T9\tGeneric 479 485\tmethod\n",
      "T10\tGeneric 501 509\tproblems\n",
      "T11\tGeneric 601 610\talgorithm\n",
      "T12\tOtherScientificTerm 744 761\tseparation margin\n",
      "T13\tMetric 880 893\taccuracy rate\n",
      "T14\tTask 899 923\tsyntactic disambiguation\n",
      "T15\tGeneric 976 984\tapproach\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R3\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R5\tCOREF Arg1:T11 Arg2:T9\n",
      "R6\tCOREF Arg1:T14 Arg2:T2\n",
      "R7\tEVALUATE-FOR Arg1:T13 Arg2:T14\n",
      "R8\tCOREF Arg1:T9 Arg2:T1\n",
      "R9\tHYPONYM-OF Arg1:T3 Arg2:T10\n",
      "R10\tHYPONYM-OF Arg1:T4 Arg2:T10\n",
      "R11\tCOREF Arg1:T15 Arg2:T11\n",
      "R12\tEVALUATE-FOR Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C92-2068.ann\n",
      "T1\tTask 4 21\tGraph unification\n",
      "T2\tTask 59 92\tunification-based grammar parsing\n",
      "T3\tMethod 112 128\tspeed-up element\n",
      "T4\tMethod 147 169\tunification algorithms\n",
      "T5\tOtherScientificTerm 187 220\tcopying  of  unmodified subgraphs\n",
      "T6\tOtherScientificTerm 200 220\tunmodified subgraphs\n",
      "T7\tGeneric 237 243\tmethod\n",
      "T8\tMethod 292 309\tstructure-sharing\n",
      "T9\tOtherScientificTerm 325 341\tlog(d) overheads\n",
      "T10\tOtherScientificTerm 366 393\tstructure-sharing of graphs\n",
      "T11\tMethod 422 441\tdependency pointers\n",
      "T12\tGeneric 458 464\tscheme\n",
      "T13\tOtherScientificTerm 477 494\tredundant copying\n",
      "T14\tOtherScientificTerm 519 553\tquasi-destructive scheme's ability\n",
      "T15\tOtherScientificTerm 565 577\tover copying\n",
      "T16\tOtherScientificTerm 584 597\tearly copying\n",
      "T17\tOtherScientificTerm 636 653\tcyclic structures\n",
      "R1\tPART-OF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T12 Arg2:T7\n",
      "R3\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R4\tFEATURE-OF Arg1:T14 Arg2:T12\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T17\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R7\tPART-OF Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C92-2115.ann\n",
      "T1\tTask 8 22\ttransfer phase\n",
      "T2\tTask 28 60\tmachine translation (MT) systems\n",
      "T3\tTask 111 119\tanalysis\n",
      "T4\tTask 126 136\tgeneration\n",
      "T5\tGeneric 146 148\tit\n",
      "T6\tOtherScientificTerm 195 208\tlexical rules\n",
      "T7\tMethod 259 279\tcase-based reasoning\n",
      "T8\tTask 285 304\tmachine translation\n",
      "T9\tTask 399 401\tMT\n",
      "T10\tMethod 440 455\ttransfer system\n",
      "T11\tMethod 469 512\tSimilarity-driven Transfer System (SimTran)\n",
      "T12\tTask 533 553\tcase-based MT (CBMT)\n",
      "R1\tCOMPARE Arg1:T1 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R4\tPART-OF Arg1:T1 Arg2:T2\n",
      "R5\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R6\tCOMPARE Arg1:T1 Arg2:T4\n",
      "R7\tCOREF Arg1:T8 Arg2:T2\n",
      "R8\tCOREF Arg1:T9 Arg2:T8\n",
      "R9\tHYPONYM-OF Arg1:T11 Arg2:T10\n",
      "R10\tCOREF Arg1:T5 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C92-3165.ann\n",
      "T1\tGeneric 27 53\trobust  interactive method\n",
      "T2\tTask 58 78\tspeech understanding\n",
      "T3\tMethod 87 109\tgeneralized LR parsing\n",
      "T4\tGeneric 131 139\tapproach\n",
      "T5\tMethod 142 149\tParsing\n",
      "T6\tMethod 250 256\tparser\n",
      "T7\tOtherScientificTerm 293 312\tnon-terminal symbol\n",
      "T8\tGeneric 546 552\tmethod\n",
      "T9\tOtherScientificTerm 582 595\tunknown words\n",
      "T10\tGeneric 816 824\tapproach\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R5\tCOREF Arg1:T6 Arg2:T5\n",
      "R6\tCOREF Arg1:T8 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R8\tCOREF Arg1:T10 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C92-4199.ann\n",
      "T1\tTask 4 23\tWord Identification\n",
      "T2\tTask 68 103\tChinese Natural Language Processing\n",
      "T3\tGeneric 128 137\tmechanism\n",
      "T4\tOtherScientificTerm 164 175\tsublanguage\n",
      "T5\tOtherScientificTerm 208 221\tunknown words\n",
      "T6\tOtherScientificTerm 237 251\tpersonal names\n",
      "T7\tMaterial 259 277\tChinese newspapers\n",
      "T8\tGeneric 294 303\tmechanism\n",
      "T9\tTask 314 343\ttitle-driven name recognition\n",
      "T10\tTask 348 379\tadaptive dynamic word formation\n",
      "T11\tTask 384 457\tidentification of 2-character and 3-character Chinese names without title\n",
      "T12\tMethod 559 588\tNTHU's statistic-based system\n",
      "T13\tGeneric 601 607\tsystem\n",
      "T14\tMethod 723 733\tWI systems\n",
      "T15\tTask 748 767\tname identification\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R4\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R5\tCOREF Arg1:T8 Arg2:T3\n",
      "R6\tPART-OF Arg1:T9 Arg2:T8\n",
      "R7\tPART-OF Arg1:T10 Arg2:T8\n",
      "R8\tPART-OF Arg1:T11 Arg2:T8\n",
      "R9\tCOREF Arg1:T13 Arg2:T12\n",
      "R10\tUSED-FOR Arg1:T7 Arg2:T3\n",
      "R11\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R12\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C92-4207.ann\n",
      "T1\tOtherScientificTerm 58 78\tspatial descriptions\n",
      "T2\tMaterial 84 92\tJapanese\n",
      "T3\tMethod 178 193\tgeometric model\n",
      "T4\tMethod 291 316\tcomputer program   SPRINT\n",
      "T5\tMaterial 333 355\tnatural language texts\n",
      "T6\tGeneric 373 378\tmodel\n",
      "T7\tGeneric 427 432\tmodel\n",
      "T8\tOtherScientificTerm 461 492\tqualitative spatial constraints\n",
      "T9\tOtherScientificTerm 539 560\tnumerical constraints\n",
      "T10\tOtherScientificTerm 570 606\tspatial attributes  of the  entities\n",
      "T11\tOtherScientificTerm 666 682\tspatial concepts\n",
      "R1\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T7 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C94-1088.ann\n",
      "T1\tMethod 25 68\tcharacters-based Chinese collocation system\n",
      "T2\tGeneric 102 104\tit\n",
      "T3\tMethod 125 142\tword-based system\n",
      "T4\tMaterial 198 218\tChinese text corpora\n",
      "T5\tMethod 224 258\tcharacter-based collocation system\n",
      "T6\tTask 287 322\tavoiding  pre-processing distortion\n",
      "T7\tTask 337 371\taccessing  sub-lexical information\n",
      "T8\tOtherScientificTerm 388 423\tword-based collocational properties\n",
      "T9\tMethod 452 495\tauxiliary module of  automatic segmentation\n",
      "R1\tCOREF Arg1:T2 Arg2:T1\n",
      "R2\tCOMPARE Arg1:T2 Arg2:T3\n",
      "R3\tCOREF Arg1:T5 Arg2:T2\n",
      "R4\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "R5\tFEATURE-OF Arg1:T7 Arg2:T5\n",
      "R6\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C94-1091.ann\n",
      "T1\tMaterial 99 112\tThai language\n",
      "T2\tMethod 181 191\tclassifier\n",
      "T3\tTask 348 368\tclassifier selection\n",
      "T4\tMethod 399 418\trule-based approach\n",
      "T5\tMethod 476 486\tclassifier\n",
      "T6\tMethod 521 531\tclassifier\n",
      "T7\tOtherScientificTerm 568 591\ttype of unit classifier\n",
      "T8\tMethod 674 693\tcorpus-based method\n",
      "T9\tMethod 750 784\tNoun Classifier Associations (NCA)\n",
      "T10\tTask 815 836\tclassifier assignment\n",
      "T11\tTask 843 879\tsemantic construction of noun phrase\n",
      "T12\tMethod 887 890\tNCA\n",
      "T13\tOtherScientificTerm 961 990\tconcept hierarchy constraints\n",
      "T14\tOtherScientificTerm 997 1021\tfrequency of occurrences\n",
      "R1\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T11\n",
      "R3\tCOREF Arg1:T12 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R8\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R9\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C96-1055.ann\n",
      "T1\tTask 36 56\tword-sense ambiguity\n",
      "T2\tMaterial 78 104\tmachine-readable resources\n",
      "T3\tTask 114 160\tconstruction of  large-scale knowledge sources\n",
      "T4\tOtherScientificTerm 211 234\tword-sense distinctions\n",
      "T5\tMetric 255 263\taccuracy\n",
      "T6\tMethod 269 292\tsemantic classification\n",
      "T7\tOtherScientificTerm 354 377\tword-sense distinctions\n",
      "T8\tMetric 399 407\taccuracy\n",
      "T9\tOtherScientificTerm 523 537\tverb semantics\n",
      "T10\tOtherScientificTerm 544 562\tsyntactic behavior\n",
      "T11\tOtherScientificTerm 664 684\tsemantic information\n",
      "T12\tOtherScientificTerm 692 706\tsyntactic cues\n",
      "T13\tOtherScientificTerm 732 746\tsyntactic cues\n",
      "T14\tOtherScientificTerm 803 814\tword senses\n",
      "T15\tGeneric 876 886\ttechniques\n",
      "T16\tOtherScientificTerm 898 909\tword senses\n",
      "T17\tMaterial 934 948\tonline sources\n",
      "R1\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R3\tCOREF Arg1:T7 Arg2:T4\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R6\tUSED-FOR Arg1:T17 Arg2:T15\n",
      "R7\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R8\tEVALUATE-FOR Arg1:T5 Arg2:T6\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C96-1062.ann\n",
      "T1\tMethod 4 28\tdomain independent model\n",
      "T2\tTask 51 98\tautomated interpretation  of  nominal compounds\n",
      "T3\tOtherScientificTerm 81 98\tnominal compounds\n",
      "T4\tMaterial 104 111\tEnglish\n",
      "T5\tGeneric 120 125\tmodel\n",
      "T6\tOtherScientificTerm 152 186\tproductive rules of interpretation\n",
      "T7\tOtherScientificTerm 217 262\tmorpho-syntactic and semantic characteristics\n",
      "T8\tOtherScientificTerm 272 292\tnominal constituents\n",
      "T9\tMethod 335 359\tPustejovsky's principles\n",
      "T10\tOtherScientificTerm 376 399\tpredicative information\n",
      "T11\tOtherScientificTerm 418 426\tnominals\n",
      "T12\tOtherScientificTerm 483 516\tgeneralizable semantic principles\n",
      "T13\tOtherScientificTerm 523 559\tdomain-specific semantic information\n",
      "T14\tGeneric 611 616\tmodel\n",
      "T15\tTask 640 669\tinterpretation  of  compounds\n",
      "T16\tOtherScientificTerm 717 737\tsemantic information\n",
      "R1\tFEATURE-OF Arg1:T7 Arg2:T8\n",
      "R2\tFEATURE-OF Arg1:T11 Arg2:T10\n",
      "R3\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R4\tCOREF Arg1:T5 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R7\tCOREF Arg1:T14 Arg2:T5\n",
      "R8\tCOREF Arg1:T8 Arg2:T3\n",
      "R9\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R10\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "R11\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\C96-2213.ann\n",
      "T1\tTask 12 52\tNatural Language Processing (NLP) system\n",
      "T2\tMaterial 60 70\tnew domain\n",
      "T3\tTask 107 124\tsyntactic parsing\n",
      "T4\tMethod 226 233\tgrammar\n",
      "T5\tOtherScientificTerm 242 280\tidiosyncracies of the  new sublanguage\n",
      "T6\tMethod 330 349\tlexicalized grammar\n",
      "T7\tMethod 412 425\thybrid system\n",
      "T8\tMethod 454 480\tknowledge-based techniques\n",
      "T9\tMethod 490 511\tcorpus-based approach\n",
      "R1\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R2\tPART-OF Arg1:T8 Arg2:T7\n",
      "R3\tPART-OF Arg1:T9 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_1992_10_abs.ann\n",
      "T1\tGeneric 23 32\talgorithm\n",
      "T2\tTask 37 67\tlabeling curvilinear structure\n",
      "T3\tMaterial 90 103\tline drawings\n",
      "T4\tMaterial 108 119\tedge images\n",
      "T5\tOtherScientificTerm 129 149\tCURVE-ELEMENT tokens\n",
      "T6\tOtherScientificTerm 164 214\tspatially-indexed and scale-indexed data structure\n",
      "T7\tMaterial 243 253\timage data\n",
      "T8\tMethod 281 320\tsmall-to-large scale grouping procedure\n",
      "T9\tTask 421 438\timage description\n",
      "T10\tOtherScientificTerm 488 501\timage contour\n",
      "T11\tOtherScientificTerm 697 727\tlocal CURVE-ELEMENT attributes\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R3\tFEATURE-OF Arg1:T4 Arg2:T2\n",
      "R4\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R5\tPART-OF Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_1993_10_abs.ann\n",
      "T1\tMethod 2 22\tmodel-based approach\n",
      "T2\tTask 26 78\ton-line cursive handwriting analysis and recognition\n",
      "T3\tGeneric 115 120\tmodel\n",
      "T4\tTask 122 141\ton-line handwriting\n",
      "T5\tTask 184 204\tcycloidal pen motion\n",
      "T6\tOtherScientificTerm 251 272\tconstant linear drift\n",
      "T7\tOtherScientificTerm 391 405\tpen trajectory\n",
      "T8\tOtherScientificTerm 521 544\twriting intelligibility\n",
      "T9\tOtherScientificTerm 611 638\tcycloidal motion parameters\n",
      "T10\tMaterial 643 664\tarbitrary handwriting\n",
      "T11\tMethod 695 732\tdiscrete motor control representation\n",
      "T12\tOtherScientificTerm 740 761\tcontinuous pen motion\n",
      "T13\tMethod 818 846\tmotor control representation\n",
      "T14\tTask 866 879\tword spotting\n",
      "T15\tTask 884 911\tmatching of cursive scripts\n",
      "T16\tMethod 968 990\tdynamic representation\n",
      "T17\tTask 1004 1035\tcursive handwriting recognition\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tPART-OF Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R7\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R10\tCOREF Arg1:T16 Arg2:T13\n",
      "R11\tCOREF Arg1:T13 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R13\tHYPONYM-OF Arg1:T17 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_1994_10_abs.ann\n",
      "T1\tMethod 0 7\tMINPRAN\n",
      "T2\tMethod 15 30\trobust operator\n",
      "T3\tGeneric 118 128\ttechniques\n",
      "T4\tMetric 141 166\tlarge outlier percentages\n",
      "T5\tMethod 168 175\tMINPRAN\n",
      "T6\tOtherScientificTerm 201 212\terror bound\n",
      "T7\tGeneric 240 242\tit\n",
      "T8\tOtherScientificTerm 317 344\tdynamic range of the sensor\n",
      "T9\tMethod 361 368\tMINPRAN\n",
      "T10\tMethod 374 389\trandom sampling\n",
      "T11\tGeneric 494 496\tIt\n",
      "T12\tMethod 638 645\tMINPRAN\n",
      "T13\tMethod 701 708\tMINPRAN\n",
      "T14\tMetric 785 811\tpercentage of true inliers\n",
      "T15\tMethod 813 820\tMINPRAN\n",
      "T16\tMaterial 865 879\tsynthetic data\n",
      "T17\tMethod 905 928\tleast median of squares\n",
      "T18\tMethod 951 958\tMINPRAN\n",
      "T19\tOtherScientificTerm 962 975\tcomplex range\n",
      "T20\tMaterial 980 994\tintensity data\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tCOREF Arg1:T5 Arg2:T1\n",
      "R4\tCOMPARE Arg1:T3 Arg2:T5\n",
      "R5\tCOREF Arg1:T7 Arg2:T5\n",
      "R6\tCOREF Arg1:T9 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R8\tCOREF Arg1:T11 Arg2:T9\n",
      "R9\tCOREF Arg1:T12 Arg2:T11\n",
      "R10\tCOREF Arg1:T13 Arg2:T12\n",
      "R11\tCOREF Arg1:T15 Arg2:T12\n",
      "R12\tCOREF Arg1:T18 Arg2:T15\n",
      "R13\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "R14\tCOMPARE Arg1:T17 Arg2:T15\n",
      "R15\tUSED-FOR Arg1:T18 Arg2:T20\n",
      "R16\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_1996_15_abs.ann\n",
      "T1\tGeneric 26 35\tframework\n",
      "T2\tTask 40 70\tsegmentation of complex scenes\n",
      "T3\tOtherScientificTerm 86 105\tphysical hypotheses\n",
      "T4\tOtherScientificTerm 110 130\tsimple image regions\n",
      "T5\tGeneric 154 163\tframework\n",
      "T6\tGeneric 189 197\tapproach\n",
      "T7\tTask 205 235\tsegmentation of complex scenes\n",
      "T8\tOtherScientificTerm 266 283\tcoherent surfaces\n",
      "T9\tOtherScientificTerm 303 327\tregions of similar color\n",
      "T10\tGeneric 377 385\tapproach\n",
      "T11\tOtherScientificTerm 403 416\tsegmentations\n",
      "T12\tMaterial 421 427\tscenes\n",
      "T13\tMaterial 439 479\tmulti-colored piece-wise uniform objects\n",
      "T14\tGeneric 491 499\tapproach\n",
      "T15\tMetric 568 578\tcomplexity\n",
      "T16\tMethod 593 630\tphysics-based segmentation algorithms\n",
      "T17\tMethod 671 686\tphysical models\n",
      "T18\tOtherScientificTerm 743 760\tcoherent surfaces\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tCOREF Arg1:T5 Arg2:T1\n",
      "R5\tCOREF Arg1:T7 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R8\tCOMPARE Arg1:T8 Arg2:T9\n",
      "R9\tCOREF Arg1:T10 Arg2:T6\n",
      "R10\tFEATURE-OF Arg1:T13 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R12\tCOREF Arg1:T14 Arg2:T10\n",
      "R13\tCOMPARE Arg1:T14 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_1998_10_abs.ann\n",
      "T1\tTask 4 43\tcompact description of a video sequence\n",
      "T2\tOtherScientificTerm 61 70\timage map\n",
      "T3\tOtherScientificTerm 77 92\tdominant motion\n",
      "T4\tGeneric 121 128\tdomains\n",
      "T5\tTask 140 168\tvideo browsing and retrieval\n",
      "T6\tTask 170 181\tcompression\n",
      "T7\tTask 183 192\tmosaicing\n",
      "T8\tTask 198 218\tvisual summarization\n",
      "T9\tGeneric 236 250\trepresentation\n",
      "T10\tGeneric 354 358\ttask\n",
      "T11\tMethod 417 443\tlocalized motion estimates\n",
      "T12\tOtherScientificTerm 476 504\tlack of temporal consistency\n",
      "T13\tOtherScientificTerm 484 504\ttemporal consistency\n",
      "T14\tGeneric 526 535\testimates\n",
      "T15\tOtherScientificTerm 554 596\tvalidity of the dominant motion assumption\n",
      "T16\tOtherScientificTerm 570 596\tdominant motion assumption\n",
      "T17\tOtherScientificTerm 609 682\toscillation between different scene interpretations and poor registration\n",
      "T18\tGeneric 698 709\toscillation\n",
      "T19\tMethod 726 738\tmotion model\n",
      "T20\tOtherScientificTerm 746 773\tgeneric temporal constraint\n",
      "T21\tMetric 794 804\trobustness\n",
      "T22\tTask 867 888\tcontent summarization\n",
      "R1\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R2\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R3\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R4\tHYPONYM-OF Arg1:T5 Arg2:T4\n",
      "R5\tHYPONYM-OF Arg1:T6 Arg2:T4\n",
      "R6\tHYPONYM-OF Arg1:T7 Arg2:T4\n",
      "R8\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R9\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R10\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R11\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R12\tCOREF Arg1:T9 Arg2:T1\n",
      "R13\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R14\tCOREF Arg1:T14 Arg2:T11\n",
      "R15\tCOREF Arg1:T18 Arg2:T17\n",
      "R16\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R17\tEVALUATE-FOR Arg1:T21 Arg2:T20\n",
      "R18\tUSED-FOR Arg1:T20 Arg2:T22\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_1999_15_abs.ann\n",
      "T1\tMethod 32 83\tprojective unifocal, bifo-cal, and trifocal tensors\n",
      "T2\tOtherScientificTerm 91 102\taffine case\n",
      "T3\tGeneric 121 128\ttensors\n",
      "T4\tOtherScientificTerm 152 170\tregistered tensors\n",
      "T5\tOtherScientificTerm 230 251\taffine specialization\n",
      "T6\tMethod 360 374\taffine cameras\n",
      "T7\tMethod 446 461\ttrifocal tensor\n",
      "T8\tOtherScientificTerm 486 510\tgeometric interpretation\n",
      "T9\tTask 537 562\testimation of the tensors\n",
      "T10\tGeneric 555 562\ttensors\n",
      "T11\tOtherScientificTerm 568 589\tpoint correspondences\n",
      "T12\tMethod 610 623\tfactorization\n",
      "T13\tGeneric 641 651\testimation\n",
      "T14\tOtherScientificTerm 657 677\tline correspondences\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T7 Arg2:T1\n",
      "R4\tCOREF Arg1:T10 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R8\tCOREF Arg1:T13 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2001_110_abs.ann\n",
      "T1\tMethod 0 31\tRepresenting images with layers\n",
      "T2\tGeneric 51 63\tapplications\n",
      "T3\tTask 74 91\tvideo compression\n",
      "T4\tTask 93 108\tmotion analysis\n",
      "T5\tTask 114 131\t3D scene analysis\n",
      "T6\tGeneric 156 164\tapproach\n",
      "T7\tOtherScientificTerm 188 194\tlayers\n",
      "T8\tMaterial 200 206\timages\n",
      "T9\tOtherScientificTerm 245 257\thomographies\n",
      "T10\tOtherScientificTerm 269 283\tplanar patches\n",
      "T11\tOtherScientificTerm 291 296\tscene\n",
      "T12\tOtherScientificTerm 304 335\tlow dimensional linear subspace\n",
      "T13\tOtherScientificTerm 337 343\tLayers\n",
      "T14\tMaterial 357 363\timages\n",
      "T15\tOtherScientificTerm 386 394\tsubspace\n",
      "T16\tOtherScientificTerm 443 451\tclusters\n",
      "T17\tMethod 495 532\tmean-shift based clustering algorithm\n",
      "T18\tTask 534 551\tGlobal optimality\n",
      "T19\tOtherScientificTerm 580 587\tregions\n",
      "T20\tOtherScientificTerm 631 636\tnoise\n",
      "T21\tOtherScientificTerm 681 700\tsubspace constraint\n",
      "R1\tPART-OF Arg1:T7 Arg2:T8\n",
      "R2\tPART-OF Arg1:T13 Arg2:T14\n",
      "R3\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R4\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R5\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R6\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R7\tHYPONYM-OF Arg1:T4 Arg2:T2\n",
      "R8\tHYPONYM-OF Arg1:T5 Arg2:T2\n",
      "R9\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R10\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R11\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R12\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R13\tPART-OF Arg1:T10 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2001_111_abs.ann\n",
      "T1\tGeneric 34 40\tmethod\n",
      "T2\tMethod 49 95\tlocal non-negative matrix factorization (LNMF)\n",
      "T3\tTask 110 185\tspatially localized, parts-based subspace representation of visual patterns\n",
      "T4\tOtherScientificTerm 190 208\tobjective function\n",
      "T5\tOtherScientificTerm 230 254\tlo-calization constraint\n",
      "T6\tOtherScientificTerm 275 300\tnon-negativity constraint\n",
      "T7\tMethod 317 320\tNMF\n",
      "T8\tMethod 376 429\tnon-subtractive (part-based) representation of images\n",
      "T9\tOtherScientificTerm 449 467\tlocalized features\n",
      "T10\tGeneric 472 481\talgorithm\n",
      "T11\tTask 503 511\tlearning\n",
      "T12\tMethod 584 588\tLNMF\n",
      "T13\tMethod 598 617\tNMF and PCA methods\n",
      "T14\tTask 622 657\tface representation and recognition\n",
      "T15\tMethod 692 696\tLNMF\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R5\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R6\tCOREF Arg1:T15 Arg2:T12\n",
      "R7\tEVALUATE-FOR Arg1:T14 Arg2:T15\n",
      "R8\tPART-OF Arg1:T6 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R10\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R11\tCOREF Arg1:T1 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2003_10_abs.ann\n",
      "T1\tMethod 2 34\t\" graphics for vision \" approach\n",
      "T2\tTask 73 87\treconstruction\n",
      "T3\tMaterial 95 123\tlarge and imperfect data set\n",
      "T4\tTask 125 139\treconstruction\n",
      "T5\tMethod 153 166\ttensor voting\n",
      "T6\tMethod 171 177\tROD-TV\n",
      "T7\tMethod 179 185\tROD-TV\n",
      "T8\tMetric 215 225\tefficiency\n",
      "T9\tMetric 230 241\trobust-ness\n",
      "T10\tOtherScientificTerm 273 295\tprimitive connectivity\n",
      "T11\tOtherScientificTerm 297 312\tview dependence\n",
      "T12\tOtherScientificTerm 318 340\tlevels of detail (LOD)\n",
      "T13\tOtherScientificTerm 342 375\tLocally inferred surface elements\n",
      "T14\tOtherScientificTerm 390 395\tnoise\n",
      "T15\tOtherScientificTerm 415 427\tlocal shapes\n",
      "T16\tOtherScientificTerm 442 460\tper-vertex normals\n",
      "T17\tMetric 464 483\tsub-voxel precision\n",
      "T18\tTask 511 532\tinterpolative shading\n",
      "T19\tOtherScientificTerm 650 669\tscanning resolution\n",
      "T20\tOtherScientificTerm 687 716\tmesh connectivity requirement\n",
      "T21\tMethod 728 734\tROD-TV\n",
      "T22\tMethod 770 809\tmultiscale feature extraction algorithm\n",
      "T23\tMethod 811 817\tROD-TV\n",
      "T24\tMethod 832 859\thierarchical data structure\n",
      "T25\tMethod 905 935\tlocal reconstruction algorithm\n",
      "T26\tMethod 939 952\ttensor voting\n",
      "T27\tGeneric 954 956\tIt\n",
      "T28\tMethod 1042 1071\ttraversing the data hierarchy\n",
      "T29\tMethod 1076 1104\tcollecting tensorial support\n",
      "T30\tGeneric 1139 1147\tapproach\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R3\tCONJUNCTION Arg1:T9 Arg2:T8\n",
      "R4\tCONJUNCTION Arg1:T11 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R6\tEVALUATE-FOR Arg1:T9 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T16 Arg2:T18\n",
      "R8\tUSED-FOR Arg1:T20 Arg2:T22\n",
      "R9\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R10\tPART-OF Arg1:T24 Arg2:T23\n",
      "R11\tHYPONYM-OF Arg1:T26 Arg2:T25\n",
      "R12\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R13\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R14\tCOREF Arg1:T7 Arg2:T6\n",
      "R15\tCONJUNCTION Arg1:T12 Arg2:T11\n",
      "R16\tEVALUATE-FOR Arg1:T8 Arg2:T7\n",
      "R17\tCOREF Arg1:T21 Arg2:T7\n",
      "R18\tCOREF Arg1:T23 Arg2:T21\n",
      "R19\tUSED-FOR Arg1:T28 Arg2:T27\n",
      "R20\tUSED-FOR Arg1:T29 Arg2:T27\n",
      "R21\tCONJUNCTION Arg1:T28 Arg2:T29\n",
      "R22\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R23\tCOREF Arg1:T1 Arg2:T30\n",
      "R24\tCOREF Arg1:T2 Arg2:T4\n",
      "R25\tCOREF Arg1:T26 Arg2:T27\n",
      "R26\tFEATURE-OF Arg1:T17 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2003_11_abs.ann\n",
      "T1\tOtherScientificTerm 4 12\tfeatures\n",
      "T2\tMethod 22 54\tMarkov random field (MRF) models\n",
      "T3\tOtherScientificTerm 84 110\trotation of image textures\n",
      "T4\tMethod 135 183\tanisotropic circular Gaussian MRF (ACGMRF) model\n",
      "T5\tTask 188 220\tmodelling rotated image textures\n",
      "T6\tTask 225 271\tretrieving rotation-invariant texture features\n",
      "T7\tOtherScientificTerm 289 308\tsingularity problem\n",
      "T8\tMethod 316 351\tleast squares estimate (LSE) method\n",
      "T9\tMethod 356 404\tapproximate least squares estimate (ALSE) method\n",
      "T10\tOtherScientificTerm 433 463\tparameters of the ACGMRF model\n",
      "T11\tMethod 451 463\tACGMRF model\n",
      "T12\tOtherScientificTerm 469 496\trotation-invariant features\n",
      "T13\tOtherScientificTerm 522 552\tparameters of the ACGMRF model\n",
      "T14\tMethod 540 552\tACGMRF model\n",
      "T15\tMethod 560 614\tone-dimensional (1-D) discrete Fourier transform (DFT)\n",
      "T16\tMetric 639 647\taccuracy\n",
      "T17\tOtherScientificTerm 680 707\trotation-invariant features\n",
      "T18\tOtherScientificTerm 720 749\tSAR (synthetic aperture radar\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R3\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R5\tFEATURE-OF Arg1:T7 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T12\n",
      "R9\tCOREF Arg1:T4 Arg2:T11\n",
      "R10\tCOREF Arg1:T11 Arg2:T14\n",
      "R11\tCOREF Arg1:T10 Arg2:T13\n",
      "R12\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2003_18_abs.ann\n",
      "T1\tMethod 23 29\tmethod\n",
      "T2\tOtherScientificTerm 43 69\tintrinsic object structure\n",
      "T3\tTask 74 96\trobust visual tracking\n",
      "T4\tOtherScientificTerm 143 169\tparameterized object state\n",
      "T5\tOtherScientificTerm 180 204\tlow dimensional manifold\n",
      "T6\tMethod 293 350\tdimensionality reduction and density estimation algorithm\n",
      "T7\tTask 355 411\tunsupervised learning of object intrinsic representation\n",
      "T8\tMethod 380 411\tobject intrinsic representation\n",
      "T9\tOtherScientificTerm 426 456\tnon-rigid part of object state\n",
      "T10\tMethod 500 515\tdynamical model\n",
      "T11\tMethod 553 577\tintrinsic representation\n",
      "T12\tOtherScientificTerm 599 625\tintrinsic object structure\n",
      "T13\tMethod 647 676\tparticle-filter style tracker\n",
      "T14\tMethod 701 732\tintrinsic object representation\n",
      "T15\tMethod 802 817\tdynamical model\n",
      "T16\tMethod 824 853\tparticle-filter style tracker\n",
      "T17\tGeneric 914 921\ttracker\n",
      "T18\tGeneric 957 965\ttrackers\n",
      "T19\tTask 973 1010\ttracking of complex non-rigid motions\n",
      "T20\tOtherScientificTerm 985 1010\tcomplex non-rigid motions\n",
      "T21\tOtherScientificTerm 1019 1032\tfish twisting\n",
      "T22\tOtherScientificTerm 1038 1052\tself-occlusion\n",
      "T23\tOtherScientificTerm 1063 1085\tinter-frame lip motion\n",
      "T24\tGeneric 1100 1106\tmethod\n",
      "T25\tTask 1153 1170\ttracking problems\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R5\tCOREF Arg1:T11 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R7\tPART-OF Arg1:T12 Arg2:T13\n",
      "R8\tCOREF Arg1:T14 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R10\tCOREF Arg1:T17 Arg2:T16\n",
      "R11\tCOMPARE Arg1:T17 Arg2:T18\n",
      "R12\tUSED-FOR Arg1:T17 Arg2:T19\n",
      "R13\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R14\tHYPONYM-OF Arg1:T21 Arg2:T20\n",
      "R15\tCONJUNCTION Arg1:T22 Arg2:T23\n",
      "R16\tFEATURE-OF Arg1:T22 Arg2:T21\n",
      "R17\tFEATURE-OF Arg1:T23 Arg2:T21\n",
      "R18\tUSED-FOR Arg1:T24 Arg2:T25\n",
      "R19\tCOREF Arg1:T15 Arg2:T10\n",
      "R20\tCOREF Arg1:T12 Arg2:T11\n",
      "R21\tCOREF Arg1:T24 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2003_21_abs.ann\n",
      "T1\tTask 52 77\tprojective reconstruction\n",
      "T2\tMaterial 92 98\timages\n",
      "T3\tTask 144 169\tProjective reconstruction\n",
      "T4\tOtherScientificTerm 203 231\t3D geometrical configuration\n",
      "T5\tOtherScientificTerm 244 265\t3D points and cameras\n",
      "T6\tOtherScientificTerm 451 468\timage coordinates\n",
      "T7\tOtherScientificTerm 753 775\trational quartic curve\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tFEATURE-OF Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2003_30_abs.ann\n",
      "T1\tGeneric 28 42\trepresentation\n",
      "T2\tOtherScientificTerm 47 72\tthree-dimensional objects\n",
      "T3\tOtherScientificTerm 85 115\taffine-invariant image patches\n",
      "T4\tOtherScientificTerm 126 147\tspatial relationships\n",
      "T5\tOtherScientificTerm 149 171\tMulti-view constraints\n",
      "T6\tMethod 226 251\tnormalized representation\n",
      "T7\tTask 281 289\tmatching\n",
      "T8\tTask 294 308\treconstruction\n",
      "T9\tTask 323 388\tacquisition of true three-dimensional affine and Euclidean models\n",
      "T10\tMaterial 403 409\timages\n",
      "T11\tGeneric 503 511\tapproach\n",
      "T12\tMethod 540 558\tsegmentation stage\n",
      "T13\tOtherScientificTerm 580 596\tcluttered scenes\n",
      "T14\tTask 623 634\trecognition\n",
      "R1\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R4\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R8\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R9\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "R10\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R11\tCOREF Arg1:T1 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2004_10_abs.ann\n",
      "T1\tTask 0 32\tImage composition (or mosaicing)\n",
      "T2\tTask 114 147\tvideo analysis and representation\n",
      "T3\tTask 191 207\tglobal alignment\n",
      "T4\tTask 212 228\tsuper-resolution\n",
      "T5\tTask 287 293\tmosaic\n",
      "T6\tMetric 311 329\tamount of blurring\n",
      "T7\tTask 331 350\tGlobal registration\n",
      "T8\tMethod 378 399\tgraph-based technique\n",
      "T9\tOtherScientificTerm 420 441\ttopological structure\n",
      "T10\tOtherScientificTerm 473 488\tspatial overlap\n",
      "T11\tMethod 498 515\tbundle adjustment\n",
      "T12\tOtherScientificTerm 536 548\thomographies\n",
      "T13\tGeneric 616 626\ttechniques\n",
      "T14\tGeneric 658 666\tapproach\n",
      "R1\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R2\tEVALUATE-FOR Arg1:T6 Arg2:T5\n",
      "R3\tCONJUNCTION Arg1:T8 Arg2:T11\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R8\tCOREF Arg1:T14 Arg2:T8\n",
      "R9\tCOMPARE Arg1:T14 Arg2:T13\n",
      "R10\tPART-OF Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2004_18_abs.ann\n",
      "T1\tTask 4 26\tautomated segmentation\n",
      "T2\tMaterial 30 36\timages\n",
      "T3\tOtherScientificTerm 81 98\tshape information\n",
      "T4\tMethod 105 131\tlow-level feature analysis\n",
      "T5\tMethod 191 197\tmethod\n",
      "T6\tTask 201 237\tshape constrained image segmentation\n",
      "T7\tOtherScientificTerm 256 289\tmixtures of feature distributions\n",
      "T8\tOtherScientificTerm 294 299\tcolor\n",
      "T9\tOtherScientificTerm 304 311\ttexture\n",
      "T10\tOtherScientificTerm 323 352\tprobabilistic shape knowledge\n",
      "T11\tGeneric 367 375\tapproach\n",
      "T12\tMethod 410 429\tBayesian statistics\n",
      "T13\tTask 449 495\trobust-ness requirement in image understanding\n",
      "T14\tMaterial 588 598\timage data\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R4\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T7 Arg2:T10\n",
      "R9\tCOREF Arg1:T11 Arg2:T5\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R11\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2004_21_abs.ann\n",
      "T1\tTask 0 20\tUncertainty handling\n",
      "T2\tTask 52 66\tshape tracking\n",
      "T3\tMethod 100 171\tfusion of measurement information with system dynamics and shape priors\n",
      "T4\tTask 193 201\ttracking\n",
      "T5\tMaterial 223 235\tnoisy images\n",
      "T6\tMaterial 244 264\tultrasound sequences\n",
      "T7\tGeneric 291 299\tapproach\n",
      "T8\tOtherScientificTerm 309 328\tuser initialization\n",
      "T9\tMethod 336 352\ttracking process\n",
      "T10\tTask 376 409\tautomatic initial-ization problem\n",
      "T11\tMethod 424 447\tboosted shape detection\n",
      "T12\tMethod 453 480\tgeneric measurement process\n",
      "T13\tGeneric 497 499\tit\n",
      "T14\tMethod 507 525\ttracking framework\n",
      "T15\tOtherScientificTerm 556 585\tlocal detection uncertainties\n",
      "T16\tOtherScientificTerm 556 614\tlocal detection uncertainties of multiple shape candidates\n",
      "T17\tOtherScientificTerm 622 637\tshape alignment\n",
      "T18\tOtherScientificTerm 655 676\tpredicted shape prior\n",
      "T19\tOtherScientificTerm 694 714\tsubspace constraints\n",
      "T20\tMethod 797 818\tposterior shape model\n",
      "T21\tOtherScientificTerm 841 859\tmaximum likelihood\n",
      "T22\tGeneric 865 874\tframework\n",
      "T23\tTask 894 927\tautomatic tracking of endocardium\n",
      "T24\tOtherScientificTerm 916 927\tendocardium\n",
      "T25\tMaterial 931 970\tultrasound sequences of the human heart\n",
      "T26\tTask 981 990\tdetection\n",
      "T27\tTask 1002 1010\ttracking\n",
      "T28\tGeneric 1058 1068\tapproaches\n",
      "T29\tOtherScientificTerm 1073 1096\tinter-expert variations\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T4 Arg2:T2\n",
      "R3\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R8\tCOREF Arg1:T10 Arg2:T13\n",
      "R9\tPART-OF Arg1:T13 Arg2:T14\n",
      "R10\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R11\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R12\tCONJUNCTION Arg1:T28 Arg2:T29\n",
      "R13\tCOREF Arg1:T4 Arg2:T27\n",
      "R14\tCONJUNCTION Arg1:T26 Arg2:T27\n",
      "R15\tCOREF Arg1:T22 Arg2:T14\n",
      "R16\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R17\tCOREF Arg1:T3 Arg2:T7\n",
      "R18\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R19\tPART-OF Arg1:T24 Arg2:T25\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2004_30_abs.ann\n",
      "T1\tTask 0 19\tBackground modeling\n",
      "T2\tTask 54 68\tvision systems\n",
      "T3\tOtherScientificTerm 140 173\tstatic or quasi-static structures\n",
      "T4\tGeneric 184 189\tscene\n",
      "T5\tOtherScientificTerm 201 228\tpersistent dynamic behavior\n",
      "T6\tTask 273 282\tdetection\n",
      "T7\tGeneric 341 347\tmethod\n",
      "T8\tTask 356 395\tmodeling and subtraction of such scenes\n",
      "T9\tGeneric 389 395\tscenes\n",
      "T10\tTask 409 448\tmodeling of the dynamic characteristics\n",
      "T11\tOtherScientificTerm 450 462\toptical flow\n",
      "T12\tOtherScientificTerm 493 500\tfeature\n",
      "T13\tOtherScientificTerm 506 530\thigher dimensional space\n",
      "T14\tOtherScientificTerm 541 552\tambiguities\n",
      "T15\tTask 560 583\tcomputation of features\n",
      "T16\tOtherScientificTerm 609 633\tdata-dependent bandwidth\n",
      "T17\tTask 638 656\tdensity estimation\n",
      "T18\tMethod 663 670\tkernels\n",
      "T19\tGeneric 750 758\tapproach\n",
      "R1\tPART-OF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T4 Arg2:T9\n",
      "R3\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R6\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R8\tFEATURE-OF Arg1:T13 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R10\tFEATURE-OF Arg1:T14 Arg2:T15\n",
      "R11\tCOREF Arg1:T7 Arg2:T19\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T14\n",
      "R13\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2005_10_abs.ann\n",
      "T1\tMethod 0 20\tProbabilistic models\n",
      "T2\tTask 82 122\tmodeling and recognition of human motion\n",
      "T3\tMethod 178 196\thuman motion model\n",
      "T4\tMethod 202 220\ttriangulated graph\n",
      "T5\tGeneric 250 256\tmodels\n",
      "T6\tOtherScientificTerm 271 280\tpositions\n",
      "T7\tOtherScientificTerm 285 295\tvelocities\n",
      "T8\tOtherScientificTerm 335 345\tappearance\n",
      "T9\tMethod 359 377\theuristic approach\n",
      "T10\tOtherScientificTerm 406 428\ttranslation invariance\n",
      "T11\tGeneric 467 475\tapproach\n",
      "T12\tGeneric 494 500\tmodels\n",
      "T13\tGeneric 511 515\tthem\n",
      "T14\tTask 520 544\thuman motion recognition\n",
      "T15\tGeneric 560 568\tapproach\n",
      "T16\tGeneric 587 591\tcues\n",
      "T17\tOtherScientificTerm 599 608\tpositions\n",
      "T18\tOtherScientificTerm 610 620\tvelocities\n",
      "T19\tOtherScientificTerm 625 635\tappearance\n",
      "T20\tTask 650 679\tlearning and detection phases\n",
      "T21\tOtherScientificTerm 707 723\tglobal variables\n",
      "T22\tGeneric 731 736\tmodel\n",
      "T23\tOtherScientificTerm 758 775\tglobal properties\n",
      "T24\tOtherScientificTerm 784 795\ttranslation\n",
      "T25\tOtherScientificTerm 797 802\tscale\n",
      "T26\tOtherScientificTerm 806 815\tviewpoint\n",
      "T27\tGeneric 821 826\tmodel\n",
      "T28\tMethod 844 863\tunsupervised manner\n",
      "T29\tMaterial 869 885\tun-labelled data\n",
      "T30\tMethod 914 941\thybrid proba-bilistic model\n",
      "T31\tOtherScientificTerm 958 974\tglobal variables\n",
      "T32\tOtherScientificTerm 981 992\ttranslation\n",
      "T33\tOtherScientificTerm 1000 1015\tlocal variables\n",
      "T34\tOtherScientificTerm 1022 1040\trelative positions\n",
      "T35\tOtherScientificTerm 1045 1070\tappearances of body parts\n",
      "T36\tMetric 1087 1105\tfaster convergence\n",
      "T37\tTask 1109 1123\tlearning phase\n",
      "T38\tMetric 1130 1140\trobustness\n",
      "T39\tOtherScientificTerm 1144 1154\tocclusions\n",
      "T40\tMaterial 1174 1190\trecognition rate\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R5\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R7\tCOREF Arg1:T12 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R10\tCOREF Arg1:T12 Arg2:T3\n",
      "R11\tCOREF Arg1:T15 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T15 Arg2:T20\n",
      "R13\tHYPONYM-OF Arg1:T17 Arg2:T16\n",
      "R14\tHYPONYM-OF Arg1:T18 Arg2:T16\n",
      "R15\tHYPONYM-OF Arg1:T19 Arg2:T16\n",
      "R16\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R17\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R18\tCOREF Arg1:T15 Arg2:T22\n",
      "R19\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R20\tHYPONYM-OF Arg1:T24 Arg2:T23\n",
      "R21\tHYPONYM-OF Arg1:T25 Arg2:T23\n",
      "R22\tUSED-FOR Arg1:T21 Arg2:T23\n",
      "R23\tHYPONYM-OF Arg1:T26 Arg2:T23\n",
      "R24\tCONJUNCTION Arg1:T24 Arg2:T25\n",
      "R25\tCONJUNCTION Arg1:T25 Arg2:T26\n",
      "R26\tCOREF Arg1:T27 Arg2:T22\n",
      "R27\tUSED-FOR Arg1:T28 Arg2:T27\n",
      "R28\tUSED-FOR Arg1:T29 Arg2:T28\n",
      "R29\tUSED-FOR Arg1:T31 Arg2:T30\n",
      "R30\tHYPONYM-OF Arg1:T32 Arg2:T31\n",
      "R31\tHYPONYM-OF Arg1:T34 Arg2:T33\n",
      "R32\tHYPONYM-OF Arg1:T35 Arg2:T33\n",
      "R33\tCONJUNCTION Arg1:T34 Arg2:T35\n",
      "R34\tFEATURE-OF Arg1:T36 Arg2:T37\n",
      "R35\tCONJUNCTION Arg1:T36 Arg2:T38\n",
      "R36\tCONJUNCTION Arg1:T38 Arg2:T40\n",
      "R37\tCOREF Arg1:T15 Arg2:T30\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2005_11_abs.ann\n",
      "T1\tMethod 21 37\treal-time system\n",
      "T2\tTask 42 84\tmultiple object tracking in dynamic scenes\n",
      "T3\tGeneric 117 123\tsystem\n",
      "T4\tOtherScientificTerm 152 188\tlong-duration and complete occlusion\n",
      "T5\tOtherScientificTerm 199 214\tprior knowledge\n",
      "T6\tOtherScientificTerm 225 230\tshape\n",
      "T7\tOtherScientificTerm 234 251\tmotion of objects\n",
      "T8\tGeneric 257 263\tsystem\n",
      "T9\tTask 290 298\ttracking\n",
      "T10\tOtherScientificTerm 312 322\tframe rate\n",
      "T11\tOtherScientificTerm 340 350\timage size\n",
      "T12\tMaterial 420 435\tvideo sequences\n",
      "T13\tOtherScientificTerm 487 524\tlong-duration and complete occlusions\n",
      "T14\tOtherScientificTerm 528 547\tchanging background\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T3 Arg2:T8\n",
      "R5\tEVALUATE-FOR Arg1:T9 Arg2:T8\n",
      "R6\tFEATURE-OF Arg1:T5 Arg2:T6\n",
      "R7\tFEATURE-OF Arg1:T5 Arg2:T7\n",
      "R8\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2005_18_abs.ann\n",
      "T1\tMethod 31 48\tembedding methods\n",
      "T2\tTask 53 110\tsegmenting feature points of piece-wise planar structures\n",
      "T3\tOtherScientificTerm 187 199\thomographies\n",
      "T4\tOtherScientificTerm 239 279\thigher-dimensional real or complex space\n",
      "T5\tOtherScientificTerm 294 304\thomography\n",
      "T6\tOtherScientificTerm 329 350\tcomplex bilinear form\n",
      "T7\tOtherScientificTerm 356 375\treal quadratic form\n",
      "T8\tOtherScientificTerm 448 461\thomo-graphies\n",
      "T9\tMethod 473 506\tclosed-form segmentation solution\n",
      "T10\tMethod 560 589\tsubspace-segmentation methods\n",
      "T11\tOtherScientificTerm 659 682\tpiece-wise planar scene\n",
      "T12\tMaterial 688 698\t2-D images\n",
      "T13\tMethod 733 751\t3-D reconstruction\n",
      "T14\tMethod 800 818\t3-D reconstruction\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R3\tCOREF Arg1:T14 Arg2:T13\n",
      "R4\tFEATURE-OF Arg1:T12 Arg2:T11\n",
      "R5\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "R6\tFEATURE-OF Arg1:T7 Arg2:T5\n",
      "R7\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R8\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2005_21_abs.ann\n",
      "T1\tMethod 0 19\tActive shape models\n",
      "T2\tMaterial 69 87\tcomplex image data\n",
      "T3\tMethod 101 126\tmodels of shape variation\n",
      "T4\tMethod 139 156\tsearch algorithms\n",
      "T5\tOtherScientificTerm 166 183\tpri-ori knowledge\n",
      "T6\tOtherScientificTerm 237 246\tlinearity\n",
      "T7\tMethod 250 253\tPCA\n",
      "T8\tOtherScientificTerm 255 270\tnon-linearities\n",
      "T9\tOtherScientificTerm 276 285\trotations\n",
      "T10\tMethod 391 435\tnon-linear extensions of active shape models\n",
      "T11\tMethod 416 435\tactive shape models\n",
      "T12\tOtherScientificTerm 542 558\tuser interaction\n",
      "T13\tTask 608 641\tbuild-ing/choosing optimal models\n",
      "T14\tGeneric 731 740\talgorithm\n",
      "T15\tMethod 754 790\tminimum description length principle\n",
      "T16\tMethod 868 883\tlinear modeling\n",
      "T17\tGeneric 978 983\tmodel\n",
      "T18\tOtherScientificTerm 996 1015\tmodes of variations\n",
      "T19\tGeneric 1030 1036\tmethod\n",
      "T20\tMaterial 1053 1067\tsynthetic data\n",
      "T21\tMaterial 1069 1083\tmedical images\n",
      "T22\tMaterial 1088 1101\thand contours\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R4\tFEATURE-OF Arg1:T6 Arg2:T7\n",
      "R5\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "R6\tCOREF Arg1:T11 Arg2:T1\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R9\tFEATURE-OF Arg1:T18 Arg2:T17\n",
      "R10\tCOREF Arg1:T19 Arg2:T17\n",
      "R11\tCOREF Arg1:T17 Arg2:T14\n",
      "R12\tEVALUATE-FOR Arg1:T20 Arg2:T19\n",
      "R13\tEVALUATE-FOR Arg1:T21 Arg2:T19\n",
      "R14\tEVALUATE-FOR Arg1:T22 Arg2:T19\n",
      "R15\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R16\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2006_10_abs.ann\n",
      "T1\tTask 25 41\tobject detection\n",
      "T2\tOtherScientificTerm 149 192\tprior on the distribution of natural images\n",
      "T3\tMethod 198 221\tsupport vector machines\n",
      "T4\tMethod 223 227\tSVMs\n",
      "T5\tOtherScientificTerm 254 265\toverfitting\n",
      "T6\tMethod 377 386\tdetectors\n",
      "T7\tOtherScientificTerm 479 502\tprior on natural images\n",
      "T8\tOtherScientificTerm 536 546\thyperplane\n",
      "T9\tMaterial 726 740\treal data sets\n",
      "T10\tMethod 765 773\tdetector\n",
      "T11\tMethod 857 878\tlinear and kernel SVM\n",
      "R1\tCOREF Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R4\tEVALUATE-FOR Arg1:T9 Arg2:T10\n",
      "R5\tCOMPARE Arg1:T10 Arg2:T11\n",
      "R6\tCOREF Arg1:T10 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2006_11_abs.ann\n",
      "T1\tMethod 2 20\trecognition scheme\n",
      "T2\tMetric 92 102\tefficiency\n",
      "T3\tMetric 107 114\tquality\n",
      "T4\tMaterial 168 177\tCD-covers\n",
      "T5\tGeneric 185 193\tdatabase\n",
      "T6\tMaterial 203 231\timages of popular music CD's\n",
      "T7\tGeneric 237 243\tscheme\n",
      "T8\tMethod 278 298\tindexing descriptors\n",
      "T9\tOtherScientificTerm 314 327\tlocal regions\n",
      "T10\tOtherScientificTerm 346 364\tbackground clutter\n",
      "T11\tOtherScientificTerm 369 378\tocclusion\n",
      "T12\tMethod 384 408\tlocal region descriptors\n",
      "T13\tOtherScientificTerm 443 458\tvocabulary tree\n",
      "T14\tOtherScientificTerm 464 479\tvocabulary tree\n",
      "T15\tMetric 619 636\tretrieval quality\n",
      "T16\tOtherScientificTerm 694 698\ttree\n",
      "T17\tOtherScientificTerm 720 732\tquantization\n",
      "T18\tOtherScientificTerm 738 750\tquantization\n",
      "T19\tOtherScientificTerm 759 767\tindexing\n",
      "T20\tMetric 840 859\trecognition quality\n",
      "T21\tTask 881 890\tretrieval\n",
      "T22\tMaterial 896 922\tdatabase with ground truth\n",
      "T23\tMethod 949 973\tvocabulary tree approach\n",
      "R1\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R2\tCOREF Arg1:T1 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R6\tCOREF Arg1:T13 Arg2:T14\n",
      "R7\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R8\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "R9\tEVALUATE-FOR Arg1:T20 Arg2:T23\n",
      "R10\tEVALUATE-FOR Arg1:T21 Arg2:T20\n",
      "R11\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "R12\tUSED-FOR Arg1:T7 Arg2:T10\n",
      "R13\tUSED-FOR Arg1:T7 Arg2:T11\n",
      "R14\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2006_18_abs.ann\n",
      "T1\tMethod 6 30\texemplar-based framework\n",
      "T2\tTask 40 56\timage completion\n",
      "T3\tTask 59 76\ttexture synthesis\n",
      "T4\tTask 81 97\timage inpainting\n",
      "T5\tMethod 146 163\tgreedy techniques\n",
      "T6\tGeneric 171 176\ttasks\n",
      "T7\tTask 204 240\tdiscrete global optimization problem\n",
      "T8\tOtherScientificTerm 248 279\twell defined objective function\n",
      "T9\tGeneric 298 305\tproblem\n",
      "T10\tMethod 314 333\toptimization scheme\n",
      "T11\tMethod 342 353\tPriority-BP\n",
      "T12\tGeneric 400 410\textensions\n",
      "T13\tMethod 425 448\tbelief propagation (BP)\n",
      "T14\tMethod 452 485\tpriority-based message scheduling\n",
      "T15\tMethod 494 515\tdynamic label pruning\n",
      "T16\tGeneric 529 539\textensions\n",
      "T17\tOtherScientificTerm 577 613\tintolerable computational cost of BP\n",
      "T18\tMethod 611 613\tBP\n",
      "T19\tGeneric 675 685\textensions\n",
      "T20\tMethod 734 753\tMRF energy function\n",
      "T21\tGeneric 788 794\tmethod\n",
      "T22\tMaterial 832 857\timage completion examples\n",
      "R1\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R2\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R6\tHYPONYM-OF Arg1:T2 Arg2:T6\n",
      "R7\tHYPONYM-OF Arg1:T3 Arg2:T6\n",
      "R8\tHYPONYM-OF Arg1:T4 Arg2:T6\n",
      "R9\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R10\tCOMPARE Arg1:T5 Arg2:T6\n",
      "R11\tCOREF Arg1:T9 Arg2:T7\n",
      "R12\tHYPONYM-OF Arg1:T11 Arg2:T10\n",
      "R13\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R14\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R15\tHYPONYM-OF Arg1:T14 Arg2:T12\n",
      "R16\tHYPONYM-OF Arg1:T15 Arg2:T12\n",
      "R17\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R18\tCOREF Arg1:T16 Arg2:T12\n",
      "R19\tPART-OF Arg1:T12 Arg2:T10\n",
      "R20\tCOREF Arg1:T18 Arg2:T13\n",
      "R21\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R22\tCOREF Arg1:T19 Arg2:T16\n",
      "R23\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R24\tCOREF Arg1:T21 Arg2:T19\n",
      "R25\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "R26\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2006_21_abs.ann\n",
      "T1\tOtherScientificTerm 20 35\tprior knowledge\n",
      "T2\tMethod 73 117\tlow-level driven image processing algorithms\n",
      "T3\tTask 160 188\tnon-rigid image registration\n",
      "T4\tMetric 211 232\tregistration criteria\n",
      "T5\tMetric 307 333\tmaximum mutual information\n",
      "T6\tGeneric 349 358\tcriterion\n",
      "T7\tGeneric 420 422\tit\n",
      "T8\tMetric 440 459\tlow-level criterion\n",
      "T9\tTask 479 491\tregistration\n",
      "T10\tOtherScientificTerm 527 548\tlow-level information\n",
      "T11\tOtherScientificTerm 570 575\tnoise\n",
      "T12\tOtherScientificTerm 577 595\tpartial occlusions\n",
      "T13\tOtherScientificTerm 599 622\tmissing image structure\n",
      "T14\tMethod 658 676\tBayesian framework\n",
      "T15\tOtherScientificTerm 699 736\tstatistically learned prior knowledge\n",
      "T16\tOtherScientificTerm 747 775\tjoint intensity distribution\n",
      "T17\tMethod 781 807\timage registration methods\n",
      "T18\tGeneric 813 818\tprior\n",
      "T19\tMethod 833 856\tkernel density estimate\n",
      "T20\tOtherScientificTerm 873 902\tjoint intensity distributions\n",
      "T21\tMaterial 941 967\tpre-registered image pairs\n",
      "T22\tOtherScientificTerm 1031 1050\tintensity relations\n",
      "T23\tOtherScientificTerm 1067 1083\timage modalities\n",
      "T24\tOtherScientificTerm 1088 1103\tslice locations\n",
      "T25\tMethod 1157 1177\tregistration process\n",
      "T26\tOtherScientificTerm 1196 1225\tmissing low-level information\n",
      "T27\tOtherScientificTerm 1229 1231\tit\n",
      "T28\tOtherScientificTerm 1239 1264\tintensity correspondences\n",
      "T29\tOtherScientificTerm 1307 1330\tintensity distributions\n",
      "R1\tHYPONYM-OF Arg1:T5 Arg2:T4\n",
      "R2\tCOREF Arg1:T6 Arg2:T5\n",
      "R3\tCOREF Arg1:T6 Arg2:T7\n",
      "R4\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "R5\tCOREF Arg1:T3 Arg2:T9\n",
      "R6\tFEATURE-OF Arg1:T16 Arg2:T15\n",
      "R7\tUSED-FOR Arg1:T14 Arg2:T17\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T17\n",
      "R9\tCOREF Arg1:T18 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T19 Arg2:T18\n",
      "R11\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R12\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R13\tCOREF Arg1:T17 Arg2:T25\n",
      "R14\tUSED-FOR Arg1:T25 Arg2:T26\n",
      "R15\tCOREF Arg1:T25 Arg2:T27\n",
      "R16\tUSED-FOR Arg1:T27 Arg2:T28\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2007_10_abs.ann\n",
      "T1\tMethod 12 50\tlinear Fukunaga-Koontz Transform (FKT)\n",
      "T2\tMethod 69 111\tdiscriminative subspaces building approach\n",
      "T3\tMethod 153 156\tFKT\n",
      "T4\tOtherScientificTerm 181 198\tsmall-sample-size\n",
      "T5\tMethod 237 247\tlinear FKT\n",
      "T6\tGeneric 258 260\tit\n",
      "T7\tTask 272 291\tmulti-class problem\n",
      "T8\tOtherScientificTerm 304 341\thigher dimensional (kernel) subspaces\n",
      "T9\tOtherScientificTerm 373 395\tdiscrimination ability\n",
      "T10\tMethod 441 473\tKernel Fukunaga-Koontz Transform\n",
      "T11\tTask 512 541\tface recognition applications\n",
      "T12\tMethod 564 589\tnon-linear generalization\n",
      "T13\tTask 618 642\tdomain specific problems\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T5 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R8\tFEATURE-OF Arg1:T6 Arg2:T9\n",
      "R9\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R10\tEVALUATE-FOR Arg1:T11 Arg2:T10\n",
      "R11\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R12\tCOREF Arg1:T10 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2007_11_abs.ann\n",
      "T1\tMethod 41 69\tLagrangian Particle Dynamics\n",
      "T2\tTask 86 126\tsegmentation of high density crowd flows\n",
      "T3\tTask 131 162\tdetection of flow instabilities\n",
      "T4\tOtherScientificTerm 184 194\tflow field\n",
      "T5\tOtherScientificTerm 210 222\tmoving crowd\n",
      "T6\tMethod 240 266\taperiodic dynamical system\n",
      "T7\tOtherScientificTerm 270 287\tgrid of particles\n",
      "T8\tOtherScientificTerm 307 317\tflow field\n",
      "T9\tMethod 343 371\tnumerical integration scheme\n",
      "T10\tOtherScientificTerm 377 399\tevolution of particles\n",
      "T11\tMethod 436 444\tFlow Map\n",
      "T12\tOtherScientificTerm 452 469\tspatial gradients\n",
      "T13\tMethod 503 534\tCauchy Green Deformation tensor\n",
      "T14\tOtherScientificTerm 651 669\tmaximum eigenvalue\n",
      "T15\tGeneric 677 683\ttensor\n",
      "T16\tOtherScientificTerm 707 749\tFinite Time Lyapunov Exponent (FTLE) field\n",
      "T17\tOtherScientificTerm 769 805\tLagrangian Coherent Structures (LCS)\n",
      "T18\tOtherScientificTerm 842 845\tLCS\n",
      "T19\tOtherScientificTerm 930 961\tboundaries of the flow segments\n",
      "T20\tMethod 967 992\tnormalized cuts framework\n",
      "T21\tMaterial 1232 1244\tGoogle Video\n",
      "T22\tMaterial 1251 1282\tNational Geographic documentary\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R5\tCOREF Arg1:T4 Arg2:T8\n",
      "R6\tCOREF Arg1:T15 Arg2:T13\n",
      "R7\tFEATURE-OF Arg1:T14 Arg2:T15\n",
      "R8\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R9\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R10\tCOREF Arg1:T18 Arg2:T17\n",
      "R11\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R12\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R13\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "R14\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R15\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R16\tUSED-FOR Arg1:T9 Arg2:T7\n",
      "R17\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R18\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2007_18_abs.ann\n",
      "T1\tMethod 28 59\thuman action recognition system\n",
      "T2\tTask 73 110\tembedded computer vision applications\n",
      "T3\tTask 114 130\tsecurity systems\n",
      "T4\tTask 132 158\thuman-computer interaction\n",
      "T5\tTask 163 187\tintelligent environments\n",
      "T6\tGeneric 193 199\tsystem\n",
      "T7\tTask 216 252\tembedded computer vision application\n",
      "T8\tGeneric 290 296\tsystem\n",
      "T9\tMethod 312 358\tlinear Support Vector Machine (SVM) classifier\n",
      "T10\tMethod 365 388\tclassification progress\n",
      "T11\tOtherScientificTerm 430 447\tembedded hardware\n",
      "T12\tOtherScientificTerm 467 492\tcompacted motion features\n",
      "T13\tMaterial 514 520\tvideos\n",
      "T14\tMethod 567 593\tMotion History Image (MHI)\n",
      "T15\tMethod 612 664\tHierarchical Motion History Histogram (HMHH) feature\n",
      "T16\tOtherScientificTerm 682 700\tmotion information\n",
      "T17\tMethod 702 706\tHMHH\n",
      "T18\tOtherScientificTerm 725 748\trich motion information\n",
      "T19\tMethod 816 819\tMHI\n",
      "T20\tMethod 824 828\tHMHH\n",
      "T21\tOtherScientificTerm 852 880\tlow dimension feature vector\n",
      "T22\tMethod 899 914\tSVM classifiers\n",
      "T23\tGeneric 951 957\tsystem\n",
      "T24\tTask 998 1009\trecognition\n",
      "R1\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R2\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T6 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T2 Arg2:T5\n",
      "R8\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R9\tCOREF Arg1:T7 Arg2:T2\n",
      "R10\tCOREF Arg1:T8 Arg2:T6\n",
      "R11\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R12\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R13\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R14\tCOREF Arg1:T17 Arg2:T15\n",
      "R15\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R16\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R17\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R18\tCOREF Arg1:T23 Arg2:T8\n",
      "R19\tEVALUATE-FOR Arg1:T24 Arg2:T23\n",
      "R20\tCOREF Arg1:T9 Arg2:T10\n",
      "R21\tCOREF Arg1:T22 Arg2:T10\n",
      "R22\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R23\tUSED-FOR Arg1:T19 Arg2:T21\n",
      "R24\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2007_21_abs.ann\n",
      "T1\tTask 33 65\tclassification of outdoor scenes\n",
      "T2\tMethod 116 140\tone-class classification\n",
      "T3\tMethod 145 178\tpatch-based clustering algorithms\n",
      "T4\tMethod 185 206\tone-class classifiers\n",
      "T5\tOtherScientificTerm 241 277\tuniform color and texture properties\n",
      "T6\tMethod 283 304\tclustering of patches\n",
      "T7\tOtherScientificTerm 411 435\tcodebook of region types\n",
      "T8\tGeneric 445 451\tmodels\n",
      "T9\tMethod 472 492\tscene representation\n",
      "T10\tOtherScientificTerm 659 680\tspatial relationships\n",
      "T11\tTask 735 755\tscene classification\n",
      "T12\tMethod 770 790\tBayesian classifiers\n",
      "T13\tMethod 816 842\tregion selection algorithm\n",
      "T14\tMaterial 1050 1066\tLabelMe data set\n",
      "T15\tGeneric 1092 1098\tmodels\n",
      "T16\tMethod 1127 1165\tbaseline global feature-based approach\n",
      "R1\tCONJUNCTION Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R5\tCOMPARE Arg1:T15 Arg2:T16\n",
      "R6\tEVALUATE-FOR Arg1:T14 Arg2:T15\n",
      "R7\tCOREF Arg1:T15 Arg2:T13\n",
      "R8\tEVALUATE-FOR Arg1:T14 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2008_100_abs.ann\n",
      "T1\tMethod 0 24\tStructured-light methods\n",
      "T2\tMaterial 43 72\tgeometric correspondence data\n",
      "T3\tTask 127 151\trobust 3D reconstruction\n",
      "T4\tMethod 179 210\tPhotogeometric Structured Light\n",
      "T5\tMethod 230 253\tstructured light method\n",
      "T6\tMethod 277 296\tphotometric methods\n",
      "T7\tMethod 298 320\tPhotometric processing\n",
      "T8\tOtherScientificTerm 375 399\trecovered surface detail\n",
      "T9\tOtherScientificTerm 420 442\tstructured-light setup\n",
      "T10\tGeneric 488 497\tframework\n",
      "T11\tMethod 505 532\tphotogeometric optimization\n",
      "T12\tMethod 636 655\tmulti-view 3D model\n",
      "T13\tMaterial 681 711\tphotometric and geometric data\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T7 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R6\tCOREF Arg1:T10 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R8\tPART-OF Arg1:T5 Arg2:T4\n",
      "R9\tPART-OF Arg1:T6 Arg2:T4\n",
      "R10\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2008_103_abs.ann\n",
      "T1\tMethod 28 89\tpartially-blurred-image classification and analysis framework\n",
      "T2\tTask 94 124\tautomatically detecting images\n",
      "T3\tMaterial 118 124\timages\n",
      "T4\tOtherScientificTerm 136 151\tblurred regions\n",
      "T5\tGeneric 193 200\tregions\n",
      "T6\tTask 228 250\tblur kernel estimation\n",
      "T7\tTask 255 271\timage deblurring\n",
      "T8\tOtherScientificTerm 292 305\tblur features\n",
      "T9\tOtherScientificTerm 317 328\timage color\n",
      "T10\tOtherScientificTerm 330 338\tgradient\n",
      "T11\tOtherScientificTerm 344 364\tspectrum information\n",
      "T12\tMethod 374 400\tfeature parameter training\n",
      "T13\tMaterial 422 436\tblurred images\n",
      "T14\tMethod 442 456\tblur detection\n",
      "T15\tOtherScientificTerm 469 482\timage patches\n",
      "T16\tMethod 491 530\tregion-wise training and classification\n",
      "T17\tGeneric 591 597\tmethod\n",
      "T18\tMaterial 634 644\timage data\n",
      "T19\tTask 707 731\tcomputer vision problems\n",
      "T20\tTask 741 756\tmotion analysis\n",
      "T21\tTask 761 778\timage restoration\n",
      "T22\tOtherScientificTerm 790 806\tblur information\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tPART-OF Arg1:T4 Arg2:T3\n",
      "R3\tCOREF Arg1:T5 Arg2:T4\n",
      "R4\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T8\n",
      "R8\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R9\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R11\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T14\n",
      "R13\tCOREF Arg1:T17 Arg2:T14\n",
      "R14\tHYPONYM-OF Arg1:T20 Arg2:T19\n",
      "R15\tHYPONYM-OF Arg1:T21 Arg2:T19\n",
      "R16\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R17\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R18\tUSED-FOR Arg1:T17 Arg2:T19\n",
      "R19\tUSED-FOR Arg1:T22 Arg2:T17\n",
      "R20\tCOREF Arg1:T1 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2008_256_abs.ann\n",
      "T1\tMethod 9 21\tobject model\n",
      "T2\tMetric 28 59\tblack-box measure of similarity\n",
      "T3\tGeneric 72 77\tmodel\n",
      "T4\tTask 113 135\tvisual object tracking\n",
      "T5\tTask 141 171\tnumerical optimization problem\n",
      "T6\tMethod 255 273\tlocal optimization\n",
      "T7\tOtherScientificTerm 295 331\tlocal mode of the similarity measure\n",
      "T8\tOtherScientificTerm 337 387\tparameter space of translation, rotation and scale\n",
      "T9\tMethod 458 472\tlocal tracking\n",
      "T10\tMethod 517 538\tprediction techniques\n",
      "T11\tMethod 548 561\tKalman filter\n",
      "T12\tTask 696 712\tobject detection\n",
      "T13\tTask 718 745\tglobal optimization problem\n",
      "T14\tGeneric 756 758\tit\n",
      "T15\tMethod 763 797\tAdaptive Simulated Annealing (ASA)\n",
      "T16\tGeneric 801 807\tmethod\n",
      "T17\tMethod 876 893\texhaustive search\n",
      "T18\tMethod 900 920\tMonte Carlo approach\n",
      "T19\tMethod 922 925\tASA\n",
      "T20\tOtherScientificTerm 953 968\tparameter space\n",
      "T21\tMethod 985 1011\tlocal deterministic search\n",
      "T22\tMethod 1022 1038\tcluster analysis\n",
      "T23\tOtherScientificTerm 1046 1069\tsampled parameter space\n",
      "T24\tMethod 1107 1120\tlocal tracker\n",
      "T25\tMethod 1126 1180\tnumerical hybrid local and global mode-seeking tracker\n",
      "T26\tMaterial 1209 1224\tairborne videos\n",
      "T27\tOtherScientificTerm 1230 1245\theavy occlusion\n",
      "T28\tOtherScientificTerm 1256 1270\tcamera motions\n",
      "T29\tGeneric 1276 1284\tapproach\n",
      "T30\tGeneric 1297 1322\tstate-of-the-art trackers\n",
      "T31\tMaterial 1330 1354\tVIVID benchmark datasets\n",
      "R1\tCOREF Arg1:T3 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R6\tCOREF Arg1:T13 Arg2:T14\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R8\tCOREF Arg1:T16 Arg2:T15\n",
      "R9\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R10\tCOREF Arg1:T15 Arg2:T19\n",
      "R11\tHYPONYM-OF Arg1:T19 Arg2:T18\n",
      "R12\tCOMPARE Arg1:T19 Arg2:T21\n",
      "R13\tCOREF Arg1:T25 Arg2:T29\n",
      "R14\tCOMPARE Arg1:T30 Arg2:T29\n",
      "R15\tEVALUATE-FOR Arg1:T31 Arg2:T29\n",
      "R16\tEVALUATE-FOR Arg1:T31 Arg2:T30\n",
      "R17\tEVALUATE-FOR Arg1:T26 Arg2:T25\n",
      "R18\tFEATURE-OF Arg1:T27 Arg2:T26\n",
      "R19\tFEATURE-OF Arg1:T28 Arg2:T26\n",
      "R20\tCONJUNCTION Arg1:T27 Arg2:T28\n",
      "R21\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R22\tUSED-FOR Arg1:T22 Arg2:T24\n",
      "R23\tPART-OF Arg1:T11 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2008_257_abs.ann\n",
      "T1\tMethod 0 16\tGraphical models\n",
      "T2\tMethod 25 48\tBayesian Networks (BNs)\n",
      "T3\tTask 91 115\tcomputer vision problems\n",
      "T4\tMethod 141 143\tBN\n",
      "T5\tOtherScientificTerm 165 184\tBN model parameters\n",
      "T6\tMaterial 231 259\trepresentative training data\n",
      "T7\tTask 310 331\tcomputer vision tasks\n",
      "T8\tOtherScientificTerm 377 404\tqualitative prior knowledge\n",
      "T9\tGeneric 415 420\tmodel\n",
      "T10\tGeneric 427 436\tknowledge\n",
      "T11\tOtherScientificTerm 455 469\tdomain experts\n",
      "T12\tOtherScientificTerm 512 545\tphysical or geometric constraints\n",
      "T13\tOtherScientificTerm 598 616\tquantitative prior\n",
      "T14\tOtherScientificTerm 622 639\tqualitative prior\n",
      "T15\tGeneric 696 700\tthem\n",
      "T16\tTask 710 732\tmodel learning process\n",
      "T17\tMethod 764 784\tclosed-form solution\n",
      "T18\tMaterial 815 836\tlimited training data\n",
      "T19\tOtherScientificTerm 855 876\tqualitative knowledge\n",
      "T20\tMethod 881 902\tBN parameter learning\n",
      "T21\tGeneric 920 926\tmethod\n",
      "T22\tGeneric 939 941\tit\n",
      "T23\tMethod 951 992\tMaximum Likelihood (ML) estimation method\n",
      "T24\tMaterial 999 1010\tsparse data\n",
      "T25\tMethod 1024 1063\tExpectation Maximization (EM) algorithm\n",
      "T26\tMaterial 1070 1085\tincomplete data\n",
      "T27\tTask 1144 1159\tcomputer vision\n",
      "T28\tGeneric 1170 1172\tit\n",
      "T29\tMethod 1184 1192\tBN model\n",
      "T30\tTask 1197 1232\tfacial Action Unit (AU) recognition\n",
      "T31\tMaterial 1238 1253\treal image data\n",
      "T32\tOtherScientificTerm 1306 1337\tgeneric qualitative constraints\n",
      "T33\tMaterial 1371 1384\ttraining data\n",
      "T34\tGeneric 1390 1396\tmethod\n",
      "T35\tOtherScientificTerm 1438 1457\tBN model parameters\n",
      "R1\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T4 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tCOREF Arg1:T10 Arg2:T8\n",
      "R7\tFEATURE-OF Arg1:T8 Arg2:T9\n",
      "R8\tCOREF Arg1:T14 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R10\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R11\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R12\tCOREF Arg1:T15 Arg2:T14\n",
      "R13\tPART-OF Arg1:T15 Arg2:T16\n",
      "R14\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R15\tCOMPARE Arg1:T22 Arg2:T23\n",
      "R16\tUSED-FOR Arg1:T24 Arg2:T22\n",
      "R17\tUSED-FOR Arg1:T24 Arg2:T23\n",
      "R18\tUSED-FOR Arg1:T26 Arg2:T25\n",
      "R19\tCOMPARE Arg1:T22 Arg2:T25\n",
      "R20\tUSED-FOR Arg1:T28 Arg2:T29\n",
      "R21\tUSED-FOR Arg1:T29 Arg2:T30\n",
      "R22\tCONJUNCTION Arg1:T32 Arg2:T33\n",
      "R23\tUSED-FOR Arg1:T33 Arg2:T34\n",
      "R24\tUSED-FOR Arg1:T32 Arg2:T34\n",
      "R25\tUSED-FOR Arg1:T34 Arg2:T35\n",
      "R26\tCOREF Arg1:T4 Arg2:T29\n",
      "R27\tCOREF Arg1:T27 Arg2:T3\n",
      "R28\tCOREF Arg1:T7 Arg2:T3\n",
      "R29\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R30\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R31\tUSED-FOR Arg1:T18 Arg2:T20\n",
      "R32\tUSED-FOR Arg1:T20 Arg2:T17\n",
      "R33\tCOREF Arg1:T21 Arg2:T22\n",
      "R34\tCOREF Arg1:T17 Arg2:T21\n",
      "R35\tUSED-FOR Arg1:T26 Arg2:T22\n",
      "R36\tCOREF Arg1:T22 Arg2:T28\n",
      "R37\tUSED-FOR Arg1:T28 Arg2:T27\n",
      "R38\tCOREF Arg1:T34 Arg2:T28\n",
      "R39\tUSED-FOR Arg1:T31 Arg2:T30\n",
      "R40\tCOREF Arg1:T9 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2008_258_abs.ann\n",
      "T1\tTask 35 78\tunsupervised seg-mentation of whole objects\n",
      "T2\tTask 105 131\tpartial scene segmentation\n",
      "T3\tOtherScientificTerm 152 171\tsoft, binary mattes\n",
      "T4\tGeneric 179 185\tmattes\n",
      "T5\tOtherScientificTerm 210 248\thypothesized object boundary fragments\n",
      "T6\tGeneric 394 414\tcontemporary methods\n",
      "T7\tTask 419 448\tunsupervised object discovery\n",
      "T8\tOtherScientificTerm 598 626\tdelineation of scene objects\n",
      "T9\tGeneric 641 649\tapproach\n",
      "T10\tMethod 679 698\tspectral clustering\n",
      "T11\tMethod 700 713\timage matting\n",
      "T12\tMethod 719 737\tboundary detection\n",
      "T13\tGeneric 739 741\tIt\n",
      "T14\tMaterial 796 813\tdataset of scenes\n",
      "T15\tTask 850 879\tunsupervised object discovery\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tCOREF Arg1:T3 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R7\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R8\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T9\n",
      "R11\tCOREF Arg1:T15 Arg2:T7\n",
      "R12\tCOREF Arg1:T1 Arg2:T7\n",
      "R13\tCOREF Arg1:T13 Arg2:T9\n",
      "R14\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R15\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2008_259_abs.ann\n",
      "T1\tMethod 28 47\tgeometric framework\n",
      "T2\tTask 52 121\tlinear or nonlinear discriminant subspace learning and classification\n",
      "T3\tGeneric 130 139\tframework\n",
      "T4\tOtherScientificTerm 145 166\tstructures of classes\n",
      "T5\tOtherScientificTerm 191 215\tsemi-Riemannian manifold\n",
      "T6\tOtherScientificTerm 241 252\tsubmanifold\n",
      "T7\tOtherScientificTerm 268 297\tambient semi-Riemannian space\n",
      "T8\tOtherScientificTerm 303 319\tclass structures\n",
      "T9\tMetric 377 419\tlocal metrics of the semi-Riemannian space\n",
      "T10\tMetric 421 444\tSemi-Riemannian metrics\n",
      "T11\tMethod 476 507\tsmoothing of discrete functions\n",
      "T12\tOtherScientificTerm 516 552\tnullity of the semi-Riemannian space\n",
      "T13\tMethod 567 601\tgeometrization of class structures\n",
      "T14\tOtherScientificTerm 614 630\tclass structures\n",
      "T15\tOtherScientificTerm 638 651\tfeature space\n",
      "T16\tOtherScientificTerm 684 722\tquadratic quantities of metric tensors\n",
      "T17\tOtherScientificTerm 730 751\tsemi-Riemannian space\n",
      "T18\tMethod 758 799\tsupervised discriminant subspace learning\n",
      "T19\tMethod 811 858\tunsupervised semi-Riemannian mani-fold learning\n",
      "T20\tGeneric 882 891\tframework\n",
      "T21\tGeneric 901 910\talgorithm\n",
      "T22\tMethod 922 966\tSemi-Riemannian Discriminant Analysis (SRDA)\n",
      "T23\tTask 985 1014\tsubspace-based classification\n",
      "T24\tMethod 1035 1039\tSRDA\n",
      "T25\tTask 1053 1084\tface recognition (singular case\n",
      "T26\tTask 1090 1150\thandwritten capital letter classification (nonsingular case)\n",
      "T27\tGeneric 1168 1178\talgorithms\n",
      "T28\tGeneric 1215 1219\tSRDA\n",
      "T29\tTask 1234 1245\trecognition\n",
      "T30\tTask 1250 1264\tclassification\n",
      "T31\tMethod 1280 1304\tsemi-Riemannian geometry\n",
      "T32\tTask 1333 1352\tpattern recognition\n",
      "T33\tTask 1357 1373\tmachine learning\n",
      "R1\tCOREF Arg1:T3 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R4\tPART-OF Arg1:T6 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R6\tCOREF Arg1:T10 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R9\tFEATURE-OF Arg1:T15 Arg2:T14\n",
      "R10\tFEATURE-OF Arg1:T17 Arg2:T16\n",
      "R11\tCOREF Arg1:T22 Arg2:T21\n",
      "R12\tUSED-FOR Arg1:T21 Arg2:T23\n",
      "R13\tCOREF Arg1:T1 Arg2:T20\n",
      "R14\tCOREF Arg1:T24 Arg2:T22\n",
      "R15\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R16\tEVALUATE-FOR Arg1:T25 Arg2:T24\n",
      "R17\tEVALUATE-FOR Arg1:T26 Arg2:T24\n",
      "R18\tCONJUNCTION Arg1:T25 Arg2:T26\n",
      "R19\tCOMPARE Arg1:T24 Arg2:T27\n",
      "R20\tCOREF Arg1:T22 Arg2:T28\n",
      "R21\tEVALUATE-FOR Arg1:T25 Arg2:T27\n",
      "R22\tEVALUATE-FOR Arg1:T26 Arg2:T27\n",
      "R23\tUSED-FOR Arg1:T28 Arg2:T29\n",
      "R24\tUSED-FOR Arg1:T28 Arg2:T30\n",
      "R25\tCONJUNCTION Arg1:T29 Arg2:T30\n",
      "R26\tCONJUNCTION Arg1:T32 Arg2:T33\n",
      "R27\tUSED-FOR Arg1:T31 Arg2:T32\n",
      "R28\tUSED-FOR Arg1:T31 Arg2:T33\n",
      "R29\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2009_10_abs.ann\n",
      "T1\tMethod 19 42\tprobabilistic framework\n",
      "T2\tTask 56 93\tvisual models of 3D object categories\n",
      "T3\tOtherScientificTerm 107 129\tappearance information\n",
      "T4\tOtherScientificTerm 134 155\tgeometric constraints\n",
      "T5\tOtherScientificTerm 239 267\t3D viewpoint transformations\n",
      "T6\tOtherScientificTerm 298 320\tsalient image features\n",
      "T7\tMethod 324 344\tgenerative framework\n",
      "T8\tGeneric 368 373\tmodel\n",
      "T9\tOtherScientificTerm 438 460\tdiscretized viewpoints\n",
      "T10\tMethod 495 523\tmixture of viewpoints models\n",
      "T11\tGeneric 530 535\tmodel\n",
      "T12\tOtherScientificTerm 599 609\tviewpoints\n",
      "T13\tMaterial 643 648\timage\n",
      "T14\tTask 650 659\tdetection\n",
      "T15\tTask 664 678\tclassification\n",
      "T16\tOtherScientificTerm 711 719\tposition\n",
      "T17\tOtherScientificTerm 724 733\tviewpoint\n",
      "T18\tMetric 761 779\trecognition scores\n",
      "T19\tGeneric 810 818\tapproach\n",
      "T20\tMethod 851 886\tgenerative proba-bilistic framework\n",
      "T21\tTask 891 915\t3D object categorization\n",
      "T22\tGeneric 929 938\talgorithm\n",
      "T23\tTask 946 960\tdetection task\n",
      "T24\tTask 969 998\tviewpoint classification task\n",
      "T25\tMaterial 1064 1088\tPASCAL VOC 2006 datasets\n",
      "T26\tTask 1128 1172\tdetection and viewpoint classification tasks\n",
      "T27\tGeneric 1198 1206\tdatasets\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R6\tUSED-FOR Arg1:T17 Arg2:T15\n",
      "R7\tUSED-FOR Arg1:T16 Arg2:T14\n",
      "R8\tUSED-FOR Arg1:T17 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R10\tCOREF Arg1:T19 Arg2:T11\n",
      "R11\tCOREF Arg1:T22 Arg2:T19\n",
      "R12\tEVALUATE-FOR Arg1:T25 Arg2:T22\n",
      "R13\tHYPONYM-OF Arg1:T25 Arg2:T27\n",
      "R14\tCOMPARE Arg1:T11 Arg2:T10\n",
      "R15\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R16\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R17\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R18\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R19\tCOREF Arg1:T20 Arg2:T19\n",
      "R20\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R21\tUSED-FOR Arg1:T22 Arg2:T24\n",
      "R22\tCONJUNCTION Arg1:T23 Arg2:T24\n",
      "R23\tEVALUATE-FOR Arg1:T27 Arg2:T26\n",
      "R24\tHYPONYM-OF Arg1:T23 Arg2:T26\n",
      "R25\tHYPONYM-OF Arg1:T24 Arg2:T26\n",
      "R26\tCOREF Arg1:T11 Arg2:T8\n",
      "R27\tCOREF Arg1:T8 Arg2:T1\n",
      "R28\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2009_11_abs.ann\n",
      "T1\tOtherScientificTerm 23 50\tpan-tilt-zoom (PTZ) cameras\n",
      "T2\tOtherScientificTerm 77 91\tpanoramic area\n",
      "T3\tOtherScientificTerm 105 128\thigh resolution imagery\n",
      "T4\tTask 144 174\tautomated surveillance systems\n",
      "T5\tOtherScientificTerm 189 200\tPTZ cameras\n",
      "T6\tGeneric 251 261\talgorithms\n",
      "T7\tOtherScientificTerm 274 331\tprior knowledge of intrinsic parameters of the PTZ camera\n",
      "T8\tOtherScientificTerm 345 365\trelative positioning\n",
      "T9\tOtherScientificTerm 370 381\torientation\n",
      "T10\tOtherScientificTerm 397 408\tPTZ cameras\n",
      "T11\tMethod 458 475\tmapping algorithm\n",
      "T12\tOtherScientificTerm 493 513\trelative positioning\n",
      "T13\tOtherScientificTerm 518 529\torientation\n",
      "T14\tOtherScientificTerm 542 553\tPTZ cameras\n",
      "T15\tMethod 565 589\tunified polynomial model\n",
      "T16\tOtherScientificTerm 663 673\tPTZ camera\n",
      "T17\tOtherScientificTerm 678 696\trelative positions\n",
      "T18\tGeneric 749 758\talgorithm\n",
      "T19\tMetric 790 814\tcomputational complexity\n",
      "T20\tMetric 828 839\tflexibility\n",
      "T21\tMetric 874 888\tpixel accuracy\n",
      "T22\tMetric 958 972\tpixel accuracy\n",
      "T23\tMethod 995 1025\tconsistent labeling approaches\n",
      "T24\tTask 1068 1098\tautomated surveillance systems\n",
      "T25\tOtherScientificTerm 1157 1168\tPTZ cameras\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T9\n",
      "R4\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R5\tFEATURE-OF Arg1:T8 Arg2:T10\n",
      "R6\tFEATURE-OF Arg1:T9 Arg2:T10\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R10\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R11\tFEATURE-OF Arg1:T13 Arg2:T14\n",
      "R12\tFEATURE-OF Arg1:T12 Arg2:T14\n",
      "R13\tEVALUATE-FOR Arg1:T19 Arg2:T18\n",
      "R14\tEVALUATE-FOR Arg1:T20 Arg2:T18\n",
      "R15\tEVALUATE-FOR Arg1:T21 Arg2:T18\n",
      "R16\tCOREF Arg1:T22 Arg2:T21\n",
      "R17\tUSED-FOR Arg1:T23 Arg2:T22\n",
      "R18\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R19\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R20\tCOREF Arg1:T4 Arg2:T24\n",
      "R21\tCOREF Arg1:T11 Arg2:T18\n",
      "R22\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2009_18_abs.ann\n",
      "T1\tGeneric 17 23\tmethod\n",
      "T2\tTask 28 53\tdetecting interest points\n",
      "T3\tOtherScientificTerm 60 81\thistogram information\n",
      "T4\tMethod 99 123\tinterest point detectors\n",
      "T5\tMetric 139 180\tpixel-wise differences in image intensity\n",
      "T6\tGeneric 186 195\tdetectors\n",
      "T7\tMethod 208 239\thistogram-based representations\n",
      "T8\tGeneric 345 354\tdetectors\n",
      "T9\tOtherScientificTerm 375 397\tlarge-scale structures\n",
      "T10\tOtherScientificTerm 402 431\tdistinctive textured patterns\n",
      "T11\tOtherScientificTerm 466 474\trotation\n",
      "T12\tOtherScientificTerm 476 498\tillumination variation\n",
      "T13\tOtherScientificTerm 504 508\tblur\n",
      "T14\tMethod 558 598\thistogram-based interest point detectors\n",
      "T15\tTask 642 666\tmatching textured scenes\n",
      "T16\tOtherScientificTerm 673 702\tblur and illumination changes\n",
      "T17\tMetric 716 729\trepeatability\n",
      "T18\tMetric 734 749\tdistinctiveness\n",
      "T19\tGeneric 771 777\tmethod\n",
      "T20\tTask 781 816\tspace-time interest point detection\n",
      "T21\tTask 821 842\taction classification\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T6 Arg2:T1\n",
      "R4\tPART-OF Arg1:T7 Arg2:T6\n",
      "R5\tEVALUATE-FOR Arg1:T5 Arg2:T4\n",
      "R6\tCOREF Arg1:T8 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R8\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T11\n",
      "R11\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R12\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R13\tUSED-FOR Arg1:T8 Arg2:T12\n",
      "R14\tUSED-FOR Arg1:T8 Arg2:T13\n",
      "R15\tCOREF Arg1:T14 Arg2:T8\n",
      "R16\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R17\tCOREF Arg1:T19 Arg2:T14\n",
      "R18\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R19\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R20\tEVALUATE-FOR Arg1:T17 Arg2:T14\n",
      "R21\tEVALUATE-FOR Arg1:T18 Arg2:T14\n",
      "R22\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2009_21_abs.ann\n",
      "T1\tTask 5 33\tcomputer vision applications\n",
      "T2\tTask 43 63\timage classification\n",
      "T3\tTask 68 82\tvideo indexing\n",
      "T4\tTask 96 131\tmulti-label classification problems\n",
      "T5\tMethod 230 265\tmulti-label classification approach\n",
      "T6\tOtherScientificTerm 271 297\thypergraph regu-larization\n",
      "T7\tOtherScientificTerm 367 377\thypergraph\n",
      "T8\tMethod 616 640\tSVM like learning system\n",
      "T9\tOtherScientificTerm 659 684\thypergraph regularization\n",
      "T10\tMethod 693 705\tRank-HLapSVM\n",
      "T11\tTask 733 768\tmulti-label classification problems\n",
      "T12\tTask 801 821\toptimization problem\n",
      "T13\tMethod 855 885\tdual coordinate descent method\n",
      "T14\tGeneric 930 943\treal datasets\n",
      "T15\tMaterial 954 963\tImageCLEF\n",
      "T16\tMaterial 968 978\tMe-diaMill\n",
      "T17\tGeneric 1040 1049\talgorithm\n",
      "R1\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R5\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "R6\tPART-OF Arg1:T9 Arg2:T8\n",
      "R7\tHYPONYM-OF Arg1:T10 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T11\n",
      "R9\tCOREF Arg1:T11 Arg2:T4\n",
      "R10\tCOREF Arg1:T5 Arg2:T8\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R12\tCOREF Arg1:T8 Arg2:T17\n",
      "R13\tHYPONYM-OF Arg1:T15 Arg2:T14\n",
      "R14\tHYPONYM-OF Arg1:T16 Arg2:T14\n",
      "R15\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R16\tEVALUATE-FOR Arg1:T14 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2010_10_abs.ann\n",
      "T1\tGeneric 17 25\tapproach\n",
      "T2\tMethod 63 73\tclassifier\n",
      "T3\tTask 86 99\tclass problem\n",
      "T4\tMaterial 147 152\timage\n",
      "T5\tOtherScientificTerm 169 182\torien-tations\n",
      "T6\tGeneric 229 236\tproblem\n",
      "T7\tMethod 252 263\tclassifiers\n",
      "T8\tGeneric 343 351\tapproach\n",
      "T9\tMethod 360 376\testimation stage\n",
      "T10\tMethod 383 403\tclassification stage\n",
      "T11\tMethod 409 418\testimator\n",
      "T12\tOtherScientificTerm 454 466\tobject poses\n",
      "T13\tMethod 498 508\tclassifier\n",
      "T14\tMetric 547 562\ttime complexity\n",
      "T15\tGeneric 570 579\talgorithm\n",
      "T16\tTask 586 600\tclassification\n",
      "T17\tMethod 626 636\tclassifier\n",
      "T18\tMethod 673 708\tboosted combination of Random Ferns\n",
      "T19\tOtherScientificTerm 714 759\tlocal histograms of oriented gradients (HOGs)\n",
      "T20\tMethod 787 806\tpre-processing step\n",
      "T21\tMethod 824 843\tsupervised learning\n",
      "T22\tOtherScientificTerm 863 877\tgradient space\n",
      "T23\tGeneric 888 896\tapproach\n",
      "T24\tGeneric 1019 1027\tdatabase\n",
      "T25\tMaterial 1036 1069\tmotorbikes under planar rotations\n",
      "T26\tGeneric 1092 1102\tconditions\n",
      "T27\tOtherScientificTerm 1111 1132\tcluttered backgrounds\n",
      "T28\tOtherScientificTerm 1134 1166\tchanging illumination conditions\n",
      "T29\tOtherScientificTerm 1171 1189\tpartial occlusions\n",
      "R1\tCOREF Arg1:T8 Arg2:T1\n",
      "R2\tCOREF Arg1:T15 Arg2:T8\n",
      "R3\tCOREF Arg1:T23 Arg2:T8\n",
      "R4\tCOREF Arg1:T11 Arg2:T9\n",
      "R5\tCOREF Arg1:T13 Arg2:T10\n",
      "R6\tCOREF Arg1:T17 Arg2:T10\n",
      "R7\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R8\tFEATURE-OF Arg1:T26 Arg2:T24\n",
      "R9\tHYPONYM-OF Arg1:T27 Arg2:T26\n",
      "R10\tHYPONYM-OF Arg1:T28 Arg2:T26\n",
      "R11\tHYPONYM-OF Arg1:T29 Arg2:T26\n",
      "R12\tCONJUNCTION Arg1:T27 Arg2:T28\n",
      "R13\tCONJUNCTION Arg1:T28 Arg2:T29\n",
      "R14\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R15\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R16\tCOREF Arg1:T6 Arg2:T3\n",
      "R17\tPART-OF Arg1:T9 Arg2:T8\n",
      "R18\tPART-OF Arg1:T10 Arg2:T8\n",
      "R19\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R20\tEVALUATE-FOR Arg1:T14 Arg2:T15\n",
      "R21\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R22\tFEATURE-OF Arg1:T19 Arg2:T18\n",
      "R23\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R24\tUSED-FOR Arg1:T21 Arg2:T23\n",
      "R25\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R26\tFEATURE-OF Arg1:T25 Arg2:T24\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2010_11_abs.ann\n",
      "T1\tTask 5 47\tclassifying high-dimensional sequence data\n",
      "T2\tMethod 76 80\tHMMs\n",
      "T3\tMethod 82 86\tCRFs\n",
      "T4\tOtherScientificTerm 140 151\toverfitting\n",
      "T5\tMethod 167 191\tdimensionality reduction\n",
      "T6\tMethod 218 248\tlow-dimensional representation\n",
      "T7\tTask 258 272\tclassification\n",
      "T8\tGeneric 303 319\tExisting methods\n",
      "T9\tTask 324 359\tsupervised dimensionality reduction\n",
      "T10\tOtherScientificTerm 417 445\tneighborhood graph structure\n",
      "T11\tOtherScientificTerm 492 510\tknown distribution\n",
      "T12\tMethod 512 553\tSufficient dimension reduction techniques\n",
      "T13\tMethod 568 598\tlow dimensional representation\n",
      "T14\tMethod 730 782\tsequence kernel dimension reduction approach (S-KDR)\n",
      "T15\tGeneric 788 796\tapproach\n",
      "T16\tOtherScientificTerm 869 911\tSpatial, temporal and periodic information\n",
      "T17\tOtherScientificTerm 963 971\tmanifold\n",
      "T18\tGeneric 991 999\tend-task\n",
      "T19\tGeneric 1041 1049\tapproach\n",
      "T20\tTask 1081 1134\tdiscrimination of human gesture and motion categories\n",
      "T21\tMaterial 1152 1180\tdatabase of dynamic textures\n",
      "R1\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R8\tCOREF Arg1:T14 Arg2:T15\n",
      "R9\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R10\tEVALUATE-FOR Arg1:T20 Arg2:T19\n",
      "R11\tEVALUATE-FOR Arg1:T21 Arg2:T19\n",
      "R12\tCOREF Arg1:T15 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2010_18_abs.ann\n",
      "T1\tMethod 0 23\tGraph-cuts optimization\n",
      "T2\tTask 40 68\tvision and graphics problems\n",
      "T3\tMethod 130 153\tgraph-cuts optimization\n",
      "T4\tOtherScientificTerm 180 199\tmulti-core machines\n",
      "T5\tMethod 227 243\tserial algorithm\n",
      "T6\tMethod 285 297\tBK algorithm\n",
      "T7\tOtherScientificTerm 391 415\tsynchronization overhead\n",
      "T8\tOtherScientificTerm 448 459\tparallelism\n",
      "T9\tMethod 495 522\tadaptive bottom-up approach\n",
      "T10\tMethod 542 554\tBK algorithm\n",
      "T11\tOtherScientificTerm 589 594\tgraph\n",
      "T12\tOtherScientificTerm 612 648\tregularly-shaped dis-joint subgraphs\n",
      "T13\tGeneric 661 665\tthem\n",
      "T14\tOtherScientificTerm 712 721\tsubgraphs\n",
      "T15\tOtherScientificTerm 755 769\tglobal optimum\n",
      "T16\tGeneric 779 788\talgorithm\n",
      "T17\tOtherScientificTerm 853 862\tsubgraphs\n",
      "T18\tOtherScientificTerm 876 894\tbalanced workloads\n",
      "T19\tOtherScientificTerm 938 946\toverhead\n",
      "T20\tGeneric 1030 1042\tapplications\n",
      "T21\tTask 1051 1076\t2D/3D image segmentations\n",
      "T22\tTask 1081 1099\t3D surface fitting\n",
      "T23\tGeneric 1137 1145\tapproach\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R5\tCOREF Arg1:T10 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R7\tCOREF Arg1:T13 Arg2:T12\n",
      "R8\tCOREF Arg1:T14 Arg2:T13\n",
      "R9\tCOREF Arg1:T16 Arg2:T9\n",
      "R10\tCOREF Arg1:T23 Arg2:T16\n",
      "R11\tHYPONYM-OF Arg1:T21 Arg2:T20\n",
      "R12\tHYPONYM-OF Arg1:T22 Arg2:T20\n",
      "R13\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "R14\tEVALUATE-FOR Arg1:T20 Arg2:T23\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2010_21_abs.ann\n",
      "T1\tMethod 0 31\tConditional Random Field models\n",
      "T2\tTask 66 100\tlow-level computer vision problems\n",
      "T3\tTask 102 111\tInference\n",
      "T4\tGeneric 121 127\tmodels\n",
      "T5\tTask 147 181\tcombinatorial optimization problem\n",
      "T6\tGeneric 188 195\tmethods\n",
      "T7\tMethod 204 214\tgraph cuts\n",
      "T8\tMethod 216 234\tbelief propagation\n",
      "T9\tOtherScientificTerm 293 309\tmodel parameters\n",
      "T10\tGeneric 381 391\tparameters\n",
      "T11\tOtherScientificTerm 415 433\tpartition function\n",
      "T12\tMethod 492 519\tstructured learning methods\n",
      "T13\tGeneric 530 537\tproblem\n",
      "T14\tTask 548 571\tlarge margin estimation\n",
      "T15\tMethod 573 592\tIterative solutions\n",
      "T16\tTask 635 662\tconvex optimization problem\n",
      "T17\tTask 699 716\tinference problem\n",
      "T18\tGeneric 776 794\tstructured methods\n",
      "T19\tMethod 834 873\tlarge margin piece-wise learning method\n",
      "T20\tTask 928 948\toptimization problem\n",
      "T21\tTask 981 995\tconvex problem\n",
      "T22\tGeneric 1077 1083\tmethod\n",
      "R1\tCOREF Arg1:T1 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tPART-OF Arg1:T5 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R5\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R8\tCOREF Arg1:T10 Arg2:T9\n",
      "R9\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R11\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R12\tCOREF Arg1:T16 Arg2:T5\n",
      "R13\tCOREF Arg1:T12 Arg2:T18\n",
      "R14\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R15\tCOREF Arg1:T19 Arg2:T22\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2010_30_abs.ann\n",
      "T1\tGeneric 15 21\tmethod\n",
      "T2\tTask 40 79\tevaluation of object detection cascades\n",
      "T3\tMethod 99 127\tdivide-and-conquer procedure\n",
      "T4\tMethod 135 161\tspace of candidate regions\n",
      "T5\tMethod 179 199\texhaustive procedure\n",
      "T6\tTask 242 260\tcascade evaluation\n",
      "T7\tGeneric 275 281\tmethod\n",
      "T8\tOtherScientificTerm 316 336\tclassifier functions\n",
      "T9\tTask 362 368\tsearch\n",
      "T10\tMethod 428 460\tsubwindow search (ESS) procedure\n",
      "T11\tGeneric 511 517\tmethod\n",
      "T12\tGeneric 545 551\tmethod\n",
      "T13\tTask 594 612\tcascade evaluation\n",
      "T14\tTask 654 687\tbranch-and-bound object detection\n",
      "T15\tOtherScientificTerm 693 720\tnonlinear quality functions\n",
      "T16\tMethod 736 771\tkernel-ized support vector machines\n",
      "T17\tMaterial 792 815\tPASCAL VOC 2006 dataset\n",
      "T18\tGeneric 861 867\tmethod\n",
      "T19\tMethod 889 907\tcascade evaluation\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tCOREF Arg1:T2 Arg2:T6\n",
      "R5\tCOREF Arg1:T7 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R7\tCOMPARE Arg1:T5 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R9\tCOREF Arg1:T11 Arg2:T7\n",
      "R10\tPART-OF Arg1:T10 Arg2:T11\n",
      "R11\tCOREF Arg1:T12 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R13\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R14\tCOREF Arg1:T18 Arg2:T12\n",
      "R15\tEVALUATE-FOR Arg1:T17 Arg2:T18\n",
      "R16\tEVALUATE-FOR Arg1:T17 Arg2:T19\n",
      "R17\tCOMPARE Arg1:T19 Arg2:T18\n",
      "R18\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R19\tHYPONYM-OF Arg1:T16 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2011_10_abs.ann\n",
      "T1\tOtherScientificTerm 0 11\tReflections\n",
      "T2\tOtherScientificTerm 0 30\tReflections in image sequences\n",
      "T3\tMaterial 15 30\timage sequences\n",
      "T4\tMethod 115 142\timage processing techniques\n",
      "T5\tTask 224 241\tmotion estimation\n",
      "T6\tTask 246 264\tobject recognition\n",
      "T7\tGeneric 298 307\ttechnique\n",
      "T8\tTask 312 352\tdetecting reflections in image sequences\n",
      "T9\tOtherScientificTerm 366 385\tmotion trajectories\n",
      "T10\tOtherScientificTerm 389 403\tfeature points\n",
      "T11\tGeneric 405 407\tIt\n",
      "T12\tOtherScientificTerm 415 425\treflection\n",
      "T13\tGeneric 513 521\tdetector\n",
      "T14\tGeneric 555 564\tdetectors\n",
      "T15\tOtherScientificTerm 579 585\tpriors\n",
      "T16\tOtherScientificTerm 596 627\tsparse and dense detection maps\n",
      "T17\tMetric 654 668\tdetection rate\n",
      "T18\tOtherScientificTerm 687 706\tpathological motion\n",
      "T19\tOtherScientificTerm 711 720\tocclusion\n",
      "R1\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T9 Arg2:T7\n",
      "R3\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "R4\tCOREF Arg1:T11 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R6\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R7\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R8\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R9\tCOREF Arg1:T11 Arg2:T13\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2011_11_abs.ann\n",
      "T1\tGeneric 19 27\tapproach\n",
      "T2\tOtherScientificTerm 65 76\tPTZ cameras\n",
      "T3\tTask 105 155\tcamera handoff in wide-area surveillance scenarios\n",
      "T4\tGeneric 172 182\tapproaches\n",
      "T5\tOtherScientificTerm 193 248\tgeometric, appearance, or correlation-based information\n",
      "T6\tOtherScientificTerm 290 304\tstatic cameras\n",
      "T7\tOtherScientificTerm 370 388\twide-area settings\n",
      "T8\tOtherScientificTerm 394 405\tPTZ cameras\n",
      "T9\tGeneric 414 422\tapproach\n",
      "T10\tOtherScientificTerm 428 440\tslave camera\n",
      "T11\tGeneric 631 641\tapproaches\n",
      "T12\tOtherScientificTerm 679 693\tmodel transfer\n",
      "T13\tMethod 738 782\tMultiple Instance Learning (MIL) formulation\n",
      "T14\tOtherScientificTerm 812 873\tlogistic softmax function of covariance-based region features\n",
      "T15\tMethod 883 907\tMAP estimation framework\n",
      "T16\tGeneric 928 936\tapproach\n",
      "T17\tOtherScientificTerm 942 971\tmultiple PTZ camera sequences\n",
      "T18\tOtherScientificTerm 983 1012\toutdoor surveillance settings\n",
      "T19\tGeneric 1040 1067\tstate-of-the-art approaches\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tCOREF Arg1:T1 Arg2:T9\n",
      "R4\tCOMPARE Arg1:T16 Arg2:T19\n",
      "R5\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R6\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R7\tCOREF Arg1:T9 Arg2:T16\n",
      "R8\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R9\tUSED-FOR Arg1:T16 Arg2:T18\n",
      "R10\tCOREF Arg1:T4 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2011_18_abs.ann\n",
      "T1\tGeneric 13 19\tmethod\n",
      "T2\tTask 39 123\trelative pose of two calibrated or uncalibrated non-overlapping surveillance cameras\n",
      "T3\tTask 193 222\tmissing point correspondences\n",
      "T4\tMethod 243 256\tSfM pipelines\n",
      "T5\tGeneric 289 297\tparadigm\n",
      "T6\tOtherScientificTerm 312 329\tnon-linear nature\n",
      "T7\tGeneric 337 344\tproblem\n",
      "T8\tGeneric 362 373\tassumptions\n",
      "T9\tOtherScientificTerm 380 402\tsurveillance scenarios\n",
      "T10\tOtherScientificTerm 467 481\tgravity vector\n",
      "T11\tGeneric 492 503\tassumptions\n",
      "T12\tGeneric 516 523\tproblem\n",
      "T13\tTask 529 557\tQuadratic Eigenvalue Problem\n",
      "T14\tOtherScientificTerm 594 613\tnonlinear monomials\n",
      "T15\tMethod 631 657\tquasi closed-form solution\n",
      "T16\tTask 701 718\tbundle adjustment\n",
      "T17\tMethod 750 770\tclosed form solution\n",
      "T18\tGeneric 796 803\tproblem\n",
      "T19\tTask 815 833\tvideo surveillance\n",
      "T20\tGeneric 905 913\tapproach\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R2\tCOREF Arg1:T5 Arg2:T4\n",
      "R3\tCOREF Arg1:T7 Arg2:T3\n",
      "R4\tFEATURE-OF Arg1:T6 Arg2:T7\n",
      "R5\tCOREF Arg1:T11 Arg2:T8\n",
      "R6\tCOREF Arg1:T12 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R11\tCOREF Arg1:T18 Arg2:T12\n",
      "R12\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R13\tFEATURE-OF Arg1:T19 Arg2:T18\n",
      "R14\tCOREF Arg1:T17 Arg2:T15\n",
      "R15\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R16\tCOREF Arg1:T20 Arg2:T1\n",
      "R17\tCOREF Arg1:T20 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2011_292_abs.ann\n",
      "T1\tMaterial 0 5\tVideo\n",
      "T2\tOtherScientificTerm 29 40\tvisual cues\n",
      "T3\tOtherScientificTerm 49 55\tmotion\n",
      "T4\tOtherScientificTerm 60 70\tappearance\n",
      "T5\tOtherScientificTerm 100 132\tlong-range temporal interactions\n",
      "T6\tGeneric 171 183\tinteractions\n",
      "T7\tMethod 212 251\tintermediate-level video representation\n",
      "T8\tTask 267 278\trecognition\n",
      "T9\tOtherScientificTerm 322 355\tspatio-temporal over-segmentation\n",
      "T10\tOtherScientificTerm 393 410\tobject boundaries\n",
      "T11\tMethod 559 603\tspatio-temporal video segmentation algorithm\n",
      "T12\tOtherScientificTerm 634 656\tlong-range motion cues\n",
      "T13\tOtherScientificTerm 704 728\tclusters of point tracks\n",
      "T14\tMethod 775 805\ttrack clustering cost function\n",
      "T15\tOtherScientificTerm 820 839\tocclusion reasoning\n",
      "T16\tOtherScientificTerm 856 882\tdepth ordering constraints\n",
      "T17\tOtherScientificTerm 895 912\tmotion similarity\n",
      "T18\tGeneric 956 964\tapproach\n",
      "T19\tMaterial 989 1021\tvideo sequences of office scenes\n",
      "T20\tMaterial 1042 1048\tmovies\n",
      "R1\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R3\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R4\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R5\tHYPONYM-OF Arg1:T4 Arg2:T2\n",
      "R6\tCOREF Arg1:T6 Arg2:T5\n",
      "R7\tPART-OF Arg1:T15 Arg2:T14\n",
      "R8\tPART-OF Arg1:T17 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R11\tEVALUATE-FOR Arg1:T19 Arg2:T18\n",
      "R12\tFEATURE-OF Arg1:T16 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2011_293_abs.ann\n",
      "T1\tTask 52 76\tobject recognition tasks\n",
      "T2\tMaterial 109 128\tuncontrolled images\n",
      "T3\tOtherScientificTerm 142 152\tilluminant\n",
      "T4\tGeneric 179 186\tmethods\n",
      "T5\tTask 191 206\tcolor constancy\n",
      "T6\tMethod 219 249\tsurface re-flectance estimates\n",
      "T7\tMaterial 260 279\tuncalibrated images\n",
      "T8\tOtherScientificTerm 327 343\tbackground scene\n",
      "T9\tTask 353 391\trecognition and retrieval applications\n",
      "T10\tTask 607 622\tcolor constancy\n",
      "T11\tTask 641 675\tmulti-view color constancy problem\n",
      "T12\tGeneric 691 697\tmethod\n",
      "T13\tTask 709 753\testimates of underlying surface re-flectance\n",
      "T14\tOtherScientificTerm 789 807\tsurface properties\n",
      "T15\tOtherScientificTerm 816 827\tilluminants\n",
      "T16\tGeneric 860 866\tmethod\n",
      "T17\tOtherScientificTerm 879 900\timage correspondences\n",
      "T18\tMethod 921 941\talignment techniques\n",
      "T19\tOtherScientificTerm 973 1003\tmatching local region features\n",
      "T20\tOtherScientificTerm 1027 1049\tmulti-view constraints\n",
      "T21\tTask 1076 1150\testimates of both scene illuminants and object color (surface reflectance)\n",
      "T22\tMethod 1170 1197\tbaseline single-view method\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R5\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R6\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R7\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R8\tCOMPARE Arg1:T22 Arg2:T20\n",
      "R9\tCOREF Arg1:T5 Arg2:T10\n",
      "R10\tCOREF Arg1:T16 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2011_300_abs.ann\n",
      "T1\tGeneric 14 23\talgorithm\n",
      "T2\tTask 28 70\tcalibrated camera relative pose estimation\n",
      "T3\tOtherScientificTerm 179 196\trelative rotation\n",
      "T4\tOtherScientificTerm 241 261\trelative translation\n",
      "T5\tGeneric 310 319\tframework\n",
      "T6\tGeneric 392 401\talgorithm\n",
      "T7\tMaterial 408 431\tsynthetic and real data\n",
      "T8\tGeneric 457 466\talgorithm\n",
      "T9\tMethod 482 513\thypothesize-and-test frameworks\n",
      "T10\tMethod 522 528\tRANSAC\n",
      "T11\tGeneric 534 542\tapproach\n",
      "T12\tOtherScientificTerm 559 588\turban and indoor environments\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T6 Arg2:T5\n",
      "R3\tCOREF Arg1:T5 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R5\tCOREF Arg1:T8 Arg2:T6\n",
      "R6\tHYPONYM-OF Arg1:T10 Arg2:T9\n",
      "R7\tCOREF Arg1:T11 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R9\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2011_303_abs.ann\n",
      "T1\tOtherScientificTerm 4 25\tco-occurrence pattern\n",
      "T2\tOtherScientificTerm 44 68\tbinary or local features\n",
      "T3\tTask 150 187\tobject, scene, and action recognition\n",
      "T4\tOtherScientificTerm 213 235\tco-occurrence patterns\n",
      "T5\tOtherScientificTerm 278 335\tconjunction (AND) and disjunction (OR) of binary features\n",
      "T6\tTask 364 413\tidentifying discriminative co-occurrence patterns\n",
      "T7\tOtherScientificTerm 376 413\tdiscriminative co-occurrence patterns\n",
      "T8\tMethod 459 477\tdata mining method\n",
      "T9\tOtherScientificTerm 506 535\toptimal co-occurrence pattern\n",
      "T10\tOtherScientificTerm 541 564\tminimum empirical error\n",
      "T11\tMaterial 578 600\tnoisy training dataset\n",
      "T12\tGeneric 607 623\tmining procedure\n",
      "T13\tOtherScientificTerm 627 646\tAND and OR patterns\n",
      "T14\tMethod 672 680\tboosting\n",
      "T15\tMetric 701 723\tgeneralization ability\n",
      "T16\tMethod 746 769\tboosting decision trees\n",
      "T17\tMethod 774 798\tboosting decision stumps\n",
      "T18\tTask 829 870\tobject, scene, and action cat-egorization\n",
      "T19\tOtherScientificTerm 913 951\tdis-criminative co-occurrence patterns\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R2\tCOREF Arg1:T4 Arg2:T1\n",
      "R3\tCOREF Arg1:T5 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T8\n",
      "R5\tCOREF Arg1:T13 Arg2:T5\n",
      "R6\tPART-OF Arg1:T13 Arg2:T14\n",
      "R7\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R8\tCOMPARE Arg1:T14 Arg2:T16\n",
      "R9\tCOMPARE Arg1:T14 Arg2:T17\n",
      "R10\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R11\tCOREF Arg1:T3 Arg2:T18\n",
      "R12\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "R13\tCOREF Arg1:T19 Arg2:T7\n",
      "R14\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R15\tEVALUATE-FOR Arg1:T15 Arg2:T17\n",
      "R16\tCOREF Arg1:T8 Arg2:T12\n",
      "R17\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R18\tPART-OF Arg1:T2 Arg2:T1\n",
      "R19\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R20\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2012_10_abs.ann\n",
      "T1\tTask 0 39\tAutomated facial expression recognition\n",
      "T2\tGeneric 100 114\tExisting works\n",
      "T3\tOtherScientificTerm 161 179\ttemporal evolution\n",
      "T4\tOtherScientificTerm 187 228\tintensity of the observed facial displays\n",
      "T5\tGeneric 230 234\tThey\n",
      "T6\tMaterial 262 325\tmultidimensional (multi-class) continuous facial behaviour data\n",
      "T7\tMethod 327 345\tbinary classifiers\n",
      "T8\tOtherScientificTerm 419 475\tintrinsic topology of multidimensional continuous facial\n",
      "T9\tOtherScientificTerm 511 528\tordinal man-ifold\n",
      "T10\tGeneric 535 543\ttopology\n",
      "T11\tMethod 574 632\tHidden Conditional Ordinal Random Field (H-CORF) framework\n",
      "T12\tTask 637 663\tdynamic ordinal regression\n",
      "T13\tOtherScientificTerm 680 697\tH-CORF parameters\n",
      "T14\tOtherScientificTerm 712 728\tordinal manifold\n",
      "T15\tGeneric 744 749\tmodel\n",
      "T16\tTask 758 790\tsimultaneous dynamic recognition\n",
      "T17\tTask 795 837\tintensity estimation of facial expressions\n",
      "T18\tMethod 890 909\tthe proposed method\n",
      "T19\tMaterial 973 1003\tspontaneous facial affect data\n",
      "R1\tCONJUNCTION Arg1:T4 Arg2:T3\n",
      "R2\tCOREF Arg1:T5 Arg2:T2\n",
      "R3\tCOREF Arg1:T18 Arg2:T15\n",
      "R4\tCOREF Arg1:T10 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R6\tPART-OF Arg1:T10 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T17\n",
      "R10\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R11\tEVALUATE-FOR Arg1:T19 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2012_11_abs.ann\n",
      "T1\tMethod 13 44\tunified variational formulation\n",
      "T2\tTask 49 89\tjoint motion estimation and segmentation\n",
      "T3\tMethod 95 122\texplicit occlusion handling\n",
      "T4\tMethod 142 186\tmulti-label representation of the flow field\n",
      "T5\tTask 222 261\tparametric representation of the motion\n",
      "T6\tMethod 272 290\tconvex formulation\n",
      "T7\tMethod 298 321\tmulti-label Potts model\n",
      "T8\tMetric 357 392\tasymmetric map-uniqueness criterion\n",
      "T9\tGeneric 420 431\tformulation\n",
      "T10\tOtherScientificTerm 444 462\tconvex constraints\n",
      "T11\tMethod 464 491\tExplicit occlusion handling\n",
      "T12\tOtherScientificTerm 535 549\tregularization\n",
      "T13\tOtherScientificTerm 554 564\tocclusions\n",
      "T14\tOtherScientificTerm 583 600\tobject boundaries\n",
      "T15\tMethod 661 682\tprimal-dual algorithm\n",
      "T16\tOtherScientificTerm 721 736\tmotion segments\n",
      "T17\tTask 767 796\tclassical motion segmentation\n",
      "T18\tTask 801 813\toptical flow\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T6 Arg2:T9\n",
      "R4\tPART-OF Arg1:T8 Arg2:T9\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R7\tCOREF Arg1:T3 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2012_18_abs.ann\n",
      "T1\tGeneric 19 28\ttechnique\n",
      "T2\tMethod 36 66\tbispectral photo-metric stereo\n",
      "T3\tOtherScientificTerm 95 107\tfluorescence\n",
      "T4\tTask 112 132\tshape reconstruction\n",
      "T5\tOtherScientificTerm 134 146\tFluorescence\n",
      "T6\tOtherScientificTerm 201 213\tnatural gems\n",
      "T7\tOtherScientificTerm 229 245\tfluorescent dyes\n",
      "T8\tOtherScientificTerm 304 316\tfluorescence\n",
      "T9\tOtherScientificTerm 354 375\tfluorescent materials\n",
      "T10\tMetric 466 476\tcomplexity\n",
      "T11\tMethod 484 500\temission process\n",
      "T12\tOtherScientificTerm 502 515\tfluo-rescence\n",
      "T13\tGeneric 547 557\talgorithms\n",
      "T14\tTask 561 576\tcomputer vision\n",
      "T15\tTask 581 597\timage processing\n",
      "T16\tOtherScientificTerm 645 655\tsimilarity\n",
      "T17\tOtherScientificTerm 664 676\tfluorescence\n",
      "T18\tOtherScientificTerm 687 705\tdiffuse reflection\n",
      "T19\tOtherScientificTerm 715 727\tfluorescence\n",
      "T20\tOtherScientificTerm 804 847\tfluorescence's wavelength-shifting property\n",
      "T21\tOtherScientificTerm 875 880\tshape\n",
      "T22\tMethod 906 925\tphotomet-ric stereo\n",
      "T23\tMaterial 929 949\temission-only images\n",
      "T24\tOtherScientificTerm 973 992\tspecular reflection\n",
      "T25\tMethod 1035 1060\tfluorescence-based method\n",
      "T26\tGeneric 1075 1082\tmethods\n",
      "T27\tOtherScientificTerm 1092 1102\treflection\n",
      "R1\tCOREF Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "R4\tEVALUATE-FOR Arg1:T10 Arg2:T11\n",
      "R5\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R8\tCOREF Arg1:T22 Arg2:T2\n",
      "R9\tUSED-FOR Arg1:T23 Arg2:T22\n",
      "R10\tCOMPARE Arg1:T26 Arg2:T25\n",
      "R11\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R12\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2013_10_abs.ann\n",
      "T1\tGeneric 19 28\talgorithm\n",
      "T2\tTask 54 100\t3D geometric structure of outdoor video scenes\n",
      "T3\tMethod 113 147\tspatio-temporal video segmentation\n",
      "T4\tOtherScientificTerm 164 177\tdynamic scene\n",
      "T5\tOtherScientificTerm 203 220\tgeometric classes\n",
      "T6\tMethod 251 269\tregion-classifiers\n",
      "T7\tOtherScientificTerm 290 320\tappearance and motion features\n",
      "T8\tOtherScientificTerm 409 438\tsegmentation hierarchy levels\n",
      "T9\tOtherScientificTerm 477 497\tgranularity a priori\n",
      "T10\tGeneric 527 534\tdataset\n",
      "T11\tOtherScientificTerm 538 564\tgeometric context of video\n",
      "T12\tGeneric 581 587\tmethod\n",
      "T13\tOtherScientificTerm 625 649\tannotated outdoor videos\n",
      "T14\tGeneric 704 711\tdataset\n",
      "T15\tMethod 726 760\tsemi-supervised learning framework\n",
      "T16\tMaterial 783 795\tlabeled data\n",
      "T17\tOtherScientificTerm 801 828\thigh confidence predictions\n",
      "T18\tOtherScientificTerm 843 857\tunlabeled data\n",
      "T19\tGeneric 863 869\tsystem\n",
      "T20\tOtherScientificTerm 905 931\tgeometric context of video\n",
      "T21\tMetric 946 954\taccuracy\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tPART-OF Arg1:T13 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R7\tEVALUATE-FOR Arg1:T10 Arg2:T12\n",
      "R8\tCOREF Arg1:T12 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R10\tUSED-FOR Arg1:T17 Arg2:T15\n",
      "R11\tEVALUATE-FOR Arg1:T21 Arg2:T19\n",
      "R12\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R13\tPART-OF Arg1:T5 Arg2:T4\n",
      "R14\tCOREF Arg1:T12 Arg2:T19\n",
      "R15\tFEATURE-OF Arg1:T11 Arg2:T10\n",
      "R16\tCOREF Arg1:T10 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2014_10_abs.ann\n",
      "T1\tMethod 14 48\timage set classification algorithm\n",
      "T2\tMethod 58 81\tunsupervised clustering\n",
      "T3\tMaterial 85 126\tlabeled training and unla-beled test data\n",
      "T4\tOtherScientificTerm 161 179\tstopping criterion\n",
      "T5\tOtherScientificTerm 185 209\tprobability distribution\n",
      "T6\tOtherScientificTerm 240 248\tclusters\n",
      "T7\tMetric 274 302\tset based similarity measure\n",
      "T8\tMethod 331 377\titerative sparse spectral clustering algorithm\n",
      "T9\tOtherScientificTerm 400 416\tproximity matrix\n",
      "T10\tOtherScientificTerm 467 491\tlocal subspace structure\n",
      "T11\tOtherScientificTerm 493 509\tInitial clusters\n",
      "T12\tOtherScientificTerm 522 543\tglobal data structure\n",
      "T13\tOtherScientificTerm 548 562\tfiner clusters\n",
      "T14\tOtherScientificTerm 595 619\tsubtle class differences\n",
      "T15\tOtherScientificTerm 639 651\tglobal scale\n",
      "T16\tMaterial 653 663\tImage sets\n",
      "T17\tMethod 704 727\tGrass-mannian manifolds\n",
      "T18\tOtherScientificTerm 763 778\tEuclidean space\n",
      "T19\tMethod 797 826\tspectral clustering algorithm\n",
      "T20\tMethod 857 875\teigenvector solver\n",
      "T21\tMetric 903 921\tcomputational cost\n",
      "T22\tMethod 925 944\tspectral clustering\n",
      "T23\tMetric 981 999\tclustering quality\n",
      "T24\tMetric 1010 1032\tclassification results\n",
      "T25\tMaterial 1063 1071\tdatasets\n",
      "T26\tGeneric 1143 1152\talgorithm\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R4\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R5\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R6\tUSED-FOR Arg1:T19 Arg2:T18\n",
      "R7\tEVALUATE-FOR Arg1:T21 Arg2:T22\n",
      "R8\tEVALUATE-FOR Arg1:T23 Arg2:T22\n",
      "R9\tUSED-FOR Arg1:T20 Arg2:T22\n",
      "R10\tCOREF Arg1:T26 Arg2:T1\n",
      "R11\tCOREF Arg1:T19 Arg2:T8\n",
      "R12\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R13\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R14\tEVALUATE-FOR Arg1:T24 Arg2:T22\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2014_11_abs.ann\n",
      "T1\tTask 38 58\tpoint cloud matching\n",
      "T2\tTask 64 86\tshape matching problem\n",
      "T3\tOtherScientificTerm 121 133\tpoint clouds\n",
      "T4\tMethod 141 161\tshape representation\n",
      "T5\tMethod 173 224\tSchrÃ¶dinger distance transform (SDT) representation\n",
      "T6\tOtherScientificTerm 256 283\tstatic SchrÃ¶dinger equation\n",
      "T7\tOtherScientificTerm 313 344\tstatic Hamilton-Jacobi equation\n",
      "T8\tMethod 366 384\tSDT representation\n",
      "T9\tOtherScientificTerm 391 410\tanalytic expression\n",
      "T10\tOtherScientificTerm 429 459\ttheoretical physics literature\n",
      "T11\tOtherScientificTerm 487 499\tunit L2 norm\n",
      "T12\tGeneric 507 509\tit\n",
      "T13\tOtherScientificTerm 512 531\tsquare-root density\n",
      "T14\tOtherScientificTerm 571 590\tunit Hilbert sphere\n",
      "T15\tOtherScientificTerm 598 616\tintrinsic geometry\n",
      "T16\tMetric 637 654\tFisher-Rao metric\n",
      "T17\tGeneric 658 672\tnatural metric\n",
      "T18\tOtherScientificTerm 681 699\tspace of densities\n",
      "T19\tOtherScientificTerm 709 729\tanalytic expressions\n",
      "T20\tOtherScientificTerm 738 755\tgeodesic distance\n",
      "T21\tGeneric 779 785\tsphere\n",
      "T22\tMethod 824 844\tRiemannian framework\n",
      "T23\tTask 867 887\tpoint cloud matching\n",
      "T24\tMethod 909 927\tmatching algorithm\n",
      "T25\tTask 937 955\tpoint set matching\n",
      "T26\tOtherScientificTerm 962 997\trigid and non-rigid transformations\n",
      "T27\tGeneric 1006 1015\tframework\n",
      "T28\tGeneric 1034 1049\ttransformations\n",
      "T29\tMethod 1065 1098\tnonlinear optimization techniques\n",
      "T30\tMethod 1144 1153\talgorithm\n",
      "T31\tMethod 1154 1165\tdubbed SDTM\n",
      "T32\tMaterial 1185 1217\tsynthetic and real data examples\n",
      "T33\tGeneric 1254 1281\tstate-of-the-art techniques\n",
      "T34\tGeneric 1313 1322\talgorithm\n",
      "T35\tMethod 1352 1385\tpoint set registration algorithms\n",
      "T36\tMetric 1394 1414\tquantitative metrics\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tHYPONYM-OF Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R4\tCOREF Arg1:T8 Arg2:T5\n",
      "R5\tHYPONYM-OF Arg1:T8 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R7\tCOREF Arg1:T14 Arg2:T21\n",
      "R8\tCOREF Arg1:T1 Arg2:T23\n",
      "R9\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R10\tCOREF Arg1:T22 Arg2:T27\n",
      "R11\tCOREF Arg1:T26 Arg2:T28\n",
      "R12\tUSED-FOR Arg1:T29 Arg2:T28\n",
      "R13\tUSED-FOR Arg1:T26 Arg2:T25\n",
      "R14\tUSED-FOR Arg1:T27 Arg2:T25\n",
      "R15\tCOREF Arg1:T31 Arg2:T30\n",
      "R16\tCOMPARE Arg1:T30 Arg2:T33\n",
      "R17\tEVALUATE-FOR Arg1:T36 Arg2:T35\n",
      "R18\tCOREF Arg1:T8 Arg2:T12\n",
      "R19\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R20\tPART-OF Arg1:T11 Arg2:T8\n",
      "R21\tCOREF Arg1:T16 Arg2:T17\n",
      "R22\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R23\tCOMPARE Arg1:T34 Arg2:T35\n",
      "R24\tCOREF Arg1:T34 Arg2:T30\n",
      "R25\tEVALUATE-FOR Arg1:T36 Arg2:T34\n",
      "R26\tFEATURE-OF Arg1:T15 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2014_18_abs.ann\n",
      "T1\tMaterial 37 71\tobject category detection datasets\n",
      "T2\tTask 84 113\tper-object 3D reconstructions\n",
      "T3\tMethod 148 188\tground truth figure-ground segmentations\n",
      "T4\tMethod 208 228\tkeypoint annotations\n",
      "T5\tGeneric 243 252\talgorithm\n",
      "T6\tOtherScientificTerm 269 285\tcamera viewpoint\n",
      "T7\tOtherScientificTerm 292 319\trigid structure-from-motion\n",
      "T8\tOtherScientificTerm 339 352\tobject shapes\n",
      "T9\tOtherScientificTerm 372 393\tvisual hull proposals\n",
      "T10\tOtherScientificTerm 404 451\tloose within-class shape similarity assumptions\n",
      "T11\tMethod 457 485\tvisual hull sampling process\n",
      "T12\tOtherScientificTerm 520 535\tprojection cone\n",
      "T13\tGeneric 662 668\tmethod\n",
      "T14\tTask 699 728\tper-object 3D reconstructions\n",
      "T15\tMaterial 769 803\tobject-category detection datasets\n",
      "T16\tMaterial 805 815\tPASCAL VOC\n",
      "T17\tMethod 859 911\tgeometry-oriented model-based recognition approaches\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R8\tHYPONYM-OF Arg1:T16 Arg2:T15\n",
      "R9\tCOREF Arg1:T13 Arg2:T5\n",
      "R10\tCOREF Arg1:T2 Arg2:T14\n",
      "R11\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R12\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R13\tUSED-FOR Arg1:T4 Arg2:T2\n",
      "R14\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R15\tCOREF Arg1:T15 Arg2:T1\n",
      "R16\tCOREF Arg1:T11 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2014_21_abs.ann\n",
      "T1\tGeneric 33 52\tautonomous pipeline\n",
      "T2\tMethod 64 114\tpersonalized parametric model (pose-driven avatar)\n",
      "T3\tOtherScientificTerm 123 142\tsingle depth sensor\n",
      "T4\tGeneric 148 154\tmethod\n",
      "T5\tMethod 298 325\ttemplate fitting techniques\n",
      "T6\tOtherScientificTerm 341 355\thuman template\n",
      "T7\tOtherScientificTerm 400 430\tglobal consistency constraints\n",
      "T8\tMethod 458 475\twatertight models\n",
      "T9\tMethod 517 533\tparametric model\n",
      "T10\tMethod 562 574\tSCAPE method\n",
      "T11\tMethod 585 601\tparametric model\n",
      "T12\tGeneric 612 614\tit\n",
      "T13\tOtherScientificTerm 633 651\tanim-itable avatar\n",
      "T14\tMethod 687 704\tdynamic 3D models\n",
      "T15\tMaterial 710 734\tsingle-view depth videos\n",
      "T16\tGeneric 794 800\tsystem\n",
      "T17\tMethod 812 826\tdynamic models\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T4 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R7\tCOREF Arg1:T9 Arg2:T11\n",
      "R8\tCOREF Arg1:T11 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R11\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R13\tCOREF Arg1:T4 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2015_300_abs.ann\n",
      "T1\tTask 26 57\testimating location information\n",
      "T2\tMaterial 64 69\timage\n",
      "T3\tMethod 92 125\tautomated representation learning\n",
      "T4\tMethod 139 174\thierarchical sparse coding approach\n",
      "T5\tOtherScientificTerm 187 195\tfeatures\n",
      "T6\tGeneric 262 264\tit\n",
      "T7\tOtherScientificTerm 272 287\tgeometric prior\n",
      "T8\tOtherScientificTerm 329 351\timage appearance space\n",
      "T9\tOtherScientificTerm 376 399\tlocation grouping space\n",
      "T10\tOtherScientificTerm 420 451\tparallel transport on manifolds\n",
      "T11\tGeneric 473 481\tapproach\n",
      "T12\tOtherScientificTerm 517 546\theterogeneous data modalities\n",
      "T13\tOtherScientificTerm 555 563\tgeo-tags\n",
      "T14\tOtherScientificTerm 568 574\tvideos\n",
      "T15\tTask 665 687\ttransferring knowledge\n",
      "T16\tTask 734 750\tgrouping of data\n",
      "T17\tMethod 789 797\tapproach\n",
      "T18\tGeneric 818 826\tdatasets\n",
      "T19\tMaterial 835 841\tim2gps\n",
      "T20\tMaterial 843 856\tSan Francisco\n",
      "T21\tMaterial 861 874\tMediaEval2010\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T6 Arg2:T4\n",
      "R4\tCOREF Arg1:T11 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R7\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R8\tHYPONYM-OF Arg1:T13 Arg2:T12\n",
      "R9\tHYPONYM-OF Arg1:T14 Arg2:T12\n",
      "R10\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R12\tCOREF Arg1:T17 Arg2:T11\n",
      "R13\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R14\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R15\tHYPONYM-OF Arg1:T19 Arg2:T18\n",
      "R16\tHYPONYM-OF Arg1:T20 Arg2:T18\n",
      "R17\tHYPONYM-OF Arg1:T21 Arg2:T18\n",
      "R18\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2015_303_abs.ann\n",
      "T1\tOtherScientificTerm 38 62\tgeneric action proposals\n",
      "T2\tMaterial 66 86\tunconstrained videos\n",
      "T3\tOtherScientificTerm 93 108\taction proposal\n",
      "T4\tOtherScientificTerm 126 167\ttemporal series of spatial bounding boxes\n",
      "T5\tOtherScientificTerm 177 203\tspatio-temporal video tube\n",
      "T6\tOtherScientificTerm 246 258\thuman action\n",
      "T7\tOtherScientificTerm 334 360\tappearance and motion cues\n",
      "T8\tMetric 389 400\tac-tionness\n",
      "T9\tMaterial 408 419\tvideo tubes\n",
      "T10\tMetric 471 488\tactionness scores\n",
      "T11\tTask 494 520\taction proposal generation\n",
      "T12\tTask 540 568\tmaximum set coverage problem\n",
      "T13\tMethod 577 590\tgreedy search\n",
      "T14\tOtherScientificTerm 623 639\taction proposals\n",
      "T15\tMetric 670 686\tactionness score\n",
      "T16\tMethod 711 737\taction proposal approaches\n",
      "T17\tOtherScientificTerm 743 759\taction proposals\n",
      "T18\tMethod 775 793\tvideo segmentation\n",
      "T19\tGeneric 876 884\tdatasets\n",
      "T20\tMaterial 886 891\tMSRII\n",
      "T21\tMaterial 896 903\tUCF 101\n",
      "T22\tOtherScientificTerm 946 962\taction proposals\n",
      "T23\tTask 997 1024\taction detection and search\n",
      "R1\tHYPONYM-OF Arg1:T5 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tEVALUATE-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R7\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R8\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R9\tHYPONYM-OF Arg1:T20 Arg2:T19\n",
      "R10\tHYPONYM-OF Arg1:T21 Arg2:T19\n",
      "R11\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R12\tEVALUATE-FOR Arg1:T19 Arg2:T22\n",
      "R13\tEVALUATE-FOR Arg1:T23 Arg2:T22\n",
      "R14\tCOREF Arg1:T22 Arg2:T17\n",
      "R15\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2016_15_abs.ann\n",
      "T1\tGeneric 22 28\tmethod\n",
      "T2\tOtherScientificTerm 42 78\tjoint embed-dings of images and text\n",
      "T3\tMethod 87 112\ttwo-branch neural network\n",
      "T4\tOtherScientificTerm 118 155\tmultiple layers of linear projections\n",
      "T5\tOtherScientificTerm 168 182\tnonlinearities\n",
      "T6\tGeneric 188 195\tnetwork\n",
      "T7\tOtherScientificTerm 215 237\tlarge-margin objective\n",
      "T8\tOtherScientificTerm 252 282\tcross-view ranking constraints\n",
      "T9\tOtherScientificTerm 288 347\twithin-view neighborhood structure preservation constraints\n",
      "T10\tOtherScientificTerm 360 386\tmetric learning literature\n",
      "T11\tGeneric 424 432\tapproach\n",
      "T12\tMetric 467 475\taccuracy\n",
      "T13\tTask 480 521\timage-to-text and text-to-image retrieval\n",
      "T14\tGeneric 527 533\tmethod\n",
      "T15\tMaterial 579 623\tFlickr30K and MSCOCO image-sentence datasets\n",
      "T16\tTask 661 681\tphrase lo-calization\n",
      "T17\tMaterial 689 715\tFlickr30K Entities dataset\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tPART-OF Arg1:T4 Arg2:T3\n",
      "R4\tPART-OF Arg1:T5 Arg2:T3\n",
      "R5\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R6\tCOREF Arg1:T6 Arg2:T3\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R8\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R9\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "R10\tFEATURE-OF Arg1:T9 Arg2:T7\n",
      "R11\tCOREF Arg1:T1 Arg2:T11\n",
      "R12\tEVALUATE-FOR Arg1:T12 Arg2:T11\n",
      "R13\tEVALUATE-FOR Arg1:T13 Arg2:T11\n",
      "R14\tCOREF Arg1:T14 Arg2:T11\n",
      "R15\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R16\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R17\tEVALUATE-FOR Arg1:T16 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2016_405_abs.ann\n",
      "T1\tMaterial 30 43\tanimated GIFs\n",
      "T2\tMaterial 47 59\tsocial media\n",
      "T3\tMaterial 103 117\trich meta-data\n",
      "T4\tTask 142 168\tanimated GIF understanding\n",
      "T5\tGeneric 189 196\tdataset\n",
      "T6\tMaterial 198 215\tTumblr GIF (TGIF)\n",
      "T7\tMaterial 227 240\tanimated GIFs\n",
      "T8\tMaterial 262 291\tnatural language descriptions\n",
      "T9\tMethod 305 318\tcrowdsourcing\n",
      "T10\tTask 377 411\timage sequence description systems\n",
      "T11\tMaterial 443 472\tnatural language descriptions\n",
      "T12\tMaterial 477 490\tanimated GIFs\n",
      "T13\tMaterial 494 505\tvideo clips\n",
      "T14\tMethod 572 588\tquality controls\n",
      "T15\tMaterial 601 621\tfree-form text input\n",
      "T16\tMaterial 696 710\tvisual content\n",
      "T17\tMaterial 715 744\tnatural language descriptions\n",
      "T18\tGeneric 752 759\tdataset\n",
      "T19\tGeneric 768 770\tit\n",
      "T20\tTask 798 828\tvisual content captioning task\n",
      "T21\tOtherScientificTerm 851 871\tstatistical analyses\n",
      "T22\tGeneric 887 894\tdataset\n",
      "T23\tMaterial 907 943\timage and video description datasets\n",
      "T24\tTask 986 1015\tanimated GIF description task\n",
      "T25\tGeneric 1029 1054\trepresentative techniques\n",
      "T26\tMethod 1056 1072\tnearest neighbor\n",
      "T27\tMethod 1074 1105\tstatistical machine translation\n",
      "T28\tMethod 1112 1137\trecurrent neural networks\n",
      "T29\tMaterial 1188 1220\tanimated GIF description dataset\n",
      "T30\tTask 1240 1267\tautomatic movie description\n",
      "R1\tCOREF Arg1:T6 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R4\tPART-OF Arg1:T17 Arg2:T18\n",
      "R5\tPART-OF Arg1:T16 Arg2:T18\n",
      "R6\tCOREF Arg1:T18 Arg2:T5\n",
      "R7\tCOREF Arg1:T22 Arg2:T18\n",
      "R8\tCOREF Arg1:T29 Arg2:T22\n",
      "R9\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R10\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R11\tCONJUNCTION Arg1:T8 Arg2:T7\n",
      "R12\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R13\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R14\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R15\tCOREF Arg1:T18 Arg2:T19\n",
      "R16\tEVALUATE-FOR Arg1:T19 Arg2:T20\n",
      "R17\tCOMPARE Arg1:T22 Arg2:T23\n",
      "R18\tCONJUNCTION Arg1:T26 Arg2:T27\n",
      "R19\tCONJUNCTION Arg1:T27 Arg2:T28\n",
      "R20\tHYPONYM-OF Arg1:T26 Arg2:T25\n",
      "R21\tHYPONYM-OF Arg1:T27 Arg2:T25\n",
      "R22\tHYPONYM-OF Arg1:T28 Arg2:T25\n",
      "R23\tUSED-FOR Arg1:T25 Arg2:T24\n",
      "R24\tUSED-FOR Arg1:T29 Arg2:T30\n",
      "R25\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2016_406_abs.ann\n",
      "T1\tTask 0 14\tImage matching\n",
      "T2\tTask 43 58\tComputer Vision\n",
      "T3\tTask 78 100\tfeature-based matching\n",
      "T4\tMethod 102 106\tSIFT\n",
      "T5\tOtherScientificTerm 189 209\tultra-wide baselines\n",
      "T6\tMaterial 229 242\taerial images\n",
      "T7\tOtherScientificTerm 258 280\tlarge camera rotations\n",
      "T8\tOtherScientificTerm 286 306\tappearance variation\n",
      "T9\tMethod 332 336\tSIFT\n",
      "T10\tMethod 341 347\tRANSAC\n",
      "T11\tMethod 376 417\tdata-driven, deep learning-based approach\n",
      "T12\tOtherScientificTerm 433 453\tlocal correspondence\n",
      "T13\tGeneric 469 476\tproblem\n",
      "T14\tTask 482 501\tclassification task\n",
      "T15\tOtherScientificTerm 537 558\tlocal correspondences\n",
      "T16\tMethod 607 626\tattention mechanism\n",
      "T17\tGeneric 727 733\tmodels\n",
      "T18\tMaterial 739 770\tdataset of urban aerial imagery\n",
      "T19\tGeneric 864 871\tproblem\n",
      "T20\tMethod 878 889\thuman study\n",
      "T21\tMaterial 895 934\tannotations from Amazon Mechanical Turk\n",
      "T22\tGeneric 960 966\tmodels\n",
      "T23\tGeneric 982 998\tstate-of-the-art\n",
      "T24\tTask 1002 1030\tultra-wide baseline matching\n",
      "T25\tMetric 1044 1058\thuman accuracy\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R3\tCOREF Arg1:T22 Arg2:T17\n",
      "R4\tCOMPARE Arg1:T22 Arg2:T25\n",
      "R5\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R6\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R7\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R9\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R10\tCOREF Arg1:T4 Arg2:T9\n",
      "R11\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R12\tCOMPARE Arg1:T22 Arg2:T23\n",
      "R13\tEVALUATE-FOR Arg1:T24 Arg2:T23\n",
      "R14\tEVALUATE-FOR Arg1:T24 Arg2:T22\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2016_413_abs.ann\n",
      "T1\tMethod 0 27\tLearned confidence measures\n",
      "T2\tTask 59 74\toutlier removal\n",
      "T3\tTask 79 98\tquality improvement\n",
      "T4\tTask 102 115\tstereo vision\n",
      "T5\tGeneric 206 210\ttask\n",
      "T6\tOtherScientificTerm 225 243\tmanual interaction\n",
      "T7\tOtherScientificTerm 245 267\tactive sensing devices\n",
      "T8\tOtherScientificTerm 275 291\tsynthetic scenes\n",
      "T9\tGeneric 310 317\tproblem\n",
      "T10\tMaterial 422 435\tstereo images\n",
      "T11\tGeneric 466 474\tapproach\n",
      "T12\tOtherScientificTerm 495 506\tview points\n",
      "T13\tOtherScientificTerm 568 587\tmultiple depth maps\n",
      "T14\tMethod 612 628\tstereo algorithm\n",
      "T15\tGeneric 779 787\tapproach\n",
      "T16\tMethod 825 852\tlearned confidence measures\n",
      "T17\tMaterial 860 877\tKITTI2012 dataset\n",
      "T18\tGeneric 897 901\tthem\n",
      "T19\tMaterial 922 959\tautomatically generated training data\n",
      "T20\tMaterial 992 1015\tlaser ground truth data\n",
      "R1\tPART-OF Arg1:T3 Arg2:T4\n",
      "R2\tPART-OF Arg1:T2 Arg2:T4\n",
      "R3\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R6\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R7\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R9\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T5\n",
      "R11\tCOREF Arg1:T9 Arg2:T5\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R13\tCOREF Arg1:T14 Arg2:T11\n",
      "R14\tCOREF Arg1:T15 Arg2:T11\n",
      "R15\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R16\tEVALUATE-FOR Arg1:T17 Arg2:T16\n",
      "R17\tCOMPARE Arg1:T20 Arg2:T19\n",
      "R18\tCOREF Arg1:T18 Arg2:T16\n",
      "R19\tUSED-FOR Arg1:T19 Arg2:T18\n",
      "R20\tCOREF Arg1:T16 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\CVPR_2016_416_abs.ann\n",
      "T1\tTask 30 78\tfine-grained sketch-based image retrieval (SBIR)\n",
      "T2\tOtherScientificTerm 86 110\tfree-hand human sketches\n",
      "T3\tTask 142 176\tinstance-level retrieval of images\n",
      "T4\tOtherScientificTerm 228 246\tvisual comparisons\n",
      "T5\tOtherScientificTerm 317 344\tfree-hand (finger) sketches\n",
      "T6\tTask 373 394\tfine-grained matching\n",
      "T7\tMaterial 430 474\tannotated cross-domain sketch-photo datasets\n",
      "T8\tMethod 543 570\tmachine learning techniques\n",
      "T9\tTask 715 755\tsketch-based image retrieval application\n",
      "T10\tOtherScientificTerm 845 885\tfine-grained triplet ranking annotations\n",
      "T11\tMethod 905 931\tdeep triplet-ranking model\n",
      "T12\tTask 936 955\tinstance-level SBIR\n",
      "T13\tMethod 969 986\tdata augmentation\n",
      "T14\tMethod 991 1019\tstaged pre-training strategy\n",
      "T15\tMaterial 1046 1085\tinsufficient fine-grained training data\n",
      "T16\tOtherScientificTerm 1184 1200\tdata sufficiency\n",
      "T17\tOtherScientificTerm 1205 1227\tover-fitting avoidance\n",
      "T18\tMethod 1242 1255\tdeep networks\n",
      "T19\tTask 1260 1299\tfine-grained cross-domain ranking tasks\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R4\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R5\tUSED-FOR Arg1:T13 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T14 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T15\n",
      "R8\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R9\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E06-1004.ann\n",
      "T1\tTask 84 121\tStatistical Machine Translation (SMT)\n",
      "T2\tMethod 242 256\tSMT algorithms\n",
      "T3\tMetric 332 356\tcomputational complexity\n",
      "T4\tGeneric 385 393\tproblems\n",
      "T5\tTask 398 401\tSMT\n",
      "T6\tMetric 462 486\tcomputational complexity\n",
      "T7\tGeneric 497 505\tproblems\n",
      "T8\tMethod 528 542\tIBM Models 1-2\n",
      "T9\tGeneric 589 601\tcomputations\n",
      "T10\tGeneric 642 648\tmodels\n",
      "T11\tMethod 705 729\tpolynomial time solution\n",
      "T12\tGeneric 749 762\thard problems\n",
      "T13\tMethod 857 887\tpolynomial time approximations\n",
      "T14\tGeneric 899 911\tcomputations\n",
      "T15\tMetric 966 976\tcomplexity\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R2\tCOREF Arg1:T7 Arg2:T4\n",
      "R3\tEVALUATE-FOR Arg1:T6 Arg2:T7\n",
      "R4\tCOMPARE Arg1:T8 Arg2:T10\n",
      "R5\tCOREF Arg1:T12 Arg2:T7\n",
      "R6\tCOREF Arg1:T5 Arg2:T1\n",
      "R7\tCOREF Arg1:T14 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R9\tEVALUATE-FOR Arg1:T3 Arg2:T4\n",
      "R10\tPART-OF Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E06-1018.ann\n",
      "T1\tGeneric 23 31\tsolution\n",
      "T2\tTask 35 89\tautomatic and  unsupervised word sense induction (WSI)\n",
      "T3\tGeneric 106 108\tIt\n",
      "T4\tMethod 145 182\tone sense per collocation observation\n",
      "T5\tGeneric 235 237\tit\n",
      "T6\tMethod 248 281\tclustering of word co-occurrences\n",
      "T7\tGeneric 290 298\tapproach\n",
      "T8\tGeneric 318 328\tapproaches\n",
      "T9\tTask 333 336\tWSI\n",
      "T10\tGeneric 346 348\tit\n",
      "T11\tMethod 377 414\tone sense per collocation observation\n",
      "T12\tOtherScientificTerm 425 443\ttriplets of  words\n",
      "T13\tMethod 487 514\ttwo-step clustering process\n",
      "T14\tOtherScientificTerm 523 546\tsentence co-occurrences\n",
      "T15\tOtherScientificTerm 552 560\tfeatures\n",
      "T16\tMetric 626 671\tautomatic and  unsupervised evaluation method\n",
      "T17\tMethod 725 761\tword sense disambiguation algorithms\n",
      "T18\tMethod 885 917\tautomatic parameter optimization\n",
      "T19\tMethod 927 940\tWSI algorithm\n",
      "R1\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T5 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R5\tCOMPARE Arg1:T7 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R8\tCOREF Arg1:T10 Arg2:T7\n",
      "R9\tCOREF Arg1:T7 Arg2:T5\n",
      "R10\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R11\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R12\tCOREF Arg1:T11 Arg2:T4\n",
      "R13\tHYPONYM-OF Arg1:T3 Arg2:T4\n",
      "R14\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R15\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R16\tCOREF Arg1:T2 Arg2:T9\n",
      "R17\tEVALUATE-FOR Arg1:T16 Arg2:T17\n",
      "R18\tCOREF Arg1:T19 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E06-1022.ann\n",
      "T1\tTask 24 93\taddressee identification  in  four-participants face-to-face meetings\n",
      "T2\tMethod 102 118\tBayesian Network\n",
      "T3\tMethod 125 148\tNaive Bayes classifiers\n",
      "T4\tOtherScientificTerm 188 217\taddressee  of a  dialogue act\n",
      "T5\tOtherScientificTerm 246 250\tgaze\n",
      "T6\tOtherScientificTerm 255 264\tutterance\n",
      "T7\tOtherScientificTerm 271 302\tconversational context features\n",
      "T8\tOtherScientificTerm 350 365\tmeeting context\n",
      "T9\tMethod 376 387\tclassifiers\n",
      "T10\tMethod 414 425\tclassifiers\n",
      "T11\tOtherScientificTerm 450 472\tconversational context\n",
      "T12\tOtherScientificTerm 479 497\tutterance features\n",
      "T13\tOtherScientificTerm 518 544\tspeaker's gaze information\n",
      "T14\tMethod 553 564\tclassifiers\n",
      "T15\tOtherScientificTerm 609 624\tmeeting context\n",
      "R1\tCONJUNCTION Arg1:T3 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R3\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R4\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R5\tCONJUNCTION Arg1:T13 Arg2:T12\n",
      "R6\tCOREF Arg1:T14 Arg2:T10\n",
      "R7\tHYPONYM-OF Arg1:T2 Arg2:T10\n",
      "R8\tHYPONYM-OF Arg1:T3 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T10\n",
      "R12\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R13\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R14\tUSED-FOR Arg1:T7 Arg2:T4\n",
      "R15\tCOREF Arg1:T10 Arg2:T9\n",
      "R16\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R17\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E06-1031.ann\n",
      "T1\tMetric 24 43\tevaluation measures\n",
      "T2\tTask 50 69\tmachine translation\n",
      "T3\tMetric 252 270\tevaluation measure\n",
      "T4\tOtherScientificTerm 297 313\tblock reordering\n",
      "T5\tOtherScientificTerm 322 336\tedit operation\n",
      "T6\tGeneric 345 352\tmeasure\n",
      "T7\tOtherScientificTerm 384 398\tquadratic time\n",
      "T8\tMetric 438 457\tevaluation measures\n",
      "T9\tOtherScientificTerm 499 532\tword-dependent substitution costs\n",
      "T10\tGeneric 564 571\tmeasure\n",
      "T11\tOtherScientificTerm 579 593\thuman judgment\n",
      "T12\tMaterial 650 664\tlanguage pairs\n",
      "T13\tGeneric 708 710\tit\n",
      "T14\tGeneric 754 764\tapproaches\n",
      "T15\tMetric 769 795\tsentence-level correlation\n",
      "T16\tOtherScientificTerm 830 863\tword dependent substitution costs\n",
      "T17\tMetric 929 958\tautomatic evaluation measures\n",
      "T18\tOtherScientificTerm 965 979\thuman judgment\n",
      "R1\tEVALUATE-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R4\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R5\tCOREF Arg1:T6 Arg2:T3\n",
      "R6\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R7\tCOMPARE Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T10 Arg2:T8\n",
      "R9\tCOREF Arg1:T8 Arg2:T6\n",
      "R10\tCOREF Arg1:T13 Arg2:T10\n",
      "R11\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R12\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R13\tCOREF Arg1:T17 Arg2:T13\n",
      "R14\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R15\tEVALUATE-FOR Arg1:T15 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E06-1035.ann\n",
      "T1\tTask 60 90\tpredicting  segment boundaries\n",
      "T2\tMaterial 96 122\tspoken multiparty dialogue\n",
      "T3\tGeneric 175 185\tapproaches\n",
      "T4\tTask 215 248\tpredicting top-level topic shifts\n",
      "T5\tTask 269 300\tidentifying subtopic boundaries\n",
      "T6\tOtherScientificTerm 358 368\tASR output\n",
      "T7\tOtherScientificTerm 385 404\thuman transcription\n",
      "T8\tOtherScientificTerm 438 446\tfeatures\n",
      "T9\tTask 460 515\tpredicting top-level and predicting subtopic boundaries\n",
      "T10\tGeneric 534 539\ttasks\n",
      "T11\tTask 549 580\tpredicting  subtopic boundaries\n",
      "T12\tMethod 589 620\tlexical cohesion-based approach\n",
      "T13\tTask 670 701\tpredicting top-level boundaries\n",
      "T14\tMethod 710 735\tmachine learning approach\n",
      "T15\tOtherScientificTerm 752 796\tlexical-cohesion and conversational features\n",
      "T16\tOtherScientificTerm 822 841\tconversational cues\n",
      "T17\tOtherScientificTerm 854 865\tcue phrases\n",
      "T18\tOtherScientificTerm 872 890\toverlapping speech\n",
      "T19\tGeneric 905 915\tindicators\n",
      "T20\tGeneric 924 949\ttop-level prediction task\n",
      "T21\tOtherScientificTerm 974 994\ttranscription errors\n",
      "T22\tOtherScientificTerm 1011 1021\tASR output\n",
      "T23\tGeneric 1049 1055\tmodels\n",
      "T24\tOtherScientificTerm 1070 1114\tlexical-cohesion and conversational features\n",
      "T25\tGeneric 1183 1188\ttasks\n",
      "R1\tCOMPARE Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R3\tFEATURE-OF Arg1:T21 Arg2:T22\n",
      "R4\tFEATURE-OF Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R6\tHYPONYM-OF Arg1:T5 Arg2:T9\n",
      "R7\tPART-OF Arg1:T13 Arg2:T9\n",
      "R8\tCONJUNCTION Arg1:T15 Arg2:T14\n",
      "R9\tHYPONYM-OF Arg1:T17 Arg2:T16\n",
      "R10\tHYPONYM-OF Arg1:T18 Arg2:T16\n",
      "R11\tCONJUNCTION Arg1:T18 Arg2:T17\n",
      "R12\tCOREF Arg1:T19 Arg2:T16\n",
      "R13\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R14\tCOREF Arg1:T20 Arg2:T13\n",
      "R15\tCONJUNCTION Arg1:T23 Arg2:T24\n",
      "R16\tCOREF Arg1:T10 Arg2:T9\n",
      "R17\tCOREF Arg1:T25 Arg2:T10\n",
      "R18\tCOREF Arg1:T23 Arg2:T14\n",
      "R19\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R20\tPART-OF Arg1:T11 Arg2:T9\n",
      "R21\tCOREF Arg1:T11 Arg2:T5\n",
      "R22\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R23\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E06-1045.ann\n",
      "T1\tTask 34 55\tdata-driven selection\n",
      "T2\tMaterial 59 83\temphatic facial displays\n",
      "T3\tTask 92 121\tembodied conversational agent\n",
      "T4\tTask 129 144\tdialogue system\n",
      "T5\tMaterial 150 169\tcorpus of sentences\n",
      "T6\tMethod 200 215\tdialogue system\n",
      "T7\tMaterial 239 254\tfacial displays\n",
      "T8\tGeneric 297 301\tdata\n",
      "T9\tGeneric 347 353\tmodels\n",
      "T10\tMaterial 369 384\tfacial displays\n",
      "T11\tGeneric 391 396\tmodel\n",
      "T12\tGeneric 500 506\tmodels\n",
      "T13\tMethod 539 555\tcross-validation\n",
      "T14\tGeneric 570 576\tcorpus\n",
      "T15\tMethod 643 659\tcross-validation\n",
      "T16\tMethod 717 733\tcross-validation\n",
      "R1\tPART-OF Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R4\tCOREF Arg1:T7 Arg2:T2\n",
      "R5\tEVALUATE-FOR Arg1:T13 Arg2:T12\n",
      "R6\tCOREF Arg1:T15 Arg2:T13\n",
      "R7\tCOREF Arg1:T16 Arg2:T15\n",
      "R8\tCOREF Arg1:T10 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R10\tCOREF Arg1:T11 Arg2:T9\n",
      "R11\tCOREF Arg1:T12 Arg2:T11\n",
      "R12\tCOREF Arg1:T8 Arg2:T5\n",
      "R13\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R14\tCOREF Arg1:T14 Arg2:T8\n",
      "R15\tCOREF Arg1:T4 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E83-1021.ann\n",
      "T1\tTask 50 71\tconceptual operations\n",
      "T2\tMaterial 110 131\tnatural language (NL)\n",
      "T3\tMethod 145 194\tStructured Inheritance Network (SI-Nets) paradigm\n",
      "T4\tGeneric 201 211\toperations\n",
      "T5\tOtherScientificTerm 245 260\tformal language\n",
      "T6\tGeneric 309 319\toperations\n",
      "T7\tMethod 340 347\tSI-Nets\n",
      "T8\tGeneric 365 375\toperations\n",
      "T9\tMethod 380 387\tSI-Nets\n",
      "T10\tOtherScientificTerm 425 448\tepistemological objects\n",
      "T11\tMethod 543 560\tconceptual system\n",
      "T12\tMaterial 566 568\tNL\n",
      "T13\tMethod 620 626\tKL-ONE\n",
      "T14\tOtherScientificTerm 650 671\tepistemological level\n",
      "T15\tGeneric 688 709\texperimental language\n",
      "T16\tMethod 712 719\tKL-Conc\n",
      "T17\tOtherScientificTerm 738 754\tconceptual level\n",
      "T18\tMethod 757 764\tKL-Conc\n",
      "T19\tMethod 836 843\tSI-Nets\n",
      "R1\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R2\tFEATURE-OF Arg1:T14 Arg2:T13\n",
      "R3\tFEATURE-OF Arg1:T17 Arg2:T16\n",
      "R4\tCOREF Arg1:T6 Arg2:T4\n",
      "R5\tCOREF Arg1:T7 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R7\tCOREF Arg1:T9 Arg2:T7\n",
      "R8\tCOREF Arg1:T8 Arg2:T6\n",
      "R9\tCOREF Arg1:T12 Arg2:T2\n",
      "R10\tCOREF Arg1:T18 Arg2:T16\n",
      "R11\tCOREF Arg1:T19 Arg2:T9\n",
      "R12\tCOMPARE Arg1:T13 Arg2:T16\n",
      "R13\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R14\tCOREF Arg1:T4 Arg2:T1\n",
      "R15\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R16\tCOREF Arg1:T16 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E83-1029.ann\n",
      "T1\tGeneric 17 23\tsystem\n",
      "T2\tTask 62 101\tscenes descriptions in natural language\n",
      "T3\tGeneric 145 155\tcomponents\n",
      "T4\tGeneric 163 169\tsystem\n",
      "T5\tMethod 190 208\tsyntactic analyzer\n",
      "T6\tMethod 223 250\tProcedural Systemic Grammar\n",
      "T7\tMethod 258 275\tsemantic analyzer\n",
      "T8\tMethod 293 321\tConceptual Dependency Theory\n",
      "T9\tOtherScientificTerm 333 343\tdictionary\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tPART-OF Arg1:T3 Arg2:T4\n",
      "R6\tPART-OF Arg1:T5 Arg2:T3\n",
      "R7\tPART-OF Arg1:T7 Arg2:T3\n",
      "R8\tPART-OF Arg1:T9 Arg2:T3\n",
      "R9\tCONJUNCTION Arg1:T5 Arg2:T7\n",
      "R10\tCONJUNCTION Arg1:T7 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E85-1004.ann\n",
      "T1\tMethod 112 131\tanalytical inverses\n",
      "T2\tOtherScientificTerm 138 164\tcompositional syntax rules\n",
      "T3\tMethod 197 231\tDefinite Clause Grammar techniques\n",
      "T4\tTask 259 301\tparser  returning  Montague analysis trees\n",
      "T5\tMethod 307 318\tparser MDCC\n",
      "T6\tMethod 354 391\taugmented Friedman - Warren algorithm\n",
      "T7\tOtherScientificTerm 405 421\tpost referencing\n",
      "T8\tOtherScientificTerm 459 492\tintenslonal logic translator LILT\n",
      "T9\tOtherScientificTerm 516 536\tderivational history\n",
      "T10\tOtherScientificTerm 556 575\treduced IL formulae\n",
      "T11\tMethod 601 615\tMontague's PTQ\n",
      "T12\tMethod 626 645\tbasic DCG mechanism\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "R4\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R6\tCOREF Arg1:T12 Arg2:T3\n",
      "R7\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R8\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E85-1037.ann\n",
      "T1\tMethod 2 18\tSystemic grammar\n",
      "T2\tTask 39 57\tAI text generation\n",
      "T3\tGeneric 86 101\timplementations\n",
      "T4\tGeneric 164 172\tapproach\n",
      "T5\tTask 186 201\ttext generation\n",
      "T6\tMethod 210 239\tAI problem solving techniques\n",
      "T7\tMethod 283 299\tsystemic grammar\n",
      "T8\tGeneric 308 316\tapproach\n",
      "T9\tMethod 370 386\tsystemic grammar\n",
      "T10\tMethod 393 408\tproblem solving\n",
      "T11\tTask 504 519\ttext generation\n",
      "T12\tMethod 540 557\tlinguistic theory\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R4\tCOREF Arg1:T3 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R6\tCOREF Arg1:T5 Arg2:T2\n",
      "R7\tCOREF Arg1:T6 Arg2:T4\n",
      "R8\tCOREF Arg1:T8 Arg2:T4\n",
      "R9\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R10\tCOREF Arg1:T11 Arg2:T5\n",
      "R11\tCOREF Arg1:T10 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E85-1041.ann\n",
      "T1\tGeneric 35 40\tmodel\n",
      "T2\tOtherScientificTerm 59 93\tstructure of communicative context\n",
      "T3\tMaterial 99 119\tdialogue interaction\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E87-1037.ann\n",
      "T1\tMethod 20 42\tgrammatical formalisms\n",
      "T2\tMethod 102 139\tcontext-free phrase-structure grammar\n",
      "T3\tOtherScientificTerm 162 165\tLFG\n",
      "T4\tOtherScientificTerm 172 179\tPATR-II\n",
      "T5\tGeneric 216 226\tformalisms\n",
      "T6\tMethod 250 273\tchart-parsing framework\n",
      "T7\tGeneric 310 320\tformalisms\n",
      "T8\tMethod 368 392\toptimal control strategy\n",
      "T9\tMethod 456 480\trule-invocation strategy\n",
      "T10\tOtherScientificTerm 594 599\trules\n",
      "T11\tMethod 697 723\trule-invocation strategies\n",
      "T12\tMethod 733 759\tcontext-free chart parsing\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tPART-OF Arg1:T11 Arg2:T12\n",
      "R3\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R4\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R5\tHYPONYM-OF Arg1:T4 Arg2:T1\n",
      "R6\tCOREF Arg1:T5 Arg2:T1\n",
      "R7\tCOREF Arg1:T7 Arg2:T5\n",
      "R8\tCOREF Arg1:T11 Arg2:T9\n",
      "R9\tCOREF Arg1:T12 Arg2:T6\n",
      "R10\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E87-1043.ann\n",
      "T1\tOtherScientificTerm 6 16\tverb forms\n",
      "T2\tGeneric 60 71\tinformation\n",
      "T3\tOtherScientificTerm 161 180\tdeictic information\n",
      "T4\tOtherScientificTerm 305 326\taspectual information\n",
      "T5\tTask 413 444\tanalysis of  verb form meanings\n",
      "T6\tGeneric 518 526\tanalysis\n",
      "T7\tOtherScientificTerm 531 556\tmodel-theoretic semantics\n",
      "R1\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T4 Arg2:T2\n",
      "R3\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E89-1006.ann\n",
      "T1\tGeneric 3 11\tproposal\n",
      "T2\tOtherScientificTerm 26 39\tFrench tenses\n",
      "T3\tMethod 62 93\tDiscourse Representation Theory\n",
      "T4\tGeneric 112 114\tit\n",
      "T5\tTask 159 162\tIMS\n",
      "T6\tGeneric 165 167\tIt\n",
      "T7\tOtherScientificTerm 185 201\ttheory of tenses\n",
      "T8\tGeneric 248 257\toperators\n",
      "T9\tOtherScientificTerm 275 298\tmeaning  of the  tenses\n",
      "T10\tOtherScientificTerm 526 541\tevent structure\n",
      "T11\tMethod 580 604\tsystem of relevant times\n",
      "T12\tOtherScientificTerm 622 638\tpreceeding  text\n",
      "T13\tOtherScientificTerm 652 671\ttemporal adverbials\n",
      "T14\tGeneric 721 727\tsystem\n",
      "T15\tOtherScientificTerm 753 768\treference times\n",
      "T16\tOtherScientificTerm 775 801\ttemporal perspective times\n",
      "T17\tOtherScientificTerm 809 820\tspeech time\n",
      "T18\tOtherScientificTerm 831 844\tlocation time\n",
      "T19\tMethod 962 986\tsystem of relevant times\n",
      "T20\tMethod 1008 1038\tsystem of temporal coordinates\n",
      "T21\tOtherScientificTerm 1173 1196\tmeaning  of the  tenses\n",
      "T22\tMethod 1215 1235\tresolution component\n",
      "T23\tMethod 1264 1282\tsyntactic analysis\n",
      "R1\tCOMPARE Arg1:T22 Arg2:T23\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R5\tCOREF Arg1:T14 Arg2:T11\n",
      "R6\tPART-OF Arg1:T15 Arg2:T14\n",
      "R7\tPART-OF Arg1:T16 Arg2:T14\n",
      "R8\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R9\tPART-OF Arg1:T17 Arg2:T14\n",
      "R10\tPART-OF Arg1:T18 Arg2:T14\n",
      "R11\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R12\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R13\tCOREF Arg1:T19 Arg2:T14\n",
      "R14\tCOREF Arg1:T20 Arg2:T19\n",
      "R15\tCOREF Arg1:T4 Arg2:T1\n",
      "R16\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R17\tCOREF Arg1:T4 Arg2:T6\n",
      "R18\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R19\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R20\tUSED-FOR Arg1:T13 Arg2:T11\n",
      "R21\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E89-1016.ann\n",
      "T1\tGeneric 61 71\tapproaches\n",
      "T2\tTask 101 139\tevaluation of Natural Language systems\n",
      "T3\tMethod 115 139\tNatural Language systems\n",
      "T4\tGeneric 169 179\tapproaches\n",
      "T5\tGeneric 209 216\tsystems\n",
      "T6\tGeneric 263 267\ttask\n",
      "T7\tTask 280 294\tdata retrieval\n",
      "T8\tGeneric 347 357\tapproaches\n",
      "T9\tMethod 435 457\tWizard of Oz technique\n",
      "T10\tOtherScientificTerm 472 487\tNL requirements\n",
      "T11\tGeneric 512 516\ttask\n",
      "T12\tMaterial 549 563\ttask dialogues\n",
      "T13\tGeneric 587 596\ttechnique\n",
      "T14\tMethod 613 646\tprototype Natural Language system\n",
      "T15\tGeneric 712 716\ttask\n",
      "T16\tGeneric 771 775\ttask\n",
      "T17\tTask 780 795\tdatabase access\n",
      "T18\tOtherScientificTerm 807 827\tcontextual reference\n",
      "T19\tMethod 942 966\tNatural Language systems\n",
      "R1\tCOREF Arg1:T8 Arg2:T4\n",
      "R2\tCOREF Arg1:T5 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R4\tEVALUATE-FOR Arg1:T4 Arg2:T5\n",
      "R5\tCOREF Arg1:T11 Arg2:T6\n",
      "R6\tCOREF Arg1:T13 Arg2:T9\n",
      "R7\tCOREF Arg1:T15 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R10\tCOREF Arg1:T19 Arg2:T14\n",
      "R11\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R12\tPART-OF Arg1:T7 Arg2:T6\n",
      "R13\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R14\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R15\tCOREF Arg1:T16 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E89-1040.ann\n",
      "T1\tTask 38 57\tmachine translation\n",
      "T2\tGeneric 123 132\tformalism\n",
      "T3\tTask 217 228\ttranslation\n",
      "T4\tMethod 286 305\tanaphoric component\n",
      "T5\tMethod 315 329\tMimo formalism\n",
      "T6\tTask 361 397\ttranslation  of  anaphoric relations\n",
      "T7\tOtherScientificTerm 479 502\tstrict compositionality\n",
      "T8\tOtherScientificTerm 509 513\tMimo\n",
      "T9\tTask 521 557\ttranslation  of  anaphoric relations\n",
      "T10\tMethod 582 601\tanaphoric component\n",
      "T11\tOtherScientificTerm 622 642\tlinguistic phenomena\n",
      "T12\tOtherScientificTerm 653 664\twh-movement\n",
      "T13\tOtherScientificTerm 667 724\tthe  passive  and the  binding of reflexives and pronouns\n",
      "T14\tOtherScientificTerm 844 855\twh-movement\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R3\tCOREF Arg1:T5 Arg2:T2\n",
      "R4\tCOREF Arg1:T8 Arg2:T5\n",
      "R5\tCOREF Arg1:T10 Arg2:T4\n",
      "R6\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R7\tCOREF Arg1:T14 Arg2:T12\n",
      "R8\tPART-OF Arg1:T4 Arg2:T5\n",
      "R9\tCOREF Arg1:T9 Arg2:T6\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R11\tHYPONYM-OF Arg1:T13 Arg2:T11\n",
      "R12\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E91-1012.ann\n",
      "T1\tMethod 40 50\tLR-parsers\n",
      "T2\tMethod 86 103\tcorrectness proof\n",
      "T3\tGeneric 106 108\tIt\n",
      "T4\tMethod 150 174\trecursive descent parser\n",
      "T5\tMethod 182 197\tnon-LR grammars\n",
      "T6\tMetric 203 218\ttime-complexity\n",
      "T7\tMethod 227 233\tparser\n",
      "T8\tMethod 282 288\tparser\n",
      "T9\tMethod 310 324\tmemo-functions\n",
      "T10\tMethod 394 408\tMemo-functions\n",
      "T11\tOtherScientificTerm 490 502\tparse forest\n",
      "T12\tMethod 510 524\tLR(0) grammars\n",
      "T13\tGeneric 531 540\talgorithm\n",
      "T14\tOtherScientificTerm 568 592\trecursive ascent parsers\n",
      "T15\tMethod 655 675\tExtended CF grammars\n",
      "T16\tMethod 679 687\tgrammars\n",
      "T17\tOtherScientificTerm 695 714\tregular expressions\n",
      "T18\tMethod 789 798\tLR-parser\n",
      "T19\tMethod 812 823\tCF grammars\n",
      "R1\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R2\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R3\tCONJUNCTION Arg1:T2 Arg2:T1\n",
      "R4\tCOREF Arg1:T8 Arg2:T7\n",
      "R5\tCOREF Arg1:T10 Arg2:T9\n",
      "R6\tCOREF Arg1:T16 Arg2:T15\n",
      "R7\tFEATURE-OF Arg1:T17 Arg2:T16\n",
      "R8\tUSED-FOR Arg1:T18 Arg2:T15\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R10\tCOREF Arg1:T13 Arg2:T8\n",
      "R11\tCOREF Arg1:T18 Arg2:T13\n",
      "R12\tCOREF Arg1:T1 Arg2:T7\n",
      "R13\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R14\tCOREF Arg1:T1 Arg2:T3\n",
      "R15\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R16\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R17\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R18\tEVALUATE-FOR Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E91-1043.ann\n",
      "T1\tMethod 35 66\tmodel of grammatical processing\n",
      "T2\tMethod 86 104\tuniform processing\n",
      "T3\tMaterial 111 128\tknowledge sources\n",
      "T4\tGeneric 158 163\tmodel\n",
      "T5\tTask 176 183\tparsing\n",
      "T6\tTask 190 200\tgeneration\n",
      "T7\tGeneric 230 235\ttasks\n",
      "T8\tMethod 259 290\tparametrized deduction  process\n",
      "T9\tTask 357 384\tnatural language processing\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tCONJUNCTION Arg1:T3 Arg2:T2\n",
      "R5\tCOREF Arg1:T4 Arg2:T1\n",
      "R6\tHYPONYM-OF Arg1:T6 Arg2:T7\n",
      "R7\tHYPONYM-OF Arg1:T5 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E91-1050.ann\n",
      "T1\tMethod 2 13\tUnification\n",
      "T2\tGeneric 40 46\tmethod\n",
      "T3\tTask 63 98\trelations  between  representations\n",
      "T4\tOtherScientificTerm 116 134\tfeature structures\n",
      "T5\tGeneric 191 199\tapproach\n",
      "T6\tMethod 217 238\tdeclarative formalism\n",
      "T7\tOtherScientificTerm 267 324\tdirect  mappings  of one  feature structure  into another\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T6 Arg2:T5\n",
      "R3\tCOMPARE Arg1:T5 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R5\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\E93-1004.ann\n",
      "T1\tMethod 31 48\tmodal language LT\n",
      "T2\tOtherScientificTerm 63 85\tconstraints  on  trees\n",
      "T3\tMethod 95 113\textension  LT (LF)\n",
      "T4\tOtherScientificTerm 129 185\tconstraints  on  trees decorated with feature structures\n",
      "T5\tGeneric 226 235\tlanguages\n",
      "T6\tMethod 274 296\tgrammatical frameworks\n",
      "T7\tMethod 381 385\tGPSG\n",
      "T8\tMethod 407 414\tLT (LF)\n",
      "T9\tMethod 443 458\tmodal languages\n",
      "T10\tMethod 504 525\tconstraint formalisms\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tCOREF Arg1:T9 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R7\tHYPONYM-OF Arg1:T3 Arg2:T5\n",
      "R8\tCOREF Arg1:T8 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E93-1023.ann\n",
      "T1\tOtherScientificTerm 105 114\tambiguity\n",
      "T2\tTask 122 132\tgeneration\n",
      "T3\tOtherScientificTerm 233 242\tambiguity\n",
      "T4\tMethod 250 276\tMORphological PArser MORPA\n",
      "T5\tMethod 298 339\tprobabilistic context-free grammar (PCFG)\n",
      "T6\tGeneric 347 349\tit\n",
      "T7\tMethod 362 411\t\"conventional\" context-free morphological grammar\n",
      "T8\tOtherScientificTerm 428 455\tungrammatical segmentations\n",
      "T9\tMethod 465 499\tprobability-based scoring function\n",
      "T10\tTask 553 558\tparse\n",
      "T11\tMethod 682 686\tPCFG\n",
      "T12\tTask 712 733\tmorphological parsing\n",
      "T13\tMethod 737 742\tMORPA\n",
      "T14\tMethod 768 774\tparser\n",
      "T15\tTask 800 832\ttext-to-speech conversion system\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tCONJUNCTION Arg1:T9 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R4\tCOREF Arg1:T6 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R8\tCOREF Arg1:T11 Arg2:T5\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R10\tCOREF Arg1:T13 Arg2:T4\n",
      "R11\tHYPONYM-OF Arg1:T13 Arg2:T14\n",
      "R12\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R13\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R14\tUSED-FOR Arg1:T9 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E93-1025.ann\n",
      "T1\tTask 13 45\tanalysis of  ellipsis resolution\n",
      "T2\tMethod 78 105\tdiscourse copying algorithm\n",
      "T3\tGeneric 162 171\ttreatment\n",
      "T4\tTask 215 245\tidentity-of-relations analyses\n",
      "T5\tGeneric 321 330\ttreatment\n",
      "T6\tOtherScientificTerm 383 391\tfull NPs\n",
      "T7\tOtherScientificTerm 402 422\treferential elements\n",
      "T8\tTask 469 481\trole linking\n",
      "T9\tOtherScientificTerm 547 555\tellipsis\n",
      "T10\tGeneric 588 596\tanalysis\n",
      "T11\tTask 624 651\tdiscourse copying phenomena\n",
      "R1\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R2\tCOREF Arg1:T5 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R4\tCOREF Arg1:T10 Arg2:T1\n",
      "R5\tCOREF Arg1:T3 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E93-1043.ann\n",
      "T1\tMethod 18 41\tmorphological component\n",
      "T2\tOtherScientificTerm 112 125\tderived words\n",
      "T3\tGeneric 145 151\tsystem\n",
      "T4\tOtherScientificTerm 174 194\ttwo-level morphology\n",
      "T5\tMethod 233 259\tfeature-based word grammar\n",
      "T6\tOtherScientificTerm 276 296\thierarchical lexicon\n",
      "T7\tOtherScientificTerm 300 319\tPolymorphemic stems\n",
      "T8\tOtherScientificTerm 373 401\tcompositional interpretation\n",
      "T9\tGeneric 417 423\tsystem\n",
      "T10\tOtherScientificTerm 480 493\tderived words\n",
      "T11\tOtherScientificTerm 557 576\twords formed ad-hoc\n",
      "T12\tGeneric 611 617\tsystem\n",
      "T13\tMethod 636 646\tCommonLisp\n",
      "T14\tMaterial 685 702\tGerman derivation\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "R4\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R6\tCOREF Arg1:T3 Arg2:T1\n",
      "R7\tCOREF Arg1:T10 Arg2:T2\n",
      "R8\tCOREF Arg1:T9 Arg2:T3\n",
      "R9\tCOREF Arg1:T12 Arg2:T9\n",
      "R10\tEVALUATE-FOR Arg1:T14 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E93-1066.ann\n",
      "T1\tTask 32 78\tfull scale two-level morphological description\n",
      "T2\tMaterial 121 144\tTurkish word structures\n",
      "T3\tGeneric 151 162\tdescription\n",
      "T4\tMethod 195 215\tPC-KIMMO environment\n",
      "T5\tMaterial 253 270\troot word lexicon\n",
      "T6\tOtherScientificTerm 354 390\tphonological and morphological rules\n",
      "T7\tMaterial 416 423\tTurkish\n",
      "T8\tMaterial 432 454\tagglutinative language\n",
      "T9\tOtherScientificTerm 462 477\tword structures\n",
      "T10\tOtherScientificTerm 490 554\tproductive affixations of derivational and inflectional suffixes\n",
      "T11\tMaterial 574 581\tTurkish\n",
      "T12\tOtherScientificTerm 588 600\tfinite-state\n",
      "T13\tOtherScientificTerm 650 659\tMorphemes\n",
      "T14\tOtherScientificTerm 742 758\tverbal structure\n",
      "T15\tOtherScientificTerm 790 810\tadverbial constructs\n",
      "T16\tTask 818 871\tsurface realizations  of  morphological constructions\n",
      "T17\tOtherScientificTerm 918 932\tphonetic rules\n",
      "T18\tOtherScientificTerm 943 956\tvowel harmony\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T3\n",
      "R5\tHYPONYM-OF Arg1:T7 Arg2:T8\n",
      "R6\tCOREF Arg1:T11 Arg2:T7\n",
      "R7\tPART-OF Arg1:T10 Arg2:T9\n",
      "R8\tHYPONYM-OF Arg1:T18 Arg2:T17\n",
      "R9\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R10\tFEATURE-OF Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E95-1021.ann\n",
      "T1\tGeneric 40 50\tapproaches\n",
      "T2\tTask 55 77\tpart-of-speech tagging\n",
      "T3\tTask 81 128\tstatistical and constraint-based disambiguation\n",
      "T4\tMaterial 138 144\tFrench\n",
      "T5\tGeneric 260 277\tconstraint system\n",
      "T6\tMethod 359 376\tstatistical model\n",
      "T7\tGeneric 399 406\tsystems\n",
      "T8\tMetric 437 445\taccuracy\n",
      "T9\tMethod 455 473\tstatistical method\n",
      "T10\tMethod 510 517\ttaggers\n",
      "T11\tMaterial 524 531\tEnglish\n",
      "T12\tMethod 543 566\tconstraint-based tagger\n",
      "R1\tCOMPARE Arg1:T5 Arg2:T6\n",
      "R2\tCOMPARE Arg1:T9 Arg2:T10\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T3 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R6\tCOREF Arg1:T9 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T12 Arg2:T5\n",
      "R9\tCOREF Arg1:T7 Arg2:T1\n",
      "R10\tHYPONYM-OF Arg1:T5 Arg2:T1\n",
      "R11\tHYPONYM-OF Arg1:T6 Arg2:T1\n",
      "R12\tEVALUATE-FOR Arg1:T8 Arg2:T9\n",
      "R13\tEVALUATE-FOR Arg1:T8 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E95-1033.ann\n",
      "T1\tOtherScientificTerm 34 72\tsentence-level and text-level anaphora\n",
      "T2\tMethod 101 131\tdependency-based grammar model\n",
      "T3\tGeneric 134 142\tCriteria\n",
      "T4\tTask 148 196\tanaphora resolution  within  sentence boundaries\n",
      "T5\tMethod 228 247\tGB's binding theory\n",
      "T6\tGeneric 256 261\tthose\n",
      "T7\tOtherScientificTerm 267 286\ttext-level anaphora\n",
      "T8\tMethod 325 355\tGrosz-Sidner-style focus model\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T6 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R4\tPART-OF Arg1:T8 Arg2:T6\n",
      "R5\tHYPONYM-OF Arg1:T7 Arg2:T1\n",
      "R6\tHYPONYM-OF Arg1:T4 Arg2:T1\n",
      "R7\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R8\tUSED-FOR Arg1:T5 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E95-1036.ann\n",
      "T1\tTask 37 54\ttemporal anaphora\n",
      "T2\tOtherScientificTerm 86 112\tquantification over events\n",
      "T3\tMethod 140 171\tDiscourse Representation Theory\n",
      "T4\tMaterial 209 229\tquantified sentences\n",
      "T5\tOtherScientificTerm 249 268\ttemporal connective\n",
      "T6\tOtherScientificTerm 316 335\ttemporal connective\n",
      "T7\tOtherScientificTerm 345 363\tsubordinate clause\n",
      "T8\tGeneric 391 398\tproblem\n",
      "T9\tOtherScientificTerm 472 490\tproportion problem\n",
      "T10\tGeneric 504 512\tsolution\n",
      "T11\tMethod 521 552\tGeneralized Quantifier approach\n",
      "T12\tOtherScientificTerm 620 634\treference time\n",
      "T13\tGeneric 682 690\tsolution\n",
      "T14\tGeneric 700 707\tproblem\n",
      "T15\tMethod 735 738\tDRT\n",
      "T16\tGeneric 776 784\tsolution\n",
      "T17\tTask 801 828\ttemporal anaphora phenomena\n",
      "T18\tMaterial 834 854\tquantified sentences\n",
      "R1\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R2\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tPART-OF Arg1:T2 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T8\n",
      "R6\tCOREF Arg1:T8 Arg2:T1\n",
      "R7\tCOREF Arg1:T14 Arg2:T8\n",
      "R8\tCOREF Arg1:T11 Arg2:T10\n",
      "R9\tCOREF Arg1:T16 Arg2:T13\n",
      "R10\tUSED-FOR Arg1:T18 Arg2:T16\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R12\tCOREF Arg1:T3 Arg2:T15\n",
      "R13\tPART-OF Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E99-1014.ann\n",
      "T1\tGeneric 24 32\tapproach\n",
      "T2\tTask 37 49\tfull parsing\n",
      "T3\tTask 65 87\tInformation Extraction\n",
      "T4\tOtherScientificTerm 129 134\trules\n",
      "T5\tOtherScientificTerm 184 206\tunambiguous structures\n",
      "T6\tOtherScientificTerm 254 274\targumental relations\n",
      "T7\tOtherScientificTerm 301 320\tmodifier attachment\n",
      "T8\tOtherScientificTerm 344 361\tglobal parse tree\n",
      "T9\tGeneric 377 385\tapproach\n",
      "T10\tGeneric 452 454\tIt\n",
      "T11\tMethod 479 488\tIE module\n",
      "T12\tMethod 494 558\tFACILE, a EU project for multilingual text classification and IE\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tPART-OF Arg1:T11 Arg2:T12\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T10 Arg2:T9\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R6\tCOREF Arg1:T9 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E99-1015.ann\n",
      "T1\tTask 27 56\tautomatic abstracting systems\n",
      "T2\tMaterial 87 105\ttraining resources\n",
      "T3\tMethod 169 186\tannotation scheme\n",
      "T4\tMaterial 192 211\tscientific articles\n",
      "T5\tGeneric 247 255\tresource\n",
      "T6\tGeneric 307 313\tscheme\n",
      "T7\tMethod 329 364\trhetorical moves  of  argumentation\n",
      "T8\tGeneric 407 413\tscheme\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T6 Arg2:T3\n",
      "R5\tCOREF Arg1:T8 Arg2:T6\n",
      "R6\tCOREF Arg1:T5 Arg2:T2\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E99-1023.ann\n",
      "T1\tTask 1 41\tDividing  sentences  in  chunks of words\n",
      "T2\tTask 79 86\tparsing\n",
      "T3\tTask 90 112\tinformation extraction\n",
      "T4\tTask 119 140\tinformation retrieval\n",
      "T5\tMethod 202 221\tdata representation\n",
      "T6\tTask 228 236\tchunking\n",
      "T7\tGeneric 252 254\tit\n",
      "T8\tTask 261 273\ttagging task\n",
      "T9\tMethod 323 343\tdata representations\n",
      "T10\tTask 364 395\trecognizing  noun phrase chunks\n",
      "T11\tMethod 421 440\tdata representation\n",
      "T12\tTask 475 483\tchunking\n",
      "T13\tMethod 539 558\tdata representation\n",
      "T14\tMethod 566 595\tmemory-based learning chunker\n",
      "T15\tTask 637 645\tchunking\n",
      "T16\tMaterial 671 679\tdata set\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R2\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R3\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R5\tEVALUATE-FOR Arg1:T16 Arg2:T14\n",
      "R6\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R7\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R8\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R9\tCOREF Arg1:T6 Arg2:T1\n",
      "R10\tCOREF Arg1:T7 Arg2:T6\n",
      "R11\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R12\tCOREF Arg1:T6 Arg2:T12\n",
      "R13\tCOREF Arg1:T12 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E99-1029.ann\n",
      "T1\tMethod 33 56\tTree Adjoining Grammars\n",
      "T2\tGeneric 66 70\tthey\n",
      "T3\tOtherScientificTerm 80 114\textended domain of locality (EDOL)\n",
      "T4\tMethod 178 207\tfeature structure unification\n",
      "T5\tTask 217 224\tparsing\n",
      "T6\tMethod 257 288\tlexicalized grammars of English\n",
      "T7\tMethod 292 298\tLEXSYS\n",
      "T8\tMethod 305 309\tXTAG\n",
      "T9\tMethod 334 342\tgrammars\n",
      "T10\tOtherScientificTerm 353 357\tEDOL\n",
      "R1\tFEATURE-OF Arg1:T1 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tCOMPARE Arg1:T7 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R5\tHYPONYM-OF Arg1:T7 Arg2:T6\n",
      "R6\tHYPONYM-OF Arg1:T8 Arg2:T6\n",
      "R7\tCOREF Arg1:T9 Arg2:T6\n",
      "R8\tCOREF Arg1:T10 Arg2:T3\n",
      "R9\tCOREF Arg1:T2 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E99-1034.ann\n",
      "T1\tOtherScientificTerm 51 77\tco-occurrence similarities\n",
      "T2\tGeneric 111 122\tquery terms\n",
      "T3\tTask 145 154\tretrieval\n",
      "T4\tGeneric 161 166\tthose\n",
      "T5\tGeneric 227 239\tuseful terms\n",
      "T6\tGeneric 294 305\tquery terms\n",
      "T7\tGeneric 337 349\tsimilarities\n",
      "T8\tOtherScientificTerm 366 408\tfirst-order and second-order co-occurrence\n",
      "T9\tOtherScientificTerm 443 460\tTerm similarities\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tCOMPARE Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R5\tCOREF Arg1:T9 Arg2:T7\n",
      "R6\tCOMPARE Arg1:T4 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\E99-1038.ann\n",
      "T1\tGeneric 15 34\toperable definition\n",
      "T2\tOtherScientificTerm 73 97\tcognito-pragmatic nature\n",
      "T3\tGeneric 114 116\tit\n",
      "T4\tOtherScientificTerm 135 144\tdiscourse\n",
      "T5\tMethod 188 247\ta file card model of  discourse model  and  knowledge store\n",
      "T6\tMethod 210 225\tdiscourse model\n",
      "T7\tOtherScientificTerm 232 247\tknowledge store\n",
      "T8\tOtherScientificTerm 328 349\tdetermination process\n",
      "T9\tMethod 356 378\tprogrammable algorithm\n",
      "T10\tMethod 381 384\tFDA\n",
      "T11\tOtherScientificTerm 420 451\tsocial and cognitive psychology\n",
      "T12\tOtherScientificTerm 513 516\tFDA\n",
      "T13\tOtherScientificTerm 524 549\tdiscourse-level construct\n",
      "T14\tMethod 557 581\tspeech synthesis systems\n",
      "T15\tMethod 600 625\tconcept-to-speech systems\n",
      "R1\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T10 Arg2:T9\n",
      "R4\tCOREF Arg1:T12 Arg2:T10\n",
      "R5\tHYPONYM-OF Arg1:T15 Arg2:T14\n",
      "R6\tPART-OF Arg1:T13 Arg2:T14\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_1998_39_abs.ann\n",
      "T1\tMethod 0 36\tImage sequence processing techniques\n",
      "T2\tTask 55 97\texchange , growth, and transport processes\n",
      "T3\tMaterial 129 150\tenvironmental physics\n",
      "T4\tMaterial 155 162\tbiology\n",
      "T5\tGeneric 170 182\tapplications\n",
      "T6\tMetric 196 204\taccuracy\n",
      "T7\tTask 213 243\testimation of the motion field\n",
      "T8\tMethod 289 308\tdynamical processes\n",
      "T9\tOtherScientificTerm 334 377\tfirst-order derivatives of the motion field\n",
      "T10\tOtherScientificTerm 384 423\tdynamical changes of the moving objects\n",
      "T11\tTask 455 498\toptimization of low-level motion estimators\n",
      "T12\tMethod 515 528\ttensor method\n",
      "T13\tMethod 560 578\tderivative filters\n",
      "T14\tOtherScientificTerm 605 637\tdisplacement vector fields (DVF)\n",
      "T15\tMetric 646 654\taccuracy\n",
      "T16\tMetric 680 692\tpixels/frame\n",
      "T17\tMaterial 697 714\treal-world images\n",
      "T18\tMetric 720 728\taccuracy\n",
      "T19\tMethod 736 749\ttensor method\n",
      "T20\tMaterial 767 795\tcomputer-generated sequences\n",
      "T21\tMaterial 802 827\tcalibrated image sequence\n",
      "T22\tMetric 854 862\taccuracy\n",
      "T23\tTask 867 884\tmotion estimation\n",
      "T24\tOtherScientificTerm 931 942\tCCD sensors\n",
      "T25\tOtherScientificTerm 959 981\tspatial nonuni-formity\n",
      "T26\tOtherScientificTerm 989 1001\tresponsivity\n",
      "T27\tMethod 1017 1038\ttwo-point calibration\n",
      "T28\tGeneric 1108 1118\ttechniques\n",
      "T29\tTask 1126 1150\tanalysis of plant growth\n",
      "T30\tTask 1155 1206\tocean surface microturbulence in IR image sequences\n",
      "T31\tTask 1215 1233\tsediment transport\n",
      "R1\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tEVALUATE-FOR Arg1:T6 Arg2:T7\n",
      "R4\tHYPONYM-OF Arg1:T5 Arg2:T2\n",
      "R5\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R7\tCOREF Arg1:T19 Arg2:T12\n",
      "R8\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R9\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "R10\tEVALUATE-FOR Arg1:T22 Arg2:T23\n",
      "R11\tCOREF Arg1:T28 Arg2:T1\n",
      "R12\tUSED-FOR Arg1:T28 Arg2:T29\n",
      "R13\tUSED-FOR Arg1:T28 Arg2:T30\n",
      "R14\tUSED-FOR Arg1:T28 Arg2:T31\n",
      "R15\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R16\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R17\tEVALUATE-FOR Arg1:T16 Arg2:T14\n",
      "R18\tEVALUATE-FOR Arg1:T20 Arg2:T19\n",
      "R19\tEVALUATE-FOR Arg1:T21 Arg2:T19\n",
      "R20\tUSED-FOR Arg1:T24 Arg2:T23\n",
      "R21\tFEATURE-OF Arg1:T25 Arg2:T26\n",
      "R22\tFEATURE-OF Arg1:T26 Arg2:T24\n",
      "R23\tCONJUNCTION Arg1:T29 Arg2:T30\n",
      "R24\tCONJUNCTION Arg1:T30 Arg2:T31\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2006_13_abs.ann\n",
      "T1\tTask 50 62\tillumination\n",
      "T2\tTask 67 82\tpose invariance\n",
      "T3\tTask 127 143\tface recognition\n",
      "T4\tMaterial 232 247\tvideo sequences\n",
      "T5\tOtherScientificTerm 334 342\tlighting\n",
      "T6\tOtherScientificTerm 344 348\tpose\n",
      "T7\tOtherScientificTerm 353 372\tuser motion pattern\n",
      "T8\tMaterial 401 412\tface images\n",
      "T9\tMetric 424 434\tresolution\n",
      "T10\tMethod 502 519\tphotometric model\n",
      "T11\tTask 523 538\timage formation\n",
      "T12\tMethod 562 579\tstatistical model\n",
      "T13\tTask 583 616\tgeneric face appearance variation\n",
      "T14\tOtherScientificTerm 667 695\textreme illumination changes\n",
      "T15\tOtherScientificTerm 713 723\tsmoothness\n",
      "T16\tOtherScientificTerm 727 775\tgeodesically local appearance manifold structure\n",
      "T17\tMethod 782 813\trobust same-identity likelihood\n",
      "T18\tOtherScientificTerm 839 856\tunseen head poses\n",
      "T19\tMethod 893 936\tvideo sequence \" reillumination \" algorithm\n",
      "T20\tMetric 948 958\trobustness\n",
      "T21\tOtherScientificTerm 962 982\tface motion patterns\n",
      "T22\tMaterial 986 991\tvideo\n",
      "T23\tMethod 1007 1041\tfully automatic recognition system\n",
      "T24\tGeneric 1064 1070\tmethod\n",
      "T25\tMaterial 1132 1147\tvideo sequences\n",
      "T26\tOtherScientificTerm 1161 1173\tillumination\n",
      "T27\tOtherScientificTerm 1175 1179\tpose\n",
      "T28\tOtherScientificTerm 1184 1205\thead motion variation\n",
      "T29\tGeneric 1227 1235\tdata set\n",
      "T30\tGeneric 1240 1246\tsystem\n",
      "T31\tMetric 1290 1306\trecognition rate\n",
      "T32\tMaterial 1332 1341\tdatabases\n",
      "T33\tMethod 1390 1409\tcommercial software\n",
      "T34\tGeneric 1414 1421\tmethods\n",
      "R1\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R2\tPART-OF Arg1:T2 Arg2:T3\n",
      "R3\tPART-OF Arg1:T1 Arg2:T3\n",
      "R4\tFEATURE-OF Arg1:T9 Arg2:T8\n",
      "R5\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R6\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R9\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R10\tFEATURE-OF Arg1:T15 Arg2:T16\n",
      "R11\tCONJUNCTION Arg1:T26 Arg2:T27\n",
      "R12\tCONJUNCTION Arg1:T27 Arg2:T28\n",
      "R13\tUSED-FOR Arg1:T24 Arg2:T23\n",
      "R14\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R15\tCONJUNCTION Arg1:T10 Arg2:T12\n",
      "R16\tFEATURE-OF Arg1:T26 Arg2:T25\n",
      "R17\tFEATURE-OF Arg1:T27 Arg2:T25\n",
      "R18\tFEATURE-OF Arg1:T28 Arg2:T25\n",
      "R19\tEVALUATE-FOR Arg1:T25 Arg2:T23\n",
      "R20\tCOREF Arg1:T23 Arg2:T30\n",
      "R21\tCOREF Arg1:T25 Arg2:T29\n",
      "R22\tEVALUATE-FOR Arg1:T29 Arg2:T30\n",
      "R23\tEVALUATE-FOR Arg1:T31 Arg2:T30\n",
      "R24\tCOMPARE Arg1:T30 Arg2:T33\n",
      "R25\tCOMPARE Arg1:T30 Arg2:T34\n",
      "R26\tCONJUNCTION Arg1:T33 Arg2:T34\n",
      "R27\tPART-OF Arg1:T21 Arg2:T22\n",
      "R28\tFEATURE-OF Arg1:T21 Arg2:T20\n",
      "R29\tEVALUATE-FOR Arg1:T20 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2012_29_abs.ann\n",
      "T1\tTask 36 75\toptimal alignment of non-rigid surfaces\n",
      "T2\tOtherScientificTerm 81 110\tmulti-view video observations\n",
      "T3\tMethod 123 159\ttemporally consistent representation\n",
      "T4\tMethod 174 200\tnon-rigid surface tracking\n",
      "T5\tMethod 210 234\tframe-to-frame alignment\n",
      "T6\tMethod 324 358\tnon-sequential tracking approaches\n",
      "T7\tMetric 420 441\tdissimilarity measure\n",
      "T8\tOtherScientificTerm 552 565\treduced drift\n",
      "T9\tMetric 580 590\trobustness\n",
      "T10\tOtherScientificTerm 600 622\tnon-rigid deformations\n",
      "T11\tOtherScientificTerm 684 692\tbranches\n",
      "T12\tOtherScientificTerm 700 704\ttree\n",
      "T13\tOtherScientificTerm 727 745\terror accumulation\n",
      "T14\tTask 758 782\tOptimisation of the tree\n",
      "T15\tMethod 787 810\tnon-sequential tracking\n",
      "T16\tMetric 842 862\ttemporal consistency\n",
      "T17\tMethod 921 933\tcluster tree\n",
      "T18\tTask 943 980\tsequential tracking in local segments\n",
      "T19\tOtherScientificTerm 966 980\tlocal segments\n",
      "T20\tOtherScientificTerm 1012 1043\tglobal non-sequential traversal\n",
      "T21\tGeneric 1056 1064\tsegments\n",
      "T22\tOtherScientificTerm 1104 1118\ttree structure\n",
      "T23\tOtherScientificTerm 1288 1306\tnon-rigid surfaces\n",
      "T24\tOtherScientificTerm 1317 1321\tface\n",
      "T25\tOtherScientificTerm 1323 1328\tcloth\n",
      "T26\tOtherScientificTerm 1333 1339\tpeople\n",
      "T27\tMethod 1375 1387\tcluster tree\n",
      "T28\tMetric 1404 1424\ttemporal consistency\n",
      "T29\tMethod 1443 1492\tsequential and non-sequential tracking approaches\n",
      "T30\tMetric 1529 1557\tsynthetic facial performance\n",
      "T31\tMethod 1591 1603\tcluster tree\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R5\tFEATURE-OF Arg1:T9 Arg2:T10\n",
      "R6\tCOREF Arg1:T15 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R8\tEVALUATE-FOR Arg1:T16 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R10\tUSED-FOR Arg1:T17 Arg2:T20\n",
      "R11\tCOREF Arg1:T19 Arg2:T21\n",
      "R12\tCOREF Arg1:T17 Arg2:T27\n",
      "R13\tEVALUATE-FOR Arg1:T28 Arg2:T27\n",
      "R14\tCOMPARE Arg1:T27 Arg2:T29\n",
      "R15\tCOREF Arg1:T27 Arg2:T31\n",
      "R16\tEVALUATE-FOR Arg1:T30 Arg2:T31\n",
      "R17\tHYPONYM-OF Arg1:T24 Arg2:T23\n",
      "R18\tHYPONYM-OF Arg1:T25 Arg2:T23\n",
      "R19\tHYPONYM-OF Arg1:T26 Arg2:T23\n",
      "R20\tCONJUNCTION Arg1:T24 Arg2:T25\n",
      "R21\tCONJUNCTION Arg1:T25 Arg2:T26\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2012_30_abs.ann\n",
      "T1\tTask 36 86\treconstructing the motion of a 3D articulated tree\n",
      "T2\tOtherScientificTerm 92 116\t2D point correspondences\n",
      "T3\tOtherScientificTerm 133 147\ttemporal prior\n",
      "T4\tOtherScientificTerm 159 172\tsmooth motion\n",
      "T5\tOtherScientificTerm 201 217\ttrajectory basis\n",
      "T6\tTask 230 256\thard combinatorial problem\n",
      "T7\tMetric 262 277\ttime complexity\n",
      "T8\tMethod 325 352\tBranch and bound strategies\n",
      "T9\tGeneric 392 402\tcomplexity\n",
      "T10\tOtherScientificTerm 422 439\tglobal optimality\n",
      "T11\tGeneric 450 454\tthey\n",
      "T12\tMethod 505 522\texhaustive search\n",
      "T13\tMethod 594 619\tcompact high-pass filters\n",
      "T14\tMethod 634 662\tdynamic programming approach\n",
      "T15\tOtherScientificTerm 755 774\tfilter interactions\n",
      "T16\tMethod 789 806\taffine projection\n",
      "T17\tTask 815 829\treconstruction\n",
      "T18\tMethod 838 856\testimating cameras\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R3\tCOREF Arg1:T9 Arg2:T7\n",
      "R4\tCOREF Arg1:T8 Arg2:T11\n",
      "R5\tCOMPARE Arg1:T11 Arg2:T12\n",
      "R6\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R7\tFEATURE-OF Arg1:T10 Arg2:T8\n",
      "R8\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R9\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R10\tCOREF Arg1:T1 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2012_37_abs.ann\n",
      "T1\tMethod 47 69\tdiscriminative patches\n",
      "T2\tTask 97 141\tunsupervised mid-level visual representation\n",
      "T3\tGeneric 377 384\tpatches\n",
      "T4\tGeneric 501 505\tthis\n",
      "T5\tTask 512 558\tunsupervised discriminative clustering problem\n",
      "T6\tMaterial 580 593\timage patches\n",
      "T7\tMethod 605 624\titerative procedure\n",
      "T8\tMethod 650 660\tclustering\n",
      "T9\tMethod 665 700\ttraining discriminative classifiers\n",
      "T10\tMethod 725 741\tcross-validation\n",
      "T11\tOtherScientificTerm 766 777\toverfitting\n",
      "T12\tMethod 838 860\tdiscriminative patches\n",
      "T13\tTask 867 911\tunsupervised mid-level visual representation\n",
      "T14\tGeneric 929 931\tit\n",
      "T15\tMethod 1000 1023\tdiscrim-inative patches\n",
      "T16\tTask 1046 1063\tsupervised regime\n",
      "T17\tTask 1073 1093\tscene classification\n",
      "T18\tGeneric 1101 1105\tthey\n",
      "T19\tMaterial 1154 1175\tMIT Indoor-67 dataset\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tCOREF Arg1:T3 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R8\tCOREF Arg1:T12 Arg2:T1\n",
      "R9\tCOREF Arg1:T13 Arg2:T2\n",
      "R10\tCOREF Arg1:T15 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R12\tHYPONYM-OF Arg1:T17 Arg2:T16\n",
      "R13\tCOREF Arg1:T18 Arg2:T15\n",
      "R14\tEVALUATE-FOR Arg1:T19 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2012_40_abs.ann\n",
      "T1\tMethod 28 41\tKAZE features\n",
      "T2\tMethod 51 108\tmultiscale 2D feature detection and description algorithm\n",
      "T3\tOtherScientificTerm 112 134\tnonlinear scale spaces\n",
      "T4\tOtherScientificTerm 244 264\tGaussian scale space\n",
      "T5\tOtherScientificTerm 287 304\tGaussian blurring\n",
      "T6\tOtherScientificTerm 334 355\tboundaries of objects\n",
      "T7\tMetric 421 462\tlocalization accuracy and distinctiveness\n",
      "T8\tMethod 500 511\t2D features\n",
      "T9\tOtherScientificTerm 517 538\tnonlinear scale space\n",
      "T10\tMethod 551 580\tnonlinear diffusion filtering\n",
      "T11\tMaterial 640 650\timage data\n",
      "T12\tOtherScientificTerm 681 698\tobject boundaries\n",
      "T13\tMetric 719 760\tlocalization accuracy and distinctiviness\n",
      "T14\tOtherScientificTerm 766 787\tnonlinear scale space\n",
      "T15\tMethod 813 857\tAdditive Operator Splitting (AOS) techniques\n",
      "T16\tMethod 862 893\tvariable con-ductance diffusion\n",
      "T17\tMaterial 933 951\tbenchmark datasets\n",
      "T18\tTask 968 1011\tmatching application on deformable surfaces\n",
      "T19\tGeneric 1029 1037\tfeatures\n",
      "T20\tMethod 1082 1086\tSURF\n",
      "T21\tOtherScientificTerm 1118 1139\tnonlinear scale space\n",
      "T22\tMethod 1159 1163\tSIFT\n",
      "T23\tGeneric 1169 1176\tresults\n",
      "T24\tTask 1222 1231\tdetection\n",
      "T25\tTask 1236 1247\tdescription\n",
      "T26\tGeneric 1265 1289\tstate-of-the-art methods\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R3\tFEATURE-OF Arg1:T9 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R5\tCOREF Arg1:T7 Arg2:T13\n",
      "R6\tCOREF Arg1:T8 Arg2:T19\n",
      "R7\tCOREF Arg1:T1 Arg2:T8\n",
      "R8\tCOMPARE Arg1:T19 Arg2:T20\n",
      "R9\tCOMPARE Arg1:T19 Arg2:T22\n",
      "R10\tCOREF Arg1:T19 Arg2:T23\n",
      "R11\tEVALUATE-FOR Arg1:T24 Arg2:T23\n",
      "R12\tEVALUATE-FOR Arg1:T25 Arg2:T23\n",
      "R13\tCONJUNCTION Arg1:T24 Arg2:T25\n",
      "R14\tCOMPARE Arg1:T23 Arg2:T26\n",
      "R15\tEVALUATE-FOR Arg1:T24 Arg2:T26\n",
      "R16\tEVALUATE-FOR Arg1:T25 Arg2:T26\n",
      "R17\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R18\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R19\tUSED-FOR Arg1:T16 Arg2:T14\n",
      "R20\tCOREF Arg1:T14 Arg2:T21\n",
      "R21\tCOREF Arg1:T9 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2014_47_abs.ann\n",
      "T1\tTask 15 56\tpredicting image or video interestingness\n",
      "T2\tMethod 68 101\tlow-level feature representations\n",
      "T3\tOtherScientificTerm 148 175\tsubjective visual attribute\n",
      "T4\tOtherScientificTerm 192 214\tinteresting-ness value\n",
      "T5\tMethod 247 263\tprediction model\n",
      "T6\tMethod 360 379\tcrowdsourcing tools\n",
      "T7\tOtherScientificTerm 391 411\tpairwise comparisons\n",
      "T8\tMethod 425 440\tmajority voting\n",
      "T9\tOtherScientificTerm 454 480\tannotation outliers/errors\n",
      "T10\tGeneric 526 529\tway\n",
      "T11\tOtherScientificTerm 542 561\tannotation outliers\n",
      "T12\tTask 581 612\tinterestingness prediction task\n",
      "T13\tMethod 618 641\tunified robust learning\n",
      "T14\tTask 645 657\trank problem\n",
      "T15\tTask 677 694\toutlier detection\n",
      "T16\tTask 699 731\tinterestingness prediction tasks\n",
      "T17\tMaterial 771 821\timage and video interestingness benchmark datasets\n",
      "T18\tGeneric 847 855\tapproach\n",
      "T19\tGeneric 882 911\tstate-of-the-art alternatives\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R6\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R8\tCOMPARE Arg1:T18 Arg2:T19\n",
      "R9\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T10 Arg2:T15\n",
      "R11\tUSED-FOR Arg1:T10 Arg2:T16\n",
      "R12\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R13\tCOREF Arg1:T10 Arg2:T18\n",
      "R14\tEVALUATE-FOR Arg1:T17 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2014_50_abs.ann\n",
      "T1\tGeneric 23 31\tapproach\n",
      "T2\tTask 48 112\tintrinsic texture properties (albedo, shading, normal) of scenes\n",
      "T3\tTask 118 143\tmultiple view acquisition\n",
      "T4\tOtherScientificTerm 150 181\tunknown illumination conditions\n",
      "T5\tOtherScientificTerm 211 229\tintrinsic textures\n",
      "T6\tOtherScientificTerm 241 274\tpixel-resolution surface textures\n",
      "T7\tOtherScientificTerm 292 323\tintrinsic appearance parameters\n",
      "T8\tMethod 352 376\tvideo relighting methods\n",
      "T9\tGeneric 382 390\tapproach\n",
      "T10\tOtherScientificTerm 418 432\tuniform albedo\n",
      "T11\tGeneric 446 448\tit\n",
      "T12\tMaterial 463 485\trichly textured scenes\n",
      "T13\tMethod 500 523\tintrinsic image methods\n",
      "T14\tTask 549 588\tinitial, low-frequency shading estimate\n",
      "T15\tOtherScientificTerm 600 630\tglobal lighting reconstruction\n",
      "T16\tOtherScientificTerm 648 681\ttexture and coarse scene geometry\n",
      "T17\tOtherScientificTerm 706 742\tinherent global ambiguity in shading\n",
      "T18\tGeneric 748 754\tmethod\n",
      "T19\tTask 769 808\trelight-ing of free-viewpoint rendering\n",
      "T20\tOtherScientificTerm 814 841\tmultiple view video capture\n",
      "T21\tTask 861 871\trelighting\n",
      "T22\tOtherScientificTerm 877 912\treproduction of fine surface detail\n",
      "R1\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T6 Arg2:T5\n",
      "R5\tCOMPARE Arg1:T9 Arg2:T8\n",
      "R6\tCOREF Arg1:T9 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R10\tFEATURE-OF Arg1:T16 Arg2:T15\n",
      "R11\tUSED-FOR Arg1:T14 Arg2:T17\n",
      "R12\tCOREF Arg1:T13 Arg2:T18\n",
      "R13\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R14\tFEATURE-OF Arg1:T22 Arg2:T21\n",
      "R15\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R16\tCOREF Arg1:T21 Arg2:T19\n",
      "R17\tCOREF Arg1:T1 Arg2:T9\n",
      "R18\tCOREF Arg1:T9 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2016_100_abs.ann\n",
      "T1\tGeneric 29 37\tapproach\n",
      "T2\tMethod 53 74\tvisual representation\n",
      "T3\tMaterial 84 120\traw spatiotemporal signals in videos\n",
      "T4\tGeneric 126 140\trepresentation\n",
      "T5\tOtherScientificTerm 160 192\tsupervision from semantic labels\n",
      "T6\tGeneric 211 217\tmethod\n",
      "T7\tTask 224 265\tunsupervised sequential verification task\n",
      "T8\tOtherScientificTerm 346 360\ttemporal order\n",
      "T9\tGeneric 379 383\ttask\n",
      "T10\tOtherScientificTerm 391 406\tsemantic labels\n",
      "T11\tMethod 428 449\tvisual representation\n",
      "T12\tMethod 458 492\tConvolutional Neural Network (CNN)\n",
      "T13\tGeneric 498 512\trepresentation\n",
      "T14\tOtherScientificTerm 522 547\tcomplementary information\n",
      "T15\tMaterial 569 594\tsupervised image datasets\n",
      "T16\tMaterial 600 608\tImageNet\n",
      "T17\tGeneric 644 650\tmethod\n",
      "T18\tOtherScientificTerm 708 718\thuman pose\n",
      "T19\tMethod 733 745\tpre-training\n",
      "T20\tTask 750 768\taction recognition\n",
      "T21\tMethod 771 781\tour method\n",
      "T22\tMethod 811 841\tlearning without external data\n",
      "T23\tGeneric 845 863\tbenchmark datasets\n",
      "T24\tMaterial 869 875\tUCF101\n",
      "T25\tMaterial 880 886\tHMDB51\n",
      "T26\tOtherScientificTerm 922 932\thuman pose\n",
      "T27\tTask 954 969\tpose estimation\n",
      "T28\tMaterial 977 999\tFLIC and MPII datasets\n",
      "T29\tGeneric 1037 1047\tapproaches\n",
      "T30\tOtherScientificTerm 1073 1084\tsupervision\n",
      "T31\tOtherScientificTerm 1086 1096\tOur method\n",
      "T32\tMethod 1118 1144\tsupervised representations\n",
      "T33\tMetric 1179 1187\taccuracy\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T2 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R5\tCOREF Arg1:T1 Arg2:T6\n",
      "R6\tCOREF Arg1:T7 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R9\tCOREF Arg1:T13 Arg2:T11\n",
      "R10\tPART-OF Arg1:T14 Arg2:T13\n",
      "R11\tHYPONYM-OF Arg1:T16 Arg2:T15\n",
      "R12\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R13\tCOREF Arg1:T6 Arg2:T17\n",
      "R14\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R15\tCOREF Arg1:T17 Arg2:T21\n",
      "R16\tCOMPARE Arg1:T21 Arg2:T22\n",
      "R17\tHYPONYM-OF Arg1:T24 Arg2:T23\n",
      "R18\tHYPONYM-OF Arg1:T25 Arg2:T23\n",
      "R19\tCONJUNCTION Arg1:T24 Arg2:T25\n",
      "R20\tEVALUATE-FOR Arg1:T23 Arg2:T22\n",
      "R21\tEVALUATE-FOR Arg1:T23 Arg2:T21\n",
      "R22\tUSED-FOR Arg1:T21 Arg2:T19\n",
      "R23\tEVALUATE-FOR Arg1:T28 Arg2:T27\n",
      "R24\tCOREF Arg1:T31 Arg2:T21\n",
      "R25\tCONJUNCTION Arg1:T32 Arg2:T31\n",
      "R26\tEVALUATE-FOR Arg1:T33 Arg2:T31\n",
      "R27\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R28\tUSED-FOR Arg1:T30 Arg2:T29\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2016_107_abs.ann\n",
      "T1\tMethod 0 8\tDiagrams\n",
      "T2\tOtherScientificTerm 43 59\tcomplex concepts\n",
      "T3\tOtherScientificTerm 62 75\trelationships\n",
      "T4\tOtherScientificTerm 80 86\tevents\n",
      "T5\tMaterial 158 172\tnatural images\n",
      "T6\tTask 174 202\tUnderstanding natural images\n",
      "T7\tMaterial 188 202\tnatural images\n",
      "T8\tTask 235 250\tcomputer vision\n",
      "T9\tTask 258 279\tdiagram understanding\n",
      "T10\tTask 350 386\tdiagram interpretation and reasoning\n",
      "T11\tGeneric 404 408\ttask\n",
      "T12\tOtherScientificTerm 428 450\tstructure of a diagram\n",
      "T13\tMethod 527 553\tDiagram Parse Graphs (DPG)\n",
      "T14\tOtherScientificTerm 589 610\tstructure of diagrams\n",
      "T15\tTask 622 651\tsyntactic parsing of diagrams\n",
      "T16\tMethod 673 677\tDPGs\n",
      "T17\tTask 701 750\tsemantic interpretation and reasoning of diagrams\n",
      "T18\tTask 769 795\tdiagram question answering\n",
      "T19\tMethod 810 827\tLSTM-based method\n",
      "T20\tTask 832 861\tsyntactic parsing of diagrams\n",
      "T21\tMethod 878 903\tDPG-based attention model\n",
      "T22\tTask 908 934\tdiagram question answering\n",
      "T23\tGeneric 953 960\tdataset\n",
      "T24\tMaterial 964 972\tdiagrams\n",
      "T25\tGeneric 1134 1140\tmodels\n",
      "T26\tTask 1145 1197\tsyntactic parsing and question answering in diagrams\n",
      "T27\tMethod 1204 1208\tDPGs\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R4\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R5\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R6\tCOREF Arg1:T7 Arg2:T5\n",
      "R7\tCOMPARE Arg1:T6 Arg2:T9\n",
      "R8\tPART-OF Arg1:T6 Arg2:T8\n",
      "R9\tCOREF Arg1:T10 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R12\tCOREF Arg1:T16 Arg2:T13\n",
      "R13\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R14\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R15\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R16\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R17\tCOREF Arg1:T22 Arg2:T18\n",
      "R18\tCOREF Arg1:T20 Arg2:T15\n",
      "R19\tFEATURE-OF Arg1:T24 Arg2:T23\n",
      "R20\tUSED-FOR Arg1:T25 Arg2:T26\n",
      "R21\tUSED-FOR Arg1:T27 Arg2:T25\n",
      "R22\tHYPONYM-OF Arg1:T20 Arg2:T26\n",
      "R23\tHYPONYM-OF Arg1:T22 Arg2:T26\n",
      "R24\tHYPONYM-OF Arg1:T19 Arg2:T25\n",
      "R25\tHYPONYM-OF Arg1:T21 Arg2:T25\n",
      "R26\tCOREF Arg1:T27 Arg2:T16\n",
      "R27\tHYPONYM-OF Arg1:T9 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2016_110_abs.ann\n",
      "T1\tTask 19 34\tcomputer vision\n",
      "T2\tMethod 54 74\thigh-capacity models\n",
      "T3\tMaterial 86 100\tlarge datasets\n",
      "T4\tMaterial 126 140\tlarge datasets\n",
      "T5\tOtherScientificTerm 146 164\tpixel-level labels\n",
      "T6\tGeneric 264 272\tapproach\n",
      "T7\tOtherScientificTerm 293 327\tpixel-accurate semantic label maps\n",
      "T8\tMaterial 332 338\timages\n",
      "T9\tOtherScientificTerm 354 375\tmodern computer games\n",
      "R1\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R4\tCOREF Arg1:T4 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tPART-OF Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2016_204_abs.ann\n",
      "T1\tTask 23 43\tMahalanobis distance\n",
      "T2\tOtherScientificTerm 60 64\tloss\n",
      "T3\tOtherScientificTerm 80 92\tweighted sum\n",
      "T4\tMetric 100 109\tprecision\n",
      "T5\tOtherScientificTerm 123 128\tranks\n",
      "T6\tOtherScientificTerm 171 189\tweighted rank loss\n",
      "T7\tTask 234 249\tcomputer vision\n",
      "T8\tTask 258 282\tperson re-identification\n",
      "T9\tMethod 303 330\tmetric learning formulation\n",
      "T10\tMethod 338 390\tWeighted Approximate Rank Component Analysis (WARCA)\n",
      "T11\tMethod 418 455\tstochastic gradient descent algorithm\n",
      "T12\tGeneric 474 490\tlearning problem\n",
      "T13\tMethod 520 549\tnon-linear extension of WARCA\n",
      "T14\tMethod 544 549\tWARCA\n",
      "T15\tMethod 563 575\tkernel trick\n",
      "T16\tOtherScientificTerm 577 599\tKernel space embedding\n",
      "T17\tOtherScientificTerm 614 643\ttraining and prediction costs\n",
      "T18\tOtherScientificTerm 653 667\tdata dimension\n",
      "T19\tMethod 691 720\tinarbitrary distance measures\n",
      "T20\tOtherScientificTerm 752 760\tfeatures\n",
      "T21\tOtherScientificTerm 804 828\tmatrix rank degeneration\n",
      "T22\tOtherScientificTerm 831 850\tnon-isolated minima\n",
      "T23\tTask 858 886\tlow-rank matrix optimization\n",
      "T24\tMethod 908 919\tregularizer\n",
      "T25\tOtherScientificTerm 953 968\tor-thonormality\n",
      "T26\tOtherScientificTerm 976 990\tlearned matrix\n",
      "T27\tGeneric 1030 1036\tmethod\n",
      "T28\tMaterial 1054 1087\tperson re-identification datasets\n",
      "T29\tMaterial 1108 1125\tscale Market-1501\n",
      "T30\tMaterial 1130 1145\tCUHK03 datasets\n",
      "T31\tGeneric 1223 1227\tthem\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T6 Arg2:T2\n",
      "R3\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R6\tHYPONYM-OF Arg1:T10 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R8\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "R9\tFEATURE-OF Arg1:T22 Arg2:T23\n",
      "R10\tFEATURE-OF Arg1:T21 Arg2:T23\n",
      "R11\tFEATURE-OF Arg1:T25 Arg2:T26\n",
      "R12\tUSED-FOR Arg1:T24 Arg2:T25\n",
      "R13\tEVALUATE-FOR Arg1:T28 Arg2:T27\n",
      "R14\tCONJUNCTION Arg1:T30 Arg2:T29\n",
      "R15\tHYPONYM-OF Arg1:T29 Arg2:T28\n",
      "R16\tHYPONYM-OF Arg1:T30 Arg2:T28\n",
      "R17\tCOREF Arg1:T31 Arg2:T28\n",
      "R18\tFEATURE-OF Arg1:T3 Arg2:T4\n",
      "R19\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R20\tCOREF Arg1:T27 Arg2:T13\n",
      "R21\tUSED-FOR Arg1:T16 Arg2:T19\n",
      "R22\tUSED-FOR Arg1:T24 Arg2:T23\n",
      "R23\tCOREF Arg1:T14 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2016_205_abs.ann\n",
      "T1\tGeneric 20 30\tapproaches\n",
      "T2\tTask 60 96\tmonocular nonrigid 3D reconstruction\n",
      "T3\tMethod 98 120\tTemplate-based methods\n",
      "T4\tMethod 125 167\tNon-rigid Structure from Motion techniques\n",
      "T5\tGeneric 185 189\tones\n",
      "T6\tOtherScientificTerm 223 247\tpoorly-textured surfaces\n",
      "T7\tGeneric 249 253\tthey\n",
      "T8\tMethod 283 297\t3D shape model\n",
      "T9\tTask 307 321\treconstruction\n",
      "T10\tGeneric 347 351\tones\n",
      "T11\tOtherScientificTerm 374 388\tshape template\n",
      "T12\tMaterial 446 460\tvideo sequence\n",
      "T13\tOtherScientificTerm 496 520\tpoorly-textured surfaces\n",
      "T14\tMethod 552 574\ttemplate-free approach\n",
      "T15\tOtherScientificTerm 595 630\tpoorly-textured, deformable surface\n",
      "T16\tMethod 657 673\tsurface isometry\n",
      "T17\tTask 688 705\t3D reconstruction\n",
      "T18\tTask 713 779\tjoint problem of non-rigid image registration and depth estimation\n",
      "T19\tGeneric 818 826\tapproach\n",
      "T20\tTask 853 871\t3D reconstructions\n",
      "T21\tGeneric 877 904\tstate-of-the-art techniques\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T4 Arg2:T1\n",
      "R4\tCOREF Arg1:T3 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R6\tCOREF Arg1:T5 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R8\tCOREF Arg1:T4 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R11\tCOREF Arg1:T14 Arg2:T19\n",
      "R12\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R13\tCOMPARE Arg1:T19 Arg2:T21\n",
      "R14\tEVALUATE-FOR Arg1:T20 Arg2:T19\n",
      "R15\tEVALUATE-FOR Arg1:T20 Arg2:T21\n",
      "R16\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R17\tCOREF Arg1:T17 Arg2:T20\n",
      "R18\tCOREF Arg1:T2 Arg2:T17\n",
      "R19\tCOREF Arg1:T2 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2016_212_abs.ann\n",
      "T1\tTask 0 24\tPerson re-identification\n",
      "T2\tOtherScientificTerm 71 75\tpose\n",
      "T3\tOtherScientificTerm 77 89\tillumination\n",
      "T4\tOtherScientificTerm 91 100\tocclusion\n",
      "T5\tOtherScientificTerm 105 116\tcamera view\n",
      "T6\tMaterial 149 164\tpedestrian data\n",
      "T7\tMethod 183 206\thighly-curved manifolds\n",
      "T8\tOtherScientificTerm 214 227\tfeature space\n",
      "T9\tMethod 249 284\tconvolutional neural networks (CNN)\n",
      "T10\tOtherScientificTerm 301 319\tfeature extraction\n",
      "T11\tOtherScientificTerm 389 406\tgeodesic distance\n",
      "T12\tMethod 460 482\tdeep embedding methods\n",
      "T13\tOtherScientificTerm 491 509\tEuclidean distance\n",
      "T14\tMethod 560 585\tmanifold learning methods\n",
      "T15\tOtherScientificTerm 605 623\tEuclidean distance\n",
      "T16\tOtherScientificTerm 631 642\tlocal range\n",
      "T17\tOtherScientificTerm 663 685\tgraphical relationship\n",
      "T18\tOtherScientificTerm 726 743\tgeodesic distance\n",
      "T19\tOtherScientificTerm 843 854\tlocal range\n",
      "T20\tOtherScientificTerm 884 897\tCNN embedding\n",
      "T21\tGeneric 919 923\tdata\n",
      "T22\tOtherScientificTerm 934 956\tintra-class variations\n",
      "T23\tMethod 992 1030\tmoderate positive sample mining method\n",
      "T24\tMethod 1040 1050\trobust CNN\n",
      "T25\tTask 1055 1079\tperson re-identification\n",
      "T26\tGeneric 1154 1162\tlearning\n",
      "T27\tOtherScientificTerm 1168 1192\tmetric weight constraint\n",
      "T28\tOtherScientificTerm 1206 1220\tlearned metric\n",
      "T29\tOtherScientificTerm 1234 1256\tgeneralization ability\n",
      "T30\tOtherScientificTerm 1327 1346\trobust deep metrics\n",
      "T31\tTask 1351 1375\tperson re-identification\n",
      "T32\tMethod 1397 1407\tdeep model\n",
      "T33\tGeneric 1438 1462\tstate-of-the-art methods\n",
      "T34\tTask 1488 1512\tperson re-identification\n",
      "T35\tMethod 1601 1612\tdeep models\n",
      "T36\tTask 1617 1641\tperson re-identification\n",
      "R1\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R3\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R5\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R6\tFEATURE-OF Arg1:T16 Arg2:T15\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T18\n",
      "R8\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R9\tCONJUNCTION Arg1:T15 Arg2:T17\n",
      "R10\tUSED-FOR Arg1:T23 Arg2:T24\n",
      "R11\tUSED-FOR Arg1:T24 Arg2:T25\n",
      "R12\tUSED-FOR Arg1:T27 Arg2:T26\n",
      "R13\tFEATURE-OF Arg1:T29 Arg2:T28\n",
      "R14\tUSED-FOR Arg1:T30 Arg2:T31\n",
      "R15\tCOMPARE Arg1:T32 Arg2:T33\n",
      "R16\tUSED-FOR Arg1:T32 Arg2:T34\n",
      "R17\tUSED-FOR Arg1:T33 Arg2:T34\n",
      "R18\tUSED-FOR Arg1:T35 Arg2:T36\n",
      "R19\tCOREF Arg1:T36 Arg2:T34\n",
      "R20\tCOREF Arg1:T34 Arg2:T25\n",
      "R21\tCOREF Arg1:T25 Arg2:T1\n",
      "R22\tFEATURE-OF Arg1:T22 Arg2:T21\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2016_215_abs.ann\n",
      "T1\tMethod 0 19\tJoint image filters\n",
      "T2\tMaterial 37 51\tguidance image\n",
      "T3\tMaterial 108 122\tguidance image\n",
      "T4\tTask 147 164\tsuppressing noise\n",
      "T5\tTask 168 196\tenhancing spatial resolution\n",
      "T6\tGeneric 198 214\tExisting methods\n",
      "T7\tMethod 240 268\texplicit filter construction\n",
      "T8\tMethod 272 305\thand-designed objective functions\n",
      "T9\tGeneric 367 371\tthem\n",
      "T10\tGeneric 377 395\tcoherent framework\n",
      "T11\tMethod 425 448\tlearning-based approach\n",
      "T12\tMethod 464 476\tjoint filter\n",
      "T13\tMethod 486 516\tConvolution-al Neural Networks\n",
      "T14\tGeneric 542 549\tmethods\n",
      "T15\tMaterial 573 587\tguidance image\n",
      "T16\tGeneric 593 599\tmethod\n",
      "T17\tTask 616 643\ttransfer salient structures\n",
      "T18\tGeneric 717 722\tmodel\n",
      "T19\tGeneric 752 756\tdata\n",
      "T20\tMaterial 764 784\tRGB and depth images\n",
      "T21\tGeneric 813 823\tmodalities\n",
      "T22\tMaterial 831 865\tFlash/Non-Flash and RGB/NIR images\n",
      "T23\tMethod 913 925\tjoint filter\n",
      "T24\tGeneric 961 985\tstate-of-the-art methods\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R3\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R4\tCOREF Arg1:T6 Arg2:T9\n",
      "R5\tCOREF Arg1:T14 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R7\tCOMPARE Arg1:T14 Arg2:T16\n",
      "R8\tCOREF Arg1:T18 Arg2:T16\n",
      "R9\tHYPONYM-OF Arg1:T20 Arg2:T19\n",
      "R10\tUSED-FOR Arg1:T19 Arg2:T18\n",
      "R11\tHYPONYM-OF Arg1:T22 Arg2:T21\n",
      "R12\tUSED-FOR Arg1:T18 Arg2:T21\n",
      "R13\tCOMPARE Arg1:T23 Arg2:T24\n",
      "R14\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R15\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R16\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R17\tCOREF Arg1:T1 Arg2:T12\n",
      "R18\tUSED-FOR Arg1:T13 Arg2:T11\n",
      "R19\tCOREF Arg1:T11 Arg2:T16\n",
      "R20\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R21\tCOREF Arg1:T12 Arg2:T23\n",
      "R22\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R23\tUSED-FOR Arg1:T1 Arg2:T5\n",
      "R24\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ECCV_2016_99_abs.ann\n",
      "T1\tTask 0 24\tHuman action recognition\n",
      "T2\tMaterial 30 61\twell-segmented 3D skeleton data\n",
      "T3\tTask 131 154\tOnline action detection\n",
      "T4\tOtherScientificTerm 223 234\taction type\n",
      "T5\tOtherScientificTerm 253 269\taction positions\n",
      "T6\tMaterial 290 306\tuntrimmed stream\n",
      "T7\tTask 347 370\tonline action detection\n",
      "T8\tMaterial 380 403\tstreaming skeleton data\n",
      "T9\tMethod 418 496\tmulti-task end-to-end Joint Classification-Regression Recurrent Neural Network\n",
      "T10\tOtherScientificTerm 519 530\taction type\n",
      "T11\tOtherScientificTerm 535 569\ttemporal localiza-tion information\n",
      "T12\tOtherScientificTerm 586 644\tjoint classification and regression optimization objective\n",
      "T13\tGeneric 651 658\tnetwork\n",
      "T14\tMethod 797 842\tdeep Long Short-Term Memory (LSTM) subnetwork\n",
      "T15\tGeneric 857 862\tmodel\n",
      "T16\tOtherScientificTerm 898 926\tlong-range temporal dynamics\n",
      "T17\tMethod 963 984\tsliding window design\n",
      "T18\tOtherScientificTerm 1007 1031\tcomputational efficiency\n",
      "T19\tTask 1061 1084\tregression optimization\n",
      "T20\tGeneric 1179 1184\tmodel\n",
      "T21\tMaterial 1203 1226\tstreaming video dataset\n",
      "T22\tGeneric 1273 1280\tdataset\n",
      "T23\tMaterial 1296 1307\tG3D dataset\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T3\n",
      "R6\tCOREF Arg1:T7 Arg2:T3\n",
      "R7\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R9\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R10\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R11\tCOREF Arg1:T13 Arg2:T9\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R13\tCOREF Arg1:T15 Arg2:T13\n",
      "R14\tFEATURE-OF Arg1:T16 Arg2:T15\n",
      "R15\tCOREF Arg1:T20 Arg2:T15\n",
      "R16\tEVALUATE-FOR Arg1:T21 Arg2:T20\n",
      "R17\tCOREF Arg1:T22 Arg2:T21\n",
      "R18\tCONJUNCTION Arg1:T22 Arg2:T23\n",
      "R19\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1001.ann\n",
      "T1\tMaterial 2 20\tOral communication\n",
      "T2\tTask 139 165\tstorage media and networks\n",
      "T3\tMaterial 202 214\tconversation\n",
      "T4\tMethod 350 382\tinformation retrieval techniques\n",
      "T5\tMethod 391 414\thistogram  of  keywords\n",
      "T6\tMethod 424 447\tdocument representation\n",
      "T7\tMaterial 454 472\toral communication\n",
      "T8\tOtherScientificTerm 605 613\tactivity\n",
      "T9\tOtherScientificTerm 622 632\tdiscussing\n",
      "T10\tOtherScientificTerm 634 642\tplanning\n",
      "T11\tOtherScientificTerm 644 653\tinforming\n",
      "T12\tOtherScientificTerm 655 668\tstory-telling\n",
      "T13\tTask 716 735\tautomatic detection\n",
      "T14\tGeneric 746 756\tactivities\n",
      "T15\tGeneric 890 900\tactivities\n",
      "T16\tMaterial 1003 1025\tdatabase  of  TV shows\n",
      "T17\tMaterial 1030 1038\tEmotions\n",
      "T18\tOtherScientificTerm 1073 1107\tdominance distribution of speakers\n",
      "R1\tCOREF Arg1:T7 Arg2:T1\n",
      "R2\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "R3\tHYPONYM-OF Arg1:T10 Arg2:T8\n",
      "R4\tHYPONYM-OF Arg1:T11 Arg2:T8\n",
      "R5\tHYPONYM-OF Arg1:T12 Arg2:T8\n",
      "R6\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R7\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R8\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R9\tCOREF Arg1:T14 Arg2:T8\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R11\tCOREF Arg1:T15 Arg2:T14\n",
      "R12\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R13\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1017.ann\n",
      "T1\tMethod 45 90\tmixed-initiative speech dialogue interactions\n",
      "T2\tMethod 136 152\tdialogue systems\n",
      "T3\tMethod 226 268\tdistributed message-passing infrastructure\n",
      "T4\tMethod 275 291\tdialogue systems\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tCOREF Arg1:T4 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1040.ann\n",
      "T1\tGeneric 42 49\toutputs\n",
      "T2\tMethod 56 91\tinformation extraction (IE) systems\n",
      "T3\tOtherScientificTerm 96 120\tnamed entity annotations\n",
      "T4\tOtherScientificTerm 127 145\tscenario templates\n",
      "T5\tMaterial 183 199\ttext collections\n",
      "T6\tMethod 217 229\ttext browser\n",
      "T7\tGeneric 280 296\tprototype system\n",
      "T8\tMaterial 355 382\tpharmaceutical news archive\n",
      "T9\tMetric 470 497\tqualitative user evaluation\n",
      "T10\tGeneric 506 512\tsystem\n",
      "T11\tMethod 655 680\tIE-enhanced text browsers\n",
      "R1\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R2\tHYPONYM-OF Arg1:T4 Arg2:T1\n",
      "R3\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R6\tCOREF Arg1:T10 Arg2:T7\n",
      "R7\tEVALUATE-FOR Arg1:T9 Arg2:T10\n",
      "R8\tCOREF Arg1:T11 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T1 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1041.ann\n",
      "T1\tMethod 55 99\tKorean-to-English machine translation system\n",
      "T2\tMethod 102 165\tCCLINC (Common Coalition Language System at Lincoln Laboratory)\n",
      "T3\tMethod 174 217\tCCLINC Korean-to-English translation system\n",
      "T4\tGeneric 236 248\tcore modules\n",
      "T5\tMethod 253 298\tlanguage understanding and generation modules\n",
      "T6\tMethod 315 354\tlanguage neutral meaning representation\n",
      "T7\tOtherScientificTerm 366 380\tsemantic frame\n",
      "T8\tGeneric 408 414\tsystem\n",
      "T9\tTask 446 465\tparsing  of  Korean\n",
      "T10\tMaterial 459 465\tKorean\n",
      "T11\tMaterial 471 490\tverb final language\n",
      "T12\tOtherScientificTerm 498 516\tovert case markers\n",
      "T13\tTask 611 622\ttranslation\n",
      "T14\tMethod 629 654\tword sense disambiguation\n",
      "T15\tTask 670 691\tword order generation\n",
      "T16\tMethod 787 836\tknowledge-based automated acquisition of grammars\n",
      "T17\tMaterial 864 889\tKorean newspaper articles\n",
      "T18\tMaterial 894 934\tmissiles and chemical biological warfare\n",
      "T19\tGeneric 940 946\tsystem\n",
      "R1\tPART-OF Arg1:T4 Arg2:T3\n",
      "R2\tFEATURE-OF Arg1:T12 Arg2:T11\n",
      "R3\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R4\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R5\tCOREF Arg1:T3 Arg2:T2\n",
      "R6\tCOREF Arg1:T5 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R8\tHYPONYM-OF Arg1:T7 Arg2:T6\n",
      "R9\tHYPONYM-OF Arg1:T10 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R11\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R12\tCOREF Arg1:T19 Arg2:T3\n",
      "R13\tUSED-FOR Arg1:T17 Arg2:T19\n",
      "R14\tCOREF Arg1:T8 Arg2:T3\n",
      "R15\tFEATURE-OF Arg1:T18 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1042.ann\n",
      "T1\tMethod 67 98\tautomated evaluation techniques\n",
      "T2\tTask 129 167\tevaluation of  human language learners\n",
      "T3\tMethod 191 223\tmachine translation (MT) systems\n",
      "T4\tGeneric 250 271\tevaluation techniques\n",
      "T5\tTask 314 345\thuman language learning process\n",
      "T6\tTask 354 373\ttranslation process\n",
      "T7\tTask 401 428\tmachine translation systems\n",
      "T8\tTask 538 555\tlanguage learning\n",
      "T9\tGeneric 581 590\tassessors\n",
      "T10\tMaterial 623 649\tnon-native language essays\n",
      "T11\tGeneric 731 740\tassessors\n",
      "T12\tOtherScientificTerm 863 889\tmachine translation output\n",
      "T13\tMaterial 945 969\ttranslated newswire text\n",
      "T14\tOtherScientificTerm 1000 1025\texpert human translations\n",
      "T15\tOtherScientificTerm 1042 1069\tmachine translation outputs\n",
      "T16\tOtherScientificTerm 1186 1210\texpert human translation\n",
      "T17\tOtherScientificTerm 1218 1237\tmachine translation\n",
      "R1\tCOREF Arg1:T4 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R4\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R5\tCONJUNCTION Arg1:T15 Arg2:T14\n",
      "R6\tCOREF Arg1:T7 Arg2:T3\n",
      "R7\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R8\tUSED-FOR Arg1:T4 Arg2:T7\n",
      "R9\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R10\tCOREF Arg1:T9 Arg2:T4\n",
      "R11\tCOREF Arg1:T11 Arg2:T9\n",
      "R12\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R13\tEVALUATE-FOR Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1049.ann\n",
      "T1\tTask 2 31\tListen-Communicate-Show (LCS)\n",
      "T2\tTask 56 91\thuman interaction with data sources\n",
      "T3\tMethod 111 147\tspoken language understanding system\n",
      "T4\tMethod 155 180\tintelligent mobile agents\n",
      "T5\tMaterial 216 235\tinformation sources\n",
      "T6\tGeneric 297 305\tapproach\n",
      "T7\tTask 314 324\tLCS-Marine\n",
      "T8\tTask 335 345\tLCS-Marine\n",
      "T9\tMethod 479 504\tmobile, intelligent agent\n",
      "T10\tGeneric 587 593\tsystem\n",
      "T11\tMaterial 827 838\tnew domains\n",
      "R1\tPART-OF Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T8 Arg2:T7\n",
      "R4\tCOREF Arg1:T10 Arg2:T8\n",
      "R5\tCOREF Arg1:T6 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1055.ann\n",
      "T1\tMethod 23 62\tAutomatic Speech Recognition technology\n",
      "T2\tTask 105 119\tdialog systems\n",
      "T3\tTask 158 176\tspeech recognition\n",
      "T4\tTask 218 232\tdialog systems\n",
      "T5\tGeneric 281 285\tthey\n",
      "T6\tOtherScientificTerm 360 375\tsystem response\n",
      "T7\tTask 425 462\tnatural language generation community\n",
      "T8\tTask 499 513\tdialog systems\n",
      "T9\tTask 542 552\tgeneration\n",
      "T10\tTask 573 587\tdialog systems\n",
      "T11\tMethod 616 665\thand-crafting  knowledge-based generation systems\n",
      "T12\tMethod 697 724\tmachine learning techniques\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tPART-OF Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R4\tCOREF Arg1:T8 Arg2:T4\n",
      "R5\tCOREF Arg1:T4 Arg2:T2\n",
      "R6\tCOREF Arg1:T10 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R8\tCOREF Arg1:T5 Arg2:T4\n",
      "R9\tCOMPARE Arg1:T7 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1058.ann\n",
      "T1\tMethod 61 82\tlanguage models (LMs)\n",
      "T2\tMethod 107 128\tinterpolation methods\n",
      "T3\tMethod 138 173\tlog-linear and linear interpolation\n",
      "T4\tMetric 374 401\tword or semantic error rate\n",
      "T5\tMethod 502 504\tLM\n",
      "T6\tMethod 544 560\tdynamic combiner\n",
      "T7\tOtherScientificTerm 568 582\thard decisions\n",
      "T8\tMethod 674 708\tdynamic language model combination\n",
      "T9\tGeneric 762 768\tmethod\n",
      "T10\tMethod 819 833\tneural network\n",
      "T11\tMethod 841 854\tdecision tree\n",
      "T12\tGeneric 862 868\tmethod\n",
      "T13\tMethod 889 892\tLMs\n",
      "T14\tMetric 900 919\tconfidence measures\n",
      "T15\tMethod 977 979\tLM\n",
      "R1\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R2\tCOREF Arg1:T8 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R5\tCONJUNCTION Arg1:T11 Arg2:T10\n",
      "R6\tCOREF Arg1:T12 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R8\tCOREF Arg1:T15 Arg2:T13\n",
      "R9\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H01-1070.ann\n",
      "T1\tGeneric 33 41\tapproach\n",
      "T2\tMethod 53 66\tn-gram models\n",
      "T3\tMethod 73 95\terror-correction rules\n",
      "T4\tTask 102 121\tThai key prediction\n",
      "T5\tTask 128 164\tThai-English language identification\n",
      "T6\tMethod 193 217\trule-reduction algorithm\n",
      "T7\tOtherScientificTerm 229 247\tmutual information\n",
      "T8\tOtherScientificTerm 264 286\terror-correction rules\n",
      "T9\tGeneric 294 303\talgorithm\n",
      "T10\tMetric 328 336\taccuracy\n",
      "T11\tTask 347 370\tlanguage identification\n",
      "T12\tTask 377 391\tkey prediction\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T5\n",
      "R6\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R7\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R8\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T9 Arg2:T12\n",
      "R11\tCOREF Arg1:T1 Arg2:T9\n",
      "R12\tEVALUATE-FOR Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-1005.ann\n",
      "T1\tOtherScientificTerm 28 74\tinformation redundancy  in  multilingual input\n",
      "T2\tTask 98 117\tmachine translation\n",
      "T3\tTask 152 174\tmultilingual summaries\n",
      "T4\tTask 203 231\tmulti-document summarization\n",
      "T5\tMaterial 271 277\tArabic\n",
      "T6\tMaterial 313 320\tEnglish\n",
      "T7\tOtherScientificTerm 403 426\tlexical-syntactic forms\n",
      "T8\tMethod 485 512\tmachine translation systems\n",
      "T9\tMaterial 605 612\tEnglish\n",
      "T10\tTask 650 670\tmachine translations\n",
      "T11\tMaterial 686 702\tArabic documents\n",
      "R1\tCOREF Arg1:T10 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-1012.ann\n",
      "T1\tMethod 24 64\tmaximum entropy word alignment algorithm\n",
      "T2\tMaterial 71 85\tArabic-English\n",
      "T3\tMaterial 97 121\tsupervised training data\n",
      "T4\tMaterial 171 188\ttraining material\n",
      "T5\tTask 207 226\tmachine translation\n",
      "T6\tMethod 251 286\tsupervised and unsupervised methods\n",
      "T7\tMethod 325 344\tprobabilistic model\n",
      "T8\tTask 359 368\talignment\n",
      "T9\tTask 391 405\tlink decisions\n",
      "T10\tMethod 451 476\tword alignment techniques\n",
      "T11\tOtherScientificTerm 522 547\tmachine translation tests\n",
      "T12\tGeneric 570 579\talgorithm\n",
      "T13\tOtherScientificTerm 600 616\thuman annotation\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R7\tCOREF Arg1:T12 Arg2:T1\n",
      "R8\tCOMPARE Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-1041.ann\n",
      "T1\tMethod 27 55\tunsupervised learning method\n",
      "T2\tOtherScientificTerm 69 91\tsingle-snippet answers\n",
      "T3\tMethod 123 149\tquestion answering systems\n",
      "T4\tMethod 168 186\tWeb search engines\n",
      "T5\tGeneric 193 199\tmethod\n",
      "T6\tMaterial 210 248\ton-line encyclopedias and dictionaries\n",
      "T7\tMaterial 308 349\tpositive and negative definition examples\n",
      "T8\tMethod 385 388\tsvm\n",
      "T9\tGeneric 460 466\tmethod\n",
      "T10\tGeneric 483 485\tit\n",
      "T11\tGeneric 502 513\talternative\n",
      "T12\tGeneric 531 537\tsystem\n",
      "T13\tMaterial 559 572\tnews articles\n",
      "T14\tMaterial 578 582\ttrec\n",
      "T15\tGeneric 594 596\tit\n",
      "T16\tMethod 608 621\tsearch engine\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R3\tCOREF Arg1:T9 Arg2:T5\n",
      "R4\tCOREF Arg1:T1 Arg2:T5\n",
      "R5\tCOREF Arg1:T10 Arg2:T9\n",
      "R6\tCOMPARE Arg1:T10 Arg2:T11\n",
      "R7\tCOREF Arg1:T16 Arg2:T4\n",
      "R8\tCOREF Arg1:T15 Arg2:T9\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R10\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R11\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R12\tCOREF Arg1:T12 Arg2:T3\n",
      "R13\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R14\tPART-OF Arg1:T13 Arg2:T14\n",
      "R15\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-1064.ann\n",
      "T1\tGeneric 19 25\tmethod\n",
      "T2\tOtherScientificTerm 53 67\tNLP structures\n",
      "T3\tMethod 77 97\treranking approaches\n",
      "T4\tMethod 118 146\tconditional log-linear model\n",
      "T5\tOtherScientificTerm 155 171\thidden variables\n",
      "T6\tOtherScientificTerm 226 239\tword clusters\n",
      "T7\tOtherScientificTerm 245 256\tword senses\n",
      "T8\tGeneric 263 268\tmodel\n",
      "T9\tMetric 330 363\tdiscriminative training criterion\n",
      "T10\tGeneric 401 406\tmodel\n",
      "T11\tOtherScientificTerm 455 482\thidden-variable assignments\n",
      "T12\tGeneric 498 508\tsummations\n",
      "T13\tMethod 556 575\tdynamic programming\n",
      "T14\tGeneric 608 613\tmodel\n",
      "T15\tTask 618 633\tparse reranking\n",
      "T16\tGeneric 640 645\tmodel\n",
      "T17\tMetric 656 665\tF-measure\n",
      "T18\tMethod 701 712\tbase parser\n",
      "T19\tMethod 749 772\tCollins (2000) reranker\n",
      "T20\tTask 816 823\tparsing\n",
      "T21\tGeneric 830 840\ttechniques\n",
      "T22\tOtherScientificTerm 876 890\tNLP structures\n",
      "T23\tOtherScientificTerm 904 915\tparse trees\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tCOMPARE Arg1:T18 Arg2:T19\n",
      "R3\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tCOREF Arg1:T8 Arg2:T4\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R7\tCOREF Arg1:T10 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R9\tCOREF Arg1:T14 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R11\tEVALUATE-FOR Arg1:T17 Arg2:T16\n",
      "R12\tCOREF Arg1:T16 Arg2:T14\n",
      "R13\tCOMPARE Arg1:T16 Arg2:T18\n",
      "R14\tCOREF Arg1:T21 Arg2:T16\n",
      "R15\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R16\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R17\tCONJUNCTION Arg1:T23 Arg2:T22\n",
      "R18\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R19\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R20\tUSED-FOR Arg1:T21 Arg2:T23\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-1095.ann\n",
      "T1\tMethod 24 75\tphrase-based statistical machine translation method\n",
      "T2\tMaterial 89 111\tnon-contiguous phrases\n",
      "T3\tGeneric 143 149\tmethod\n",
      "T4\tGeneric 170 177\tphrases\n",
      "T5\tMaterial 187 207\tword-aligned corpora\n",
      "T6\tMethod 225 254\tstatistical translation model\n",
      "T7\tGeneric 291 298\tphrases\n",
      "T8\tMethod 316 331\ttraining method\n",
      "T9\tMetric 346 383\tmaximization of  translation accuracy\n",
      "T10\tMetric 409 431\tNIST evaluation metric\n",
      "T11\tOtherScientificTerm 436 448\tTranslations\n",
      "T12\tMethod 478 497\tbeam-search decoder\n",
      "T13\tGeneric 571 577\tmethod\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R4\tCOREF Arg1:T4 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R6\tEVALUATE-FOR Arg1:T5 Arg2:T3\n",
      "R7\tCOREF Arg1:T7 Arg2:T4\n",
      "R8\tEVALUATE-FOR Arg1:T10 Arg2:T6\n",
      "R9\tCOREF Arg1:T13 Arg2:T1\n",
      "R10\tCOREF Arg1:T6 Arg2:T1\n",
      "R11\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-1101.ann\n",
      "T1\tOtherScientificTerm 33 55\tcomputational problems\n",
      "T2\tMethod 74 106\tprobabilistic translation models\n",
      "T3\tTask 162 181\tmachine translation\n",
      "T4\tGeneric 192 198\tmodels\n",
      "T5\tMethod 227 262\tprobabilistic context-free grammars\n",
      "T6\tOtherScientificTerm 367 395\texponential time lower-bound\n",
      "R1\tFEATURE-OF Arg1:T1 Arg2:T2\n",
      "R2\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R4\tCOREF Arg1:T4 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-1115.ann\n",
      "T1\tTask 29 64\tquestion-focused sentence retrieval\n",
      "T2\tMaterial 80 93\tnews articles\n",
      "T3\tMaterial 107 126\tmulti-event stories\n",
      "T4\tTask 462 488\tsentence retrieval problem\n",
      "T5\tMethod 503 533\tstochastic, graph-based method\n",
      "T6\tTask 641 662\tgeneric summarization\n",
      "T7\tGeneric 721 727\tmethod\n",
      "T8\tGeneric 750 752\tit\n",
      "T9\tGeneric 783 791\tbaseline\n",
      "T10\tOtherScientificTerm 874 899\tIDF-weighted word overlap\n",
      "T11\tGeneric 927 933\tmethod\n",
      "T12\tMetric 947 957\tTRDR score\n",
      "T13\tGeneric 1006 1014\tbaseline\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R6\tCOREF Arg1:T7 Arg2:T5\n",
      "R7\tCOREF Arg1:T11 Arg2:T7\n",
      "R8\tCOREF Arg1:T13 Arg2:T9\n",
      "R9\tEVALUATE-FOR Arg1:T12 Arg2:T11\n",
      "R10\tEVALUATE-FOR Arg1:T12 Arg2:T13\n",
      "R11\tCOREF Arg1:T8 Arg2:T7\n",
      "R12\tCOMPARE Arg1:T9 Arg2:T8\n",
      "R13\tCOMPARE Arg1:T11 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-1117.ann\n",
      "T1\tTask 39 59\tautomatic evaluation\n",
      "T2\tTask 39 113\tautomatic evaluation  of  machine translation  and  document summarization\n",
      "T3\tTask 65 84\tmachine translation\n",
      "T4\tTask 91 113\tdocument summarization\n",
      "T5\tGeneric 138 146\tapproach\n",
      "T6\tGeneric 165 172\tmeasure\n",
      "T7\tMetric 181 188\tPOURPRE\n",
      "T8\tTask 197 253\tautomatically evaluating answers to definition questions\n",
      "T9\tMaterial 587 620\tTREC 2003 and TREC 2004 QA tracks\n",
      "T10\tOtherScientificTerm 637 645\trankings\n",
      "T11\tGeneric 663 669\tmetric\n",
      "T12\tOtherScientificTerm 693 710\tofficial rankings\n",
      "T13\tMetric 724 731\tPOURPRE\n",
      "T14\tGeneric 776 783\tmetrics\n",
      "R1\tEVALUATE-FOR Arg1:T1 Arg2:T3\n",
      "R2\tEVALUATE-FOR Arg1:T1 Arg2:T4\n",
      "R3\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T7 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R6\tCOREF Arg1:T13 Arg2:T7\n",
      "R7\tCOREF Arg1:T11 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R9\tEVALUATE-FOR Arg1:T9 Arg2:T11\n",
      "R10\tCOREF Arg1:T11 Arg2:T13\n",
      "R11\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R12\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R13\tEVALUATE-FOR Arg1:T9 Arg2:T13\n",
      "R14\tEVALUATE-FOR Arg1:T9 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H05-2007.ann\n",
      "T1\tGeneric 15 21\tmethod\n",
      "T2\tOtherScientificTerm 38 80\tsystematic  patterns  in  translation data\n",
      "T3\tMaterial 89 117\tpart-of-speech tag sequences\n",
      "T4\tGeneric 141 149\tanalysis\n",
      "T5\tMethod 158 173\tdiagnostic tool\n",
      "T6\tMethod 205 232\tmachine translation systems\n",
      "T7\tGeneric 260 271\tapplication\n",
      "T8\tOtherScientificTerm 312 352\tpatterns  in  machine translation output\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R2\tCOREF Arg1:T1 Arg2:T4\n",
      "R3\tPART-OF Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R5\tCOREF Arg1:T7 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H89-1027.ann\n",
      "T1\tMethod 48 103\tphonetically-based spoken language understanding system\n",
      "T2\tMethod 113 119\tSUMMIT\n",
      "T3\tMethod 180 195\theuristic rules\n",
      "T4\tMethod 233 254\tknowledge engineering\n",
      "T5\tGeneric 261 269\tapproach\n",
      "T6\tOtherScientificTerm 295 311\tspeech knowledge\n",
      "T7\tMethod 358 376\tmathematical tools\n",
      "T8\tGeneric 385 391\tsystem\n",
      "T9\tOtherScientificTerm 394 402\tfeatures\n",
      "T10\tMethod 409 428\tdecision strategies\n",
      "T11\tMaterial 495 506\tspeech data\n",
      "T12\tGeneric 534 540\tsystem\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R3\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R5\tCOREF Arg1:T5 Arg2:T2\n",
      "R6\tCOREF Arg1:T8 Arg2:T5\n",
      "R7\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R8\tCOREF Arg1:T12 Arg2:T8\n",
      "R9\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H89-2019.ann\n",
      "T1\tMethod 48 116\tdomain-independent means of evaluating Spoken Language Systems (SLS)\n",
      "T2\tGeneric 134 142\tsoftware\n",
      "T3\tMethod 186 196\tComparator\n",
      "T4\tGeneric 214 228\tspecifications\n",
      "T5\tOtherScientificTerm 235 253\tanswer expressions\n",
      "T6\tMethod 262 289\tCommon Answer Specification\n",
      "T7\tMethod 297 300\tCAS\n",
      "T8\tMethod 309 319\tComparator\n",
      "T9\tMethod 362 365\tSLS\n",
      "T10\tMethod 439 466\tCommon Answer Specification\n",
      "T11\tOtherScientificTerm 484 514\tsyntax  of  answer expressions\n",
      "T12\tMethod 667 677\tComparator\n",
      "T13\tOtherScientificTerm 708 711\tCAS\n",
      "T14\tMethod 758 777\tComparator software\n",
      "T15\tMethod 815 827\tCAS approach\n",
      "R1\tCOREF Arg1:T3 Arg2:T2\n",
      "R2\tCOREF Arg1:T7 Arg2:T6\n",
      "R3\tCOREF Arg1:T8 Arg2:T3\n",
      "R4\tCOREF Arg1:T9 Arg2:T1\n",
      "R5\tCOREF Arg1:T10 Arg2:T7\n",
      "R6\tCOREF Arg1:T12 Arg2:T8\n",
      "R7\tCOREF Arg1:T13 Arg2:T10\n",
      "R8\tCOREF Arg1:T15 Arg2:T13\n",
      "R9\tCOREF Arg1:T14 Arg2:T8\n",
      "R10\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R11\tCOREF Arg1:T6 Arg2:T4\n",
      "R12\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R13\tCONJUNCTION Arg1:T2 Arg2:T4\n",
      "R14\tPART-OF Arg1:T2 Arg2:T1\n",
      "R15\tPART-OF Arg1:T4 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H89-2066.ann\n",
      "T1\tMethod 44 66\tspoken language system\n",
      "T2\tMaterial 109 120\tvoice input\n",
      "T3\tTask 127 154\tinteractive problem solving\n",
      "T4\tMaterial 181 198\tcontinuous speech\n",
      "T5\tTask 287 305\tspeech recognition\n",
      "T6\tTask 312 339\tnatural language processing\n",
      "T7\tTask 353 373\tspeech understanding\n",
      "T8\tGeneric 380 386\tsystem\n",
      "T9\tMethod 503 556\trobust and high-performance speech recognition system\n",
      "T10\tMethod 567 589\tsegment-based approach\n",
      "T11\tTask 595 615\tphonetic recognition\n",
      "T12\tMethod 623 641\trecognition system\n",
      "T13\tTask 679 706\tnatural language processing\n",
      "T14\tTask 720 749\tspoken language understanding\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R4\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R6\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R7\tCOREF Arg1:T8 Arg2:T1\n",
      "R8\tCOREF Arg1:T9 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R10\tCOREF Arg1:T12 Arg2:T9\n",
      "R11\tCONJUNCTION Arg1:T13 Arg2:T12\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R13\tCOREF Arg1:T14 Arg2:T7\n",
      "R14\tCOREF Arg1:T13 Arg2:T6\n",
      "R15\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R16\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H90-1011.ann\n",
      "T1\tGeneric 35 43\tapproach\n",
      "T2\tTask 48 55\tparsing\n",
      "T3\tTask 91 116\tunification-based parsing\n",
      "T4\tTask 126 171\tclassification-based knowledge representation\n",
      "T5\tMethod 178 218\tunification-based grammatical frameworks\n",
      "T6\tOtherScientificTerm 267 289\tlinguistic information\n",
      "T7\tGeneric 292 296\tthey\n",
      "T8\tMethod 364 408\tKL-ONE-like knowledge representation systems\n",
      "T9\tMethod 455 501\tclassification-based representation techniques\n",
      "T10\tOtherScientificTerm 522 563\tunification-based linguistic descriptions\n",
      "T11\tOtherScientificTerm 608 642\tsemantic and syntactic information\n",
      "T12\tGeneric 658 664\tsystem\n",
      "T13\tMethod 790 797\tparsing\n",
      "T14\tMethod 861 888\tKL-ONE style representation\n",
      "T15\tTask 895 902\tparsing\n",
      "T16\tTask 909 932\tsemantic interpretation\n",
      "T17\tMethod 961 977\tPSI-KLONE system\n",
      "T18\tTask 994 1001\tparsing\n",
      "T19\tMethod 1026 1043\tinference process\n",
      "T20\tMethod 1052 1086\tincremental description refinement\n",
      "R1\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R2\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R5\tCONJUNCTION Arg1:T4 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R7\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R8\tCOREF Arg1:T7 Arg2:T5\n",
      "R9\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R10\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R12\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R13\tUSED-FOR Arg1:T17 Arg2:T14\n",
      "R14\tCOREF Arg1:T18 Arg2:T15\n",
      "R15\tHYPONYM-OF Arg1:T20 Arg2:T19\n",
      "R16\tCOREF Arg1:T14 Arg2:T8\n",
      "R17\tCOREF Arg1:T15 Arg2:T13\n",
      "R18\tCOREF Arg1:T12 Arg2:T1\n",
      "R19\tUSED-FOR Arg1:T20 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H90-1016.ann\n",
      "T1\tGeneric 19 26\tmethods\n",
      "T2\tGeneric 31 39\thardware\n",
      "T3\tMethod 102 135\tintegrated Spoken Language System\n",
      "T4\tGeneric 151 161\talgorithms\n",
      "T5\tOtherScientificTerm 221 247\tN-Best sentence hypotheses\n",
      "T6\tOtherScientificTerm 261 286\tgrammar coverage problems\n",
      "T7\tMethod 298 351\tfully-connected first-order statistical class grammar\n",
      "T8\tMethod 360 383\tspeech-search algorithm\n",
      "T9\tOtherScientificTerm 406 411\tboard\n",
      "T10\tOtherScientificTerm 428 443\tIntel i860 chip\n",
      "T11\tOtherScientificTerm 493 498\tSUN 4\n",
      "T12\tOtherScientificTerm 505 520\tstraight C code\n",
      "T13\tOtherScientificTerm 529 534\tboard\n",
      "T14\tOtherScientificTerm 561 568\tVME bus\n",
      "T15\tOtherScientificTerm 578 582\tSUN4\n",
      "T16\tGeneric 605 611\tsystem\n",
      "T17\tMethod 630 653\tnatural language system\n",
      "T18\tOtherScientificTerm 660 680\tapplication back end\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R2\tPART-OF Arg1:T14 Arg2:T15\n",
      "R3\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R7\tCOMPARE Arg1:T10 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R10\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R11\tCOREF Arg1:T16 Arg2:T3\n",
      "R12\tCOREF Arg1:T8 Arg2:T4\n",
      "R13\tCOREF Arg1:T4 Arg2:T1\n",
      "R14\tPART-OF Arg1:T10 Arg2:T9\n",
      "R15\tCOREF Arg1:T9 Arg2:T13\n",
      "R16\tUSED-FOR Arg1:T13 Arg2:T16\n",
      "R17\tPART-OF Arg1:T17 Arg2:T13\n",
      "R18\tPART-OF Arg1:T18 Arg2:T13\n",
      "R19\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H90-1060.ann\n",
      "T1\tTask 47 93\tlarge vocabulary continuous speech recognition\n",
      "T2\tTask 135 200\tspeaker-independent (SI) training  of  hidden Markov models (HMM)\n",
      "T3\tMaterial 234 240\tspeech\n",
      "T4\tOtherScientificTerm 413 472\taveraging the  statistics  of  independently trained models\n",
      "T5\tOtherScientificTerm 496 527\tpooling of all the  speech data\n",
      "T6\tTask 610 624\tSI recognition\n",
      "T7\tMetric 648 663\tword error rate\n",
      "T8\tMaterial 714 746\tDARPA Resource Management corpus\n",
      "T9\tTask 905 928\tspeaker adaptation (SA)\n",
      "T10\tMaterial 945 954\tSI corpus\n",
      "T11\tMethod 1024 1054\tprobabilistic spectral mapping\n",
      "T12\tMethod 1156 1171\treference model\n",
      "T13\tTask 1315 1325\tadaptation\n",
      "T14\tMetric 1334 1344\terror rate\n",
      "T15\tTask 1408 1410\tSI\n",
      "R1\tEVALUATE-FOR Arg1:T10 Arg2:T9\n",
      "R2\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R3\tEVALUATE-FOR Arg1:T8 Arg2:T6\n",
      "R4\tCOREF Arg1:T13 Arg2:T9\n",
      "R5\tCOREF Arg1:T15 Arg2:T6\n",
      "R6\tCOMPARE Arg1:T4 Arg2:T5\n",
      "R7\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H91-1010.ann\n",
      "T1\tMethod 45 63\tLincoln CSR system\n",
      "T2\tMethod 90 108\tsemiphone modeling\n",
      "T3\tMethod 152 166\tduration model\n",
      "T4\tMetric 185 195\terror rate\n",
      "T5\tMethod 219 249\ttriphone and semiphone systems\n",
      "T6\tMethod 259 276\ttraining strategy\n",
      "T7\tMethod 408 434\trapid adaptation technique\n",
      "T8\tMethod 450 460\trecognizer\n",
      "T9\tMethod 488 519\tbigram back-off language models\n",
      "T10\tGeneric 526 532\tsystem\n",
      "T11\tTask 564 571\tRM task\n",
      "T12\tTask 581 594\tATIS CSR task\n",
      "T13\tTask 701 722\tRM and ATIS CSR tasks\n",
      "R1\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R3\tHYPONYM-OF Arg1:T2 Arg2:T5\n",
      "R4\tHYPONYM-OF Arg1:T11 Arg2:T13\n",
      "R5\tHYPONYM-OF Arg1:T12 Arg2:T13\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R8\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R9\tEVALUATE-FOR Arg1:T4 Arg2:T5\n",
      "R10\tCOREF Arg1:T1 Arg2:T10\n",
      "R11\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H91-1067.ann\n",
      "T1\tGeneric 37 44\tprogram\n",
      "T2\tMaterial 59 77\ttagged text corpus\n",
      "T3\tOtherScientificTerm 116 140\tsubcategorization frames\n",
      "T4\tMetric 302 322\tFalse positive rates\n",
      "T5\tOtherScientificTerm 356 380\tsubcategorization frames\n",
      "T6\tMaterial 500 528\tsubcategorization dictionary\n",
      "R1\tEVALUATE-FOR Arg1:T2 Arg2:T1\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\H91-1077.ann\n",
      "T1\tGeneric 3 9\tmethod\n",
      "T2\tTask 14 30\tsense resolution\n",
      "T3\tMaterial 62 69\tWordNet\n",
      "T4\tMaterial 75 100\ton-line  lexical database\n",
      "T5\tOtherScientificTerm 121 139\tsemantic relations\n",
      "T6\tOtherScientificTerm 143 151\tsynonymy\n",
      "T7\tOtherScientificTerm 155 163\tantonymy\n",
      "T8\tOtherScientificTerm 167 175\thyponymy\n",
      "T9\tOtherScientificTerm 179 187\tmeronymy\n",
      "T10\tOtherScientificTerm 191 223\tcausal and troponymic entailment\n",
      "T11\tMaterial 277 284\tWordNet\n",
      "T12\tOtherScientificTerm 319 345\tsemantically related words\n",
      "T13\tTask 382 398\tsense resolution\n",
      "T14\tTask 408 423\ttext processing\n",
      "T15\tGeneric 502 512\tprocedures\n",
      "T16\tOtherScientificTerm 580 598\talternative senses\n",
      "T17\tOtherScientificTerm 608 623\tpolysemous word\n",
      "T18\tOtherScientificTerm 739 754\tpolysemous word\n",
      "T19\tOtherScientificTerm 978 993\tpolysemous word\n",
      "T20\tMaterial 1106 1113\tWordNet\n",
      "T21\tOtherScientificTerm 1150 1167\tsemantic distance\n",
      "T22\tGeneric 1372 1381\tprocedure\n",
      "T23\tTask 1432 1453\tinformation retrieval\n",
      "T24\tTask 1457 1479\tmechanical translation\n",
      "T25\tTask 1483 1511\tintelligent tutoring systems\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R2\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R3\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R6\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R7\tHYPONYM-OF Arg1:T7 Arg2:T5\n",
      "R8\tHYPONYM-OF Arg1:T8 Arg2:T5\n",
      "R9\tHYPONYM-OF Arg1:T9 Arg2:T5\n",
      "R10\tHYPONYM-OF Arg1:T10 Arg2:T5\n",
      "R11\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R12\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R13\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R14\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R15\tCOREF Arg1:T11 Arg2:T3\n",
      "R16\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R17\tCOREF Arg1:T20 Arg2:T11\n",
      "R18\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R19\tUSED-FOR Arg1:T22 Arg2:T24\n",
      "R20\tUSED-FOR Arg1:T22 Arg2:T25\n",
      "R21\tCONJUNCTION Arg1:T23 Arg2:T24\n",
      "R22\tCONJUNCTION Arg1:T24 Arg2:T25\n",
      "R23\tHYPONYM-OF Arg1:T22 Arg2:T15\n",
      "R24\tPART-OF Arg1:T5 Arg2:T3\n",
      "R25\tHYPONYM-OF Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H92-1003.ann\n",
      "T1\tMaterial 46 68\tspoken language corpus\n",
      "T2\tTask 79 122\tATIS (Air Travel Information System) domain\n",
      "T3\tGeneric 131 146\tdata collection\n",
      "T4\tMethod 319 354\tmulti-site data collection paradigm\n",
      "T5\tGeneric 413 423\tcollection\n",
      "T6\tMaterial 469 487\tspontaneous speech\n",
      "T7\tTask 519 595\tmulti-site common evaluation of speech, natural language and spoken language\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T5 Arg2:T3\n",
      "R4\tEVALUATE-FOR Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H92-1010.ann\n",
      "T1\tTask 88 105\tspeech processing\n",
      "T2\tTask 143 170\tHuman-Machine Communication\n",
      "T3\tTask 185 212\tNatural Language Processing\n",
      "T4\tTask 217 256\tNon Verbal and Multimodal Communication\n",
      "R1\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R3\tHYPONYM-OF Arg1:T4 Arg2:T2\n",
      "R4\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H92-1017.ann\n",
      "T1\tGeneric 42 73\tdomain-independent capabilities\n",
      "T2\tMethod 98 142\tParamax spoken language understanding system\n",
      "T3\tTask 147 170\tnon-monotonic reasoning\n",
      "T4\tTask 175 204\timplicit reference resolution\n",
      "T5\tTask 213 238\tdatabase query paraphrase\n",
      "T6\tMaterial 286 320\tFebruary 1992 ATIS benchmark tests\n",
      "T7\tMethod 526 573\tn-best speech/language integration architecture\n",
      "T8\tMetric 589 603\tOCR   accuracy\n",
      "R1\tPART-OF Arg1:T1 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T4 Arg2:T1\n",
      "R4\tHYPONYM-OF Arg1:T5 Arg2:T1\n",
      "R5\tEVALUATE-FOR Arg1:T8 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H92-1026.ann\n",
      "T1\tMethod 18 68\tgenerative probabilistic model of natural language\n",
      "T2\tMethod 87 90\tHBG\n",
      "T3\tOtherScientificTerm 128 150\tlinguistic information\n",
      "T4\tTask 164 173\tambiguity\n",
      "T5\tMethod 179 182\tHBG\n",
      "T6\tOtherScientificTerm 198 254\tlexical, syntactic, semantic, and structural information\n",
      "T7\tOtherScientificTerm 266 276\tparse tree\n",
      "T8\tTask 288 310\tdisambiguation process\n",
      "T9\tMaterial 338 367\tcorpus of bracketed sentences\n",
      "T10\tMaterial 381 389\tTreebank\n",
      "T11\tMethod 414 436\tdecision tree building\n",
      "T12\tOtherScientificTerm 478 488\tparse tree\n",
      "T13\tOtherScientificTerm 523 528\tparse\n",
      "T14\tTask 606 624\tgrammar  tailoring\n",
      "T15\tMethod 640 664\tlinguistic introspection\n",
      "T16\tOtherScientificTerm 705 710\tparse\n",
      "T17\tOtherScientificTerm 718 736\thead-to-head tests\n",
      "T18\tMethod 771 807\trobust  probabilistic parsing models\n",
      "T19\tMethod 826 831\tP-CFG\n",
      "T20\tMethod 839 848\tHBG model\n",
      "T21\tMethod 877 882\tP-CFG\n",
      "T22\tMetric 902 924\tparsing accuracy  rate\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tCOMPARE Arg1:T20 Arg2:T21\n",
      "R4\tCOREF Arg1:T2 Arg2:T1\n",
      "R5\tCOREF Arg1:T5 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T8\n",
      "R7\tCOREF Arg1:T10 Arg2:T9\n",
      "R8\tCONJUNCTION Arg1:T9 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R10\tCOREF Arg1:T19 Arg2:T21\n",
      "R11\tCOREF Arg1:T20 Arg2:T5\n",
      "R12\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R13\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R14\tUSED-FOR Arg1:T9 Arg2:T12\n",
      "R15\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R16\tEVALUATE-FOR Arg1:T22 Arg2:T20\n",
      "R17\tHYPONYM-OF Arg1:T19 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H92-1036.ann\n",
      "T1\tMethod 15 46\tmaximum a posteriori estimation\n",
      "T2\tMethod 52 99\tcontinuous density hidden Markov models (CDHMM)\n",
      "T3\tMethod 118 145\tMLE reestimation algorithms\n",
      "T4\tMethod 161 187\tforward-backward algorithm\n",
      "T5\tMethod 198 225\tsegmental k-means algorithm\n",
      "T6\tOtherScientificTerm 247 268\treestimation formulas\n",
      "T7\tMethod 285 332\tHMM with Gaussian mixture observation densities\n",
      "T8\tMethod 369 386\tBayesian learning\n",
      "T9\tTask 441 473\tspeech recognition  applications\n",
      "T10\tTask 483 502\tparameter smoothing\n",
      "T11\tTask 507 525\tspeaker adaptation\n",
      "T12\tTask 530 552\tspeaker group modeling\n",
      "T13\tTask 559 578\tcorrective training\n",
      "T14\tGeneric 619 631\tapplications\n",
      "T15\tMethod 679 702\tMAP estimation approach\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R2\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R3\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R4\tCONJUNCTION Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R7\tHYPONYM-OF Arg1:T10 Arg2:T9\n",
      "R8\tHYPONYM-OF Arg1:T11 Arg2:T9\n",
      "R9\tHYPONYM-OF Arg1:T12 Arg2:T9\n",
      "R10\tHYPONYM-OF Arg1:T13 Arg2:T9\n",
      "R11\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R12\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R13\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R14\tCOREF Arg1:T14 Arg2:T9\n",
      "R15\tCOREF Arg1:T15 Arg2:T1\n",
      "R16\tEVALUATE-FOR Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H92-1045.ann\n",
      "T1\tOtherScientificTerm 36 52\tpolysemous words\n",
      "T2\tMethod 166 199\tword-sense disambiguation systems\n",
      "T3\tGeneric 203 206\tone\n",
      "T4\tMaterial 219 237\tbilingual material\n",
      "T5\tMaterial 245 262\tCanadian Hansards\n",
      "T6\tGeneric 274 279\tother\n",
      "T7\tMaterial 292 312\tmonolingual material\n",
      "T8\tMaterial 317 334\tRoget's Thesaurus\n",
      "T9\tMaterial 341 363\tGrolier's Encyclopedia\n",
      "T10\tOtherScientificTerm 432 441\tdiscourse\n",
      "T11\tOtherScientificTerm 466 481\tpolysemous word\n",
      "T12\tOtherScientificTerm 534 556\twell-written discourse\n",
      "T13\tOtherScientificTerm 752 761\tdiscourse\n",
      "T14\tOtherScientificTerm 842 852\tconstraint\n",
      "T15\tMethod 892 927\tword-sense disambiguation algorithm\n",
      "T16\tGeneric 944 946\tit\n",
      "T17\tMethod 984 1009\tdisambiguation algorithms\n",
      "T18\tOtherScientificTerm 1041 1061\tdiscourse constraint\n",
      "R1\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T6 Arg2:T2\n",
      "R3\tEVALUATE-FOR Arg1:T4 Arg2:T3\n",
      "R4\tCOREF Arg1:T5 Arg2:T4\n",
      "R5\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R6\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R7\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R8\tCONJUNCTION Arg1:T3 Arg2:T6\n",
      "R9\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R10\tEVALUATE-FOR Arg1:T16 Arg2:T17\n",
      "R11\tCOREF Arg1:T15 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H93-1076.ann\n",
      "T1\tGeneric 5 11\tthemes\n",
      "T2\tTask 29 61\tspeech and text image processing\n",
      "T3\tMethod 122 144\trecognition technology\n",
      "T4\tTask 150 180\tdocument-oriented applications\n",
      "T5\tGeneric 183 186\tOne\n",
      "T6\tGeneric 209 216\tsystems\n",
      "T7\tMethod 264 279\ttext processors\n",
      "T8\tMaterial 306 334\taudio and scanned image data\n",
      "T9\tGeneric 355 360\ttheme\n",
      "T10\tMethod 376 409\tspeech and text-image recognition\n",
      "T11\tOtherScientificTerm 467 496\tdocuments with signal content\n",
      "T12\tGeneric 526 534\tresearch\n",
      "T13\tGeneric 578 584\tthemes\n",
      "T14\tMethod 589 606\ttext-image editor\n",
      "T15\tMethod 615 626\twordspotter\n",
      "T16\tTask 633 659\tvoice editing and indexing\n",
      "T17\tMethod 673 691\tdecoding framework\n",
      "T18\tTask 698 732\tscanned-document content retrieval\n",
      "T19\tTask 821 867\tsignal-based document processing functionality\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R3\tHYPONYM-OF Arg1:T5 Arg2:T1\n",
      "R4\tCOREF Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R6\tHYPONYM-OF Arg1:T9 Arg2:T1\n",
      "R7\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R8\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R9\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R10\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R11\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R12\tPART-OF Arg1:T1 Arg2:T2\n",
      "R13\tCOREF Arg1:T13 Arg2:T1\n",
      "R14\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R15\tHYPONYM-OF Arg1:T14 Arg2:T12\n",
      "R16\tHYPONYM-OF Arg1:T15 Arg2:T12\n",
      "R17\tHYPONYM-OF Arg1:T17 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H94-1064.ann\n",
      "T1\tTask 51 119\tmultilingual, speaker-independent, large vocabulary speech dictation\n",
      "T2\tMethod 141 157\tLIMSI recognizer\n",
      "T3\tMaterial 187 206\tARPA NOV93 CSR test\n",
      "T4\tMaterial 255 275\tWSJ and BREF corpora\n",
      "T5\tGeneric 334 341\tcorpora\n",
      "T6\tTask 344 360\tword recognition\n",
      "T7\tGeneric 445 455\trecognizer\n",
      "T8\tMethod 470 492\tcontinuous density HMM\n",
      "T9\tMethod 500 516\tGaussian mixture\n",
      "T10\tTask 523 540\tacoustic modeling\n",
      "T11\tMethod 547 564\tn-gram statistics\n",
      "T12\tMaterial 584 599\tnewspaper texts\n",
      "T13\tTask 606 623\tlanguage modeling\n",
      "T14\tGeneric 630 640\trecognizer\n",
      "T15\tMethod 649 687\ttime-synchronous graph-search strategy\n",
      "T16\tMethod 766 797\tbigram back-off language models\n",
      "T17\tOtherScientificTerm 847 857\tword graph\n",
      "T18\tMethod 879 885\tbigram\n",
      "T19\tMethod 904 926\ttrigram language model\n",
      "T20\tTask 930 947\tAcoustic modeling\n",
      "T21\tOtherScientificTerm 955 978\tcepstrum-based features\n",
      "T22\tMethod 982 1034\tcontext-dependent phone models (intra and interword)\n",
      "T23\tMethod 1038 1059\tphone duration models\n",
      "T24\tMethod 1067 1087\tsex-dependent models\n",
      "R1\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R2\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R3\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R4\tEVALUATE-FOR Arg1:T3 Arg2:T2\n",
      "R5\tEVALUATE-FOR Arg1:T4 Arg2:T2\n",
      "R6\tCOREF Arg1:T7 Arg2:T2\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R9\tEVALUATE-FOR Arg1:T12 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T11 Arg2:T7\n",
      "R11\tCONJUNCTION Arg1:T8 Arg2:T11\n",
      "R12\tCOREF Arg1:T14 Arg2:T7\n",
      "R13\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R14\tCONJUNCTION Arg1:T16 Arg2:T15\n",
      "R15\tUSED-FOR Arg1:T16 Arg2:T14\n",
      "R16\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R17\tCOREF Arg1:T20 Arg2:T10\n",
      "R18\tCONJUNCTION Arg1:T19 Arg2:T17\n",
      "R19\tUSED-FOR Arg1:T22 Arg2:T20\n",
      "R20\tUSED-FOR Arg1:T23 Arg2:T20\n",
      "R21\tUSED-FOR Arg1:T24 Arg2:T20\n",
      "R22\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "R23\tCONJUNCTION Arg1:T22 Arg2:T23\n",
      "R24\tCONJUNCTION Arg1:T23 Arg2:T24\n",
      "R25\tHYPONYM-OF Arg1:T3 Arg2:T5\n",
      "R26\tHYPONYM-OF Arg1:T4 Arg2:T5\n",
      "R27\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R28\tEVALUATE-FOR Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\H94-1102.ann\n",
      "T1\tMethod 93 139\tcontinuous speech recognition (CSR) techniques\n",
      "T2\tTask 169 198\tSpoken Language Systems (SLS)\n",
      "T3\tTask 241 285\tmilitary and civilian computer-based systems\n",
      "T4\tTask 367 411\tspeech recognition and understanding systems\n",
      "T5\tMethod 454 480\tspoken language technology\n",
      "T6\tTask 488 517\tmilitary and civilian systems\n",
      "T7\tMethod 568 571\tCSR\n",
      "T8\tTask 577 612\tmobile military command and control\n",
      "T9\tMethod 668 686\tacoustic modelling\n",
      "T10\tMethod 689 701\trapid search\n",
      "T11\tMethod 708 746\trecognition-time adaptation techniques\n",
      "T12\tMethod 760 780\tlarge-vocabulary CSR\n",
      "T13\tGeneric 805 815\ttechniques\n",
      "T14\tMaterial 828 861\tARPA large-vocabulary CSR corpora\n",
      "T15\tTask 870 896\tmilitary application tasks\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R5\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R6\tCOREF Arg1:T6 Arg2:T3\n",
      "R7\tCOREF Arg1:T5 Arg2:T2\n",
      "R8\tCOREF Arg1:T7 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R10\tUSED-FOR Arg1:T9 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R12\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R13\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R14\tHYPONYM-OF Arg1:T9 Arg2:T13\n",
      "R15\tHYPONYM-OF Arg1:T10 Arg2:T13\n",
      "R16\tHYPONYM-OF Arg1:T11 Arg2:T13\n",
      "R17\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R18\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R19\tUSED-FOR Arg1:T9 Arg2:T15\n",
      "R20\tUSED-FOR Arg1:T10 Arg2:T15\n",
      "R21\tUSED-FOR Arg1:T11 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-2013.ann\n",
      "T1\tGeneric 15 19\ttool\n",
      "T2\tMethod 30 35\tILIMP\n",
      "T3\tMaterial 62 82\traw text  in  French\n",
      "T4\tGeneric 269 273\ttool\n",
      "T5\tTask 325 352\tanaphoric occurrences of il\n",
      "T6\tMethod 369 395\tanaphora resolution system\n",
      "T7\tMetric 544 558\tprecision rate\n",
      "T8\tMethod 565 570\tILIMP\n",
      "T9\tGeneric 630 635\ttasks\n",
      "T10\tGeneric 648 654\tmethod\n",
      "T11\tMethod 671 676\tILIMP\n",
      "T12\tMethod 724 729\tILIMP\n",
      "T13\tMethod 736 770\tmodular  syntactic analysis system\n",
      "R1\tEVALUATE-FOR Arg1:T7 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R3\tCOREF Arg1:T2 Arg2:T1\n",
      "R4\tCOREF Arg1:T1 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T12 Arg2:T11\n",
      "R9\tCOREF Arg1:T11 Arg2:T8\n",
      "R10\tCOREF Arg1:T8 Arg2:T4\n",
      "R11\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-2014.ann\n",
      "T1\tMetric 3 32\tAutomatic  evaluation metrics\n",
      "T2\tTask 39 71\tMachine Translation (MT) systems\n",
      "T3\tMetric 84 88\tBLEU\n",
      "T4\tMetric 94 98\tNIST\n",
      "T5\tGeneric 133 137\tthey\n",
      "T6\tTask 164 193\tassessment of  language pairs\n",
      "T7\tOtherScientificTerm 179 193\tlanguage pairs\n",
      "T8\tOtherScientificTerm 201 216\tEnglish-Chinese\n",
      "T9\tOtherScientificTerm 222 238\tEnglish-Japanese\n",
      "T10\tTask 258 283\tword segmentation problem\n",
      "T11\tMetric 355 359\tBLEU\n",
      "T12\tMethod 365 377\tword n-grams\n",
      "T13\tOtherScientificTerm 407 423\tcharacter  level\n",
      "T14\tMetric 437 441\tBLEU\n",
      "T15\tOtherScientificTerm 451 467\tcharacter  level\n",
      "T16\tTask 484 509\tword segmentation problem\n",
      "T17\tGeneric 513 515\tit\n",
      "T18\tMethod 554 572\tcommercial systems\n",
      "T19\tMethod 625 647\tstatistical MT systems\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R2\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R3\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R4\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R5\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R6\tCOREF Arg1:T14 Arg2:T11\n",
      "R7\tCOREF Arg1:T11 Arg2:T3\n",
      "R8\tCOMPARE Arg1:T18 Arg2:T19\n",
      "R9\tCOREF Arg1:T17 Arg2:T14\n",
      "R10\tCOREF Arg1:T16 Arg2:T10\n",
      "R11\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R12\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R13\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R14\tEVALUATE-FOR Arg1:T17 Arg2:T18\n",
      "R15\tEVALUATE-FOR Arg1:T17 Arg2:T19\n",
      "R16\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R17\tEVALUATE-FOR Arg1:T1 Arg2:T2\n",
      "R18\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R19\tHYPONYM-OF Arg1:T4 Arg2:T1\n",
      "R20\tCOREF Arg1:T1 Arg2:T5\n",
      "R21\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-2021.ann\n",
      "T1\tMethod 122 150\tChinese-to-English SMT model\n",
      "T2\tTask 165 190\tword sense disambiguation\n",
      "T3\tMethod 222 248\tWSD evaluation methodology\n",
      "T4\tMaterial 275 313\tSenseval-3 Chinese lexical sample task\n",
      "T5\tMethod 370 419\tdedicated  word sense disambiguation (WSD) models\n",
      "T6\tMaterial 447 476\tSenseval  series of workshops\n",
      "T7\tMetric 528 539\tBLEU scores\n",
      "T8\tTask 545 582\tstatistical machine translation (SMT)\n",
      "T9\tMethod 599 609\tSMT models\n",
      "T10\tTask 645 656\ttranslation\n",
      "T11\tMetric 733 747\tWSD   accuracy\n",
      "T12\tMethod 753 763\tSMT models\n",
      "T13\tGeneric 808 812\tthat\n",
      "T14\tMethod 820 841\tdedicated  WSD models\n",
      "T15\tMetric 892 906\tWSD   accuracy\n",
      "T16\tMethod 928 938\tSMT models\n",
      "T17\tGeneric 971 975\tthat\n",
      "T18\tMethod 987 1008\tdedicated  WSD models\n",
      "T19\tMethod 1118 1128\tSMT models\n",
      "T20\tMethod 1169 1190\tdedicated  WSD models\n",
      "T21\tMethod 1204 1207\tSMT\n",
      "T22\tMethod 1265 1275\tWSD models\n",
      "R1\tEVALUATE-FOR Arg1:T2 Arg2:T1\n",
      "R2\tEVALUATE-FOR Arg1:T7 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R4\tCOREF Arg1:T21 Arg2:T19\n",
      "R5\tCOREF Arg1:T19 Arg2:T16\n",
      "R6\tCOREF Arg1:T16 Arg2:T12\n",
      "R7\tEVALUATE-FOR Arg1:T4 Arg2:T1\n",
      "R8\tEVALUATE-FOR Arg1:T3 Arg2:T1\n",
      "R9\tEVALUATE-FOR Arg1:T11 Arg2:T12\n",
      "R10\tCOREF Arg1:T12 Arg2:T9\n",
      "R11\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R12\tCOREF Arg1:T14 Arg2:T18\n",
      "R13\tCOREF Arg1:T20 Arg2:T18\n",
      "R14\tCOMPARE Arg1:T19 Arg2:T20\n",
      "R15\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "R16\tEVALUATE-FOR Arg1:T6 Arg2:T5\n",
      "R17\tCOREF Arg1:T14 Arg2:T5\n",
      "R18\tCOREF Arg1:T22 Arg2:T20\n",
      "R19\tCOMPARE Arg1:T17 Arg2:T15\n",
      "R20\tCOMPARE Arg1:T13 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-2043.ann\n",
      "T1\tMethod 8 35\tnatural language processing\n",
      "T2\tTask 55 67\ttrend survey\n",
      "T3\tTask 55 116\ttrend survey on  Japanese natural language processing studies\n",
      "T4\tMaterial 72 116\tJapanese natural language processing studies\n",
      "T5\tMaterial 412 424\tJapanese NLP\n",
      "T6\tTask 466 479\ttrend surveys\n",
      "T7\tMethod 487 490\tNLP\n",
      "R1\tCOREF Arg1:T6 Arg2:T2\n",
      "R2\tCOREF Arg1:T7 Arg2:T1\n",
      "R3\tCOREF Arg1:T5 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-2044.ann\n",
      "T1\tMaterial 9 25\tChinese language\n",
      "T2\tTask 105 154\tambiguity resolution  of  right-side dependencies\n",
      "T3\tTask 174 192\tdependency parsing\n",
      "T4\tMethod 254 285\tshift-reduce dependency parsers\n",
      "T5\tMetric 310 322\tconnectivity\n",
      "T6\tOtherScientificTerm 330 345\tdependency tree\n",
      "T7\tOtherScientificTerm 387 410\tright-side dependencies\n",
      "T8\tMethod 436 476\ttwo-phase shift-reduce dependency parser\n",
      "T9\tMethod 488 500\tSVM learning\n",
      "T10\tOtherScientificTerm 508 528\tleft-side dependents\n",
      "T11\tOtherScientificTerm 535 564\tright-side nominal dependents\n",
      "T12\tOtherScientificTerm 596 624\tright-side verbal dependents\n",
      "T13\tGeneric 692 698\tmethod\n",
      "T14\tMethod 721 752\tshift-reduce dependency parsers\n",
      "T15\tMaterial 763 777\tChine language\n",
      "T16\tMetric 804 823\tdependency accuracy\n",
      "R1\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R2\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R3\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R4\tCONJUNCTION Arg1:T12 Arg2:T11\n",
      "R5\tCOREF Arg1:T14 Arg2:T4\n",
      "R6\tEVALUATE-FOR Arg1:T16 Arg2:T14\n",
      "R7\tCOREF Arg1:T13 Arg2:T8\n",
      "R8\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R9\tEVALUATE-FOR Arg1:T15 Arg2:T13\n",
      "R10\tCOREF Arg1:T15 Arg2:T1\n",
      "R11\tEVALUATE-FOR Arg1:T16 Arg2:T13\n",
      "R12\tEVALUATE-FOR Arg1:T5 Arg2:T6\n",
      "R13\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-2048.ann\n",
      "T1\tMethod 2 39\tStatistical machine translation (SMT)\n",
      "T2\tTask 79 106\tnatural language processing\n",
      "T3\tMethod 230 233\tSMT\n",
      "T4\tMethod 265 295\trule-based translation systems\n",
      "T5\tTask 392 411\ttranslation systems\n",
      "T6\tOtherScientificTerm 417 436\tnew  language pairs\n",
      "T7\tOtherScientificTerm 441 453\tnew  domains\n",
      "T8\tMethod 511 542\tstatistical machine translation\n",
      "T9\tMethod 670 680\tSMT system\n",
      "T10\tMethod 787 790\tSMT\n",
      "T11\tMethod 829 833\tSTTK\n",
      "T12\tMethod 840 880\tstatistical machine translation tool kit\n",
      "T13\tTask 932 950\ttranslation system\n",
      "T14\tMethod 955 959\tSTTK\n",
      "T15\tMethod 1080 1090\tSMT system\n",
      "T16\tGeneric 1094 1096\tIt\n",
      "T17\tMethod 1138 1194\trule-based and example based machine translation modules\n",
      "T18\tTask 1208 1247\tmulti engine machine translation system\n",
      "T19\tGeneric 1277 1285\ttool kit\n",
      "R1\tCOMPARE Arg1:T3 Arg2:T4\n",
      "R2\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T3 Arg2:T1\n",
      "R4\tCOREF Arg1:T8 Arg2:T3\n",
      "R5\tCOREF Arg1:T9 Arg2:T8\n",
      "R6\tCOREF Arg1:T10 Arg2:T8\n",
      "R7\tHYPONYM-OF Arg1:T11 Arg2:T12\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R9\tCOREF Arg1:T13 Arg2:T5\n",
      "R10\tCOREF Arg1:T14 Arg2:T11\n",
      "R11\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R12\tCOREF Arg1:T16 Arg2:T14\n",
      "R13\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R14\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R15\tUSED-FOR Arg1:T16 Arg2:T18\n",
      "R16\tCOREF Arg1:T19 Arg2:T14\n",
      "R17\tHYPONYM-OF Arg1:T4 Arg2:T17\n",
      "R18\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R19\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R20\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-3022.ann\n",
      "T1\tMethod 24 48\tword segmentation system\n",
      "T2\tGeneric 102 110\tapproach\n",
      "T3\tTask 115 128\tword breaking\n",
      "T4\tTask 135 153\tOOV identification\n",
      "T5\tGeneric 297 303\tsystem\n",
      "T6\tOtherScientificTerm 344 364\tsegmentation bakeoff\n",
      "T7\tOtherScientificTerm 370 377\tPK-open\n",
      "T8\tOtherScientificTerm 381 390\tPK-closed\n",
      "T9\tOtherScientificTerm 394 401\tAS-open\n",
      "T10\tOtherScientificTerm 405 414\tAS-closed\n",
      "T11\tOtherScientificTerm 418 425\tHK-open\n",
      "T12\tOtherScientificTerm 429 438\tHK-closed\n",
      "T13\tOtherScientificTerm 442 450\tMSR-open\n",
      "T14\tOtherScientificTerm 457 468\tMSR- closed\n",
      "T15\tOtherScientificTerm 525 533\tMSR-open\n",
      "T16\tOtherScientificTerm 537 546\tMSR-close\n",
      "T17\tOtherScientificTerm 553 560\tPK-open\n",
      "T18\tGeneric 627 633\tsystem\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R3\tCOREF Arg1:T5 Arg2:T1\n",
      "R4\tHYPONYM-OF Arg1:T7 Arg2:T6\n",
      "R5\tHYPONYM-OF Arg1:T8 Arg2:T6\n",
      "R6\tHYPONYM-OF Arg1:T9 Arg2:T6\n",
      "R7\tHYPONYM-OF Arg1:T10 Arg2:T6\n",
      "R8\tHYPONYM-OF Arg1:T11 Arg2:T6\n",
      "R9\tCOREF Arg1:T16 Arg2:T14\n",
      "R10\tCOREF Arg1:T17 Arg2:T7\n",
      "R11\tCOREF Arg1:T18 Arg2:T5\n",
      "R12\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R13\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R14\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R15\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R16\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R17\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R18\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R19\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R20\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "R21\tHYPONYM-OF Arg1:T12 Arg2:T6\n",
      "R22\tHYPONYM-OF Arg1:T13 Arg2:T6\n",
      "R23\tHYPONYM-OF Arg1:T14 Arg2:T6\n",
      "R24\tCOREF Arg1:T13 Arg2:T15\n",
      "R25\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R26\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-4008.ann\n",
      "T1\tMaterial 2 30\tTaiwan Child Language Corpus\n",
      "T2\tGeneric 203 209\tcorpus\n",
      "T3\tMaterial 223 268\tChild Language Data Exchange System (CHILDES)\n",
      "T4\tGeneric 288 294\tcorpus\n",
      "T5\tTask 354 369\tdata collection\n",
      "T6\tTask 373 386\ttranscription\n",
      "T7\tTask 390 407\tword segmentation\n",
      "T8\tTask 415 440\tpart-of-speech annotation\n",
      "T9\tGeneric 451 457\tcorpus\n",
      "T10\tGeneric 481 487\tcorpus\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R3\tCOREF Arg1:T2 Arg2:T1\n",
      "R4\tCOREF Arg1:T4 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R8\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R9\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R10\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R11\tCOREF Arg1:T9 Arg2:T4\n",
      "R12\tCOREF Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-4010.ann\n",
      "T1\tMaterial 57 80\tEnglish-Chinese bitexts\n",
      "T2\tGeneric 135 139\tthem\n",
      "T3\tMethod 187 203\tnumbering system\n",
      "T4\tOtherScientificTerm 213 233\tlegal text hierarchy\n",
      "T5\tMaterial 319 335\tbilingual corpus\n",
      "T6\tGeneric 503 505\tIt\n",
      "T7\tTask 535 556\tempirical MT research\n",
      "T8\tMaterial 636 659\tEnglish-Chinese bitexts\n",
      "R1\tCOREF Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T6 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R4\tCOREF Arg1:T8 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-5003.ann\n",
      "T1\tTask 14 49\tmachine translation (MT) evaluation\n",
      "T2\tTask 86 136\tsentence-level semantic equivalence classification\n",
      "T3\tMetric 198 219\tMT evaluation methods\n",
      "T4\tMetric 221 225\tBLEU\n",
      "T5\tMetric 227 231\tNIST\n",
      "T6\tMetric 233 236\tWER\n",
      "T7\tMetric 241 244\tPER\n",
      "T8\tMethod 260 271\tclassifiers\n",
      "T9\tTask 285 305\tsemantic equivalence\n",
      "T10\tTask 312 322\tentailment\n",
      "T11\tMethod 353 374\tclassification method\n",
      "T12\tMetric 386 389\tPER\n",
      "T13\tOtherScientificTerm 408 434\tpart of speech information\n",
      "T14\tTask 472 500\tword matches and non-matches\n",
      "T15\tMethod 545 569\tMT evaluation techniques\n",
      "T16\tOtherScientificTerm 599 607\tfeatures\n",
      "T17\tTask 614 639\tparaphrase classification\n",
      "T18\tTask 665 675\tentailment\n",
      "T19\tGeneric 684 693\ttechnique\n",
      "T20\tTask 731 756\tparaphrase classification\n",
      "T21\tMetric 731 765\tparaphrase classification accuracy\n",
      "T22\tGeneric 790 796\tmodels\n",
      "R1\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R3\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R6\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R7\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R8\tHYPONYM-OF Arg1:T7 Arg2:T3\n",
      "R9\tHYPONYM-OF Arg1:T6 Arg2:T3\n",
      "R10\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R11\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R12\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R13\tUSED-FOR Arg1:T3 Arg2:T8\n",
      "R14\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R15\tCOREF Arg1:T11 Arg2:T8\n",
      "R16\tCOREF Arg1:T12 Arg2:T7\n",
      "R17\tCOREF Arg1:T15 Arg2:T3\n",
      "R18\tUSED-FOR Arg1:T15 Arg2:T17\n",
      "R19\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R20\tUSED-FOR Arg1:T15 Arg2:T18\n",
      "R21\tCOREF Arg1:T19 Arg2:T11\n",
      "R22\tCOMPARE Arg1:T19 Arg2:T22\n",
      "R23\tCOREF Arg1:T20 Arg2:T17\n",
      "R24\tEVALUATE-FOR Arg1:T21 Arg2:T19\n",
      "R25\tEVALUATE-FOR Arg1:T21 Arg2:T22\n",
      "R26\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R27\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-5004.ann\n",
      "T1\tTask 27 63\tcompositional classes of paraphrases\n",
      "T2\tMethod 86 110\tclass-oriented framework\n",
      "T3\tMaterial 128 147\tparaphrase examples\n",
      "T4\tMaterial 160 182\tsentential paraphrases\n",
      "T5\tMethod 250 280\tautomatic candidate generation\n",
      "T6\tMethod 287 303\tmanual judgement\n",
      "T7\tMaterial 349 366\tparaphrase corpus\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R6\tCOREF Arg1:T4 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-5008.ann\n",
      "T1\tGeneric 14 20\tmethod\n",
      "T2\tOtherScientificTerm 51 61\tparaphrase\n",
      "T3\tMetric 135 174\tmachine translation evaluation measures\n",
      "T4\tMetric 182 186\tBLEU\n",
      "T5\tMetric 193 197\tNIST\n",
      "T6\tOtherScientificTerm 233 244\tparaphrases\n",
      "T7\tMetric 290 304\tgrammaticality\n",
      "T8\tMetric 355 377\tequivalence in meaning\n",
      "T9\tOtherScientificTerm 403 414\tparaphrases\n",
      "T10\tMethod 427 446\tmeaning equivalence\n",
      "T11\tMethod 452 462\tentailment\n",
      "T12\tMetric 491 534\tinternal  lexical and syntactical variation\n",
      "T13\tOtherScientificTerm 549 560\tparaphrases\n",
      "T14\tOtherScientificTerm 594 612\thand-produced sets\n",
      "T15\tOtherScientificTerm 621 631\tparaphrase\n",
      "T16\tGeneric 655 661\tmethod\n",
      "T17\tTask 717 730\tMT evaluation\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R3\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R4\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R6\tCONJUNCTION Arg1:T8 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R9\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R10\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R11\tCOREF Arg1:T16 Arg2:T1\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R13\tCONJUNCTION Arg1:T12 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-5009.ann\n",
      "T1\tGeneric 25 42\tevaluation method\n",
      "T2\tMethod 57 78\tlatent variable model\n",
      "T3\tOtherScientificTerm 85 96\tparaphrases\n",
      "T4\tOtherScientificTerm 185 200\tlatent variable\n",
      "T5\tGeneric 210 215\tmodel\n",
      "T6\tOtherScientificTerm 295 305\tparaphrase\n",
      "T7\tGeneric 426 432\tmethod\n",
      "T8\tMetric 588 596\taccuracy\n",
      "T9\tGeneric 615 621\tmethod\n",
      "T10\tOtherScientificTerm 640 657\ttopic information\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T5 Arg2:T2\n",
      "R3\tEVALUATE-FOR Arg1:T1 Arg2:T3\n",
      "R4\tCOREF Arg1:T7 Arg2:T1\n",
      "R5\tCOREF Arg1:T9 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R7\tEVALUATE-FOR Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-6010.ann\n",
      "T1\tTask 44 79\tquantifying noun groups  in  German\n",
      "T2\tMaterial 73 79\tGerman\n",
      "T3\tOtherScientificTerm 304 325\tgrammar sensu stricto\n",
      "T4\tMaterial 337 345\ttreebank\n",
      "T5\tOtherScientificTerm 387 411\tfine-grained  annotation\n",
      "T6\tMaterial 421 430\ttree-bank\n",
      "T7\tMethod 468 486\tstochastic parsers\n",
      "T8\tMaterial 504 513\ttree-bank\n",
      "T9\tMethod 523 531\tgrammars\n",
      "T10\tMaterial 551 559\ttreebank\n",
      "T11\tMaterial 585 593\ttreebank\n",
      "T12\tTask 636 673\ttheoretical linguistic investigations\n",
      "T13\tMethod 791 796\tSILVA\n",
      "T14\tMethod 802 831\tparsing  and  extraction tool\n",
      "T15\tMaterial 838 857\tGerman text corpora\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R4\tHYPONYM-OF Arg1:T13 Arg2:T14\n",
      "R5\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R6\tCOREF Arg1:T11 Arg2:T10\n",
      "R7\tCOREF Arg1:T10 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R9\tCOREF Arg1:T6 Arg2:T8\n",
      "R10\tCOREF Arg1:T6 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I05-6011.ann\n",
      "T1\tMethod 25 42\tannotating scheme\n",
      "T2\tMaterial 58 68\thonorifics\n",
      "T3\tOtherScientificTerm 71 87\trespectful words\n",
      "T4\tMaterial 91 101\tHonorifics\n",
      "T5\tMaterial 128 136\tJapanese\n",
      "T6\tOtherScientificTerm 230 253\treferential information\n",
      "T7\tOtherScientificTerm 279 292\tzero pronouns\n",
      "T8\tOtherScientificTerm 309 336\tmachine translation outputs\n",
      "T9\tMaterial 352 362\thonorifics\n",
      "T10\tMaterial 428 438\thonorifics\n",
      "T11\tOtherScientificTerm 453 458\tranks\n",
      "T12\tOtherScientificTerm 513 518\tranks\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tCOREF Arg1:T4 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R7\tCOREF Arg1:T9 Arg2:T4\n",
      "R8\tCOREF Arg1:T10 Arg2:T9\n",
      "R9\tCOREF Arg1:T12 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I08-1027.ann\n",
      "T1\tTask 2 45\tAutomatic estimation  of  word significance\n",
      "T2\tOtherScientificTerm 28 45\tword significance\n",
      "T3\tTask 61 100\tspeech-based Information Retrieval (IR)\n",
      "T4\tOtherScientificTerm 127 139\tsignificance\n",
      "T5\tTask 164 166\tIR\n",
      "T6\tTask 170 204\tautomatic speech recognition (ASR)\n",
      "T7\tMetric 247 278\tweighted word error rate (WWER)\n",
      "T8\tTask 337 339\tIR\n",
      "T9\tMetric 354 375\tword error rate (WER)\n",
      "T10\tMethod 417 434\tdecoding strategy\n",
      "T11\tMetric 452 456\tWWER\n",
      "T12\tMethod 470 498\tMinimum Bayes-Risk framework\n",
      "T13\tTask 553 556\tASR\n",
      "T14\tTask 563 565\tIR\n",
      "T15\tMethod 616 643\tautomatic estimation method\n",
      "T16\tOtherScientificTerm 650 677\tword significance (weights)\n",
      "T17\tTask 706 708\tIR\n",
      "T18\tMetric 758 777\tevaluation measures\n",
      "T19\tTask 783 786\tASR\n",
      "T20\tTask 793 795\tIR\n",
      "T21\tGeneric 835 841\tmethod\n",
      "T22\tTask 848 889\tspeech-based information retrieval system\n",
      "T23\tTask 912 921\tIR system\n",
      "T24\tGeneric 942 948\tmethod\n",
      "R1\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R2\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R3\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R4\tCOREF Arg1:T4 Arg2:T2\n",
      "R5\tCOREF Arg1:T8 Arg2:T5\n",
      "R6\tCOMPARE Arg1:T9 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R8\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "R9\tEVALUATE-FOR Arg1:T18 Arg2:T20\n",
      "R10\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R11\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R12\tHYPONYM-OF Arg1:T22 Arg2:T23\n",
      "R13\tCOREF Arg1:T24 Arg2:T21\n",
      "R14\tCOREF Arg1:T21 Arg2:T15\n",
      "R15\tCOREF Arg1:T16 Arg2:T4\n",
      "R16\tCOREF Arg1:T17 Arg2:T14\n",
      "R17\tCOREF Arg1:T14 Arg2:T8\n",
      "R18\tCOREF Arg1:T19 Arg2:T13\n",
      "R19\tCOREF Arg1:T11 Arg2:T7\n",
      "R20\tCOREF Arg1:T6 Arg2:T13\n",
      "R21\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R22\tCOREF Arg1:T20 Arg2:T17\n",
      "R23\tCOREF Arg1:T23 Arg2:T20\n",
      "R24\tCOREF Arg1:T22 Arg2:T3\n",
      "R25\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\I08-1043.ann\n",
      "T1\tMethod 24 67\tmethod to automatically acquire paraphrases\n",
      "T2\tMaterial 76 93\tbilingual corpora\n",
      "T3\tOtherScientificTerm 116 146\tbilingual dependency relations\n",
      "T4\tOtherScientificTerm 174 202\tmonolingual dependency parse\n",
      "T5\tMethod 247 279\tstatistical alignment techniques\n",
      "T6\tMethod 293 312\tparaphrasing method\n",
      "T7\tOtherScientificTerm 398 440\tbilingual context  of  dependency relation\n",
      "T8\tOtherScientificTerm 491 502\tparaphrases\n",
      "T9\tGeneric 558 564\tmethod\n",
      "T10\tOtherScientificTerm 577 610\tgeneralized translation knowledge\n",
      "T11\tOtherScientificTerm 633 644\tparaphrases\n",
      "T12\tGeneric 662 668\tmethod\n",
      "T13\tOtherScientificTerm 685 718\tgeneralized translation knowledge\n",
      "T14\tTask 725 751\tKorean-English translation\n",
      "T15\tMaterial 780 837\tparallel corpora  of a  Korean and English language pairs\n",
      "T16\tMethod 858 877\tparaphrasing method\n",
      "T17\tOtherScientificTerm 901 912\tparaphrases\n",
      "T18\tMetric 925 934\tprecision\n",
      "T19\tMaterial 971 977\tKorean\n",
      "T20\tMaterial 984 991\tEnglish\n",
      "T21\tOtherScientificTerm 1003 1024\ttranslation knowledge\n",
      "T22\tMaterial 1046 1063\tbilingual corpora\n",
      "T23\tOtherScientificTerm 1110 1121\tparaphrases\n",
      "T24\tMetric 1139 1156\tcompression ratio\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T3\n",
      "R3\tCOREF Arg1:T6 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R7\tCOREF Arg1:T12 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R10\tCOREF Arg1:T16 Arg2:T6\n",
      "R11\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "R12\tCOREF Arg1:T22 Arg2:T2\n",
      "R13\tCOREF Arg1:T23 Arg2:T17\n",
      "R14\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R15\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R16\tCOREF Arg1:T15 Arg2:T22\n",
      "R17\tEVALUATE-FOR Arg1:T18 Arg2:T16\n",
      "R18\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R19\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R20\tUSED-FOR Arg1:T23 Arg2:T21\n",
      "R21\tEVALUATE-FOR Arg1:T24 Arg2:T21\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_1997_706_abs.ann\n",
      "T1\tMethod 0 27\tUtterance Verification (UV)\n",
      "T2\tMethod 57 98\tAutomatic Speech Recognition (ASR) System\n",
      "T3\tOtherScientificTerm 134 152\tspontaneous speech\n",
      "T4\tOtherScientificTerm 154 183\tout-of-vocabulary (OOV) words\n",
      "T5\tOtherScientificTerm 188 203\tacoustic noises\n",
      "T6\tMethod 248 260\tUV procedure\n",
      "T7\tMethod 289 305\tConfidence tests\n",
      "T8\tOtherScientificTerm 321 346\tdecoded string hypotheses\n",
      "T9\tOtherScientificTerm 406 415\tOOV words\n",
      "T10\tOtherScientificTerm 420 426\tnoises\n",
      "T11\tMethod 437 447\tASR system\n",
      "T12\tTask 493 506\tWord Spotting\n",
      "T13\tTask 511 538\tNoise Spotting capabilities\n",
      "T14\tMethod 547 559\tUV procedure\n",
      "T15\tMethod 588 604\tconfidence tests\n",
      "T16\tGeneric 606 609\ttwo\n",
      "T17\tMetric 619 636\tacoustic measures\n",
      "T18\tGeneric 641 644\tone\n",
      "T19\tOtherScientificTerm 656 678\tlinguistic information\n",
      "T20\tOtherScientificTerm 693 715\thierarchical structure\n",
      "T21\tTask 750 771\ttelephone application\n",
      "T22\tTask 777 808\tnatural number recognition task\n",
      "T23\tMetric 834 852\trecognition errors\n",
      "T24\tMetric 873 887\trejection rate\n",
      "T25\tMetric 933 949\tfalse acceptance\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T6 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R4\tCONJUNCTION Arg1:T10 Arg2:T9\n",
      "R5\tCOREF Arg1:T11 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R8\tCOREF Arg1:T14 Arg2:T6\n",
      "R9\tFEATURE-OF Arg1:T22 Arg2:T21\n",
      "R10\tEVALUATE-FOR Arg1:T23 Arg2:T22\n",
      "R11\tHYPONYM-OF Arg1:T16 Arg2:T15\n",
      "R12\tHYPONYM-OF Arg1:T18 Arg2:T15\n",
      "R13\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R14\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R15\tUSED-FOR Arg1:T19 Arg2:T18\n",
      "R16\tUSED-FOR Arg1:T15 Arg2:T20\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_1997_707_abs.ann\n",
      "T1\tOtherScientificTerm 0 30\tNonstationary chaotic behavior\n",
      "T2\tOtherScientificTerm 41 49\toxymoron\n",
      "T3\tGeneric 66 73\tmethods\n",
      "T4\tOtherScientificTerm 88 107\tnonstationary chaos\n",
      "T5\tGeneric 128 136\texamples\n",
      "T6\tMaterial 147 165\tbiological signals\n",
      "T7\tMaterial 167 178\tocean waves\n",
      "T8\tMaterial 183 195\ttraffic flow\n",
      "T9\tOtherScientificTerm 275 295\tnonstationary events\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R3\tHYPONYM-OF Arg1:T7 Arg2:T5\n",
      "R4\tHYPONYM-OF Arg1:T8 Arg2:T5\n",
      "R5\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R6\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_1997_714_abs.ann\n",
      "T1\tMethod 0 23\tLPC based speech coders\n",
      "T2\tOtherScientificTerm 37 46\tbit rates\n",
      "T3\tOtherScientificTerm 95 122\tbuzzy or metallic artefacts\n",
      "T4\tMaterial 130 146\tsynthetic speech\n",
      "T5\tOtherScientificTerm 224 241\texcitation source\n",
      "T6\tOtherScientificTerm 287 300\tlow bit rates\n",
      "T7\tMethod 322 333\tLPC vocoder\n",
      "T8\tOtherScientificTerm 364 378\tLPC excitation\n",
      "T9\tOtherScientificTerm 388 403\tfrequency bands\n",
      "T10\tOtherScientificTerm 412 437\tvariable cutoff frequency\n",
      "T11\tMaterial 490 512\tvoiced parts of speech\n",
      "T12\tMaterial 547 562\tunvoiced speech\n",
      "T13\tGeneric 580 585\tcoder\n",
      "T14\tMaterial 612 632\tmixed voicing speech\n",
      "T15\tMaterial 637 669\tspeech containing acoustic noise\n",
      "T16\tMaterial 701 729\tsoft natural sounding speech\n",
      "T17\tMethod 760 783\tparameter determination\n",
      "T18\tMethod 788 811\tquantisation techniques\n",
      "T19\tGeneric 843 848\tcoder\n",
      "T20\tOtherScientificTerm 857 870\tlow bit rates\n",
      "R1\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R2\tFEATURE-OF Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R5\tCOREF Arg1:T13 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T16\n",
      "R9\tCOREF Arg1:T13 Arg2:T19\n",
      "R10\tFEATURE-OF Arg1:T20 Arg2:T19\n",
      "R11\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R12\tUSED-FOR Arg1:T17 Arg2:T19\n",
      "R13\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_2011_587_abs.ann\n",
      "T1\tGeneric 34 43\talgorithm\n",
      "T2\tTask 65 93\ton-line interference effects\n",
      "T3\tTask 111 152\tGlobal Navigation Satellite System (GNSS)\n",
      "T4\tTask 157 189\tInertial Navigation System (INS)\n",
      "T5\tTask 195 212\tGNSS/INS coupling\n",
      "T6\tMethod 240 268\tExtended Kalman Filter (EKF)\n",
      "T7\tTask 285 317\taccurate and robust localization\n",
      "T8\tOtherScientificTerm 329 341\tinterference\n",
      "T9\tOtherScientificTerm 352 374\tGNSS measurement noise\n",
      "T10\tMetric 419 439\tpositioning accuracy\n",
      "T11\tOtherScientificTerm 549 559\tcovariance\n",
      "T12\tOtherScientificTerm 567 578\tEKF outputs\n",
      "T13\tMethod 598 619\tleast square estimate\n",
      "T14\tOtherScientificTerm 637 651\tvariance jumps\n",
      "T15\tGeneric 664 674\testimation\n",
      "T16\tMethod 688 701\tBayesian test\n",
      "T17\tOtherScientificTerm 756 767\tGNSS signal\n",
      "T18\tTask 918 937\tnavigation solution\n",
      "T19\tGeneric 1007 1015\tapproach\n",
      "T20\tMaterial 1019 1033\tsimulated data\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R5\tFEATURE-OF Arg1:T12 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R7\tCOREF Arg1:T15 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R9\tEVALUATE-FOR Arg1:T20 Arg2:T19\n",
      "R10\tHYPONYM-OF Arg1:T3 Arg2:T5\n",
      "R11\tHYPONYM-OF Arg1:T4 Arg2:T5\n",
      "R12\tCOREF Arg1:T19 Arg2:T16\n",
      "R13\tCOREF Arg1:T16 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_2011_588_abs.ann\n",
      "T1\tMaterial 42 60\tmeasurable signals\n",
      "T2\tMethod 66 86\tfrequency components\n",
      "T3\tOtherScientificTerm 102 132\trotational speed of the engine\n",
      "T4\tOtherScientificTerm 153 163\tvibrations\n",
      "T5\tOtherScientificTerm 165 196\telectrical system voltage level\n",
      "T6\tOtherScientificTerm 202 215\tambient sound\n",
      "T7\tGeneric 223 230\tsignals\n",
      "T8\tTask 273 312\tspeed and related states of the vehicle\n",
      "T9\tMethod 410 430\tfrequency components\n",
      "T10\tOtherScientificTerm 439 444\tspeed\n",
      "T11\tOtherScientificTerm 459 464\tgears\n",
      "T12\tOtherScientificTerm 551 569\tgear scale factors\n",
      "T13\tGeneric 575 588\ttraining data\n",
      "T14\tOtherScientificTerm 608 626\tspeed measurements\n",
      "T15\tTask 675 693\testimation problem\n",
      "T16\tTask 713 750\tmaximum likelihood estimation problem\n",
      "T17\tMethod 755 765\theuristics\n",
      "T18\tTask 803 840\tnumerical evaluation of the estimator\n",
      "T19\tGeneric 831 840\testimator\n",
      "T20\tMethod 916 933\testimation method\n",
      "T21\tMaterial 949 958\treal data\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tHYPONYM-OF Arg1:T4 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T5 Arg2:T1\n",
      "R4\tHYPONYM-OF Arg1:T6 Arg2:T1\n",
      "R5\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R6\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R7\tCOREF Arg1:T1 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R11\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R12\tCOREF Arg1:T19 Arg2:T20\n",
      "R13\tEVALUATE-FOR Arg1:T21 Arg2:T20\n",
      "R14\tFEATURE-OF Arg1:T10 Arg2:T11\n",
      "R15\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R16\tFEATURE-OF Arg1:T2 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_2011_598_abs.ann\n",
      "T1\tMetric 41 59\tmeasures of speech\n",
      "T2\tTask 76 102\tintelligibility prediction\n",
      "T3\tMaterial 106 124\tsynthesized speech\n",
      "T4\tOtherScientificTerm 128 152\tdiverse noisy situations\n",
      "T5\tMetric 173 198\tintel-ligibility measures\n",
      "T6\tMetric 204 215\tDau measure\n",
      "T7\tMetric 221 239\tglimpse proportion\n",
      "T8\tMetric 248 282\tSpeech Intelligibility Index (SII)\n",
      "T9\tMetric 289 304\tquality measure\n",
      "T10\tMetric 311 357\tPerceptual Evaluation of Speech Quality (PESQ)\n",
      "T11\tTask 367 399\tgeneration of synthesized speech\n",
      "T12\tMethod 427 460\tHMM-based speech synthesis system\n",
      "T13\tOtherScientificTerm 466 482\tnoisy conditions\n",
      "T14\tOtherScientificTerm 498 513\tadditive noises\n",
      "T15\tGeneric 519 527\tmeasures\n",
      "T16\tMetric 547 580\tsubjective intelligibility scores\n",
      "T17\tMetric 631 634\tDau\n",
      "T18\tMetric 643 659\tglimpse measures\n",
      "T19\tMethod 675 704\tpredictors of intelligibility\n",
      "T20\tMetric 711 723\tcorrelations\n",
      "T21\tOtherScientificTerm 742 759\tsubjective scores\n",
      "T22\tGeneric 765 773\tmeasures\n",
      "T23\tTask 793 823\tpredictions of intelligibility\n",
      "T24\tMaterial 828 844\tsynthetic speech\n",
      "T25\tMaterial 881 895\tnatural speech\n",
      "T26\tMetric 915 926\tSII measure\n",
      "T27\tMaterial 972 990\tsynthesized speech\n",
      "T28\tMethod 997 1014\tideal binary mask\n",
      "T29\tMetric 1040 1055\tGlimpse measure\n",
      "T30\tTask 1079 1106\tintelligibility predictions\n",
      "R1\tHYPONYM-OF Arg1:T10 Arg2:T9\n",
      "R2\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R3\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R4\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R5\tHYPONYM-OF Arg1:T7 Arg2:T5\n",
      "R6\tHYPONYM-OF Arg1:T8 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R8\tPART-OF Arg1:T14 Arg2:T13\n",
      "R9\tHYPONYM-OF Arg1:T5 Arg2:T1\n",
      "R10\tHYPONYM-OF Arg1:T9 Arg2:T1\n",
      "R11\tCOREF Arg1:T1 Arg2:T15\n",
      "R12\tCOMPARE Arg1:T15 Arg2:T16\n",
      "R13\tCOREF Arg1:T6 Arg2:T17\n",
      "R14\tCOREF Arg1:T7 Arg2:T18\n",
      "R15\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R16\tCOREF Arg1:T15 Arg2:T22\n",
      "R17\tUSED-FOR Arg1:T24 Arg2:T23\n",
      "R18\tCOREF Arg1:T2 Arg2:T23\n",
      "R19\tCOMPARE Arg1:T24 Arg2:T25\n",
      "R20\tHYPONYM-OF Arg1:T26 Arg2:T22\n",
      "R21\tEVALUATE-FOR Arg1:T22 Arg2:T23\n",
      "R22\tUSED-FOR Arg1:T29 Arg2:T30\n",
      "R23\tCOREF Arg1:T23 Arg2:T30\n",
      "R24\tUSED-FOR Arg1:T28 Arg2:T27\n",
      "R25\tCOREF Arg1:T29 Arg2:T18\n",
      "R26\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R27\tEVALUATE-FOR Arg1:T1 Arg2:T2\n",
      "R28\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "R29\tEVALUATE-FOR Arg1:T20 Arg2:T18\n",
      "R30\tEVALUATE-FOR Arg1:T20 Arg2:T17\n",
      "R31\tHYPONYM-OF Arg1:T18 Arg2:T19\n",
      "R32\tHYPONYM-OF Arg1:T17 Arg2:T19\n",
      "R33\tCOMPARE Arg1:T18 Arg2:T21\n",
      "R34\tCOMPARE Arg1:T17 Arg2:T21\n",
      "R35\tCONJUNCTION Arg1:T5 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_2016_11_abs.ann\n",
      "T1\tTask 15 96\tblind separation of underdetermined instantaneous mixtures of independent signals\n",
      "T2\tGeneric 120 126\tmethod\n",
      "T3\tOtherScientificTerm 138 153\tnonstationarity\n",
      "T4\tOtherScientificTerm 161 177\toriginal signals\n",
      "T5\tGeneric 183 190\tsignals\n",
      "T6\tGeneric 346 353\tsignals\n",
      "T7\tMethod 395 427\tfirst-order autoregressive model\n",
      "T8\tGeneric 434 439\tmodel\n",
      "T9\tTask 477 520\tblind separation of natural speech signals.\n",
      "T10\tMethod 523 540\tseparation method\n",
      "T11\tOtherScientificTerm 623 646\tCramÃ©r-Rao lower bound)\n",
      "T12\tGeneric 682 695\tassumed model\n",
      "T13\tOtherScientificTerm 712 734\tnatural speech signals\n",
      "T14\tGeneric 741 747\tmethod\n",
      "T15\tMetric 765 784\tseparation accuracy\n",
      "T16\tGeneric 818 825\tmethods\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tCOREF Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R4\tCOREF Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R6\tCOREF Arg1:T8 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R8\tCOMPARE Arg1:T14 Arg2:T16\n",
      "R9\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R10\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R11\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T13\n",
      "R13\tCOREF Arg1:T14 Arg2:T10\n",
      "R14\tCOREF Arg1:T8 Arg2:T12\n",
      "R15\tFEATURE-OF Arg1:T11 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_2016_14_abs.ann\n",
      "T1\tTask 4 29\tmobile speech application\n",
      "T2\tMetric 31 62\tspeaker DOA estimation accuracy\n",
      "T3\tMetric 64 87\tinterference robustness\n",
      "T4\tMetric 92 113\tcompact physical size\n",
      "T5\tMethod 171 199\tacoustic vector sensor (AVS)\n",
      "T6\tMethod 215 239\tDOA estimation algorithm\n",
      "T7\tOtherScientificTerm 328 358\tnon-speech interferences (NSI)\n",
      "T8\tMethod 382 421\trobust speaker DOA estimation algorithm\n",
      "T9\tGeneric 423 425\tIt\n",
      "T10\tMethod 454 483\tinter-sensor data ratio model\n",
      "T11\tMethod 490 493\tAVS\n",
      "T12\tMethod 497 522\tbispectrum domain (BISDR)\n",
      "T13\tGeneric 541 561\tfavorable properties\n",
      "T14\tMethod 565 575\tbispectrum\n",
      "T15\tOtherScientificTerm 585 615\tzero value of Gaussian process\n",
      "T16\tOtherScientificTerm 630 660\tdistribution of speech and NSI\n",
      "T17\tOtherScientificTerm 657 660\tNSI\n",
      "T18\tMethod 687 702\tbispectrum mask\n",
      "T19\tOtherScientificTerm 738 754\tspeaker DOA cues\n",
      "T20\tMethod 769 774\tBISDR\n",
      "T21\tOtherScientificTerm 790 793\tNSI\n",
      "T22\tOtherScientificTerm 806 821\tspeech sparsity\n",
      "T23\tOtherScientificTerm 832 852\tbispectrum amplitude\n",
      "T24\tGeneric 952 961\talgorithm\n",
      "T25\tOtherScientificTerm 976 990\tNSI conditions\n",
      "T26\tMetric 1001 1004\tSIR\n",
      "R1\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R2\tFEATURE-OF Arg1:T3 Arg2:T1\n",
      "R3\tFEATURE-OF Arg1:T4 Arg2:T1\n",
      "R4\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R5\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R6\tCOREF Arg1:T9 Arg2:T8\n",
      "R7\tCOREF Arg1:T5 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R9\tCOREF Arg1:T17 Arg2:T7\n",
      "R10\tCOREF Arg1:T20 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R12\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R13\tCOREF Arg1:T21 Arg2:T7\n",
      "R14\tCOREF Arg1:T21 Arg2:T25\n",
      "R15\tUSED-FOR Arg1:T24 Arg2:T25\n",
      "R16\tCOREF Arg1:T9 Arg2:T24\n",
      "R17\tCOREF Arg1:T6 Arg2:T8\n",
      "R18\tHYPONYM-OF Arg1:T15 Arg2:T13\n",
      "R19\tHYPONYM-OF Arg1:T16 Arg2:T13\n",
      "R20\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R21\tUSED-FOR Arg1:T9 Arg2:T13\n",
      "R22\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_2016_3_abs.ann\n",
      "T1\tTask 0 33\tSpeech-based depression detection\n",
      "T2\tMetric 198 208\trobustness\n",
      "T3\tOtherScientificTerm 212 223\tspeech cues\n",
      "T4\tOtherScientificTerm 271 276\tnoise\n",
      "T5\tOtherScientificTerm 281 294\treverberation\n",
      "T6\tTask 298 319\tdepression prediction\n",
      "T7\tMethod 338 381\tmel-frequency cepstral coefficients (MFCCs)\n",
      "T8\tGeneric 390 398\tfeatures\n",
      "T9\tMetric 412 428\tnoise robustness\n",
      "T10\tMethod 430 477\tdamped oscillator cepstral coefficients (DOCCs)\n",
      "T11\tMaterial 503 551\tAudioVisual Emotion Recognition Challenge (AVEC)\n",
      "T12\tOtherScientificTerm 567 581\tadditive noise\n",
      "T13\tOtherScientificTerm 586 599\treverberation\n",
      "T14\tMetric 653 671\tevaluation metrics\n",
      "T15\tMethod 751 764\tMFCC features\n",
      "T16\tOtherScientificTerm 820 825\tnoise\n",
      "T17\tOtherScientificTerm 830 843\treverberation\n",
      "T18\tMethod 845 858\tDOCC features\n",
      "T19\tOtherScientificTerm 898 932\thigher-order cepstral coefficients\n",
      "T20\tMethod 965 991\tartificial neural networks\n",
      "T21\tMethod 1011 1036\tsupport vector regression\n",
      "T22\tMaterial 1046 1064\tspontaneous speech\n",
      "T23\tMaterial 1105 1116\tread speech\n",
      "T24\tOtherScientificTerm 1129 1173\tcross-corpus (and cross-language) experiment\n",
      "T25\tMetric 1189 1223\tnoise and reverberation robustness\n",
      "T26\tMethod 1228 1233\tDOCCs\n",
      "T27\tMethod 1243 1248\tMFCCs\n",
      "T28\tTask 1289 1327\treal-world robust depression detection\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R3\tFEATURE-OF Arg1:T5 Arg2:T6\n",
      "R4\tFEATURE-OF Arg1:T4 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R7\tCOREF Arg1:T10 Arg2:T8\n",
      "R8\tCOREF Arg1:T15 Arg2:T7\n",
      "R9\tCOMPARE Arg1:T18 Arg2:T15\n",
      "R10\tCOREF Arg1:T18 Arg2:T10\n",
      "R11\tCOMPARE Arg1:T20 Arg2:T21\n",
      "R12\tCOMPARE Arg1:T22 Arg2:T23\n",
      "R13\tCOMPARE Arg1:T26 Arg2:T27\n",
      "R14\tCOREF Arg1:T26 Arg2:T18\n",
      "R15\tCOREF Arg1:T27 Arg2:T15\n",
      "R16\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R17\tEVALUATE-FOR Arg1:T25 Arg2:T26\n",
      "R18\tEVALUATE-FOR Arg1:T25 Arg2:T27\n",
      "R19\tEVALUATE-FOR Arg1:T24 Arg2:T26\n",
      "R20\tEVALUATE-FOR Arg1:T24 Arg2:T27\n",
      "R21\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R22\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R23\tCONJUNCTION Arg1:T8 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICASSP_2016_4_abs.ann\n",
      "T1\tOtherScientificTerm 0 34\tHigh frequency oscillations (HFOs)\n",
      "T2\tOtherScientificTerm 64 99\tepileptic brain tissue and activity\n",
      "T3\tOtherScientificTerm 101 105\tHFOs\n",
      "T4\tTask 172 199\tanalysis of discrete events\n",
      "T5\tMaterial 203 250\thigh-temporal resolution, intracranial EEG data\n",
      "T6\tTask 282 306\tdimensionality reduction\n",
      "T7\tTask 315 354\tassessing feasibility of classification\n",
      "T8\tTask 340 354\tclassification\n",
      "T9\tTask 356 380\tDimensionality reduction\n",
      "T10\tMaterial 412 420\tmanifold\n",
      "T11\tOtherScientificTerm 458 472\tfeatures space\n",
      "T12\tTask 492 504\tHFO analysis\n",
      "T13\tOtherScientificTerm 520 535\tlinear manifold\n",
      "T14\tMethod 659 673\tlinear methods\n",
      "T15\tOtherScientificTerm 720 728\tmanifold\n",
      "T16\tOtherScientificTerm 780 786\tbounds\n",
      "T17\tOtherScientificTerm 794 820\tBayes classification error\n",
      "T18\tOtherScientificTerm 872 876\tHFOs\n",
      "T19\tGeneric 878 883\tthose\n",
      "T20\tGeneric 914 919\tthose\n",
      "T21\tTask 1004 1032\tclinical use of HFO features\n",
      "T22\tOtherScientificTerm 1020 1032\tHFO features\n",
      "T23\tOtherScientificTerm 1067 1082\tdiscrete events\n",
      "T24\tOtherScientificTerm 1103 1120\taction potentials\n",
      "T25\tOtherScientificTerm 1124 1143\tmulti-unit activity\n",
      "R1\tCOREF Arg1:T1 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tHYPONYM-OF Arg1:T19 Arg2:T18\n",
      "R4\tHYPONYM-OF Arg1:T20 Arg2:T18\n",
      "R5\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R7\tCOREF Arg1:T6 Arg2:T9\n",
      "R8\tCOREF Arg1:T3 Arg2:T18\n",
      "R9\tHYPONYM-OF Arg1:T24 Arg2:T23\n",
      "R10\tHYPONYM-OF Arg1:T25 Arg2:T23\n",
      "R11\tCONJUNCTION Arg1:T24 Arg2:T25\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_1999_47_abs.ann\n",
      "T1\tTask 0 22\tBackground maintenance\n",
      "T2\tTask 48 74\tvideo surveillance systems\n",
      "T3\tMethod 87 97\tWallflower\n",
      "T4\tGeneric 101 123\tthree-component system\n",
      "T5\tTask 128 150\tbackground maintenance\n",
      "T6\tMethod 156 177\tpixel-level component\n",
      "T7\tMethod 187 203\tWiener filtering\n",
      "T8\tTask 212 264\tprobabilistic predictions of the expected background\n",
      "T9\tMethod 270 292\tregion-level component\n",
      "T10\tOtherScientificTerm 302 343\thomogeneous regions of foreground objects\n",
      "T11\tMethod 353 374\tframe-level component\n",
      "T12\tGeneric 488 494\tsystem\n",
      "T13\tMethod 508 541\tbackground subtraction algorithms\n",
      "T14\tMethod 543 553\tWallflower\n",
      "T15\tGeneric 586 596\talgorithms\n",
      "T16\tMethod 724 744\tnormative principles\n",
      "T17\tTask 749 771\tbackground maintenance\n",
      "R1\tPART-OF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T5 Arg2:T1\n",
      "R3\tCOREF Arg1:T3 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tPART-OF Arg1:T6 Arg2:T4\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R9\tPART-OF Arg1:T9 Arg2:T4\n",
      "R10\tPART-OF Arg1:T11 Arg2:T4\n",
      "R11\tCONJUNCTION Arg1:T6 Arg2:T9\n",
      "R12\tCONJUNCTION Arg1:T9 Arg2:T11\n",
      "R13\tCOREF Arg1:T3 Arg2:T12\n",
      "R14\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R15\tCOREF Arg1:T14 Arg2:T12\n",
      "R16\tCOREF Arg1:T15 Arg2:T13\n",
      "R17\tCOMPARE Arg1:T14 Arg2:T15\n",
      "R18\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R19\tCOREF Arg1:T5 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2001_47_abs.ann\n",
      "T1\tOtherScientificTerm 28 56\tpriori geometric constraints\n",
      "T2\tMethod 62 94\t3â€“D stereo reconstruction scheme\n",
      "T3\tOtherScientificTerm 129 146\timage information\n",
      "T4\tOtherScientificTerm 193 202\t3â€“D shape\n",
      "T5\tGeneric 208 216\tapproach\n",
      "T6\tMethod 233 276\titerative deformation of a 3â€“D surface mesh\n",
      "T7\tOtherScientificTerm 292 310\tobjective function\n",
      "T8\tMethod 335 354\tanisotropic meshing\n",
      "T9\tMethod 362 384\tnon-quadratic approach\n",
      "T10\tOtherScientificTerm 388 402\tregularization\n",
      "T11\tTask 437 451\treconstruction\n",
      "T12\tOtherScientificTerm 466 480\ttriangulations\n",
      "T13\tOtherScientificTerm 490 498\tvertices\n",
      "T14\tOtherScientificTerm 500 535\tStructural or numerical constraints\n",
      "T15\tMethod 569 591\treconstruction process\n",
      "T16\tMethod 602 633\tconstrained optimization scheme\n",
      "T17\tGeneric 635 639\tThey\n",
      "T18\tTask 652 666\treconstruction\n",
      "T19\tOtherScientificTerm 712 728\tpriori knowledge\n",
      "T20\tOtherScientificTerm 735 747\tobject shape\n",
      "T21\tOtherScientificTerm 776 795\tmodeling properties\n",
      "T22\tOtherScientificTerm 799 820\tdifferential features\n",
      "T23\tGeneric 826 830\tthem\n",
      "T24\tTask 892 910\t3â€“D reconstruction\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R4\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R6\tPART-OF Arg1:T1 Arg2:T2\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R11\tUSED-FOR Arg1:T16 Arg2:T14\n",
      "R12\tCOREF Arg1:T18 Arg2:T11\n",
      "R13\tCOREF Arg1:T14 Arg2:T17\n",
      "R14\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R15\tFEATURE-OF Arg1:T20 Arg2:T19\n",
      "R16\tCOREF Arg1:T23 Arg2:T17\n",
      "R17\tUSED-FOR Arg1:T23 Arg2:T24\n",
      "R18\tCOREF Arg1:T24 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2001_50_abs.ann\n",
      "T1\tMethod 17 56\tmodel-based bundle adjustment algorithm\n",
      "T2\tMethod 72 80\t3D model\n",
      "T3\tMaterial 118 124\timages\n",
      "T4\tOtherScientificTerm 130 145\tunknown motions\n",
      "T5\tOtherScientificTerm 203 223\tisolated 3D features\n",
      "T6\tGeneric 246 255\talgorithm\n",
      "T7\tOtherScientificTerm 263 270\tsurface\n",
      "T8\tGeneric 335 357\tmodel-based approaches\n",
      "T9\tGeneric 363 371\tapproach\n",
      "T10\tOtherScientificTerm 430 441\tmodel space\n",
      "T11\tOtherScientificTerm 447 459\tregular-izer\n",
      "T12\tGeneric 477 479\tit\n",
      "T13\tOtherScientificTerm 487 499\tsearch space\n",
      "T14\tGeneric 599 608\talgorithm\n",
      "T15\tOtherScientificTerm 685 693\tsurfaces\n",
      "T16\tOtherScientificTerm 730 756\tprior 2D-to-3D association\n",
      "T17\tTask 775 788\tface modeling\n",
      "T18\tMetric 817 829\tface metrics\n",
      "T19\tOtherScientificTerm 877 890\tface geometry\n",
      "T20\tOtherScientificTerm 915 927\tsearch space\n",
      "T21\tMethod 941 953\tposed system\n",
      "T22\tMaterial 977 1000\tsynthetic and real data\n",
      "T23\tGeneric 1020 1029\talgorithm\n",
      "T24\tGeneric 1085 1089\tones\n",
      "R1\tPART-OF Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T1 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R6\tCOREF Arg1:T9 Arg2:T6\n",
      "R7\tCOMPARE Arg1:T8 Arg2:T9\n",
      "R8\tCOREF Arg1:T10 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R10\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R11\tCOMPARE Arg1:T11 Arg2:T13\n",
      "R12\tCOREF Arg1:T9 Arg2:T14\n",
      "R13\tCOREF Arg1:T14 Arg2:T23\n",
      "R14\tEVALUATE-FOR Arg1:T22 Arg2:T23\n",
      "R15\tCOREF Arg1:T8 Arg2:T24\n",
      "R16\tCOMPARE Arg1:T23 Arg2:T24\n",
      "R17\tEVALUATE-FOR Arg1:T22 Arg2:T24\n",
      "R18\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R19\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R20\tUSED-FOR Arg1:T18 Arg2:T20\n",
      "R21\tUSED-FOR Arg1:T18 Arg2:T21\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2003_150_abs.ann\n",
      "T1\tMethod 13 50\tsingle-image highlight removal method\n",
      "T2\tOtherScientificTerm 69 99\tillumination-based constraints\n",
      "T3\tTask 105 122\timage in-painting\n",
      "T4\tOtherScientificTerm 131 153\toccluded image regions\n",
      "T5\tOtherScientificTerm 176 186\tinpainting\n",
      "T6\tOtherScientificTerm 188 204\thighlight pixels\n",
      "T7\tTask 253 271\tinpainting process\n",
      "T8\tOtherScientificTerm 273 284\tConstraints\n",
      "T9\tOtherScientificTerm 306 318\tpixel colors\n",
      "T10\tOtherScientificTerm 320 344\thighlight color analysis\n",
      "T11\tOtherScientificTerm 349 378\tillumination color uniformity\n",
      "T12\tGeneric 399 405\tmethod\n",
      "T13\tOtherScientificTerm 417 459\testimation of the underlying diffuse color\n",
      "T14\tOtherScientificTerm 484 508\tillumination constraints\n",
      "T15\tOtherScientificTerm 527 559\trecovery of shading and textures\n",
      "T16\tTask 563 573\tinpainting\n",
      "T17\tMethod 644 650\tmethod\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R2\tCOREF Arg1:T7 Arg2:T3\n",
      "R3\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R5\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T12\n",
      "R7\tCOREF Arg1:T14 Arg2:T8\n",
      "R8\tCOREF Arg1:T16 Arg2:T7\n",
      "R9\tCOREF Arg1:T12 Arg2:T1\n",
      "R10\tPART-OF Arg1:T2 Arg2:T3\n",
      "R11\tCOREF Arg1:T17 Arg2:T12\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R13\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2003_151_abs.ann\n",
      "T1\tGeneric 6 15\talgorithm\n",
      "T2\tTask 32 53\tnovel view generation\n",
      "T3\tTask 57 97\tone-to-one teleconferencing applications\n",
      "T4\tMaterial 109 122\tvideo streams\n",
      "T5\tOtherScientificTerm 139 146\tcameras\n",
      "T6\tOtherScientificTerm 174 190\tcomputer monitor\n",
      "T7\tGeneric 206 215\talgorithm\n",
      "T8\tMaterial 228 234\timages\n",
      "T9\tOtherScientificTerm 242 256\tvirtual camera\n",
      "T10\tOtherScientificTerm 260 278\tarbitrary position\n",
      "T11\tOtherScientificTerm 332 343\teye contact\n",
      "T12\tGeneric 349 358\ttechnique\n",
      "T13\tMethod 384 421\tdynamic-programming, stereo algorithm\n",
      "T14\tTask 436 457\tnovel-view generation\n",
      "T15\tMethod 522 539\tthree-plane graph\n",
      "T16\tMethod 544 576\tdense-stereo dynamic-programming\n",
      "T17\tTask 602 620\tocclusion labeling\n",
      "T18\tOtherScientificTerm 628 656\tcompact geometric derivation\n",
      "T19\tTask 661 681\tnovel-view synthesis\n",
      "T20\tMethod 685 730\tdirect projection of the minimum-cost surface\n",
      "T21\tGeneric 773 782\talgorithm\n",
      "T22\tTask 791 833\ttemporal maintenance of a background model\n",
      "T23\tTask 849 872\trendering of occlusions\n",
      "T24\tOtherScientificTerm 884 912\ttemporal artefacts (flicker)\n",
      "T25\tMethod 920 946\tcost aggregation algorithm\n",
      "T26\tOtherScientificTerm 973 1010\tthree-dimensional matching cost space\n",
      "T27\tMetric 1052 1062\trobustness\n",
      "T28\tGeneric 1074 1083\talgorithm\n",
      "T29\tOtherScientificTerm 1087 1117\tspatial and temporal artefacts\n",
      "T30\tMaterial 1122 1147\tlong stereo video streams\n",
      "T31\tTask 1181 1246\tsynthesis of cyclopean views of extended conversational sequences\n",
      "T32\tOtherScientificTerm 1194 1209\tcyclopean views\n",
      "T33\tMaterial 1213 1246\textended conversational sequences\n",
      "T34\tTask 1271 1280\tsynthesis\n",
      "T35\tOtherScientificTerm 1295 1321\ttranslating virtual camera\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tCOREF Arg1:T1 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R4\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T11\n",
      "R6\tCOREF Arg1:T12 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R11\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R12\tUSED-FOR Arg1:T20 Arg2:T18\n",
      "R13\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R14\tUSED-FOR Arg1:T21 Arg2:T23\n",
      "R15\tUSED-FOR Arg1:T25 Arg2:T26\n",
      "R16\tCONJUNCTION Arg1:T25 Arg2:T21\n",
      "R17\tCOREF Arg1:T12 Arg2:T21\n",
      "R18\tCOREF Arg1:T21 Arg2:T28\n",
      "R19\tEVALUATE-FOR Arg1:T27 Arg2:T28\n",
      "R20\tUSED-FOR Arg1:T21 Arg2:T24\n",
      "R21\tUSED-FOR Arg1:T28 Arg2:T29\n",
      "R22\tUSED-FOR Arg1:T35 Arg2:T34\n",
      "R23\tUSED-FOR Arg1:T29 Arg2:T30\n",
      "R24\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R25\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R26\tCOREF Arg1:T2 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2003_158_abs.ann\n",
      "T1\tGeneric 23 32\talgorithm\n",
      "T2\tTask 37 96\tcomputing optical flow, shape, motion, lighting, and albedo\n",
      "T3\tMaterial 105 119\timage sequence\n",
      "T4\tMaterial 125 157\trigidly-moving Lambertian object\n",
      "T5\tOtherScientificTerm 164 184\tdistant illumination\n",
      "T6\tGeneric 190 197\tproblem\n",
      "T7\tMaterial 253 259\tmotion\n",
      "T8\tMaterial 261 278\tmulti-view stereo\n",
      "T9\tMaterial 284 303\tphoto-metric stereo\n",
      "T10\tGeneric 326 335\talgorithm\n",
      "T11\tOtherScientificTerm 350 390\tspatial and temporal intensity variation\n",
      "T12\tGeneric 394 398\tcues\n",
      "T13\tGeneric 404 410\tformer\n",
      "T14\tOtherScientificTerm 422 426\tflow\n",
      "T15\tGeneric 435 441\tlatter\n",
      "T16\tOtherScientificTerm 453 472\tsurface orientation\n",
      "T17\tGeneric 490 494\tcues\n",
      "T18\tTask 503 566\tdense reconstruction of both textured and texture-less surfaces\n",
      "T19\tGeneric 572 581\talgorithm\n",
      "T20\tMethod 603 672\testimating affine camera parameters, illumination , shape, and albedo\n",
      "T21\tMaterial 728 755\tvideos of hand-held objects\n",
      "R1\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "R2\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R5\tCOREF Arg1:T2 Arg2:T6\n",
      "R6\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R7\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R10\tCOREF Arg1:T11 Arg2:T12\n",
      "R11\tHYPONYM-OF Arg1:T13 Arg2:T12\n",
      "R12\tHYPONYM-OF Arg1:T15 Arg2:T12\n",
      "R13\tCONJUNCTION Arg1:T13 Arg2:T15\n",
      "R14\tCOREF Arg1:T17 Arg2:T12\n",
      "R15\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R16\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R17\tCOREF Arg1:T10 Arg2:T1\n",
      "R18\tCOREF Arg1:T19 Arg2:T10\n",
      "R19\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2003_161_abs.ann\n",
      "T1\tTask 4 37\tperception of transparent objects\n",
      "T2\tMaterial 43 49\timages\n",
      "T3\tOtherScientificTerm 165 184\ttransparent objects\n",
      "T4\tOtherScientificTerm 248 267\ttransparent objects\n",
      "T5\tOtherScientificTerm 302 310\tfeatures\n",
      "T6\tOtherScientificTerm 337 355\ttransparent object\n",
      "T7\tGeneric 380 385\tthose\n",
      "T8\tMethod 445 465\tmodel-based approach\n",
      "T9\tOtherScientificTerm 481 524\tshapes and the poses of transparent objects\n",
      "T10\tOtherScientificTerm 530 542\tknown motion\n",
      "T11\tGeneric 548 555\tobjects\n",
      "T12\tGeneric 579 583\tthey\n",
      "T13\tOtherScientificTerm 603 618\tmultiple layers\n",
      "T14\tOtherScientificTerm 634 652\trefractive indices\n",
      "T15\tGeneric 736 745\talgorithm\n",
      "T16\tGeneric 763 765\tit\n",
      "T17\tMaterial 769 780\treal scenes\n",
      "T18\tOtherScientificTerm 794 813\ttransparent objects\n",
      "T19\tOtherScientificTerm 832 853\tshapes of the objects\n",
      "T20\tMetric 864 872\taccuracy\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOMPARE Arg1:T7 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R5\tCOREF Arg1:T11 Arg2:T12\n",
      "R6\tPART-OF Arg1:T13 Arg2:T12\n",
      "R7\tCOREF Arg1:T8 Arg2:T15\n",
      "R8\tFEATURE-OF Arg1:T14 Arg2:T13\n",
      "R9\tCOREF Arg1:T16 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R11\tPART-OF Arg1:T18 Arg2:T17\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T19\n",
      "R13\tEVALUATE-FOR Arg1:T20 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2005_47_abs.ann\n",
      "T1\tTask 0 32\tFace images of non-frontal views\n",
      "T2\tMetric 97 122\tface recognition accuracy\n",
      "T3\tMetric 174 190\trecognition rate\n",
      "T4\tMethod 207 231\tface recognition systems\n",
      "T5\tMaterial 248 270\tlive CCTV camera input\n",
      "T6\tMethod 300 318\tBayesian framework\n",
      "T7\tOtherScientificTerm 365 374\tviewpoint\n",
      "T8\tOtherScientificTerm 379 391\tillumination\n",
      "T9\tTask 393 420\tface image super-resolution\n",
      "T10\tTask 425 436\trecognition\n",
      "T11\tOtherScientificTerm 440 452\ttensor space\n",
      "T12\tMaterial 462 500\tsingle modal low-resolution face image\n",
      "T13\tOtherScientificTerm 522 569\tmultiple factor interactions of training tensor\n",
      "T14\tTask 593 624\thigh-resolution reconstructions\n",
      "T15\tOtherScientificTerm 642 652\tmodalities\n",
      "T16\tTask 657 673\tface recognition\n",
      "T17\tTask 697 742\tpixel-domain super-resolution and recognition\n",
      "T18\tTask 821 837\tsuper-resolution\n",
      "T19\tTask 842 853\trecognition\n",
      "T20\tOtherScientificTerm 878 922\tmaximum likelihood identity parameter vector\n",
      "T21\tOtherScientificTerm 926 954\thigh-resolution tensor space\n",
      "T22\tTask 959 970\trecognition\n",
      "T23\tTask 993 1042\tmulti-modal super-resolution and face recognition\n",
      "T24\tOtherScientificTerm 1072 1090\timaging modalities\n",
      "T25\tMaterial 1098 1119\tlow-resolution images\n",
      "T26\tMetric 1163 1180\trecognition rates\n",
      "T27\tMethod 1195 1235\ttensorface and eigenface representations\n",
      "R1\tEVALUATE-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R5\tFEATURE-OF Arg1:T15 Arg2:T14\n",
      "R6\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R7\tFEATURE-OF Arg1:T21 Arg2:T20\n",
      "R8\tUSED-FOR Arg1:T20 Arg2:T22\n",
      "R9\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R10\tUSED-FOR Arg1:T25 Arg2:T23\n",
      "R11\tEVALUATE-FOR Arg1:T26 Arg2:T23\n",
      "R12\tEVALUATE-FOR Arg1:T26 Arg2:T27\n",
      "R13\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R14\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R15\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R16\tFEATURE-OF Arg1:T11 Arg2:T10\n",
      "R17\tHYPONYM-OF Arg1:T18 Arg2:T17\n",
      "R18\tHYPONYM-OF Arg1:T19 Arg2:T17\n",
      "R19\tUSED-FOR Arg1:T20 Arg2:T18\n",
      "R20\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R21\tCOREF Arg1:T22 Arg2:T19\n",
      "R22\tCOREF Arg1:T19 Arg2:T16\n",
      "R23\tCOREF Arg1:T16 Arg2:T10\n",
      "R24\tCOREF Arg1:T18 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2005_50_abs.ann\n",
      "T1\tGeneric 8 18\tapproaches\n",
      "T2\tTask 22 49\tobject category recognition\n",
      "T3\tGeneric 58 66\tdatasets\n",
      "T4\tOtherScientificTerm 135 146\tsupervision\n",
      "T5\tGeneric 162 170\tapproach\n",
      "T6\tOtherScientificTerm 189 204\tobject category\n",
      "T7\tMethod 256 276\timage search engines\n",
      "T8\tGeneric 321 326\tmodel\n",
      "T9\tMethod 328 336\tTSI-pLSA\n",
      "T10\tMethod 352 356\tpLSA\n",
      "T11\tOtherScientificTerm 372 384\tvisual words\n",
      "T12\tOtherScientificTerm 397 416\tspatial information\n",
      "T13\tGeneric 466 474\tapproach\n",
      "T14\tOtherScientificTerm 495 518\tintra-class variability\n",
      "T15\tOtherScientificTerm 543 559\tunrelated images\n",
      "T16\tMethod 572 586\tsearch engines\n",
      "T17\tGeneric 604 610\tmodels\n",
      "T18\tGeneric 623 632\ttest sets\n",
      "T19\tGeneric 680 687\tmethods\n",
      "T20\tMaterial 699 721\thand prepared datasets\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tCOREF Arg1:T5 Arg2:T8\n",
      "R5\tCOREF Arg1:T8 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T9 Arg2:T13\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R10\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R11\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R13\tCOREF Arg1:T7 Arg2:T16\n",
      "R14\tCOREF Arg1:T13 Arg2:T17\n",
      "R15\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R16\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R17\tCOMPARE Arg1:T19 Arg2:T17\n",
      "R18\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "R19\tPART-OF Arg1:T12 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2009_47_abs.ann\n",
      "T1\tGeneric 27 36\ttechnique\n",
      "T2\tTask 41 58\trobust estimation\n",
      "T3\tOtherScientificTerm 99 147\tinherent uncertainty of the estimation procedure\n",
      "T4\tMethod 167 204\tefficient robust estimation algorithm\n",
      "T5\tTask 246 275\trandomized model verification\n",
      "T6\tGeneric 285 289\tthis\n",
      "T7\tGeneric 371 381\tstrategies\n",
      "T8\tMethod 395 422\trobust estimation procedure\n",
      "T9\tMethod 474 491\tRANSAC techniques\n",
      "T10\tOtherScientificTerm 512 529\tprior information\n",
      "T11\tOtherScientificTerm 543 559\tsampling process\n",
      "T12\tGeneric 580 589\talgorithm\n",
      "T13\tMethod 651 657\tRANSAC\n",
      "T14\tOtherScientificTerm 692 715\ttheoretical predictions\n",
      "T15\tGeneric 739 748\talgorithm\n",
      "T16\tTask 783 812\tgeometric estimation problems\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T6 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R6\tCOREF Arg1:T4 Arg2:T8\n",
      "R7\tCOMPARE Arg1:T9 Arg2:T8\n",
      "R8\tCOREF Arg1:T12 Arg2:T8\n",
      "R9\tCOREF Arg1:T13 Arg2:T9\n",
      "R10\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R11\tCOREF Arg1:T15 Arg2:T12\n",
      "R12\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2011_47_abs.ann\n",
      "T1\tGeneric 13 19\tmethod\n",
      "T2\tTask 24 44\tdetecting 3D objects\n",
      "T3\tOtherScientificTerm 51 67\tmulti-modalities\n",
      "T4\tGeneric 75 77\tit\n",
      "T5\tGeneric 105 107\tit\n",
      "T6\tOtherScientificTerm 133 138\timage\n",
      "T7\tOtherScientificTerm 145 160\tdense depth map\n",
      "T8\tOtherScientificTerm 172 204\tcomplementary object information\n",
      "T9\tGeneric 206 208\tIt\n",
      "T10\tOtherScientificTerm 269 298\ttime consuming training stage\n",
      "T11\tOtherScientificTerm 315 333\tuntextured objects\n",
      "T12\tGeneric 335 337\tIt\n",
      "T13\tOtherScientificTerm 381 390\ttemplates\n",
      "T14\tOtherScientificTerm 418 428\tmodalities\n",
      "T15\tOtherScientificTerm 465 483\tcommodity hardware\n",
      "T16\tGeneric 493 501\tapproach\n",
      "T17\tGeneric 528 552\tstate-of-the-art methods\n",
      "T18\tOtherScientificTerm 556 573\tsingle modalities\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R7\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "R8\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R9\tCOREF Arg1:T9 Arg2:T5\n",
      "R10\tCOREF Arg1:T9 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R12\tCOREF Arg1:T16 Arg2:T12\n",
      "R13\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R14\tUSED-FOR Arg1:T16 Arg2:T18\n",
      "R15\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2011_50_abs.ann\n",
      "T1\tTask 7 22\tsecurity domain\n",
      "T2\tTask 40 79\tidentifying rare behaviours of interest\n",
      "T3\tOtherScientificTerm 52 79\trare behaviours of interest\n",
      "T4\tMaterial 81 98\tTraining examples\n",
      "T5\tGeneric 109 119\tbehaviours\n",
      "T6\tGeneric 149 153\tthey\n",
      "T7\tMethod 230 257\tweakly supervised algorithm\n",
      "T8\tOtherScientificTerm 274 284\tbehaviours\n",
      "T9\tOtherScientificTerm 362 376\tGlobal context\n",
      "T10\tTask 403 435\tdetection of abnormal behaviours\n",
      "T11\tOtherScientificTerm 469 486\tPragmatic aspects\n",
      "T12\tMethod 516 532\tparameter tuning\n",
      "R1\tCOREF Arg1:T5 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tCOREF Arg1:T4 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R6\tCOREF Arg1:T10 Arg2:T2\n",
      "R7\tPART-OF Arg1:T2 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2013_25_abs.ann\n",
      "T1\tMethod 13 28\tscanning method\n",
      "T2\tOtherScientificTerm 43 90\tdense sub-pixel camera-projector correspondence\n",
      "T3\tOtherScientificTerm 113 136\tphotometric calibration\n",
      "T4\tOtherScientificTerm 172 189\trelative geometry\n",
      "T5\tMetric 191 208\tSubpixel accuracy\n",
      "T6\tOtherScientificTerm 244 258\tzero-crossings\n",
      "T7\tOtherScientificTerm 302 323\tunstructured patterns\n",
      "T8\tOtherScientificTerm 332 373\tgray-level band-pass white noise patterns\n",
      "T9\tMetric 388 398\trobustness\n",
      "T10\tOtherScientificTerm 402 419\tindirect lighting\n",
      "T11\tOtherScientificTerm 424 445\tscene discontinuities\n",
      "T12\tGeneric 496 502\tmethod\n",
      "T13\tOtherScientificTerm 512 526\tscene geometry\n",
      "T14\tMetric 537 555\tsubpixel precision\n",
      "T15\tGeneric 566 568\tit\n",
      "T16\tTask 599 628\tactive reconstruction systems\n",
      "T17\tGeneric 656 680\tstate of the art methods\n",
      "T18\tMethod 689 710\tmi-cro phase shifting\n",
      "T19\tMethod 715 739\tmodulated phase shifting\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tEVALUATE-FOR Arg1:T9 Arg2:T8\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R4\tCOREF Arg1:T12 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R6\tCOREF Arg1:T15 Arg2:T12\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R8\tFEATURE-OF Arg1:T14 Arg2:T13\n",
      "R9\tHYPONYM-OF Arg1:T18 Arg2:T17\n",
      "R10\tHYPONYM-OF Arg1:T19 Arg2:T17\n",
      "R11\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "R12\tFEATURE-OF Arg1:T11 Arg2:T9\n",
      "R13\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R14\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2013_26_abs.ann\n",
      "T1\tMethod 43 86\tcoarse-to-fine energy minimization strategy\n",
      "T2\tTask 91 119\tsemantic video segmenta-tion\n",
      "T3\tGeneric 125 133\tstrategy\n",
      "T4\tTask 148 196\thierarchical abstraction of the supervoxel graph\n",
      "T5\tOtherScientificTerm 269 278\thierarchy\n",
      "T6\tOtherScientificTerm 335 349\tcoarser graphs\n",
      "T7\tGeneric 355 363\tstrategy\n",
      "T8\tGeneric 380 382\tit\n",
      "T9\tOtherScientificTerm 433 445\tfinest graph\n",
      "T10\tGeneric 447 449\tIt\n",
      "T11\tGeneric 468 470\tit\n",
      "T12\tOtherScientificTerm 499 514\tenergy function\n",
      "T13\tMethod 581 610\tenergy minimization algorithm\n",
      "T14\tMethod 618 628\tgraph cuts\n",
      "T15\tMethod 633 651\tbelief propagation\n",
      "T16\tGeneric 654 656\tIt\n",
      "T17\tTask 692 701\tinference\n",
      "T18\tGeneric 714 722\tdatasets\n",
      "T19\tOtherScientificTerm 747 773\tspatio-temporal continuity\n",
      "T20\tGeneric 827 835\tstrategy\n",
      "T21\tMethod 857 880\thierarchical approaches\n",
      "T22\tMaterial 899 919\timage and video data\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R4\tCOREF Arg1:T3 Arg2:T7\n",
      "R5\tCOREF Arg1:T7 Arg2:T8\n",
      "R6\tCOREF Arg1:T7 Arg2:T10\n",
      "R7\tCOREF Arg1:T10 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R10\tCONJUNCTION Arg1:T11 Arg2:T13\n",
      "R11\tHYPONYM-OF Arg1:T14 Arg2:T13\n",
      "R12\tHYPONYM-OF Arg1:T15 Arg2:T13\n",
      "R13\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R14\tCOREF Arg1:T11 Arg2:T20\n",
      "R15\tCOMPARE Arg1:T20 Arg2:T21\n",
      "R16\tCOREF Arg1:T10 Arg2:T16\n",
      "R17\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R18\tFEATURE-OF Arg1:T19 Arg2:T18\n",
      "R19\tEVALUATE-FOR Arg1:T18 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2013_33_abs.ann\n",
      "T1\tGeneric 23 31\tapproach\n",
      "T2\tTask 35 64\tlocalizing functional objects\n",
      "T3\tMaterial 68 87\tsurveillance videos\n",
      "T4\tOtherScientificTerm 96 112\tdomain knowledge\n",
      "T5\tOtherScientificTerm 119 142\tsemantic object classes\n",
      "T6\tOtherScientificTerm 173 191\tFunctional objects\n",
      "T7\tOtherScientificTerm 204 239\tdiscriminative appearance and shape\n",
      "T8\tGeneric 245 249\tthey\n",
      "T9\tOtherScientificTerm 485 503\tfunctional objects\n",
      "T10\tMethod 693 714\tLa-grangian mechanics\n",
      "T11\tOtherScientificTerm 908 926\tfunctional objects\n",
      "T12\tMethod 1075 1093\tBayesian framework\n",
      "T13\tOtherScientificTerm 1130 1163\tpeople's trajectories and intents\n",
      "T14\tOtherScientificTerm 1165 1192\tconstraint map of the scene\n",
      "T15\tOtherScientificTerm 1198 1229\tlocations of functional objects\n",
      "T16\tMethod 1233 1284\tdata-driven Markov Chain Monte Carlo (MCMC) process\n",
      "T17\tTask 1297 1306\tinference\n",
      "T18\tMaterial 1326 1365\tvideos of public squares and courtyards\n",
      "T19\tTask 1400 1429\tlocalizing functional objects\n",
      "T20\tTask 1434 1466\tpredicting people's trajectories\n",
      "T21\tOtherScientificTerm 1494 1507\tvideo footage\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R4\tCOREF Arg1:T8 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R6\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T15\n",
      "R8\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R9\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R11\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "R12\tEVALUATE-FOR Arg1:T18 Arg2:T20\n",
      "R13\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R14\tCOREF Arg1:T19 Arg2:T2\n",
      "R15\tCOREF Arg1:T1 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2013_36_abs.ann\n",
      "T1\tTask 48 71\tcreation of city models\n",
      "T2\tGeneric 113 119\tmethod\n",
      "T3\tTask 124 175\tsynthesizing complex, photo-realistic facade images\n",
      "T4\tMethod 241 260\tsemantic components\n",
      "T5\tOtherScientificTerm 264 270\ttiling\n",
      "T6\tOtherScientificTerm 298 305\ttilings\n",
      "T7\tOtherScientificTerm 336 351\tfacade textures\n",
      "T8\tOtherScientificTerm 386 410\toccluded parts inpainted\n",
      "T9\tGeneric 414 431\tgenetic algorithm\n",
      "T10\tOtherScientificTerm 449 456\tfacades\n",
      "T11\tOtherScientificTerm 468 483\tinpainted parts\n",
      "T12\tGeneric 611 637\tmultiple standard datasets\n",
      "T13\tGeneric 736 742\tmethod\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R6\tCOREF Arg1:T9 Arg2:T13\n",
      "R7\tEVALUATE-FOR Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2013_47_abs.ann\n",
      "T1\tOtherScientificTerm 0 12\tLight fields\n",
      "T2\tMethod 17 44\timage-based representations\n",
      "T3\tOtherScientificTerm 54 74\tdensely sampled rays\n",
      "T4\tOtherScientificTerm 80 97\tscene description\n",
      "T5\tTask 125 157\tgeometric structures of 3D lines\n",
      "T6\tOtherScientificTerm 161 170\tray space\n",
      "T7\tTask 185 210\tlight field triangulation\n",
      "T8\tTask 215 230\tstereo matching\n",
      "T9\tTask 236 257\ttriangulation problem\n",
      "T10\tOtherScientificTerm 278 287\tray space\n",
      "T11\tOtherScientificTerm 293 333\tcontinuous and non-overlapping simplices\n",
      "T12\tOtherScientificTerm 376 389\ttriangulation\n",
      "T13\tOtherScientificTerm 401 429\tpiecewise-linear interpolant\n",
      "T14\tTask 441 469\tlight field super-resolution\n",
      "T15\tOtherScientificTerm 488 505\tlight field space\n",
      "T16\tOtherScientificTerm 534 550\t3D line segments\n",
      "T17\tOtherScientificTerm 600 618\tbilinear subspaces\n",
      "T18\tOtherScientificTerm 707 725\tbilinear subspaces\n",
      "T19\tOtherScientificTerm 729 745\tline constraints\n",
      "T20\tMethod 761 801\tConstrained Delaunay Triangulation (CDT)\n",
      "T21\tMethod 853 893\tline-assisted graph-cut (LAGC) algorithm\n",
      "T22\tOtherScientificTerm 919 938\t3D line constraints\n",
      "T23\tTask 944 971\tlight field stereo matching\n",
      "T24\tMaterial 988 1011\tsynthetic and real data\n",
      "T25\tMethod 1031 1064\ttriangulation and LAGC algorithms\n",
      "T26\tGeneric 1076 1102\tstate-of-the-art solutions\n",
      "T27\tMetric 1106 1114\taccuracy\n",
      "T28\tMetric 1119 1133\tvisual quality\n",
      "R1\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R3\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T8\n",
      "R5\tCOREF Arg1:T7 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R8\tCOREF Arg1:T9 Arg2:T12\n",
      "R9\tCOMPARE Arg1:T25 Arg2:T26\n",
      "R10\tEVALUATE-FOR Arg1:T27 Arg2:T25\n",
      "R11\tEVALUATE-FOR Arg1:T28 Arg2:T25\n",
      "R12\tEVALUATE-FOR Arg1:T27 Arg2:T26\n",
      "R13\tEVALUATE-FOR Arg1:T28 Arg2:T26\n",
      "R14\tEVALUATE-FOR Arg1:T24 Arg2:T25\n",
      "R15\tEVALUATE-FOR Arg1:T24 Arg2:T26\n",
      "R16\tHYPONYM-OF Arg1:T21 Arg2:T25\n",
      "R17\tHYPONYM-OF Arg1:T20 Arg2:T25\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2013_50_abs.ann\n",
      "T1\tMethod 0 27\tRegression-based techniques\n",
      "T2\tTask 61 94\tpeople counting in crowded scenes\n",
      "T3\tGeneric 119 129\ttechniques\n",
      "T4\tTask 162 177\tdata annotation\n",
      "T5\tTask 182 196\tmodel training\n",
      "T6\tOtherScientificTerm 341 359\tinformative frames\n",
      "T7\tTask 377 387\tannotation\n",
      "T8\tGeneric 451 464\tlabelled data\n",
      "T9\tMaterial 470 494\tabundant unlabelled data\n",
      "T10\tTask 595 610\tdata annotation\n",
      "T11\tMethod 649 704\tunified active and semi-supervised regression framework\n",
      "T12\tMethod 729 746\ttransfer learning\n",
      "T13\tOtherScientificTerm 777 814\tgeometric structure of crowd patterns\n",
      "T14\tMethod 819 836\tmanifold analysis\n",
      "T15\tGeneric 894 902\tapproach\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R3\tCOREF Arg1:T4 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R5\tCOREF Arg1:T11 Arg2:T15\n",
      "R6\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T11\n",
      "R8\tCOREF Arg1:T7 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R10\tCOMPARE Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2015_392_abs.ann\n",
      "T1\tGeneric 32 40\tapproach\n",
      "T2\tTask 53 85\toriented object proposals (OOPs)\n",
      "T3\tMetric 100 115\tdetection error\n",
      "T4\tOtherScientificTerm 134 160\torientations of the object\n",
      "T5\tOtherScientificTerm 208 222\tobject regions\n",
      "T6\tOtherScientificTerm 236 264\tpixelwise object probability\n",
      "T7\tOtherScientificTerm 292 302\tobjectness\n",
      "T8\tTask 351 378\tproposal generation problem\n",
      "T9\tMethod 384 415\tgenerative proba-bilistic model\n",
      "T10\tOtherScientificTerm 426 442\tobject proposals\n",
      "T11\tOtherScientificTerm 456 462\tshapes\n",
      "T12\tOtherScientificTerm 470 475\tsizes\n",
      "T13\tOtherScientificTerm 480 492\torientations\n",
      "T14\tOtherScientificTerm 526 551\tlocal maximum likelihoods\n",
      "T15\tGeneric 561 569\tapproach\n",
      "T16\tGeneric 604 606\tit\n",
      "T17\tMethod 617 632\tobject detector\n",
      "T18\tOtherScientificTerm 661 673\torientations\n",
      "T19\tOtherScientificTerm 690 713\tshapes of the proposals\n",
      "T20\tOtherScientificTerm 788 804\tsampling windows\n",
      "T21\tGeneric 830 832\tit\n",
      "T22\tMethod 840 863\tmassive window sampling\n",
      "T23\tOtherScientificTerm 890 909\tnumber of proposals\n",
      "T24\tMetric 935 941\trecall\n",
      "T25\tMaterial 962 985\tPASCAL VOC 2007 dataset\n",
      "T26\tMethod 1009 1012\tOOP\n",
      "T27\tGeneric 1029 1058\tstate-of-the-art fast methods\n",
      "T28\tOtherScientificTerm 1094 1121\trotation invariant property\n",
      "T29\tMethod 1130 1160\tclass-specific object detector\n",
      "T30\tMethod 1214 1241\tproposal generation methods\n",
      "T31\tMaterial 1252 1277\tobject rotation scenarios\n",
      "T32\tMaterial 1281 1298\tgeneral scenarios\n",
      "T33\tTask 1311 1315\tOOPs\n",
      "R1\tEVALUATE-FOR Arg1:T3 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R4\tFEATURE-OF Arg1:T11 Arg2:T10\n",
      "R5\tCOMPARE Arg1:T26 Arg2:T27\n",
      "R6\tUSED-FOR Arg1:T28 Arg2:T29\n",
      "R7\tCOMPARE Arg1:T29 Arg2:T30\n",
      "R8\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R9\tCOMPARE Arg1:T6 Arg2:T7\n",
      "R10\tCOREF Arg1:T15 Arg2:T9\n",
      "R11\tCOREF Arg1:T21 Arg2:T15\n",
      "R12\tCOREF Arg1:T16 Arg2:T15\n",
      "R13\tEVALUATE-FOR Arg1:T24 Arg2:T21\n",
      "R14\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R15\tCOREF Arg1:T9 Arg2:T1\n",
      "R16\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R17\tUSED-FOR Arg1:T21 Arg2:T23\n",
      "R18\tEVALUATE-FOR Arg1:T25 Arg2:T26\n",
      "R19\tCOREF Arg1:T33 Arg2:T26\n",
      "R20\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R21\tHYPONYM-OF Arg1:T13 Arg2:T11\n",
      "R22\tUSED-FOR Arg1:T14 Arg2:T10\n",
      "R23\tCONJUNCTION Arg1:T31 Arg2:T32\n",
      "R24\tEVALUATE-FOR Arg1:T31 Arg2:T30\n",
      "R25\tEVALUATE-FOR Arg1:T32 Arg2:T30\n",
      "R26\tEVALUATE-FOR Arg1:T31 Arg2:T29\n",
      "R27\tEVALUATE-FOR Arg1:T32 Arg2:T29\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2015_393_abs.ann\n",
      "T1\tTask 37 59\tloss-aware predictions\n",
      "T2\tTask 37 90\tloss-aware predictions in image segmentation settings\n",
      "T3\tTask 63 90\timage segmentation settings\n",
      "T4\tOtherScientificTerm 101 120\tevaluation function\n",
      "T5\tMetric 128 165\tIntersection-over-Union (IoU) measure\n",
      "T6\tMethod 200 226\timage segmentation systems\n",
      "T7\tGeneric 253 272\tdominant approaches\n",
      "T8\tGeneric 278 283\tfirst\n",
      "T9\tOtherScientificTerm 301 326\tExpected-IoU (EIoU) score\n",
      "T10\tOtherScientificTerm 330 379\tExpected-Intersection-over-Expected-Union (EIoEU)\n",
      "T11\tGeneric 389 404\tsecond approach\n",
      "T12\tOtherScientificTerm 425 429\tEIoU\n",
      "T13\tTask 559 584\timage seg-mentation tasks\n",
      "T14\tGeneric 689 696\tmethods\n",
      "T15\tOtherScientificTerm 705 710\tEIoEU\n",
      "T16\tMethod 705 724\tEIoEU approximation\n",
      "T17\tGeneric 807 817\tapproaches\n",
      "T18\tTask 855 879\timage segmentation tasks\n",
      "R1\tEVALUATE-FOR Arg1:T5 Arg2:T6\n",
      "R2\tHYPONYM-OF Arg1:T5 Arg2:T4\n",
      "R3\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R4\tHYPONYM-OF Arg1:T11 Arg2:T7\n",
      "R5\tCOREF Arg1:T12 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T16 Arg2:T14\n",
      "R7\tCOREF Arg1:T14 Arg2:T17\n",
      "R8\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R9\tCOREF Arg1:T13 Arg2:T18\n",
      "R10\tCOREF Arg1:T10 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2015_400_abs.ann\n",
      "T1\tMethod 0 12\tHough voting\n",
      "T2\tOtherScientificTerm 18 48\tgeometric transformation space\n",
      "T3\tTask 70 90\tspatial verification\n",
      "T4\tOtherScientificTerm 117 141\tfeature detection errors\n",
      "T5\tOtherScientificTerm 157 215\tinflexible quan-tization of single feature correspondences\n",
      "T6\tGeneric 258 264\tmethod\n",
      "T7\tMethod 273 295\tadaptive dither voting\n",
      "T8\tTask 301 328\trobust spatial verification\n",
      "T9\tGeneric 416 422\tmethod\n",
      "T10\tOtherScientificTerm 457 490\tmultiple dithered transformations\n",
      "T11\tGeneric 562 568\tmethod\n",
      "T12\tOtherScientificTerm 626 653\ttransformation quantization\n",
      "T13\tOtherScientificTerm 687 705\tregards mismatches\n",
      "T14\tOtherScientificTerm 724 745\tgeometric constraints\n",
      "T15\tOtherScientificTerm 753 770\tdithering process\n",
      "T16\tOtherScientificTerm 803 817\tnon-uniformity\n",
      "T17\tMethod 823 838\tHough histogram\n",
      "T18\tOtherScientificTerm 846 864\tspatial similarity\n",
      "T19\tOtherScientificTerm 875 901\tmultiple matching surfaces\n",
      "T20\tGeneric 980 986\tmethod\n",
      "T21\tGeneric 992 998\tmethod\n",
      "T22\tGeneric 1032 1044\tcounterparts\n",
      "T23\tMetric 1053 1061\taccuracy\n",
      "T24\tMetric 1066 1077\tscalability\n",
      "T25\tTask 1111 1146\tretrieval of small, rotated objects\n",
      "R1\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tCOREF Arg1:T7 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R5\tCOREF Arg1:T8 Arg2:T3\n",
      "R6\tCOREF Arg1:T6 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R8\tCOREF Arg1:T11 Arg2:T9\n",
      "R9\tFEATURE-OF Arg1:T16 Arg2:T17\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T19\n",
      "R11\tCOREF Arg1:T20 Arg2:T11\n",
      "R12\tCOREF Arg1:T21 Arg2:T20\n",
      "R13\tCOMPARE Arg1:T22 Arg2:T21\n",
      "R14\tEVALUATE-FOR Arg1:T23 Arg2:T21\n",
      "R15\tEVALUATE-FOR Arg1:T24 Arg2:T21\n",
      "R16\tEVALUATE-FOR Arg1:T23 Arg2:T22\n",
      "R17\tEVALUATE-FOR Arg1:T24 Arg2:T22\n",
      "R18\tUSED-FOR Arg1:T21 Arg2:T25\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2015_403_abs.ann\n",
      "T1\tOtherScientificTerm 46 57\taging faces\n",
      "T2\tMethod 101 132\tage-group specific dictionaries\n",
      "T3\tOtherScientificTerm 156 172\tdictionary bases\n",
      "T4\tOtherScientificTerm 255 276\taging process pattern\n",
      "T5\tMethod 311 329\tlinear combination\n",
      "T6\tGeneric 339 347\tpatterns\n",
      "T7\tTask 371 397\tpersonalized aging process\n",
      "T8\tMethod 457 484\tdictionary learning process\n",
      "T9\tMethod 504 522\taging dictionaries\n",
      "T10\tOtherScientificTerm 552 587\tpersonalized facial characteristics\n",
      "T11\tOtherScientificTerm 594 598\tmole\n",
      "T12\tTask 627 640\taging process\n",
      "T13\tOtherScientificTerm 837 882\tpersonality-aware coupled reconstruction loss\n",
      "T14\tGeneric 908 920\tdictionaries\n",
      "T15\tGeneric 1040 1048\tsolution\n",
      "T16\tGeneric 1060 1077\tstate-of-the-arts\n",
      "T17\tOtherScientificTerm 1089 1119\tpersonalized aging progression\n",
      "T18\tTask 1157 1184\tcross-age face verification\n",
      "T19\tMethod 1188 1212\tsynthesizing aging faces\n",
      "R1\tCOREF Arg1:T4 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R4\tPART-OF Arg1:T3 Arg2:T2\n",
      "R5\tHYPONYM-OF Arg1:T11 Arg2:T10\n",
      "R6\tCOMPARE Arg1:T15 Arg2:T16\n",
      "R7\tUSED-FOR Arg1:T19 Arg2:T18\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T17\n",
      "R9\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R10\tCOREF Arg1:T7 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R12\tCOREF Arg1:T2 Arg2:T9\n",
      "R13\tCOREF Arg1:T9 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICCV_2015_50_abs.ann\n",
      "T1\tTask 0 51\tDetecting fine-grained subtle changes among a scene\n",
      "T2\tMethod 98 122\tchange detection methods\n",
      "T3\tTask 136 177\tdetecting large-scale significant changes\n",
      "T4\tMethod 231 250\tend-to-end approach\n",
      "T5\tGeneric 271 278\tproblem\n",
      "T6\tMethod 294 318\tactive camera relocation\n",
      "T7\tMetric 429 450\tdetection sensitivity\n",
      "T8\tMetric 455 463\taccuracy\n",
      "T9\tOtherScientificTerm 546 559\tilluminations\n",
      "T10\tTask 680 709\tfine-grained change detection\n",
      "T11\tTask 715 741\tjoint optimization problem\n",
      "T12\tGeneric 759 766\tfactors\n",
      "T13\tOtherScientificTerm 774 806\tnormal-aware lighting difference\n",
      "T14\tOtherScientificTerm 808 839\tcamera geometry correction flow\n",
      "T15\tOtherScientificTerm 845 867\treal scene change mask\n",
      "T16\tGeneric 888 895\tfactors\n",
      "T17\tOtherScientificTerm 901 922\tcoarse-to-fine manner\n",
      "T18\tOtherScientificTerm 944 959\tchange decision\n",
      "T19\tMethod 963 980\trank minimization\n",
      "T20\tMaterial 997 1016\treal-world datasets\n",
      "T21\tTask 1030 1080\tfine-grained change detection of misaligned scenes\n",
      "T22\tOtherScientificTerm 1087 1122\tvaried multiple lighting conditions\n",
      "T23\tGeneric 1183 1191\tapproach\n",
      "T24\tMethod 1214 1238\tchange detection methods\n",
      "T25\tOtherScientificTerm 1270 1288\treal scene changes\n",
      "T26\tOtherScientificTerm 1315 1334\tlighting variations\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tCOREF Arg1:T3 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R5\tHYPONYM-OF Arg1:T13 Arg2:T12\n",
      "R6\tHYPONYM-OF Arg1:T14 Arg2:T12\n",
      "R7\tHYPONYM-OF Arg1:T15 Arg2:T12\n",
      "R8\tFEATURE-OF Arg1:T12 Arg2:T11\n",
      "R9\tCOREF Arg1:T12 Arg2:T16\n",
      "R10\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R11\tUSED-FOR Arg1:T19 Arg2:T18\n",
      "R12\tFEATURE-OF Arg1:T22 Arg2:T21\n",
      "R13\tEVALUATE-FOR Arg1:T20 Arg2:T21\n",
      "R14\tCOMPARE Arg1:T23 Arg2:T24\n",
      "R15\tUSED-FOR Arg1:T23 Arg2:T25\n",
      "R16\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R17\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R18\tCOREF Arg1:T4 Arg2:T23\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_1995_30_abs.ann\n",
      "T1\tMethod 27 32\tAnt-Q\n",
      "T2\tMethod 94 104\tQ-learning\n",
      "T3\tTask 160 235\tsymmetric and asym-metric instances of the traveling salesman problem (TSP)\n",
      "T4\tMethod 237 253\tAnt-Q algorithms\n",
      "T5\tMethod 283 298\tant system (AS)\n",
      "T6\tMethod 302 323\tdistributed algorithm\n",
      "T7\tTask 328 354\tcombinatorial optimization\n",
      "T8\tMethod 489 491\tAS\n",
      "T9\tMethod 524 536\tAnt-Q family\n",
      "T10\tGeneric 557 566\tinstances\n",
      "T11\tGeneric 575 581\tfamily\n",
      "T12\tOtherScientificTerm 608 610\tAS\n",
      "T13\tMethod 661 666\tAnt-Q\n",
      "T14\tMethod 708 713\tAnt-Q\n",
      "T15\tTask 717 730\tsymmetric TSP\n",
      "T16\tMethod 778 798\theuristic approaches\n",
      "T17\tMethod 808 823\tneural networks\n",
      "T18\tMethod 827 839\tlocal search\n",
      "T19\tMethod 859 864\tAnt-Q\n",
      "T20\tTask 883 897\tasymmetric TSP\n",
      "T21\tMethod 929 934\tAnt-Q\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R2\tHYPONYM-OF Arg1:T8 Arg2:T9\n",
      "R3\tCOREF Arg1:T9 Arg2:T4\n",
      "R4\tCOREF Arg1:T21 Arg2:T19\n",
      "R5\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R6\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R7\tCOMPARE Arg1:T14 Arg2:T16\n",
      "R8\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R9\tCOREF Arg1:T14 Arg2:T13\n",
      "R10\tCOREF Arg1:T19 Arg2:T14\n",
      "R11\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R12\tUSED-FOR Arg1:T18 Arg2:T16\n",
      "R13\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R14\tHYPONYM-OF Arg1:T5 Arg2:T6\n",
      "R15\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R16\tCOREF Arg1:T8 Arg2:T5\n",
      "R17\tCOREF Arg1:T11 Arg2:T9\n",
      "R18\tPART-OF Arg1:T10 Arg2:T11\n",
      "R19\tCOMPARE Arg1:T10 Arg2:T12\n",
      "R20\tCOREF Arg1:T13 Arg2:T9\n",
      "R21\tHYPONYM-OF Arg1:T15 Arg2:T3\n",
      "R22\tHYPONYM-OF Arg1:T20 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_1995_38_abs.ann\n",
      "T1\tTask 21 50\tlearning in autonomous agents\n",
      "T2\tMethod 75 107\tdomain-speciic models of actions\n",
      "T3\tTask 122 138\tplanning systems\n",
      "T4\tGeneric 166 173\tmethods\n",
      "T5\tMethod 199 212\taction models\n",
      "T6\tOtherScientificTerm 267 280\tdomain expert\n",
      "T7\tMetric 288 295\tmethods\n",
      "T8\tMethod 360 382\taction model formalism\n",
      "T9\tMethod 424 439\tre-active agent\n",
      "T10\tMethod 474 499\tnoise-handling mechanisms\n",
      "T11\tMethod 584 589\tGOLEM\n",
      "T12\tMethod 607 620\taction models\n",
      "T13\tMethod 647 673\tintegrated learning system\n",
      "T14\tTask 711 733\tsimulated construction\n",
      "T15\tTask 738 750\tooce domains\n",
      "R1\tCOREF Arg1:T4 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R4\tCOREF Arg1:T12 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R7\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R8\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R9\tEVALUATE-FOR Arg1:T15 Arg2:T13\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R11\tUSED-FOR Arg1:T10 Arg2:T7\n",
      "R12\tCOREF Arg1:T7 Arg2:T13\n",
      "R13\tCOREF Arg1:T5 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_2006_111_abs.ann\n",
      "T1\tMethod 0 16\tBoosting methods\n",
      "T2\tMethod 98 109\tclassifiers\n",
      "T3\tMethod 206 216\tclassifier\n",
      "T4\tMethod 328 346\tboosting algorithm\n",
      "T5\tMethod 348 354\tarc-gv\n",
      "T6\tOtherScientificTerm 383 403\tmargins distribution\n",
      "T7\tMethod 409 417\tAdaBoost\n",
      "T8\tMethod 607 613\tarc-gv\n",
      "T9\tMetric 648 658\tcomplexity\n",
      "T10\tMethod 666 682\tbase classifiers\n",
      "T11\tMethod 769 783\tmargins theory\n",
      "T12\tMetric 900 926\tbase-classifier complexity\n",
      "R1\tHYPONYM-OF Arg1:T5 Arg2:T4\n",
      "R2\tCOMPARE Arg1:T5 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R4\tHYPONYM-OF Arg1:T10 Arg2:T8\n",
      "R5\tCOREF Arg1:T8 Arg2:T5\n",
      "R6\tEVALUATE-FOR Arg1:T9 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_2006_112_abs.ann\n",
      "T1\tGeneric 22 31\tframework\n",
      "T2\tTask 36 62\tonline multiclass learning\n",
      "T3\tOtherScientificTerm 76 104\tnotion of hypothesis sharing\n",
      "T4\tGeneric 113 122\tframework\n",
      "T5\tGeneric 240 249\tframework\n",
      "T6\tTask 308 333\tmulticlass categorization\n",
      "T7\tMethod 465 486\tmulticlass Perceptron\n",
      "T8\tGeneric 494 503\tframework\n",
      "T9\tMethod 517 548\tunifying mistake bound analysis\n",
      "T10\tMethod 684 707\tonline learning process\n",
      "T11\tGeneric 742 750\tapproach\n",
      "T12\tGeneric 764 766\tit\n",
      "T13\tGeneric 779 786\tmethods\n",
      "T14\tMaterial 795 825\tsynthetic and natural datasets\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T1 Arg2:T4\n",
      "R4\tCOREF Arg1:T4 Arg2:T5\n",
      "R5\tCOREF Arg1:T5 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tCOREF Arg1:T8 Arg2:T11\n",
      "R8\tCOREF Arg1:T11 Arg2:T12\n",
      "R9\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R10\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R11\tEVALUATE-FOR Arg1:T14 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_2006_119_abs.ann\n",
      "T1\tTask 63 79\tboard game of Go\n",
      "T2\tMaterial 85 115\tgame records of expert players\n",
      "T3\tOtherScientificTerm 144 168\tprobability distribution\n",
      "T4\tGeneric 234 246\tdistribution\n",
      "T5\tOtherScientificTerm 276 287\tcomputer Go\n",
      "T6\tOtherScientificTerm 323 344\tstand-alone Go player\n",
      "T7\tGeneric 346 348\tIt\n",
      "T8\tMethod 378 391\tmove selector\n",
      "T9\tMethod 396 407\tmove sorter\n",
      "T10\tMethod 412 428\tgame tree search\n",
      "T11\tTask 438 451\ttraining tool\n",
      "T12\tOtherScientificTerm 456 466\tGo players\n",
      "T13\tGeneric 472 478\tmethod\n",
      "T14\tMethod 510 535\tpattern extraction scheme\n",
      "T15\tMethod 630 657\tBayesian learning algorithm\n",
      "T16\tOtherScientificTerm 765 786\tlocal pattern context\n",
      "T17\tGeneric 792 798\tsystem\n",
      "T18\tMaterial 821 833\texpert games\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T4 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R7\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R8\tCOREF Arg1:T13 Arg2:T7\n",
      "R9\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R10\tPART-OF Arg1:T14 Arg2:T13\n",
      "R11\tPART-OF Arg1:T15 Arg2:T13\n",
      "R12\tCOREF Arg1:T17 Arg2:T13\n",
      "R13\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R14\tUSED-FOR Arg1:T7 Arg2:T11\n",
      "R15\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R16\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_2006_122_abs.ann\n",
      "T1\tMethod 7 41\tmodel-based policy search approach\n",
      "T2\tTask 45 72\treinforcement learning (RL)\n",
      "T3\tOtherScientificTerm 74 82\tpolicies\n",
      "T4\tOtherScientificTerm 131 154\tMarkov decision process\n",
      "T5\tTask 169 208\thigh-dimensional continuous-state tasks\n",
      "T6\tGeneric 261 266\tmodel\n",
      "T7\tGeneric 287 296\talgorithm\n",
      "T8\tOtherScientificTerm 307 313\tpolicy\n",
      "T9\tTask 380 393\tmodel-free RL\n",
      "T10\tOtherScientificTerm 440 456\treal-life trials\n",
      "T11\tMethod 486 502\thybrid algorithm\n",
      "T12\tMethod 525 542\tapproximate model\n",
      "T13\tOtherScientificTerm 571 587\treal-life trials\n",
      "T14\tTask 634 652\tpolicy evaluations\n",
      "T15\tOtherScientificTerm 659 675\treal-life trials\n",
      "T16\tMethod 696 713\tapproximate model\n",
      "T17\tGeneric 779 788\talgorithm\n",
      "T18\tOtherScientificTerm 798 822\tnear-optimal performance\n",
      "T19\tGeneric 944 955\tcrude model\n",
      "T20\tOtherScientificTerm 978 994\treal-life trials\n",
      "T21\tGeneric 1001 1010\talgorithm\n",
      "T22\tOtherScientificTerm 1022 1046\tnear-optimal performance\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R5\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R6\tCOREF Arg1:T17 Arg2:T21\n",
      "R7\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R8\tUSED-FOR Arg1:T19 Arg2:T21\n",
      "R9\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R10\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R11\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R12\tCOREF Arg1:T6 Arg2:T7\n",
      "R13\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_2016_10_abs.ann\n",
      "T1\tTask 20 50\tspecialized regression problem\n",
      "T2\tOtherScientificTerm 61 83\tsampling probabilities\n",
      "T3\tMaterial 88 95\trecords\n",
      "T4\tMaterial 99 108\tdatabases\n",
      "T5\tMaterial 147 154\trecords\n",
      "T6\tOtherScientificTerm 177 194\taggregate queries\n",
      "T7\tMethod 253 285\tprincipled and provable solution\n",
      "T8\tGeneric 295 302\tproblem\n",
      "T9\tGeneric 304 306\tit\n",
      "T10\tTask 371 390\tregression problems\n",
      "T11\tOtherScientificTerm 397 401\tloss\n",
      "T12\tOtherScientificTerm 435 454\tregressed-to values\n",
      "T13\tMethod 468 486\tcost zero solution\n",
      "T14\tOtherScientificTerm 529 552\thard budget constraints\n",
      "T15\tOtherScientificTerm 571 586\treg-ularization\n",
      "T16\tMethod 638 693\tregularized Empirical Risk Minimization (ERM) algorithm\n",
      "T17\tMethod 809 825\tuniform sampling\n",
      "T18\tMethod 839 858\tstratified sampling\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tEVALUATE-FOR Arg1:T6 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R4\tPART-OF Arg1:T3 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R6\tCOREF Arg1:T5 Arg2:T3\n",
      "R7\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R8\tCOREF Arg1:T1 Arg2:T8\n",
      "R9\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R10\tCOREF Arg1:T7 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_2016_11_abs.ann\n",
      "T1\tMethod 4 60\trobust principal component analysis (robust PCA) problem\n",
      "T2\tTask 89 118\tmachine learning applications\n",
      "T3\tOtherScientificTerm 155 166\tdata matrix\n",
      "T4\tOtherScientificTerm 172 185\tlow rank part\n",
      "T5\tOtherScientificTerm 193 208\tsparse residual\n",
      "T6\tGeneric 224 234\tapproaches\n",
      "T7\tOtherScientificTerm 273 303\tlow rank plus sparse structure\n",
      "T8\tOtherScientificTerm 327 343\tside information\n",
      "T9\tGeneric 443 454\tinformation\n",
      "T10\tMethod 460 470\trobust PCA\n",
      "T11\tMethod 517 527\trobust PCA\n",
      "T12\tOtherScientificTerm 533 549\tside information\n",
      "T13\tOtherScientificTerm 562 577\tprior structure\n",
      "T14\tOtherScientificTerm 582 602\tfeatures of entities\n",
      "T15\tTask 621 629\trecovery\n",
      "T16\tTask 644 658\tconvex problem\n",
      "T17\tOtherScientificTerm 674 690\tside information\n",
      "T18\tMethod 694 704\trobust PCA\n",
      "T19\tOtherScientificTerm 723 738\tlow rank matrix\n",
      "T20\tGeneric 781 787\tmethod\n",
      "T21\tOtherScientificTerm 882 899\tlow rank matrices\n",
      "T22\tMethod 939 949\trobust PCA\n",
      "T23\tGeneric 987 993\tmethod\n",
      "T24\tOtherScientificTerm 1051 1059\tfeatures\n",
      "T25\tMethod 1063 1073\trobust PCA\n",
      "T26\tTask 1154 1180\tnoisy image classification\n",
      "T27\tGeneric 1198 1204\tmethod\n",
      "T28\tOtherScientificTerm 1261 1277\tside information\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R3\tCOREF Arg1:T1 Arg2:T10\n",
      "R4\tCOREF Arg1:T10 Arg2:T11\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R7\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R8\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R9\tPART-OF Arg1:T17 Arg2:T18\n",
      "R10\tCOREF Arg1:T11 Arg2:T18\n",
      "R11\tCOREF Arg1:T18 Arg2:T22\n",
      "R12\tCOREF Arg1:T22 Arg2:T25\n",
      "R13\tUSED-FOR Arg1:T28 Arg2:T27\n",
      "R14\tEVALUATE-FOR Arg1:T26 Arg2:T27\n",
      "R15\tUSED-FOR Arg1:T23 Arg2:T21\n",
      "R16\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R17\tCOREF Arg1:T20 Arg2:T23\n",
      "R18\tFEATURE-OF Arg1:T24 Arg2:T25\n",
      "R19\tCOREF Arg1:T23 Arg2:T27\n",
      "R20\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R21\tCOREF Arg1:T8 Arg2:T9\n",
      "R22\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R23\tPART-OF Arg1:T4 Arg2:T3\n",
      "R24\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R25\tPART-OF Arg1:T5 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_2016_18_abs.ann\n",
      "T1\tTask 7 30\tObject Recognition task\n",
      "T2\tTask 70 95\tcategorization of objects\n",
      "T3\tTask 100 122\testimating object pose\n",
      "T4\tGeneric 134 140\tformer\n",
      "T5\tMethod 156 185\tview-invariant representation\n",
      "T6\tGeneric 197 203\tlatter\n",
      "T7\tGeneric 215 229\trepresentation\n",
      "T8\tOtherScientificTerm 251 267\tpose information\n",
      "T9\tMethod 323 342\tdeep archi-tectures\n",
      "T10\tTask 372 399\tobject category recognition\n",
      "T11\tMethod 401 422\tDeep learning methods\n",
      "T12\tGeneric 458 462\ttask\n",
      "T13\tTask 477 499\tobject pose estimation\n",
      "T14\tGeneric 512 522\tapproaches\n",
      "T15\tMethod 590 639\tConvolutional Neural Networks (CNN) architectures\n",
      "T16\tTask 683 701\tobject recognition\n",
      "T17\tTask 706 721\tpose estimation\n",
      "T18\tOtherScientificTerm 754 760\tlayers\n",
      "T19\tMethod 772 782\tCNN models\n",
      "T20\tGeneric 815 819\tthem\n",
      "T21\tMethod 857 894\tlayers of distributed representations\n",
      "T22\tMethod 902 906\tCNNs\n",
      "T23\tOtherScientificTerm 917 940\tobject pose information\n",
      "T24\tGeneric 949 953\tthis\n",
      "T25\tMethod 971 1002\tobject category representations\n",
      "T26\tMaterial 1066 1085\tmulti-view datasets\n",
      "R1\tCOREF Arg1:T4 Arg2:T2\n",
      "R2\tCOREF Arg1:T6 Arg2:T3\n",
      "R3\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R7\tPART-OF Arg1:T2 Arg2:T1\n",
      "R8\tPART-OF Arg1:T3 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R10\tCOREF Arg1:T10 Arg2:T2\n",
      "R11\tCOREF Arg1:T12 Arg2:T10\n",
      "R12\tCOREF Arg1:T13 Arg2:T3\n",
      "R13\tCOREF Arg1:T14 Arg2:T11\n",
      "R14\tCOREF Arg1:T17 Arg2:T13\n",
      "R15\tCOREF Arg1:T19 Arg2:T15\n",
      "R16\tPART-OF Arg1:T21 Arg2:T22\n",
      "R17\tUSED-FOR Arg1:T21 Arg2:T23\n",
      "R18\tCOREF Arg1:T24 Arg2:T21\n",
      "R19\tCOMPARE Arg1:T24 Arg2:T25\n",
      "R20\tCOREF Arg1:T22 Arg2:T19\n",
      "R21\tPART-OF Arg1:T18 Arg2:T19\n",
      "R22\tCOREF Arg1:T20 Arg2:T18\n",
      "R23\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R24\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R25\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R26\tUSED-FOR Arg1:T15 Arg2:T17\n",
      "R27\tCOREF Arg1:T16 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\ICML_2016_21_abs.ann\n",
      "T1\tMethod 19 62\tlimited-memory stochastic block BFGS update\n",
      "T2\tTask 67 147\tincorporating enriched curvature information in stochastic approximation methods\n",
      "T3\tGeneric 156 162\tmethod\n",
      "T4\tOtherScientificTerm 184 206\tinverse Hessian matrix\n",
      "T5\tGeneric 229 231\tit\n",
      "T6\tOtherScientificTerm 284 291\tHessian\n",
      "T7\tOtherScientificTerm 301 350\trandomly generated compressed form of the Hessian\n",
      "T8\tMethod 371 391\tsketching strategies\n",
      "T9\tMethod 407 426\tquasi-Newton method\n",
      "T10\tMethod 437 466\tstochastic block BFGS updates\n",
      "T11\tMethod 485 517\tvariance reduction approach SVRG\n",
      "T12\tOtherScientificTerm 529 555\tbatch stochastic gradients\n",
      "T13\tOtherScientificTerm 567 585\tlinear convergence\n",
      "T14\tGeneric 603 609\tmethod\n",
      "T15\tTask 630 670\tlarge-scale logistic regression problems\n",
      "T16\tGeneric 687 693\tmethod\n",
      "T17\tGeneric 747 771\tstate-of-the-art methods\n",
      "R1\tCOREF Arg1:T1 Arg2:T3\n",
      "R2\tCOREF Arg1:T5 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R4\tHYPONYM-OF Arg1:T7 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R6\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T12\n",
      "R10\tCOREF Arg1:T1 Arg2:T16\n",
      "R11\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R12\tEVALUATE-FOR Arg1:T15 Arg2:T17\n",
      "R13\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R14\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R15\tCOREF Arg1:T9 Arg2:T14\n",
      "R16\tFEATURE-OF Arg1:T13 Arg2:T14\n",
      "R17\tHYPONYM-OF Arg1:T8 Arg2:T16\n",
      "R18\tHYPONYM-OF Arg1:T9 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_1995_190_abs.ann\n",
      "T1\tMethod 13 26\tprocess model\n",
      "T2\tTask 31 73\thierarchical perceptual sound organization\n",
      "T3\tOtherScientificTerm 92 109\tperceptual sounds\n",
      "T4\tOtherScientificTerm 122 144\tincoming sound signals\n",
      "T5\tTask 158 187\tperceptual sound organization\n",
      "T6\tTask 193 215\tscene analysis problem\n",
      "T7\tMaterial 223 238\tauditory domain\n",
      "T8\tGeneric 244 249\tmodel\n",
      "T9\tMethod 271 289\tprocessing modules\n",
      "T10\tMethod 296 314\thypothesis network\n",
      "T11\tMethod 412 429\tprocessing module\n",
      "T12\tGeneric 448 454\tmodule\n",
      "T13\tMethod 527 545\thypothesis network\n",
      "T14\tMethod 554 572\thypothesis network\n",
      "T15\tMethod 626 640\tinternal model\n",
      "T16\tMaterial 644 661\tperceptual sounds\n",
      "T17\tMethod 705 710\tmodel\n",
      "T18\tMethod 714 741\tmusic scene analysis system\n",
      "T19\tOtherScientificTerm 765 799\tacoustic signals of ensemble music\n",
      "T20\tMaterial 818 824\trhythm\n",
      "T21\tMaterial 826 832\tchords\n",
      "T22\tMaterial 838 868\tsource-separated musical notes\n",
      "T23\tGeneric 905 911\tmethod\n",
      "T24\tOtherScientificTerm 959 982\tinformation integration\n",
      "T25\tMethod 1000 1014\tinternal model\n",
      "T26\tMaterial 1018 1048\thierarchical perceptual sounds\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tPART-OF Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R4\tHYPONYM-OF Arg1:T2 Arg2:T5\n",
      "R5\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R6\tPART-OF Arg1:T9 Arg2:T8\n",
      "R7\tCOREF Arg1:T11 Arg2:T9\n",
      "R8\tCOREF Arg1:T13 Arg2:T10\n",
      "R9\tCOREF Arg1:T14 Arg2:T13\n",
      "R10\tCOREF Arg1:T17 Arg2:T15\n",
      "R11\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "R12\tUSED-FOR Arg1:T18 Arg2:T20\n",
      "R13\tPART-OF Arg1:T15 Arg2:T14\n",
      "R14\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R15\tPART-OF Arg1:T10 Arg2:T8\n",
      "R16\tCOREF Arg1:T11 Arg2:T12\n",
      "R17\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R18\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R19\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R20\tUSED-FOR Arg1:T18 Arg2:T21\n",
      "R21\tUSED-FOR Arg1:T18 Arg2:T22\n",
      "R22\tCOREF Arg1:T25 Arg2:T15\n",
      "R23\tUSED-FOR Arg1:T25 Arg2:T26\n",
      "R24\tFEATURE-OF Arg1:T24 Arg2:T23\n",
      "R25\tUSED-FOR Arg1:T24 Arg2:T25\n",
      "R26\tCOREF Arg1:T23 Arg2:T8\n",
      "R27\tCOREF Arg1:T8 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2001_12_abs.ann\n",
      "T1\tMethod 98 112\tweb interfaces\n",
      "T2\tOtherScientificTerm 127 138\tdesktop PCs\n",
      "T3\tOtherScientificTerm 236 256\tdeep link structures\n",
      "T4\tGeneric 324 333\talgorithm\n",
      "T5\tMethod 335 342\tMINPATH\n",
      "T6\tTask 372 395\twireless web navigation\n",
      "T7\tMethod 446 453\tMINPATH\n",
      "T8\tGeneric 489 494\tmodel\n",
      "T9\tOtherScientificTerm 498 518\tweb visitor behavior\n",
      "T10\tTask 535 560\tsavings of shortcut links\n",
      "T11\tGeneric 624 641\tpredictive models\n",
      "T12\tMethod 653 680\tNaÂ¨Ä±ve Bayes mixture models\n",
      "T13\tMethod 685 710\tmixtures of Markov models\n",
      "T14\tMethod 747 754\tMINPATH\n",
      "R1\tCOREF Arg1:T5 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R4\tCOREF Arg1:T7 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R6\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R7\tHYPONYM-OF Arg1:T13 Arg2:T11\n",
      "R8\tCOREF Arg1:T14 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R10\tCOREF Arg1:T11 Arg2:T8\n",
      "R11\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R12\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R13\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2001_4_abs.ann\n",
      "T1\tGeneric 6 15\talgorithm\n",
      "T2\tTask 38 75\tdimensional container packing problem\n",
      "T3\tGeneric 112 121\talgorithm\n",
      "T4\tMethod 152 190\tapproach of wall building and layering\n",
      "T5\tGeneric 192 194\tIt\n",
      "T6\tGeneric 288 294\tmethod\n",
      "T7\tMaterial 329 339\tOR-Library\n",
      "T8\tGeneric 384 393\talgorithm\n",
      "T9\tMetric 416 443\taverage packing utilization\n",
      "R1\tEVALUATE-FOR Arg1:T9 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T1 Arg2:T3\n",
      "R4\tCOMPARE Arg1:T3 Arg2:T4\n",
      "R5\tCOREF Arg1:T3 Arg2:T5\n",
      "R6\tCOREF Arg1:T5 Arg2:T6\n",
      "R7\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R8\tCOREF Arg1:T5 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2001_5_abs.ann\n",
      "T1\tMethod 34 48\tprocess models\n",
      "T2\tTask 73 103\tscience and engineering fields\n",
      "T3\tMaterial 183 198\tknowledge bases\n",
      "T4\tOtherScientificTerm 203 213\tontologies\n",
      "T5\tOtherScientificTerm 218 223\trules\n",
      "T6\tTask 270 293\tchecking process models\n",
      "T7\tMethod 279 293\tprocess models\n",
      "T8\tTask 326 366\tchecking and refining planning knowledge\n",
      "T9\tTask 384 409\tautomated plan generation\n",
      "T10\tGeneric 492 514\tcomplementary approach\n",
      "T11\tMethod 550 564\tprocess models\n",
      "T12\tGeneric 570 576\tsystem\n",
      "T13\tMethod 585 590\tKANAL\n",
      "T14\tMethod 625 639\tprocess models\n",
      "T15\tMaterial 677 679\tKB\n",
      "T16\tGeneric 762 764\tIt\n",
      "T17\tMethod 772 795\tinterdepen-dency models\n",
      "T18\tGeneric 824 828\tthem\n",
      "T19\tOtherScientificTerm 837 843\terrors\n",
      "T20\tOtherScientificTerm 856 861\tfixes\n",
      "T21\tMethod 897 902\tKANAL\n",
      "T22\tMethod 946 960\tprocess models\n",
      "R1\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R3\tCOREF Arg1:T10 Arg2:T12\n",
      "R4\tCOREF Arg1:T13 Arg2:T12\n",
      "R5\tCOREF Arg1:T12 Arg2:T16\n",
      "R6\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R7\tCOREF Arg1:T17 Arg2:T18\n",
      "R8\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R9\tUSED-FOR Arg1:T18 Arg2:T20\n",
      "R10\tCOREF Arg1:T16 Arg2:T21\n",
      "R11\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R12\tCOREF Arg1:T1 Arg2:T7\n",
      "R13\tCOREF Arg1:T7 Arg2:T11\n",
      "R14\tCOREF Arg1:T11 Arg2:T22\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2003_15_abs.ann\n",
      "T1\tMethod 5 29\tdescription logics (DLs)\n",
      "T2\tMethod 38 62\tknowledge representation\n",
      "T3\tMethod 188 191\tDLs\n",
      "T4\tMethod 374 400\tnatural description logics\n",
      "T5\tOtherScientificTerm 442 475\ttight NEx-PTlME complexity bounds\n",
      "R1\tCOREF Arg1:T1 Arg2:T3\n",
      "R2\tCONJUNCTION Arg1:T2 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2010_4_abs.ann\n",
      "T1\tTask 3 28\tBayesian machine learning\n",
      "T2\tOtherScientificTerm 30 46\tconjugate priors\n",
      "T3\tOtherScientificTerm 168 183\tconjugate prior\n",
      "T4\tOtherScientificTerm 216 231\tconjugate prior\n",
      "T5\tOtherScientificTerm 247 265\tBregman divergence\n",
      "T6\tOtherScientificTerm 311 327\tconjugate priors\n",
      "T7\tOtherScientificTerm 443 459\tconjugate priors\n",
      "T8\tOtherScientificTerm 541 584\tgeometric understanding of conjugate priors\n",
      "T9\tOtherScientificTerm 568 584\tconjugate priors\n",
      "T10\tGeneric 599 614\thyperparameters\n",
      "T11\tGeneric 637 642\tprior\n",
      "T12\tMethod 662 702\tgenerative and discriminative components\n",
      "T13\tMethod 708 720\thybrid model\n",
      "T14\tTask 725 749\tsemi-supervised learning\n",
      "R1\tPART-OF Arg1:T2 Arg2:T1\n",
      "R2\tPART-OF Arg1:T12 Arg2:T13\n",
      "R3\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R4\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R6\tCOREF Arg1:T9 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2010_5_abs.ann\n",
      "T1\tTask 19 40\tlinear classification\n",
      "T2\tGeneric 61 73\tapplications\n",
      "T3\tTask 82 105\tdocument classification\n",
      "T4\tMethod 178 194\ttraining methods\n",
      "T5\tOtherScientificTerm 251 266\tcomputer memory\n",
      "T6\tGeneric 274 281\tmethods\n",
      "T7\tGeneric 310 314\tdata\n",
      "T8\tOtherScientificTerm 331 346\tmemory capacity\n",
      "T9\tOtherScientificTerm 358 371\trandom access\n",
      "T10\tOtherScientificTerm 379 383\tdisk\n",
      "T11\tMethod 410 438\tblock minimization framework\n",
      "T12\tGeneric 443 447\tdata\n",
      "T13\tOtherScientificTerm 464 475\tmemory size\n",
      "T14\tOtherScientificTerm 525 529\tdisk\n",
      "T15\tMethod 553 569\tlearning methods\n",
      "T16\tGeneric 622 631\tframework\n",
      "T17\tMethod 636 656\tprimal and dual SVMs\n",
      "T18\tGeneric 893 899\tmethod\n",
      "R1\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R2\tCOREF Arg1:T6 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R4\tCOREF Arg1:T11 Arg2:T16\n",
      "R5\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R6\tCOREF Arg1:T18 Arg2:T16\n",
      "R7\tCOMPARE Arg1:T7 Arg2:T8\n",
      "R8\tCOMPARE Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2013_15_abs.ann\n",
      "T1\tMethod 4 25\tInterval Algebra (IA)\n",
      "T2\tMethod 46 78\tRegion Connection Calculus (RCC)\n",
      "T3\tMethod 87 92\tRCC-8\n",
      "T4\tMethod 111 145\tArtificial Intelligence approaches\n",
      "T5\tTask 150 229\trepresenting and reasoning about qualitative temporal and topological relations\n",
      "T6\tOtherScientificTerm 183 229\tqualitative temporal and topological relations\n",
      "T7\tOtherScientificTerm 249 272\tqualitative information\n",
      "T8\tMethod 296 332\tQualitative Constraint Network (QCN)\n",
      "T9\tTask 365 395\tminimal labeling problem (MLP)\n",
      "T10\tGeneric 414 423\talgorithm\n",
      "T11\tMethod 483 486\tQCN\n",
      "T12\tGeneric 492 501\talgorithm\n",
      "T13\tMethod 512 524\tchordal QCNs\n",
      "T14\tOtherScientificTerm 543 562\tpartial consistency\n",
      "T15\tOtherScientificTerm 582 597\tâ—† G-consistency\n",
      "T16\tGeneric 621 630\talgorithm\n",
      "T17\tOtherScientificTerm 688 706\tpatchwork property\n",
      "T18\tMethod 766 769\tQCN\n",
      "T19\tMethod 794 798\tQCNs\n",
      "T20\tMethod 794 814\tQCNs of IA and RCC-8\n",
      "T21\tMethod 802 804\tIA\n",
      "T22\tMethod 809 814\tRCC-8\n",
      "T23\tGeneric 862 870\tapproach\n",
      "R1\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tHYPONYM-OF Arg1:T2 Arg2:T4\n",
      "R4\tHYPONYM-OF Arg1:T1 Arg2:T4\n",
      "R5\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R6\tCOREF Arg1:T6 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R8\tCOREF Arg1:T8 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R10\tHYPONYM-OF Arg1:T15 Arg2:T14\n",
      "R11\tCOREF Arg1:T12 Arg2:T16\n",
      "R12\tCOREF Arg1:T1 Arg2:T21\n",
      "R13\tCOREF Arg1:T3 Arg2:T22\n",
      "R14\tPART-OF Arg1:T13 Arg2:T12\n",
      "R15\tCOREF Arg1:T10 Arg2:T12\n",
      "R16\tPART-OF Arg1:T14 Arg2:T12\n",
      "R17\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R18\tCOREF Arg1:T18 Arg2:T19\n",
      "R19\tCOREF Arg1:T12 Arg2:T23\n",
      "R20\tEVALUATE-FOR Arg1:T20 Arg2:T23\n",
      "R21\tCOREF Arg1:T18 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2013_4_abs.ann\n",
      "T1\tTask 42 70\thigh-level program execution\n",
      "T2\tTask 115 143\thigh-level program execution\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2013_5_abs.ann\n",
      "T1\tMethod 0 22\tConstraint propagation\n",
      "T2\tMethod 55 77\tconstraint programming\n",
      "T3\tMethod 128 177\tSpecial-purpose constraint propagation algorithms\n",
      "T4\tMethod 488 516\tgeneral purpose prop-agators\n",
      "T5\tOtherScientificTerm 532 542\tconstraint\n",
      "T6\tMethod 672 681\tSHORTSTR2\n",
      "T7\tMethod 704 744\tSimple Tabular Reduction algorithm STR2+\n",
      "T8\tMethod 759 768\tSHORTSTR2\n",
      "T9\tMethod 813 821\tSHORTGAC\n",
      "T10\tMethod 826 835\tHAGGISGAC\n",
      "T11\tOtherScientificTerm 898 908\tconstraint\n",
      "T12\tOtherScientificTerm 924 938\tshort supports\n",
      "T13\tOtherScientificTerm 944 961\tshort support set\n",
      "T14\tOtherScientificTerm 1000 1023\tfull-length support set\n",
      "T15\tMethod 1035 1044\tSHORTSTR2\n",
      "T16\tOtherScientificTerm 1076 1087\tconstraints\n",
      "T17\tMethod 1093 1098\tSTR2+\n",
      "T18\tMethod 1147 1156\tSHORTSTR2\n",
      "T19\tGeneric 1187 1196\talgorithm\n",
      "T20\tOtherScientificTerm 1209 1223\tshort supports\n",
      "T21\tOtherScientificTerm 1229 1249\tfull-length supports\n",
      "T22\tOtherScientificTerm 1273 1292\tdrop-in replacement\n",
      "T23\tMethod 1297 1302\tSTR2+\n",
      "R1\tCOMPARE Arg1:T8 Arg2:T9\n",
      "R2\tCOMPARE Arg1:T8 Arg2:T10\n",
      "R3\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R4\tCOREF Arg1:T6 Arg2:T8\n",
      "R5\tCOREF Arg1:T8 Arg2:T15\n",
      "R6\tCOREF Arg1:T15 Arg2:T18\n",
      "R7\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R8\tCONJUNCTION Arg1:T19 Arg2:T18\n",
      "R9\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R10\tUSED-FOR Arg1:T18 Arg2:T20\n",
      "R11\tUSED-FOR Arg1:T21 Arg2:T18\n",
      "R12\tUSED-FOR Arg1:T21 Arg2:T18\n",
      "R13\tUSED-FOR Arg1:T21 Arg2:T19\n",
      "R14\tUSED-FOR Arg1:T21 Arg2:T19\n",
      "R15\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R16\tUSED-FOR Arg1:T18 Arg2:T22\n",
      "R17\tCOREF Arg1:T23 Arg2:T7\n",
      "R18\tCOREF Arg1:T17 Arg2:T23\n",
      "R19\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R20\tPART-OF Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2016_412_abs.ann\n",
      "T1\tTask 44 72\thash-tag recommendation task\n",
      "T2\tMaterial 77 87\tmicroblogs\n",
      "T3\tOtherScientificTerm 260 280\thandcrafted features\n",
      "T4\tMethod 317 353\tconvolutional neural networks (CNNs)\n",
      "T5\tTask 363 396\tnatural language processing tasks\n",
      "T6\tMethod 422 426\tCNNs\n",
      "T7\tTask 442 472\thashtag recommendation problem\n",
      "T8\tOtherScientificTerm 493 506\ttrigger words\n",
      "T9\tGeneric 608 620\tarchitecture\n",
      "T10\tOtherScientificTerm 629 648\tattention mechanism\n",
      "T11\tGeneric 684 688\tdata\n",
      "T12\tGeneric 770 775\tmodel\n",
      "T13\tGeneric 788 812\tstate-of-the-art methods\n",
      "T14\tOtherScientificTerm 831 844\ttrigger words\n",
      "T15\tGeneric 910 916\tmethod\n",
      "T16\tGeneric 926 949\tstate-of-the-art method\n",
      "T17\tMetric 972 980\tF1-score\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tEVALUATE-FOR Arg1:T17 Arg2:T16\n",
      "R3\tCOREF Arg1:T16 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tCOREF Arg1:T6 Arg2:T4\n",
      "R6\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R8\tCOREF Arg1:T9 Arg2:T12\n",
      "R9\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R10\tCOREF Arg1:T7 Arg2:T1\n",
      "R11\tCOREF Arg1:T15 Arg2:T12\n",
      "R12\tCOMPARE Arg1:T15 Arg2:T16\n",
      "R13\tEVALUATE-FOR Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2016_413_abs.ann\n",
      "T1\tTask 8 23\tauction domains\n",
      "T2\tGeneric 264 270\tdomain\n",
      "T3\tMethod 281 303\tcombinatorial auctions\n",
      "T4\tGeneric 327 331\tthey\n",
      "T5\tOtherScientificTerm 340 381\tviolations of individual rationality (IR)\n",
      "T6\tOtherScientificTerm 354 381\tindividual rationality (IR)\n",
      "T7\tTask 460 498\tdesign of core-selecting payment rules\n",
      "T8\tGeneric 508 515\tdomains\n",
      "T9\tGeneric 556 562\tdomain\n",
      "T10\tOtherScientificTerm 588 600\tpayment rule\n",
      "T11\tOtherScientificTerm 685 690\trules\n",
      "T12\tOtherScientificTerm 841 854\tIR violations\n",
      "T13\tOtherScientificTerm 870 890\tcore-selecting rules\n",
      "T14\tOtherScientificTerm 911 913\tIR\n",
      "T15\tGeneric 962 967\trules\n",
      "T16\tMethod 981 1026\tcomputational Bayes-Nash equilibrium analysis\n",
      "T17\tGeneric 1066 1071\trules\n",
      "T18\tMetric 1127 1156\trate of ex-post IR violations\n",
      "T19\tOtherScientificTerm 1171 1191\tcore-selecting rules\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T4\n",
      "R3\tCOREF Arg1:T2 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tCOREF Arg1:T8 Arg2:T9\n",
      "R6\tCOREF Arg1:T5 Arg2:T12\n",
      "R7\tCOREF Arg1:T6 Arg2:T14\n",
      "R8\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R9\tCOREF Arg1:T13 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R11\tCOREF Arg1:T15 Arg2:T17\n",
      "R12\tCOMPARE Arg1:T17 Arg2:T19\n",
      "R13\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R14\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2016_420_abs.ann\n",
      "T1\tTask 3 24\tcross-domain learning\n",
      "T2\tOtherScientificTerm 71 88\tdomain divergence\n",
      "T3\tGeneric 112 128\tdominant factors\n",
      "T4\tOtherScientificTerm 146 156\tviewpoints\n",
      "T5\tOtherScientificTerm 167 178\tresolutions\n",
      "T6\tOtherScientificTerm 192 205\tilluminations\n",
      "T7\tOtherScientificTerm 223 242\tintermediate domain\n",
      "T8\tTask 312 328\tlearning problem\n",
      "T9\tMethod 358 412\tCoupled Marginalized Denoising Auto-encoders framework\n",
      "T10\tTask 428 448\tcross-domain problem\n",
      "T11\tMethod 478 514\tmarginalized denoising auto-encoders\n",
      "T12\tGeneric 516 519\tone\n",
      "T13\tGeneric 543 548\tother\n",
      "T14\tMethod 618 650\tdenoising auto-encoders learning\n",
      "T15\tMethod 669 684\tfeature mapping\n",
      "T16\tOtherScientificTerm 732 751\tintermediate domain\n",
      "T17\tOtherScientificTerm 789 813\tmaximum margin criterion\n",
      "T18\tOtherScientificTerm 821 845\tintra-class com-pactness\n",
      "T19\tOtherScientificTerm 850 869\tinter-class penalty\n",
      "T20\tOtherScientificTerm 915 938\tdiscriminative features\n",
      "T21\tGeneric 994 999\ttasks\n",
      "T22\tGeneric 1041 1047\tmethod\n",
      "T23\tGeneric 1057 1081\tstate-of-the-art methods\n",
      "R1\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R2\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R4\tPART-OF Arg1:T3 Arg2:T2\n",
      "R5\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R6\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R7\tCOREF Arg1:T8 Arg2:T1\n",
      "R8\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R9\tCOREF Arg1:T10 Arg2:T8\n",
      "R10\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R11\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R12\tHYPONYM-OF Arg1:T13 Arg2:T11\n",
      "R13\tPART-OF Arg1:T15 Arg2:T14\n",
      "R14\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R15\tHYPONYM-OF Arg1:T18 Arg2:T17\n",
      "R16\tHYPONYM-OF Arg1:T19 Arg2:T17\n",
      "R17\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R18\tCOMPARE Arg1:T22 Arg2:T23\n",
      "R19\tCOREF Arg1:T22 Arg2:T9\n",
      "R20\tEVALUATE-FOR Arg1:T21 Arg2:T22\n",
      "R21\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCAI_2016_423_abs.ann\n",
      "T1\tTask 0 29\tLearning video representation\n",
      "T2\tOtherScientificTerm 386 395\tsemantics\n",
      "T3\tOtherScientificTerm 402 421\tcontext information\n",
      "T4\tMethod 465 506\tintrinsic representation of a video frame\n",
      "T5\tGeneric 542 550\tapproach\n",
      "T6\tMethod 564 589\tdeep video representation\n",
      "T7\tOtherScientificTerm 608 635\tlocal and holistic contexts\n",
      "T8\tMethod 664 690\ttriplet sampling mechanism\n",
      "T9\tOtherScientificTerm 705 751\tlocal temporal relationship of adjacent frames\n",
      "T10\tMethod 767 787\tdeep representations\n",
      "T11\tOtherScientificTerm 821 849\tgraph structure of the video\n",
      "T12\tOtherScientificTerm 856 862\tpriori\n",
      "T13\tGeneric 939 947\tapproach\n",
      "T14\tMethod 988 1046\tend-to-end deep convolutional neu-ral network architecture\n",
      "T15\tGeneric 1091 1113\tlearned representation\n",
      "T16\tTask 1146 1169\tvideo recognition tasks\n",
      "T17\tTask 1171 1180\tretrieval\n",
      "T18\tTask 1183 1197\tclassification\n",
      "T19\tTask 1203 1222\thighlight detection\n",
      "T20\tGeneric 1241 1262\tvideo representations\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R6\tCOREF Arg1:T5 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R8\tHYPONYM-OF Arg1:T17 Arg2:T16\n",
      "R9\tHYPONYM-OF Arg1:T18 Arg2:T16\n",
      "R10\tHYPONYM-OF Arg1:T19 Arg2:T16\n",
      "R11\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R12\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R13\tCOMPARE Arg1:T15 Arg2:T20\n",
      "R14\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "R15\tEVALUATE-FOR Arg1:T16 Arg2:T20\n",
      "R16\tCOREF Arg1:T6 Arg2:T15\n",
      "R17\tCOREF Arg1:T6 Arg2:T10\n",
      "R18\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\IJCNLP_2005_3_abs.ann\n",
      "T1\tTask 0 26\tAutomatic image annotation\n",
      "T2\tTask 83 107\tsemantic image retrieval\n",
      "T3\tMaterial 112 129\ttext descriptions\n",
      "T4\tTask 156 197\tautomatically labeling the image contents\n",
      "T5\tOtherScientificTerm 224 232\tkeywords\n",
      "T6\tOtherScientificTerm 270 285\timage semantics\n",
      "T7\tMethod 289 325\tMaximum Entropy Model-based approach\n",
      "T8\tTask 341 367\tautomatic image annotation\n",
      "T9\tTask 411 419\ttraining\n",
      "T10\tOtherScientificTerm 429 446\tvisual vocabulary\n",
      "T11\tOtherScientificTerm 461 472\tblob-tokens\n",
      "T12\tOtherScientificTerm 489 502\timage content\n",
      "T13\tGeneric 535 559\tstatistical relationship\n",
      "T14\tOtherScientificTerm 583 594\tblob-tokens\n",
      "T15\tOtherScientificTerm 599 607\tkeywords\n",
      "T16\tMethod 613 634\tMaximum Entropy Model\n",
      "T17\tTask 704 714\tannotation\n",
      "T18\tOtherScientificTerm 767 775\tkeywords\n",
      "T19\tOtherScientificTerm 806 820\tblob-token set\n",
      "T20\tMaterial 885 914\tmedium-sized image collection\n",
      "T21\tMaterial 943 958\tCorel Photo CDs\n",
      "T22\tTask 1007 1017\tannotation\n",
      "T23\tGeneric 1038 1044\tmethod\n",
      "T24\tMethod 1074 1092\tannotation methods\n",
      "T25\tMetric 1108 1122\tmean precision\n",
      "T26\tMethod 1151 1172\tMaximum Entropy Model\n",
      "T27\tTask 1188 1214\tautomatic image annotation\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T19 Arg2:T18\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R6\tUSED-FOR Arg1:T16 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T26 Arg2:T27\n",
      "R8\tEVALUATE-FOR Arg1:T25 Arg2:T24\n",
      "R9\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R10\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R11\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R12\tCOREF Arg1:T1 Arg2:T8\n",
      "R13\tPART-OF Arg1:T11 Arg2:T10\n",
      "R14\tCOMPARE Arg1:T23 Arg2:T24\n",
      "R15\tCOREF Arg1:T8 Arg2:T17\n",
      "R16\tCOREF Arg1:T17 Arg2:T22\n",
      "R17\tUSED-FOR Arg1:T23 Arg2:T22\n",
      "R18\tUSED-FOR Arg1:T24 Arg2:T22\n",
      "R19\tCOREF Arg1:T16 Arg2:T26\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2000_483_abs.ann\n",
      "T1\tMaterial 22 58\tout-of-domain acoustic training data\n",
      "T2\tMethod 72 89\tspeech recognizer\n",
      "T3\tMaterial 170 199\tWallstreet Journal (WSJ) data\n",
      "T4\tMethod 211 221\trecognizer\n",
      "T5\tMaterial 261 277\tPhonebook domain\n",
      "T6\tOtherScientificTerm 296 324\tcommon language (US English)\n",
      "T7\tOtherScientificTerm 376 408\tmicrophone vs. telephone channel\n",
      "T8\tOtherScientificTerm 410 427\tcontinuous speech\n",
      "T9\tOtherScientificTerm 432 446\tisolated words\n",
      "T10\tMethod 548 570\tWSJ-trained recognizer\n",
      "T11\tMaterial 581 596\tadaptation data\n",
      "T12\tMaterial 613 638\tPhonebook training corpus\n",
      "T13\tTask 677 688\trecognition\n",
      "T14\tOtherScientificTerm 732 740\tmismatch\n",
      "T15\tTask 780 791\trecognition\n",
      "T16\tMethod 809 850\tPhonebook-trained baseline acoustic model\n",
      "T17\tMaterial 871 898\tout-of-domain training data\n",
      "T18\tMethod 924 963\tadaptation and normalization techniques\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tEVALUATE-FOR Arg1:T5 Arg2:T4\n",
      "R4\tPART-OF Arg1:T11 Arg2:T12\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R8\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R9\tCOREF Arg1:T13 Arg2:T15\n",
      "R10\tCOREF Arg1:T2 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2000_490_abs.ann\n",
      "T1\tMethod 11 24\tN-gram models\n",
      "T2\tTask 72 101\tstatistical language modeling\n",
      "T3\tMethod 162 177\tlanguage models\n",
      "T4\tMethod 191 217\tartificial neural networks\n",
      "T5\tMethod 231 245\tlanguage model\n",
      "T6\tMethod 284 298\tneural network\n",
      "T7\tMethod 311 325\tlanguage model\n",
      "T8\tMethod 373 392\tstatistical methods\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T5 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tCOREF Arg1:T6 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tCOMPARE Arg1:T6 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2001_21_abs.ann\n",
      "T1\tMethod 0 8\tSmartKom\n",
      "T2\tMethod 14 38\tmultimodal dialog system\n",
      "T3\tMaterial 53 59\tspeech\n",
      "T4\tMaterial 61 68\tgesture\n",
      "T5\tTask 99 131\tSpontaneous speech understanding\n",
      "T6\tTask 153 196\tvideo-based recognition of natural gestures\n",
      "T7\tMethod 235 243\tSmartKom\n",
      "T8\tMethod 261 282\tcomputational methods\n",
      "T9\tTask 300 368\tintegration and mutual disambiguation of multimodal input and output\n",
      "T10\tOtherScientificTerm 374 402\tsemantic and pragmatic level\n",
      "T11\tOtherScientificTerm 404 412\tSmartKom\n",
      "T12\tMethod 429 473\tsituated delegation-oriented dialog paradigm\n",
      "T13\tOtherScientificTerm 515 546\tvirtual communication assistant\n",
      "T14\tOtherScientificTerm 588 605\tgraphical display\n",
      "T15\tMethod 623 644\tSmartKom architecture\n",
      "T16\tOtherScientificTerm 660 685\tXML-based markup language\n",
      "T17\tMaterial 690 708\tmultimodal content\n",
      "T18\tMethod 781 802\tSmartKom demonstrator\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R3\tCOREF Arg1:T7 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R7\tUSED-FOR Arg1:T4 Arg2:T2\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R9\tCOREF Arg1:T7 Arg2:T11\n",
      "R10\tCOREF Arg1:T11 Arg2:T15\n",
      "R11\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R12\tCOREF Arg1:T15 Arg2:T18\n",
      "R13\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R14\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2001_28_abs.ann\n",
      "T1\tMethod 74 101\tspeaker verification system\n",
      "T2\tMethod 206 233\tspeaker verification system\n",
      "T3\tMethod 368 383\tuser evaluation\n",
      "T4\tMaterial 425 436\tspeech data\n",
      "T5\tMethod 611 631\tHidden Markov Models\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2001_31_abs.ann\n",
      "T1\tGeneric 22 28\tmethod\n",
      "T2\tTask 33 72\tblind estimation of reverberation times\n",
      "T3\tOtherScientificTerm 76 98\treverberant enclosures\n",
      "T4\tGeneric 113 122\talgorithm\n",
      "T5\tMethod 137 189\tstatistical model of short-term log-energy sequences\n",
      "T6\tMaterial 194 210\techo-free speech\n",
      "T7\tMethod 283 351\tMaximum Likelihood estimate of the room full-band reverberation time\n",
      "T8\tGeneric 357 374\testimation method\n",
      "T9\tGeneric 442 448\tmethod\n",
      "T10\tTask 482 517\trobust automatic speech recognition\n",
      "T11\tOtherScientificTerm 521 545\treverberant environments\n",
      "T12\tMethod 549 564\tmodel selection\n",
      "T13\tGeneric 575 586\tapplication\n",
      "T14\tOtherScientificTerm 592 610\treverberation time\n",
      "T15\tOtherScientificTerm 639 668\treverberated speech utterance\n",
      "T16\tGeneric 691 701\testimation\n",
      "T17\tMethod 734 748\tacoustic model\n",
      "T18\tGeneric 769 775\tmodels\n",
      "T19\tOtherScientificTerm 795 829\tartificial re-verberant conditions\n",
      "T20\tTask 831 849\tSpeech recognition\n",
      "T21\tOtherScientificTerm 865 908\tsimulated and real reverberant environments\n",
      "T22\tGeneric 936 944\tapproach\n",
      "T23\tMethod 972 1005\tchannel normaliza-tion techniques\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T1 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R6\tCOREF Arg1:T8 Arg2:T7\n",
      "R7\tCOREF Arg1:T8 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R9\tFEATURE-OF Arg1:T11 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T9\n",
      "R11\tCOREF Arg1:T10 Arg2:T13\n",
      "R12\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R13\tFEATURE-OF Arg1:T21 Arg2:T20\n",
      "R14\tCOREF Arg1:T4 Arg2:T22\n",
      "R15\tCOMPARE Arg1:T23 Arg2:T22\n",
      "R16\tEVALUATE-FOR Arg1:T20 Arg2:T22\n",
      "R17\tEVALUATE-FOR Arg1:T20 Arg2:T23\n",
      "R18\tPART-OF Arg1:T17 Arg2:T18\n",
      "R19\tFEATURE-OF Arg1:T19 Arg2:T18\n",
      "R20\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2006_21_abs.ann\n",
      "T1\tMethod 26 59\tlanguage model adaptation methods\n",
      "T2\tOtherScientificTerm 68 77\tword list\n",
      "T3\tMaterial 84 94\traw corpus\n",
      "T4\tGeneric 127 133\tmethod\n",
      "T5\tMaterial 152 162\traw corpus\n",
      "T6\tOtherScientificTerm 185 194\tword list\n",
      "T7\tGeneric 246 251\tmodel\n",
      "T8\tMaterial 261 277\tsegmented corpus\n",
      "T9\tMethod 287 331\tsentence-by-sentence error correction method\n",
      "T10\tGeneric 602 608\tmethod\n",
      "T11\tGeneric 776 783\tmethods\n",
      "T12\tTask 788 816\tpreparing a segmented corpus\n",
      "T13\tMethod 834 849\tlanguage models\n",
      "T14\tMetric 859 888\tspeech recognition accuracies\n",
      "T15\tGeneric 931 937\tmethod\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R3\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R8\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R9\tCOREF Arg1:T1 Arg2:T10\n",
      "R10\tCOREF Arg1:T10 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2006_28_abs.ann\n",
      "T1\tOtherScientificTerm 24 64\tautomatic phonetic transcriptions (APTs)\n",
      "T2\tOtherScientificTerm 77 118\tmanually verified phonetic transcriptions\n",
      "T3\tTask 159 182\tpronunciation variation\n",
      "T4\tTask 258 272\tclassification\n",
      "T5\tTask 366 389\tpronunciation variation\n",
      "T6\tMethod 402 413\tclassifiers\n",
      "T7\tMaterial 421 437\tspeech processes\n",
      "T8\tOtherScientificTerm 457 467\talignments\n",
      "T9\tOtherScientificTerm 474 477\tAPT\n",
      "T10\tOtherScientificTerm 485 488\tMPT\n",
      "T11\tOtherScientificTerm 496 519\tcanonical transcription\n",
      "T12\tMaterial 543 554\tclassifiers\n",
      "T13\tOtherScientificTerm 594 616\tunknown transcriptions\n",
      "T14\tMaterial 627 638\tread speech\n",
      "T15\tMaterial 642 661\ttelephone dialogues\n",
      "T16\tMaterial 684 700\tspeech processes\n",
      "T17\tMethod 880 900\tAPT-based classifier\n",
      "T18\tMetric 916 939\tclassification accuracy\n",
      "T19\tMethod 949 969\tMPT-based classifier\n",
      "T20\tOtherScientificTerm 989 1012\tclassification features\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R3\tCOMPARE Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T3 Arg2:T5\n",
      "R5\tCOREF Arg1:T9 Arg2:T1\n",
      "R6\tCOREF Arg1:T10 Arg2:T2\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T8\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R11\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R12\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R13\tCOREF Arg1:T6 Arg2:T12\n",
      "R14\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R15\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R16\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R17\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R18\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R19\tCOMPARE Arg1:T17 Arg2:T19\n",
      "R20\tUSED-FOR Arg1:T20 Arg2:T17\n",
      "R21\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R22\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2006_31_abs.ann\n",
      "T1\tMethod 82 120\tstatistical machine learning algorithm\n",
      "T2\tOtherScientificTerm 150 192\tsmallest meaning-bearing units of language\n",
      "T3\tOtherScientificTerm 195 204\tmorphemes\n",
      "T4\tGeneric 215 220\tthese\n",
      "T5\tGeneric 271 276\ttasks\n",
      "T6\tTask 286 315\tspeech and text understanding\n",
      "T7\tTask 317 336\tmachine translation\n",
      "T8\tTask 338 359\tinformation retrieval\n",
      "T9\tTask 365 394\tstatistical language modeling\n",
      "T10\tMethod 570 594\tsegmen-tation algorithms\n",
      "T11\tTask 598 633\tlarge vocabulary speech recognition\n",
      "T12\tMethod 640 674\tstatistical n-gram language models\n",
      "T13\tMaterial 766 815\tag-glutinative and morphologically rich languages\n",
      "T14\tMaterial 817 824\tFinnish\n",
      "T15\tMaterial 829 837\tTurk-ish\n",
      "R1\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R4\tHYPONYM-OF Arg1:T14 Arg2:T13\n",
      "R5\tHYPONYM-OF Arg1:T15 Arg2:T13\n",
      "R6\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R7\tHYPONYM-OF Arg1:T7 Arg2:T5\n",
      "R8\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R9\tHYPONYM-OF Arg1:T8 Arg2:T5\n",
      "R10\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R11\tHYPONYM-OF Arg1:T9 Arg2:T5\n",
      "R12\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R13\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R14\tCOREF Arg1:T3 Arg2:T4\n",
      "R15\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R16\tEVALUATE-FOR Arg1:T12 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2007_20_abs.ann\n",
      "T1\tMethod 24 43\tdialogue management\n",
      "T2\tTask 51 80\tinformation navigation system\n",
      "T3\tMaterial 92 115\tdocument knowledge base\n",
      "T4\tOtherScientificTerm 166 190\tN-best candidates of ASR\n",
      "T5\tOtherScientificTerm 195 217\tcontextual information\n",
      "T6\tGeneric 235 241\tsystem\n",
      "T7\tGeneric 259 265\tsystem\n",
      "T8\tTask 294 331\tgenerating responses or confirmations\n",
      "T9\tTask 379 405\tminimization of Bayes risk\n",
      "T10\tMetric 415 421\treward\n",
      "T11\tOtherScientificTerm 426 458\tcorrect information presentation\n",
      "T12\tMetric 463 470\tpenalty\n",
      "T13\tOtherScientificTerm 475 490\tredundant turns\n",
      "T14\tGeneric 515 523\tstrategy\n",
      "T15\tTask 533 593\tspoken dialogue system \" Dialogue Navigator for Kyoto City \"\n",
      "T16\tOtherScientificTerm 611 640\tquestion-answering capability\n",
      "T17\tGeneric 672 681\tframework\n",
      "T18\tMetric 703 728\tsuccess rate of retrieval\n",
      "T19\tMetric 737 760\taverage number of turns\n",
      "T20\tOtherScientificTerm 765 783\tinformation access\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T9\n",
      "R8\tCOREF Arg1:T14 Arg2:T9\n",
      "R9\tCOREF Arg1:T7 Arg2:T6\n",
      "R10\tCOREF Arg1:T6 Arg2:T2\n",
      "R11\tCOREF Arg1:T17 Arg2:T14\n",
      "R12\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R13\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R14\tEVALUATE-FOR Arg1:T19 Arg2:T17\n",
      "R15\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R16\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R17\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R18\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R19\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R20\tFEATURE-OF Arg1:T16 Arg2:T15\n",
      "R21\tCOREF Arg1:T7 Arg2:T15\n",
      "R22\tCONJUNCTION Arg1:T10 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2007_21_abs.ann\n",
      "T1\tMethod 13 17\tHMMs\n",
      "T2\tOtherScientificTerm 23 48\tweak duration constraints\n",
      "T3\tMaterial 92 116\tcorrupted speech signals\n",
      "T4\tGeneric 121 127\tmodels\n",
      "T5\tMaterial 139 151\tclean speech\n",
      "T6\tMethod 166 173\tdecoder\n",
      "T7\tOtherScientificTerm 185 197\tword matches\n",
      "T8\tOtherScientificTerm 203 224\tunrealistic durations\n",
      "T9\tOtherScientificTerm 274 299\tword duration constraints\n",
      "T10\tMethod 303 317\tunrolling HMMs\n",
      "T11\tOtherScientificTerm 328 335\tlattice\n",
      "T12\tOtherScientificTerm 342 369\tword duration probabilities\n",
      "T13\tOtherScientificTerm 397 414\tstate transitions\n",
      "T14\tMethod 429 433\tHMMs\n",
      "T15\tMethod 467 483\tViterbi decoding\n",
      "T16\tTask 500 527\tconnected-digit recognition\n",
      "T17\tOtherScientificTerm 558 578\tduration constraints\n",
      "T18\tMethod 583 590\tdecoder\n",
      "T19\tOtherScientificTerm 601 613\tword matches\n",
      "T20\tMetric 650 666\tword error rates\n",
      "T21\tOtherScientificTerm 717 733\tnoise conditions\n",
      "R1\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R8\tCONJUNCTION Arg1:T15 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R10\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R11\tUSED-FOR Arg1:T16 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2007_28_abs.ann\n",
      "T1\tGeneric 26 44\ttwo-pass algorithm\n",
      "T2\tTask 49 122\tExtra Large (more than 1M words) Vocabulary COntinuous Speech recognition\n",
      "T3\tTask 136 168\tInformation Retrieval (ELVIRCOS)\n",
      "T4\tGeneric 192 200\tapproach\n",
      "T5\tMethod 219 238\trecognition process\n",
      "T6\tGeneric 248 254\tpasses\n",
      "T7\tGeneric 265 275\tfirst pass\n",
      "T8\tOtherScientificTerm 287 299\twords subset\n",
      "T9\tGeneric 308 331\tsecond pass recognition\n",
      "T10\tMethod 341 372\tinformation retrieval procedure\n",
      "T11\tMethod 374 396\tWord graph composition\n",
      "T12\tMaterial 401 418\tcontinuous speech\n",
      "T13\tGeneric 443 451\tapproach\n",
      "T14\tTask 476 511\tlarge vocabulary speech recognition\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tHYPONYM-OF Arg1:T7 Arg2:T6\n",
      "R5\tCOREF Arg1:T6 Arg2:T5\n",
      "R6\tHYPONYM-OF Arg1:T9 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R10\tCOREF Arg1:T14 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2007_31_abs.ann\n",
      "T1\tMethod 40 60\tHMM-based TTS system\n",
      "T2\tMaterial 72 85\tGerman speech\n",
      "T3\tOtherScientificTerm 180 196\tcontext features\n",
      "T4\tGeneric 215 221\tsystem\n",
      "T5\tMaterial 251 273\tfootball announcements\n",
      "T6\tMaterial 316 333\texpressive speech\n",
      "T7\tMethod 356 360\tHMMs\n",
      "T8\tMaterial 388 422\tintelligible neutral German speech\n",
      "T9\tMaterial 529 545\tfootball dataset\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T1 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2007_40_abs.ann\n",
      "T1\tTask 0 24\tInformation distillation\n",
      "T2\tMaterial 102 168\tmassive, possibly multilingual, audio and textual document sources\n",
      "T3\tOtherScientificTerm 220 254\tinformation extraction annotations\n",
      "T4\tTask 266 301\tdocument retrieval for distillation\n",
      "T5\tOtherScientificTerm 350 370\tdistillation queries\n",
      "T6\tOtherScientificTerm 394 413\tannotation elements\n",
      "T7\tTask 433 477\tNIST Automatic Content Extraction (ACE) task\n",
      "T8\tOtherScientificTerm 517 527\tACE events\n",
      "T9\tMethod 573 601\tinformation retrieval engine\n",
      "T10\tMetric 629 638\tprecision\n",
      "T11\tMetric 650 662\trecall rates\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2008_20_abs.ann\n",
      "T1\tTask 16 47\texpressive speech communication\n",
      "T2\tMaterial 537 553\tIEMOCAP database\n",
      "T3\tTask 555 626\tdiscrete (categorical) and continuous (attribute) emotional assessments\n",
      "T4\tOtherScientificTerm 744 780\texpression and perception of emotion\n",
      "T5\tGeneric 802 810\tdatabase\n",
      "T6\tOtherScientificTerm 918 942\tactivation-valence space\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tCOREF Arg1:T5 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2008_21_abs.ann\n",
      "T1\tTask 38 63\tCzech talking head system\n",
      "T2\tGeneric 89 96\tmethods\n",
      "T3\tTask 106 129\tvisual speech animation\n",
      "T4\tMethod 207 223\tsynthesis method\n",
      "T5\tMethod 227 245\t3D animation model\n",
      "T6\tMethod 260 292\tpseudo-muscular animation schema\n",
      "T7\tTask 308 334\tanimation of visual speech\n",
      "T8\tTask 357 367\tlipreading\n",
      "T9\tMethod 385 401\tanimation schema\n",
      "T10\tTask 499 532\tforming articulatory trajectories\n",
      "T11\tOtherScientificTerm 556 585\tlabial coarticulation effects\n",
      "T12\tGeneric 587 589\tIt\n",
      "T13\tMethod 606 622\tsynthesis method\n",
      "T14\tOtherScientificTerm 634 667\tselection of articulatory targets\n",
      "T15\tMethod 672 695\tinterpolation technique\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R4\tCOREF Arg1:T3 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R7\tCOREF Arg1:T10 Arg2:T12\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R9\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R10\tUSED-FOR Arg1:T15 Arg2:T12\n",
      "R11\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2008_28_abs.ann\n",
      "T1\tTask 19 33\tencoding sound\n",
      "T2\tTask 38 57\tneuronal processing\n",
      "T3\tOtherScientificTerm 74 94\tanalog pressure wave\n",
      "T4\tOtherScientificTerm 109 141\tdiscrete nerve-action potentials\n",
      "T5\tMethod 150 161\tpool models\n",
      "T6\tOtherScientificTerm 169 192\tinner hair cell synapse\n",
      "T7\tMethod 269 286\tvisual inspection\n",
      "T8\tMethod 291 325\tautomatic speech recognition (ASR)\n",
      "T9\tMethod 344 372\toffset adaptation (OA) model\n",
      "T10\tMethod 403 405\tOA\n",
      "T11\tTask 415 455\tphase locking in the auditory nerve (AN)\n",
      "T12\tMetric 467 479\tASR accuracy\n",
      "T13\tOtherScientificTerm 484 492\tfeatures\n",
      "T14\tOtherScientificTerm 506 522\tAN fibers (ANFs)\n",
      "T15\tMethod 543 545\tOA\n",
      "T16\tTask 561 580\tauditory processing\n",
      "T17\tOtherScientificTerm 584 603\tonset neurons (ONs)\n",
      "T18\tOtherScientificTerm 636 654\tauditory brainstem\n",
      "T19\tMethod 656 686\tMulti-layer perceptrons (MLPs)\n",
      "T20\tMethod 723 753\tGaussian mixture models (GMMs)\n",
      "T21\tOtherScientificTerm 767 807\tANF-based and ON-based auditory features\n",
      "T22\tOtherScientificTerm 855 911\tMSG (Modulation-filtered Spec-troGram) auditory features\n",
      "T23\tOtherScientificTerm 963 971\tfeatures\n",
      "T24\tMethod 995 999\tMLPs\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R5\tCOREF Arg1:T10 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R8\tCOREF Arg1:T15 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R10\tUSED-FOR Arg1:T17 Arg2:T15\n",
      "R11\tCOMPARE Arg1:T19 Arg2:T20\n",
      "R12\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R13\tUSED-FOR Arg1:T19 Arg2:T21\n",
      "R14\tCOREF Arg1:T24 Arg2:T19\n",
      "R15\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R16\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R17\tUSED-FOR Arg1:T10 Arg2:T13\n",
      "R18\tEVALUATE-FOR Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2013_21_abs.ann\n",
      "T1\tOtherScientificTerm 59 77\tlack of structures\n",
      "T2\tTask 59 106\tlack of structures in traditional n-gram models\n",
      "T3\tMethod 93 106\tn-gram models\n",
      "T4\tTask 125 160\tweakly supervised dependency parser\n",
      "T5\tOtherScientificTerm 176 189\tspeech syntax\n",
      "T6\tMaterial 213 238\tannotated training corpus\n",
      "T7\tOtherScientificTerm 240 252\tLabeled data\n",
      "T8\tOtherScientificTerm 274 292\thand-crafted rules\n",
      "T9\tOtherScientificTerm 311 330\tsyntactic knowledge\n",
      "T10\tMethod 332 350\tBayesian inference\n",
      "T11\tOtherScientificTerm 368 373\trules\n",
      "T12\tGeneric 404 408\tthem\n",
      "T13\tOtherScientificTerm 419 442\tcomplex tree structures\n",
      "T14\tOtherScientificTerm 459 491\tdiscriminative model's posterior\n",
      "T15\tMaterial 504 520\tunlabeled corpus\n",
      "T16\tGeneric 527 536\tposterior\n",
      "T17\tOtherScientificTerm 545 576\tsparse se-lectional preferences\n",
      "T18\tGeneric 621 626\tmodel\n",
      "T19\tMaterial 643 676\tEnglish and Czech newspaper texts\n",
      "T20\tMaterial 703 739\tFrench broadcast news transcriptions\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R3\tCOREF Arg1:T11 Arg2:T12\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R5\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R8\tCOREF Arg1:T14 Arg2:T16\n",
      "R9\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R10\tEVALUATE-FOR Arg1:T19 Arg2:T18\n",
      "R11\tEVALUATE-FOR Arg1:T20 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2013_28_abs.ann\n",
      "T1\tMaterial 26 74\tunder-explored language genre of spoken language\n",
      "T2\tMaterial 75 90\tlyrics in music\n",
      "T3\tMethod 106 129\tunsuper-vised induction\n",
      "T4\tMethod 136 177\tSMT-style stochastic transduction grammar\n",
      "T5\tMaterial 182 196\thip hop lyrics\n",
      "T6\tMethod 209 262\tfully-automatically learned challenge-response system\n",
      "T7\tMaterial 277 291\trhyming lyrics\n",
      "T8\tMaterial 357 371\thip hop lyrics\n",
      "T9\tGeneric 442 450\tapproach\n",
      "T10\tOtherScientificTerm 507 546\tpriori linguistic or phonetic knowledge\n",
      "T11\tGeneric 606 611\tmodel\n",
      "T12\tOtherScientificTerm 661 677\thuman evaluators\n",
      "T13\tMethod 730 753\tphrase-based SMT models\n",
      "T14\tGeneric 768 772\ttask\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R5\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R6\tCOREF Arg1:T9 Arg2:T6\n",
      "R7\tCOREF Arg1:T11 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T3 Arg2:T6\n",
      "R9\tCOMPARE Arg1:T11 Arg2:T13\n",
      "R10\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R11\tEVALUATE-FOR Arg1:T14 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2013_31_abs.ann\n",
      "T1\tMethod 28 73\tdigital signal processor (DSP) implementation\n",
      "T2\tMethod 77 120\treal-time statistical voice conversion (VC)\n",
      "T3\tTask 125 150\tsilent speech enhancement\n",
      "T4\tTask 155 190\telectrolaryngeal speech enhancement\n",
      "T5\tOtherScientificTerm 197 220\tsilent speech interface\n",
      "T6\tMaterial 234 258\tnon-audible murmur (NAM)\n",
      "T7\tMaterial 298 312\taudible speech\n",
      "T8\tMaterial 332 355\tElectrolaryngeal speech\n",
      "T9\tMaterial 387 404\talaryngeal speech\n",
      "T10\tMethod 432 447\tspeaking method\n",
      "T11\tOtherScientificTerm 452 466\tlaryngectomees\n",
      "T12\tMetric 481 494\tsound quality\n",
      "T13\tMaterial 498 501\tNAM\n",
      "T14\tMaterial 498 529\tNAM and electrolaryngeal speech\n",
      "T15\tMethod 564 566\tVC\n",
      "T16\tGeneric 645 647\tit\n",
      "T17\tGeneric 685 692\tdevices\n",
      "T18\tMaterial 698 732\tsufficient computational resources\n",
      "T19\tGeneric 755 762\tdevices\n",
      "T20\tMaterial 797 828\tlimited computational resources\n",
      "T21\tMethod 911 923\treal-time VC\n",
      "T22\tOtherScientificTerm 929 932\tDSP\n",
      "T23\tMethod 955 981\tspeech enhancement systems\n",
      "T24\tMethod 991 1003\treal-time VC\n",
      "T25\tGeneric 1005 1008\tone\n",
      "T26\tMaterial 1014 1017\tNAM\n",
      "T27\tMaterial 1023 1038\twhispered voice\n",
      "T28\tGeneric 1047 1052\tother\n",
      "T29\tMaterial 1058 1081\telectrolaryngeal speech\n",
      "T30\tMaterial 1087 1100\tnatural voice\n",
      "T31\tGeneric 1121 1128\tmethods\n",
      "T32\tMetric 1142 1160\tcomputational cost\n",
      "T33\tMetric 1178 1197\tconversion accuracy\n",
      "T34\tMethod 1249 1261\treal-time VC\n",
      "T35\tOtherScientificTerm 1289 1292\tDSP\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "R4\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R5\tHYPONYM-OF Arg1:T8 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R8\tCOREF Arg1:T13 Arg2:T6\n",
      "R9\tEVALUATE-FOR Arg1:T12 Arg2:T14\n",
      "R10\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "R11\tCOREF Arg1:T21 Arg2:T24\n",
      "R12\tCOREF Arg1:T6 Arg2:T26\n",
      "R13\tEVALUATE-FOR Arg1:T32 Arg2:T31\n",
      "R14\tCONJUNCTION Arg1:T32 Arg2:T33\n",
      "R15\tEVALUATE-FOR Arg1:T33 Arg2:T31\n",
      "R16\tCOREF Arg1:T24 Arg2:T34\n",
      "R17\tCOREF Arg1:T22 Arg2:T35\n",
      "R18\tUSED-FOR Arg1:T35 Arg2:T34\n",
      "R19\tUSED-FOR Arg1:T24 Arg2:T23\n",
      "R20\tHYPONYM-OF Arg1:T25 Arg2:T23\n",
      "R21\tHYPONYM-OF Arg1:T28 Arg2:T23\n",
      "R22\tCONJUNCTION Arg1:T25 Arg2:T28\n",
      "R23\tCOREF Arg1:T15 Arg2:T16\n",
      "R24\tFEATURE-OF Arg1:T18 Arg2:T17\n",
      "R25\tFEATURE-OF Arg1:T20 Arg2:T19\n",
      "R26\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R27\tCOREF Arg1:T2 Arg2:T21\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2014_20_abs.ann\n",
      "T1\tTask 26 65\tmultilingual feature-level data sharing\n",
      "T2\tMethod 70 123\tDeep Neural Network (DNN) stacked bottleneck features\n",
      "T3\tTask 177 200\tlanguage identification\n",
      "T4\tMaterial 286 308\tmultilingual resources\n",
      "T5\tMaterial 331 352\tIARPA-Babel languages\n",
      "T6\tOtherScientificTerm 363 382\tbottleneck features\n",
      "T7\tGeneric 447 452\tthose\n",
      "T8\tGeneric 532 536\tdata\n",
      "T9\tTask 582 603\tmultilingual training\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tCOMPARE Arg1:T7 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2014_28_abs.ann\n",
      "T1\tMethod 28 80\tstatistical singing voice conversion (SVC) technique\n",
      "T2\tMethod 86 114\tdirect waveform modification\n",
      "T3\tOtherScientificTerm 128 149\tspectrum differential\n",
      "T4\tOtherScientificTerm 167 179\tvoice timbre\n",
      "T5\tMethod 244 251\tvocoder\n",
      "T6\tOtherScientificTerm 264 297\tconverted singing voice waveforms\n",
      "T7\tMethod 299 302\tSVC\n",
      "T8\tOtherScientificTerm 332 361\tsinging voice characteristics\n",
      "T9\tMetric 443 457\tspeech quality\n",
      "T10\tOtherScientificTerm 465 488\tconverted singing voice\n",
      "T11\tOtherScientificTerm 537 558\tnatural singing voice\n",
      "T12\tMethod 627 650\tvocoder-based framework\n",
      "T13\tMethod 696 726\tstatistical conversion process\n",
      "T14\tOtherScientificTerm 820 827\tspectra\n",
      "T15\tOtherScientificTerm 882 911\tdifferential spectral feature\n",
      "T16\tMethod 942 983\tdifferential Gaussian mixture model (GMM)\n",
      "T17\tMethod 1034 1037\tGMM\n",
      "T18\tMethod 1048 1064\tconversion model\n",
      "T19\tMethod 1085 1088\tSVC\n",
      "T20\tGeneric 1145 1151\tmethod\n",
      "T21\tMetric 1195 1209\tspeech quality\n",
      "T22\tMetric 1262 1300\tconversion accuracy of singer identity\n",
      "T23\tMethod 1330 1333\tSVC\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tCOREF Arg1:T7 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R6\tEVALUATE-FOR Arg1:T9 Arg2:T10\n",
      "R7\tCOMPARE Arg1:T10 Arg2:T11\n",
      "R8\tEVALUATE-FOR Arg1:T9 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R11\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R12\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R13\tEVALUATE-FOR Arg1:T21 Arg2:T20\n",
      "R14\tCOMPARE Arg1:T20 Arg2:T23\n",
      "R15\tEVALUATE-FOR Arg1:T22 Arg2:T20\n",
      "R16\tUSED-FOR Arg1:T22 Arg2:T23\n",
      "R17\tEVALUATE-FOR Arg1:T21 Arg2:T23\n",
      "R18\tCOREF Arg1:T13 Arg2:T20\n",
      "R19\tCOREF Arg1:T13 Arg2:T1\n",
      "R20\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2014_31_abs.ann\n",
      "T1\tMaterial 63 81\ti-vector challenge\n",
      "T2\tMaterial 113 156\tNIST Speaker Recognition Evaluations (SREs)\n",
      "T3\tMaterial 184 194\tSRE series\n",
      "T4\tMaterial 200 218\ti-vector challenge\n",
      "T5\tOtherScientificTerm 252 280\tfixed-length feature vectors\n",
      "T6\tOtherScientificTerm 298 331\tlow-dimensional space (i-vectors)\n",
      "T7\tMaterial 344 360\taudio recordings\n",
      "T8\tOtherScientificTerm 464 486\taudio processing field\n",
      "T9\tMaterial 509 512\tSRE\n",
      "T10\tMaterial 518 536\ti-vector challenge\n",
      "T11\tGeneric 729 743\tleading system\n",
      "T12\tGeneric 800 815\tbaseline system\n",
      "R1\tCOREF Arg1:T1 Arg2:T4\n",
      "R2\tCOREF Arg1:T2 Arg2:T9\n",
      "R3\tCOMPARE Arg1:T11 Arg2:T12\n",
      "R4\tCOMPARE Arg1:T9 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R6\tCOREF Arg1:T2 Arg2:T3\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R8\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R9\tCOMPARE Arg1:T7 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2014_40_abs.ann\n",
      "T1\tOtherScientificTerm 52 96\tfundamental frequency (F0) contour of speech\n",
      "T2\tMaterial 104 114\ttext input\n",
      "T3\tTask 119 143\ttext-to-speech synthesis\n",
      "T4\tMethod 177 194\tstatistical model\n",
      "T5\tOtherScientificTerm 232 250\tspeech F0 contours\n",
      "T6\tMethod 294 308\tFujisaki model\n",
      "T7\tOtherScientificTerm 314 332\tremarkable feature\n",
      "T8\tGeneric 341 346\tmodel\n",
      "T9\tGeneric 355 357\tit\n",
      "T10\tGeneric 396 405\talgorithm\n",
      "T11\tMethod 424 443\tstatistical methods\n",
      "T12\tOtherScientificTerm 463 488\tFujisaki-model parameters\n",
      "T13\tOtherScientificTerm 494 509\traw F0 contours\n",
      "T14\tOtherScientificTerm 542 567\tFujisaki-model parameters\n",
      "T15\tMaterial 575 585\ttext input\n",
      "T16\tMethod 595 615\tstatistical learning\n",
      "T17\tGeneric 652 657\tmodel\n",
      "T18\tMethod 707 735\tparameter training algorithm\n",
      "T19\tGeneric 752 757\tmodel\n",
      "T20\tMethod 769 807\tdecision tree-based context clustering\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tCOREF Arg1:T1 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tCOREF Arg1:T4 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R7\tFEATURE-OF Arg1:T7 Arg2:T8\n",
      "R8\tCOREF Arg1:T8 Arg2:T9\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R10\tCOREF Arg1:T9 Arg2:T10\n",
      "R11\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R12\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R13\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R14\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R15\tUSED-FOR Arg1:T20 Arg2:T18\n",
      "R16\tCOREF Arg1:T9 Arg2:T17\n",
      "R17\tUSED-FOR Arg1:T16 Arg2:T14\n",
      "R18\tCOREF Arg1:T19 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2015_16_abs.ann\n",
      "T1\tMethod 10 37\tStacked Auto-Encoders (SAE)\n",
      "T2\tTask 70 98\tlearning imbalanced datasets\n",
      "T3\tMethod 155 180\tNeural Network classifier\n",
      "T4\tMethod 197 210\tSAE structure\n",
      "T5\tMethod 253 294\tAutomatic Speech Recognition (ASR) system\n",
      "T6\tTask 296 311\tError detection\n",
      "T7\tMaterial 318 341\tautomatic transcription\n",
      "T8\tMethod 367 377\tASR system\n",
      "T9\tMetric 403 418\tword error rate\n",
      "T10\tMethod 545 563\tbinary classi-fier\n",
      "T11\tMethod 625 636\tclassifiers\n",
      "T12\tTask 641 675\tautomatically detecting ASR errors\n",
      "T13\tGeneric 691 694\tone\n",
      "T14\tMethod 706 739\tstacked auto-encoder architecture\n",
      "T15\tMaterial 827 851\tautomatic transcriptions\n",
      "T16\tMaterial 858 872\tEnglish corpus\n",
      "T17\tMaterial 888 897\tTED talks\n",
      "T18\tMethod 932 942\tclassifier\n",
      "T19\tMetric 965 990\treceiving operating curve\n",
      "T20\tGeneric 1001 1008\tmeasure\n",
      "T21\tMetric 1017 1036\tmean absolute error\n",
      "T22\tMetric 1093 1108\tword error rate\n",
      "T23\tMethod 1144 1154\tclassifier\n",
      "T24\tMethod 1164 1167\tSAE\n",
      "T25\tOtherScientificTerm 1180 1190\tASR errors\n",
      "T26\tMethod 1213 1235\tclassification methods\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T4 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tCOREF Arg1:T8 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R8\tHYPONYM-OF Arg1:T13 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R10\tCOREF Arg1:T14 Arg2:T1\n",
      "R11\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R12\tFEATURE-OF Arg1:T16 Arg2:T15\n",
      "R13\tCOREF Arg1:T21 Arg2:T20\n",
      "R14\tEVALUATE-FOR Arg1:T19 Arg2:T18\n",
      "R15\tEVALUATE-FOR Arg1:T20 Arg2:T18\n",
      "R16\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R17\tCOREF Arg1:T24 Arg2:T14\n",
      "R18\tUSED-FOR Arg1:T24 Arg2:T23\n",
      "R19\tUSED-FOR Arg1:T23 Arg2:T25\n",
      "R20\tCOMPARE Arg1:T23 Arg2:T26\n",
      "R21\tUSED-FOR Arg1:T26 Arg2:T25\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\INTERSPEECH_2015_9_abs.ann\n",
      "T1\tMaterial 23 32\ttext data\n",
      "T2\tMaterial 50 53\tweb\n",
      "T3\tMethod 65 80\tlanguage models\n",
      "T4\tTask 85 113\tAutomatic Speech Recognition\n",
      "T5\tTask 118 132\tKeyword Search\n",
      "T6\tMaterial 137 159\tLow Resource Languages\n",
      "T7\tGeneric 190 196\tgenres\n",
      "T8\tMaterial 207 212\tblogs\n",
      "T9\tMaterial 214 225\tonline news\n",
      "T10\tMaterial 227 247\ttranslated TED talks\n",
      "T11\tMaterial 253 262\tsubtitles\n",
      "T12\tMethod 270 307\tlinearly interpolated language models\n",
      "T13\tMaterial 322 327\tblogs\n",
      "T14\tMaterial 332 347\tmovie subtitles\n",
      "T15\tMethod 370 422\tlanguage modeling of conversational telephone speech\n",
      "T16\tOtherScientificTerm 454 480\tout-of-vocabulary keywords\n",
      "T17\tMaterial 512 520\tweb data\n",
      "T18\tMetric 533 560\tTerm Error Rate Performance\n",
      "T19\tMetric 582 609\tMaximum Term-Weighted Value\n",
      "T20\tTask 613 627\tKeyword Search\n",
      "T21\tOtherScientificTerm 694 730\treduction of out-of-vocabulary items\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R5\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R6\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R7\tHYPONYM-OF Arg1:T10 Arg2:T7\n",
      "R8\tHYPONYM-OF Arg1:T11 Arg2:T7\n",
      "R9\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R10\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R11\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R13\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R14\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R15\tEVALUATE-FOR Arg1:T19 Arg2:T20\n",
      "R16\tCOREF Arg1:T8 Arg2:T13\n",
      "R17\tCOREF Arg1:T11 Arg2:T14\n",
      "R18\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R19\tUSED-FOR Arg1:T17 Arg2:T20\n",
      "R20\tEVALUATE-FOR Arg1:T18 Arg2:T20\n",
      "R21\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R22\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R23\tUSED-FOR Arg1:T12 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J05-1003.ann\n",
      "T1\tGeneric 24 34\tapproaches\n",
      "T2\tMethod 75 95\tprobabilistic parser\n",
      "T3\tMethod 109 115\tparser\n",
      "T4\tOtherScientificTerm 136 152\tcandidate parses\n",
      "T5\tOtherScientificTerm 238 245\tranking\n",
      "T6\tGeneric 257 263\tparses\n",
      "T7\tGeneric 277 282\tmodel\n",
      "T8\tOtherScientificTerm 328 335\tranking\n",
      "T9\tOtherScientificTerm 357 365\tfeatures\n",
      "T10\tOtherScientificTerm 375 379\ttree\n",
      "T11\tGeneric 414 422\tapproach\n",
      "T12\tGeneric 431 433\tit\n",
      "T13\tOtherScientificTerm 444 448\ttree\n",
      "T14\tOtherScientificTerm 492 500\tfeatures\n",
      "T15\tOtherScientificTerm 538 546\tfeatures\n",
      "T16\tOtherScientificTerm 602 612\tderivation\n",
      "T17\tMethod 620 636\tgenerative model\n",
      "T18\tOtherScientificTerm 657 665\tfeatures\n",
      "T19\tGeneric 701 707\tmethod\n",
      "T20\tTask 717 731\treranking task\n",
      "T21\tMethod 749 766\tboosting approach\n",
      "T22\tTask 772 788\tranking problems\n",
      "T23\tMethod 839 854\tboosting method\n",
      "T24\tTask 860 867\tparsing\n",
      "T25\tMaterial 874 902\tWall Street Journal treebank\n",
      "T26\tGeneric 910 916\tmethod\n",
      "T27\tOtherScientificTerm 931 945\tlog-likelihood\n",
      "T28\tMethod 956 970\tbaseline model\n",
      "T29\tOtherScientificTerm 1039 1047\tfeatures\n",
      "T30\tOtherScientificTerm 1055 1066\tparse trees\n",
      "T31\tGeneric 1108 1113\tmodel\n",
      "T32\tGeneric 1126 1131\tmodel\n",
      "T33\tMetric 1150 1159\tF-measure\n",
      "T34\tMetric 1191 1200\tF-measure\n",
      "T35\tGeneric 1218 1232\tbaseline model\n",
      "T36\tGeneric 1286 1295\talgorithm\n",
      "T37\tMethod 1305 1322\tboosting approach\n",
      "T38\tOtherScientificTerm 1354 1383\tsparsity of the feature space\n",
      "T39\tMaterial 1393 1405\tparsing data\n",
      "T40\tGeneric 1467 1476\talgorithm\n",
      "T41\tMethod 1519 1536\tboosting approach\n",
      "T42\tGeneric 1558 1564\tmethod\n",
      "T43\tMethod 1652 1677\tfeature selection methods\n",
      "T44\tMethod 1687 1722\tlog-linear (maximum-entropy) models\n",
      "T45\tTask 1775 1805\tnatural language parsing (NLP)\n",
      "T46\tTask 1858 1870\tNLP problems\n",
      "T47\tTask 1903 1916\tranking tasks\n",
      "T48\tTask 1934 1952\tspeech recognition\n",
      "T49\tTask 1957 1976\tmachine translation\n",
      "T50\tTask 1984 2011\tnatural language generation\n",
      "R1\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R2\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R3\tEVALUATE-FOR Arg1:T33 Arg2:T32\n",
      "R4\tFEATURE-OF Arg1:T38 Arg2:T39\n",
      "R5\tPART-OF Arg1:T43 Arg2:T44\n",
      "R6\tCOREF Arg1:T3 Arg2:T2\n",
      "R7\tCOREF Arg1:T6 Arg2:T4\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R10\tCOREF Arg1:T12 Arg2:T11\n",
      "R11\tCOREF Arg1:T11 Arg2:T1\n",
      "R12\tCOREF Arg1:T15 Arg2:T14\n",
      "R13\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R14\tUSED-FOR Arg1:T21 Arg2:T19\n",
      "R15\tUSED-FOR Arg1:T23 Arg2:T24\n",
      "R16\tCOREF Arg1:T26 Arg2:T23\n",
      "R17\tCONJUNCTION Arg1:T27 Arg2:T28\n",
      "R18\tPART-OF Arg1:T27 Arg2:T26\n",
      "R19\tCOREF Arg1:T31 Arg2:T28\n",
      "R20\tCOREF Arg1:T32 Arg2:T26\n",
      "R21\tUSED-FOR Arg1:T36 Arg2:T37\n",
      "R22\tUSED-FOR Arg1:T38 Arg2:T36\n",
      "R23\tCOREF Arg1:T40 Arg2:T36\n",
      "R24\tCOMPARE Arg1:T40 Arg2:T41\n",
      "R25\tCOREF Arg1:T42 Arg2:T40\n",
      "R26\tHYPONYM-OF Arg1:T48 Arg2:T46\n",
      "R27\tHYPONYM-OF Arg1:T49 Arg2:T46\n",
      "R28\tHYPONYM-OF Arg1:T50 Arg2:T46\n",
      "R29\tCONJUNCTION Arg1:T48 Arg2:T49\n",
      "R30\tCONJUNCTION Arg1:T49 Arg2:T50\n",
      "R31\tCOREF Arg1:T23 Arg2:T21\n",
      "R32\tCOREF Arg1:T41 Arg2:T37\n",
      "R33\tCOREF Arg1:T5 Arg2:T8\n",
      "R34\tCOREF Arg1:T20 Arg2:T22\n",
      "R35\tCOREF Arg1:T22 Arg2:T47\n",
      "R36\tUSED-FOR Arg1:T25 Arg2:T23\n",
      "R37\tCOREF Arg1:T37 Arg2:T32\n",
      "R38\tCOMPARE Arg1:T35 Arg2:T32\n",
      "R39\tCOREF Arg1:T35 Arg2:T28\n",
      "R40\tUSED-FOR Arg1:T47 Arg2:T46\n",
      "R41\tHYPONYM-OF Arg1:T48 Arg2:T47\n",
      "R42\tHYPONYM-OF Arg1:T49 Arg2:T47\n",
      "R43\tHYPONYM-OF Arg1:T50 Arg2:T47\n",
      "R44\tCOREF Arg1:T33 Arg2:T34\n",
      "R45\tEVALUATE-FOR Arg1:T34 Arg2:T35\n",
      "R46\tFEATURE-OF Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J05-4003.ann\n",
      "T1\tGeneric 21 27\tmethod\n",
      "T2\tTask 33 63\tdiscovering parallel sentences\n",
      "T3\tMaterial 69 101\tcomparable, non-parallel corpora\n",
      "T4\tMethod 117 143\tmaximum entropy classifier\n",
      "T5\tGeneric 269 277\tapproach\n",
      "T6\tMaterial 291 304\tparallel data\n",
      "T7\tMaterial 318 377\tChinese, Arabic, and English non-parallel newspaper corpora\n",
      "T8\tGeneric 445 447\tit\n",
      "T9\tMethod 496 534\tstatistical machine translation system\n",
      "T10\tMethod 572 581\tMT system\n",
      "T11\tMaterial 640 655\tparallel corpus\n",
      "T12\tMaterial 700 719\tnon-parallel corpus\n",
      "T13\tGeneric 733 739\tmethod\n",
      "T14\tMaterial 809 826\tscarce  resources\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tPART-OF Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R5\tCOREF Arg1:T5 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R7\tCOREF Arg1:T10 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R9\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R10\tCOREF Arg1:T5 Arg2:T8\n",
      "R11\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R12\tCOREF Arg1:T5 Arg2:T4\n",
      "R13\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R14\tCOREF Arg1:T8 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J81-1002.ann\n",
      "T1\tGeneric 41 48\tmethods\n",
      "T2\tTask 54 84\tcreating natural language text\n",
      "T3\tGeneric 94 113\tprocessing paradigm\n",
      "T4\tMethod 123 143\tFragment-and-Compose\n",
      "T5\tMethod 382 413\tKDS (Knowledge Delivery System)\n",
      "T6\tGeneric 436 444\tparadigm\n",
      "T7\tMethod 781 810\tFragment-and-Compose paradigm\n",
      "T8\tGeneric 821 842\tcomputational methods\n",
      "T9\tMethod 848 851\tKDS\n",
      "R1\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T4 Arg2:T3\n",
      "R4\tCOREF Arg1:T6 Arg2:T3\n",
      "R5\tCOREF Arg1:T7 Arg2:T6\n",
      "R6\tCOREF Arg1:T9 Arg2:T5\n",
      "R7\tCOREF Arg1:T3 Arg2:T1\n",
      "R8\tPART-OF Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J82-3002.ann\n",
      "T1\tMethod 55 97\tnatural language question answering system\n",
      "T2\tMethod 109 116\tChat-80\n",
      "T3\tMethod 121 128\tChat-80\n",
      "T4\tGeneric 224 230\tsystem\n",
      "T5\tOtherScientificTerm 259 265\tProlog\n",
      "T6\tOtherScientificTerm 272 292\tprogramming language\n",
      "T7\tOtherScientificTerm 304 309\tlogic\n",
      "T8\tMethod 332 361\tlogic-based grammar formalism\n",
      "T9\tMethod 371 393\textraposition grammars\n",
      "T10\tMethod 398 405\tChat-80\n",
      "T11\tOtherScientificTerm 448 472\tProlog   subset of logic\n",
      "T12\tOtherScientificTerm 491 509\tlogical expression\n",
      "T13\tMethod 537 555\tplanning algorithm\n",
      "T14\tOtherScientificTerm 573 579\tProlog\n",
      "T15\tMethod 588 606\tquery optimisation\n",
      "T16\tMaterial 614 633\trelational database\n",
      "T17\tOtherScientificTerm 651 662\tProlog form\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R3\tCOREF Arg1:T3 Arg2:T2\n",
      "R4\tCOREF Arg1:T4 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R6\tHYPONYM-OF Arg1:T5 Arg2:T6\n",
      "R7\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "R8\tCOREF Arg1:T10 Arg2:T4\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R11\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J86-1002.ann\n",
      "T1\tGeneric 5 11\tmethod\n",
      "T2\tTask 17 33\terror correction\n",
      "T3\tMaterial 39 55\till-formed input\n",
      "T4\tOtherScientificTerm 85 102\tdialogue patterns\n",
      "T5\tGeneric 137 145\tpatterns\n",
      "T6\tTask 171 187\tError correction\n",
      "T7\tTask 218 225\tparsing\n",
      "T8\tMethod 340 383\tdialogue acquisition and tracking algorithm\n",
      "T9\tMethod 453 477\tvoice interactive system\n",
      "T10\tMethod 541 569\terror correction methodology\n",
      "T11\tMaterial 577 597\tstereotypic dialogue\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T5 Arg2:T4\n",
      "R5\tCOREF Arg1:T6 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R7\tCOREF Arg1:T10 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J86-3001.ann\n",
      "T1\tMethod 35 64\ttheory of discourse structure\n",
      "T2\tOtherScientificTerm 123 132\tdiscourse\n",
      "T3\tGeneric 144 150\ttheory\n",
      "T4\tOtherScientificTerm 153 172\tdiscourse structure\n",
      "T5\tGeneric 221 231\tcomponents\n",
      "T6\tOtherScientificTerm 292 312\tlinguistic structure\n",
      "T7\tOtherScientificTerm 356 377\tintentional structure\n",
      "T8\tOtherScientificTerm 433 450\tattentional state\n",
      "T9\tOtherScientificTerm 460 480\tlinguistic structure\n",
      "T10\tOtherScientificTerm 511 520\tdiscourse\n",
      "T11\tOtherScientificTerm 576 597\tintentional structure\n",
      "T12\tOtherScientificTerm 613 640\tdiscourse-relevant purposes\n",
      "T13\tOtherScientificTerm 733 750\tattentional state\n",
      "T14\tOtherScientificTerm 828 837\tdiscourse\n",
      "T15\tOtherScientificTerm 853 870\tattentional state\n",
      "T16\tOtherScientificTerm 975 984\tdiscourse\n",
      "T17\tOtherScientificTerm 1084 1103\tdiscourse phenomena\n",
      "T18\tOtherScientificTerm 1109 1120\tcue phrases\n",
      "T19\tOtherScientificTerm 1125 1146\treferring expressions\n",
      "T20\tOtherScientificTerm 1155 1168\tinterruptions\n",
      "T21\tMethod 1177 1238\ttheory of attention, intention, and aggregation of utterances\n",
      "T22\tOtherScientificTerm 1294 1304\tdiscourses\n",
      "T23\tOtherScientificTerm 1331 1340\tdiscourse\n",
      "T24\tOtherScientificTerm 1396 1407\tcue phrases\n",
      "T25\tOtherScientificTerm 1412 1433\treferring expressions\n",
      "T26\tOtherScientificTerm 1442 1455\tinterruptions\n",
      "T27\tGeneric 1477 1483\ttheory\n",
      "T28\tOtherScientificTerm 1558 1567\tdiscourse\n",
      "T29\tMethod 1572 1592\tDiscourse processing\n",
      "T30\tOtherScientificTerm 1644 1653\tdiscourse\n",
      "T31\tOtherScientificTerm 1730 1739\tdiscourse\n",
      "T32\tOtherScientificTerm 1802 1811\tdiscourse\n",
      "T33\tOtherScientificTerm 1870 1887\tattentional state\n",
      "T34\tGeneric 1896 1906\tprocessing\n",
      "T35\tTask 1939 1956\trecognition tasks\n",
      "T36\tOtherScientificTerm 1992 2001\tdiscourse\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R2\tPART-OF Arg1:T5 Arg2:T4\n",
      "R3\tPART-OF Arg1:T6 Arg2:T5\n",
      "R4\tPART-OF Arg1:T7 Arg2:T5\n",
      "R5\tPART-OF Arg1:T8 Arg2:T5\n",
      "R6\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R7\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R8\tCOREF Arg1:T9 Arg2:T6\n",
      "R9\tCOREF Arg1:T11 Arg2:T7\n",
      "R10\tCOREF Arg1:T13 Arg2:T8\n",
      "R11\tCOREF Arg1:T15 Arg2:T13\n",
      "R12\tHYPONYM-OF Arg1:T18 Arg2:T17\n",
      "R13\tHYPONYM-OF Arg1:T19 Arg2:T17\n",
      "R14\tHYPONYM-OF Arg1:T20 Arg2:T17\n",
      "R15\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R16\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R17\tCOREF Arg1:T27 Arg2:T21\n",
      "R18\tCOREF Arg1:T34 Arg2:T29\n",
      "R19\tCOREF Arg1:T3 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J86-4002.ann\n",
      "T1\tTask 47 73\thuman-machine interactions\n",
      "T2\tOtherScientificTerm 81 109\tnatural language environment\n",
      "T3\tOtherScientificTerm 484 502\treference failures\n",
      "T4\tOtherScientificTerm 534 553\tspeaker's intention\n",
      "T5\tTask 590 606\tmiscommunication\n",
      "T6\tTask 720 737\tmiscommunications\n",
      "T7\tGeneric 754 758\tthem\n",
      "T8\tTask 805 821\tmiscommunication\n",
      "T9\tTask 828 846\treference problems\n",
      "T10\tGeneric 883 893\ttechniques\n",
      "T11\tTask 908 929\tfailures of reference\n",
      "T12\tTask 1173 1194\textensional reference\n",
      "R1\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T7 Arg2:T6\n",
      "R3\tCOREF Arg1:T6 Arg2:T5\n",
      "R4\tCOREF Arg1:T8 Arg2:T6\n",
      "R5\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J87-1003.ann\n",
      "T1\tMaterial 2 9\tEnglish\n",
      "T2\tOtherScientificTerm 62 75\tcoordinations\n",
      "T3\tOtherScientificTerm 116 157\tstrictly syntactic cross-serial agreement\n",
      "T4\tGeneric 165 174\tagreement\n",
      "T5\tOtherScientificTerm 210 215\tnouns\n",
      "T6\tOtherScientificTerm 222 240\treflexive pronouns\n",
      "T7\tOtherScientificTerm 299 317\tgrammatical number\n",
      "T8\tMaterial 323 330\tEnglish\n",
      "T9\tOtherScientificTerm 339 357\tgrammatical gender\n",
      "T10\tMaterial 363 372\tlanguages\n",
      "T11\tMaterial 383 389\tFrench\n",
      "T12\tMethod 463 480\tInterchange Lemma\n",
      "T13\tMaterial 541 548\tEnglish\n",
      "R1\tCOREF Arg1:T4 Arg2:T3\n",
      "R2\tHYPONYM-OF Arg1:T11 Arg2:T10\n",
      "R3\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R4\tFEATURE-OF Arg1:T9 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J87-3001.ann\n",
      "T1\tOtherScientificTerm 23 56\tdictionary word sense definitions\n",
      "T2\tMethod 88 118\thierarchy of  phrasal patterns\n",
      "T3\tGeneric 137 143\tsystem\n",
      "T4\tGeneric 159 168\tmechanism\n",
      "T5\tMaterial 229 271\tLongman Dictionary of Contemporary English\n",
      "T6\tGeneric 294 304\tdictionary\n",
      "T7\tGeneric 324 330\tsystem\n",
      "T8\tGeneric 340 342\tit\n",
      "T9\tOtherScientificTerm 351 372\trestricted vocabulary\n",
      "T10\tOtherScientificTerm 382 404\tword sense definitions\n",
      "T11\tTask 492 527\tclassification  of new  word senses\n",
      "T12\tOtherScientificTerm 573 594\trestricted vocabulary\n",
      "T13\tOtherScientificTerm 803 825\tphrasal analysis rules\n",
      "T14\tTask 1155 1174\trobustness problems\n",
      "T15\tMethod 1207 1242\tnatural language processing systems\n",
      "T16\tMaterial 1260 1279\tincomplete  lexicon\n",
      "T17\tOtherScientificTerm 1290 1338\tincomplete  knowledge  of  phrasal constructions\n",
      "R1\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R2\tFEATURE-OF Arg1:T14 Arg2:T15\n",
      "R3\tCOREF Arg1:T6 Arg2:T5\n",
      "R4\tCOREF Arg1:T7 Arg2:T3\n",
      "R5\tCOREF Arg1:T6 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R7\tCOREF Arg1:T12 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R9\tCOREF Arg1:T4 Arg2:T2\n",
      "R10\tPART-OF Arg1:T4 Arg2:T3\n",
      "R11\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R12\tHYPONYM-OF Arg1:T16 Arg2:T14\n",
      "R13\tHYPONYM-OF Arg1:T17 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J88-3002.ann\n",
      "T1\tMethod 8 39\tintelligent interactive systems\n",
      "T2\tGeneric 91 95\tthey\n",
      "T3\tTask 176 189\tuser modeling\n",
      "T4\tMethod 200 207\tsystems\n",
      "T5\tMethod 256 266\tuser model\n",
      "T6\tGeneric 279 281\tit\n",
      "T7\tMethod 328 338\tuser model\n",
      "T8\tMethod 415 426\tUser models\n",
      "T9\tGeneric 561 565\tthey\n",
      "T10\tMethod 636 646\tuser model\n",
      "T11\tTask 677 690\tuser modeling\n",
      "T12\tMethod 778 801\tuser modeling component\n",
      "T13\tGeneric 809 815\tsystem\n",
      "T14\tGeneric 917 923\tsystem\n",
      "T15\tTask 968 981\tuser modeling\n",
      "T16\tMethod 1087 1108\tuser modeling systems\n",
      "R1\tPART-OF Arg1:T3 Arg2:T4\n",
      "R2\tCOREF Arg1:T2 Arg2:T1\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tCOREF Arg1:T7 Arg2:T5\n",
      "R5\tCOREF Arg1:T8 Arg2:T7\n",
      "R6\tCOREF Arg1:T9 Arg2:T8\n",
      "R7\tCOREF Arg1:T10 Arg2:T9\n",
      "R8\tCOREF Arg1:T14 Arg2:T13\n",
      "R9\tPART-OF Arg1:T12 Arg2:T13\n",
      "R10\tCOREF Arg1:T6 Arg2:T5\n",
      "R11\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R12\tCOREF Arg1:T11 Arg2:T3\n",
      "R13\tCOREF Arg1:T15 Arg2:T11\n",
      "R14\tCOREF Arg1:T16 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J89-4003.ann\n",
      "T1\tGeneric 4 9\tmodel\n",
      "T2\tOtherScientificTerm 45 63\tclass of languages\n",
      "T3\tOtherScientificTerm 85 98\treduplication\n",
      "T4\tMaterial 104 126\tcontext-free languages\n",
      "T5\tMethod 134 139\tmodel\n",
      "T6\tMethod 147 165\tpushdown automaton\n",
      "T7\tOtherScientificTerm 204 217\treduplication\n",
      "T8\tOtherScientificTerm 233 238\tstack\n",
      "T9\tOtherScientificTerm 259 277\tclass of languages\n",
      "T10\tMaterial 327 349\tcontext-free languages\n",
      "T11\tMaterial 360 377\tindexed languages\n",
      "T12\tGeneric 385 390\tmodel\n",
      "T13\tOtherScientificTerm 438 452\treduplications\n",
      "T14\tMaterial 491 508\tnatural languages\n",
      "T15\tGeneric 515 517\tit\n",
      "T16\tMethod 577 590\tformal models\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R3\tCOREF Arg1:T5 Arg2:T1\n",
      "R4\tHYPONYM-OF Arg1:T5 Arg2:T6\n",
      "R5\tCOREF Arg1:T9 Arg2:T2\n",
      "R6\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R7\tCOREF Arg1:T12 Arg2:T5\n",
      "R8\tCOREF Arg1:T15 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R10\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R11\tCOREF Arg1:T4 Arg2:T10\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J90-3002.ann\n",
      "T1\tMethod 38 44\teditor\n",
      "T2\tMaterial 59 81\tstructured  dictionary\n",
      "T3\tMethod 118 124\teditor\n",
      "T4\tGeneric 212 222\tdictionary\n",
      "T5\tMethod 243 260\tlinguistic theory\n",
      "T6\tTask 330 357\tnatural language processing\n",
      "T7\tMaterial 453 473\tlinguistic databases\n",
      "T8\tMethod 518 524\teditor\n",
      "T9\tOtherScientificTerm 550 565\tcoherence rules\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R3\tCOREF Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R5\tCOREF Arg1:T7 Arg2:T4\n",
      "R6\tCOREF Arg1:T8 Arg2:T3\n",
      "R7\tCOREF Arg1:T2 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\J97-1004.ann\n",
      "T1\tMethod 36 54\texplanation system\n",
      "T2\tOtherScientificTerm 183 214\tmultisentential discourse plans\n",
      "T3\tOtherScientificTerm 234 249\tdiscourse plans\n",
      "T4\tTask 499 521\texplanation generation\n",
      "T5\tMaterial 529 575\tsemantically rich, large-scale knowledge bases\n",
      "T6\tMethod 609 634\trobust explanation system\n",
      "T7\tOtherScientificTerm 653 701\tmultisentential and multi-paragraph explanations\n",
      "T8\tMaterial 715 741\tlarge-scale knowledge base\n",
      "T9\tMaterial 760 777\tbotanical anatomy\n",
      "T10\tMaterial 779 789\tphysiology\n",
      "T11\tMaterial 795 806\tdevelopment\n",
      "T12\tGeneric 825 847\tevaluation methodology\n",
      "T13\tGeneric 900 911\tmethodology\n",
      "T14\tMethod 971 989\texplanation system\n",
      "T15\tGeneric 999 1009\tevaluation\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R4\tCOREF Arg1:T6 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R7\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T13 Arg2:T12\n",
      "R9\tCOREF Arg1:T14 Arg2:T6\n",
      "R10\tEVALUATE-FOR Arg1:T13 Arg2:T14\n",
      "R11\tCOREF Arg1:T15 Arg2:T13\n",
      "R12\tCOREF Arg1:T6 Arg2:T1\n",
      "R13\tFEATURE-OF Arg1:T9 Arg2:T8\n",
      "R14\tFEATURE-OF Arg1:T10 Arg2:T8\n",
      "R15\tFEATURE-OF Arg1:T11 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\L08-1050.ann\n",
      "T1\tMaterial 69 104\tlanguage corpus annotation scenario\n",
      "T2\tOtherScientificTerm 121 140\tdiscourse relations\n",
      "T3\tMaterial 146 151\tCzech\n",
      "T4\tOtherScientificTerm 200 248\tsyntactically motivated relations  in  discourse\n",
      "T5\tMaterial 309 339\tPrague Dependency Treebank 2.0\n",
      "T6\tMaterial 350 375\tPenn Discourse Treebank 2\n",
      "T7\tOtherScientificTerm 417 466\tsyntactico-semantic (tectogrammatical) annotation\n",
      "T8\tMaterial 476 502\tPrague Dependency Treebank\n",
      "T9\tGeneric 512 514\tit\n",
      "T10\tTask 538 579\tsentence-boundary-crossing representation\n",
      "T11\tTask 614 645\tdiscourse level  of  annotation\n",
      "T12\tMethod 746 780\tPraguian dependency-based approach\n",
      "T13\tMethod 799 824\tPenn discourse annotation\n",
      "T14\tMethod 849 902\tanalysis and classification of  discourse connectives\n",
      "R1\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R2\tCOREF Arg1:T7 Arg2:T9\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R6\tPART-OF Arg1:T7 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R8\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R9\tCOMPARE Arg1:T13 Arg2:T12\n",
      "R10\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R11\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R12\tEVALUATE-FOR Arg1:T14 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\L08-1097.ann\n",
      "T1\tTask 44 140\tunsupervised automatic acquisition  of  Italian and English verb subcategorization frames (SCFs)\n",
      "T2\tOtherScientificTerm 84 140\tItalian and English verb subcategorization frames (SCFs)\n",
      "T3\tMaterial 148 174\tgeneral and domain corpora\n",
      "T4\tGeneric 190 199\ttechnique\n",
      "T5\tMaterial 213 249\tsyntactically shallow-parsed corpora\n",
      "T6\tMethod 288 305\tsearch heuristics\n",
      "T7\tOtherScientificTerm 336 362\tlexico-syntactic knowledge\n",
      "T8\tOtherScientificTerm 371 375\tSCFs\n",
      "T9\tMethod 452 479\tlexical acquisition systems\n",
      "T10\tOtherScientificTerm 528 546\tSCFs distributions\n",
      "T11\tOtherScientificTerm 565 592\tsimilar semantic properties\n",
      "T12\tMethod 702 744\tMinimum Description Length Principle (MDL)\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R3\tCOREF Arg1:T8 Arg2:T2\n",
      "R4\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\L08-1110.ann\n",
      "T1\tMethod 46 68\tstatistical techniques\n",
      "T2\tTask 74 81\tranking\n",
      "T3\tOtherScientificTerm 126 159\tgraph  of  translation hypotheses\n",
      "T4\tOtherScientificTerm 222 238\thypotheses graph\n",
      "T5\tMethod 262 277\tshallow mapping\n",
      "T6\tMethod 284 301\tpermutation rules\n",
      "T7\tOtherScientificTerm 335 340\tnodes\n",
      "T8\tOtherScientificTerm 357 405\tvectors representing morpho-syntactic properties\n",
      "T9\tGeneric 466 473\tmethods\n",
      "T10\tOtherScientificTerm 491 520\tstatistical feature functions\n",
      "T11\tMethod 540 557\tvector components\n",
      "T12\tOtherScientificTerm 565 582\tfeature functions\n",
      "T13\tOtherScientificTerm 645 667\tlog-linear combination\n",
      "T14\tOtherScientificTerm 706 723\ttranslation paths\n",
      "T15\tOtherScientificTerm 733 738\tgraph\n",
      "T16\tMethod 757 784\tlanguage modelling toolkits\n",
      "T17\tMethod 792 817\tCMU  and the  SRI toolkit\n",
      "T18\tMethod 852 892\tword-lemma based feature function models\n",
      "T19\tMethod 923 941\ttoken-based models\n",
      "T20\tOtherScientificTerm 957 981\tPoS-tag feature function\n",
      "T21\tMethod 991 1007\tword-lemma model\n",
      "T22\tTask 1051 1071\tlexical translations\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R2\tCOMPARE Arg1:T18 Arg2:T19\n",
      "R3\tPART-OF Arg1:T20 Arg2:T21\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R6\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R7\tCOREF Arg1:T12 Arg2:T10\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R10\tCOREF Arg1:T21 Arg2:T18\n",
      "R11\tCOREF Arg1:T4 Arg2:T15\n",
      "R12\tCOREF Arg1:T4 Arg2:T3\n",
      "R13\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R14\tPART-OF Arg1:T14 Arg2:T15\n",
      "R15\tHYPONYM-OF Arg1:T17 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\L08-1154.ann\n",
      "T1\tOtherScientificTerm 63 98\tinternal and contextual information\n",
      "T2\tOtherScientificTerm 117 138\tdomain specific terms\n",
      "T3\tOtherScientificTerm 192 200\tfeatures\n",
      "T4\tOtherScientificTerm 271 279\tfeatures\n",
      "T5\tGeneric 359 367\tapproach\n",
      "T6\tTask 373 388\tterm extraction\n",
      "T7\tOtherScientificTerm 400 410\tdelimiters\n",
      "T8\tGeneric 476 484\tapproach\n",
      "T9\tOtherScientificTerm 509 523\tterm frequency\n",
      "T10\tGeneric 557 565\tapproach\n",
      "T11\tOtherScientificTerm 590 600\thard rules\n",
      "T12\tOtherScientificTerm 679 695\tdomain knowledge\n",
      "T13\tGeneric 780 788\tapproach\n",
      "T14\tGeneric 838 840\tit\n",
      "T15\tMaterial 867 891\tresource-limited domains\n",
      "T16\tGeneric 894 905\tEvaluations\n",
      "T17\tTask 948 971\tChinese term extraction\n",
      "T18\tTask 1105 1124\tnew term extraction\n",
      "T19\tGeneric 1153 1161\tapproach\n",
      "T20\tGeneric 1193 1197\ttool\n",
      "T21\tTask 1203 1227\tdomain lexicon expansion\n",
      "R1\tFEATURE-OF Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R4\tCOREF Arg1:T8 Arg2:T5\n",
      "R5\tCOMPARE Arg1:T8 Arg2:T9\n",
      "R6\tCOREF Arg1:T10 Arg2:T8\n",
      "R7\tCOREF Arg1:T13 Arg2:T10\n",
      "R8\tCOREF Arg1:T13 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R10\tEVALUATE-FOR Arg1:T16 Arg2:T17\n",
      "R11\tCOREF Arg1:T19 Arg2:T13\n",
      "R12\tUSED-FOR Arg1:T19 Arg2:T21\n",
      "R13\tCOREF Arg1:T20 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\L08-1260.ann\n",
      "T1\tMethod 88 124\tlexicon grammar for Polish (SyntLex)\n",
      "T2\tTask 156 244\tcomputer-assisted acquisition and morpho-syntactic description of verb-noun collocations\n",
      "T3\tMaterial 250 256\tPolish\n",
      "T4\tGeneric 327 333\tphases\n",
      "T5\tTask 346 399\tdictionary-based acquisition  of  collocation lexicon\n",
      "T6\tTask 402 419\tfeasibility study\n",
      "T7\tTask 425 464\tcorpus-based lexicon enlargement  phase\n",
      "T8\tTask 467 529\tcorpus-based lexicon enlargement  and  collocation description\n",
      "T9\tMethod 610 631\tcorpus-based approach\n",
      "T10\tMaterial 670 702\tverb-noun collocation dictionary\n",
      "T11\tMaterial 707 713\tPolish\n",
      "T12\tMaterial 746 780\tSyntLex Dictionary of Collocations\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T5 Arg2:T4\n",
      "R3\tHYPONYM-OF Arg1:T8 Arg2:T4\n",
      "R4\tFEATURE-OF Arg1:T11 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R7\tHYPONYM-OF Arg1:T6 Arg2:T4\n",
      "R8\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R9\tCONJUNCTION Arg1:T8 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\L08-1540.ann\n",
      "T1\tMaterial 50 74\tlarge Czech MWE database\n",
      "T2\tOtherScientificTerm 110 114\tMWEs\n",
      "T3\tOtherScientificTerm 129 142\tlexical units\n",
      "T4\tGeneric 146 148\tIt\n",
      "T5\tMaterial 194 207\tencyclopedias\n",
      "T6\tMaterial 214 226\tdictionaries\n",
      "T7\tMaterial 229 279\tpublic  databases  of  proper names  and  toponyms\n",
      "T8\tGeneric 283 295\tcollocations\n",
      "T9\tMaterial 312 325\tCzech WordNet\n",
      "T10\tMaterial 328 368\tlists of  botanical and zoological terms\n",
      "T11\tGeneric 416 424\tdatabase\n",
      "T12\tOtherScientificTerm 451 455\tMWEs\n",
      "T13\tMaterial 516 529\tMWEs database\n",
      "T14\tMaterial 560 581\tCzech National Corpus\n",
      "T15\tOtherScientificTerm 669 673\tMWEs\n",
      "T16\tGeneric 708 714\tcorpus\n",
      "T17\tOtherScientificTerm 797 801\tMWEs\n",
      "T18\tGeneric 824 833\ttechnique\n",
      "T19\tTask 850 868\tWord Sketch Engine\n",
      "T20\tOtherScientificTerm 901 923\tstatistical parameters\n",
      "T21\tOtherScientificTerm 947 951\tMWEs\n",
      "T22\tOtherScientificTerm 1020 1024\tMWEs\n",
      "T23\tGeneric 1064 1072\tdatabase\n",
      "T24\tTask 1107 1114\ttagging\n",
      "T25\tTask 1121 1134\tlemmatization\n",
      "T26\tOtherScientificTerm 1180 1184\tMWEs\n",
      "T27\tGeneric 1217 1221\tthem\n",
      "T28\tOtherScientificTerm 1235 1248\tlexical units\n",
      "T29\tTask 1266 1273\ttagging\n",
      "T30\tTask 1280 1293\tlemmatization\n",
      "R1\tCOREF Arg1:T9 Arg2:T8\n",
      "R2\tFEATURE-OF Arg1:T20 Arg2:T19\n",
      "R3\tUSED-FOR Arg1:T23 Arg2:T24\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T4\n",
      "R8\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R9\tCOREF Arg1:T11 Arg2:T4\n",
      "R10\tCOREF Arg1:T13 Arg2:T11\n",
      "R11\tCOREF Arg1:T16 Arg2:T14\n",
      "R12\tCOREF Arg1:T17 Arg2:T15\n",
      "R13\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R14\tCOREF Arg1:T22 Arg2:T21\n",
      "R15\tCONJUNCTION Arg1:T24 Arg2:T25\n",
      "R16\tUSED-FOR Arg1:T23 Arg2:T25\n",
      "R17\tCOREF Arg1:T27 Arg2:T26\n",
      "R18\tCOREF Arg1:T15 Arg2:T12\n",
      "R19\tCOREF Arg1:T23 Arg2:T13\n",
      "R20\tUSED-FOR Arg1:T26 Arg2:T29\n",
      "R21\tUSED-FOR Arg1:T26 Arg2:T30\n",
      "R22\tCONJUNCTION Arg1:T29 Arg2:T30\n",
      "R23\tUSED-FOR Arg1:T7 Arg2:T4\n",
      "R24\tUSED-FOR Arg1:T10 Arg2:T4\n",
      "R25\tCONJUNCTION Arg1:T10 Arg2:T8\n",
      "R26\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R27\tCOREF Arg1:T29 Arg2:T24\n",
      "R28\tCOREF Arg1:T30 Arg2:T25\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\M91-1029.ann\n",
      "T1\tMethod 6 69\tPRC Adaptive Knowledge-based Text Understanding System (PAKTUS)\n",
      "T2\tGeneric 195 201\tsystem\n",
      "T3\tOtherScientificTerm 225 245\tcore English lexicon\n",
      "T4\tMethod 249 256\tgrammar\n",
      "T5\tMethod 263 286\tconcept representations\n",
      "T6\tMethod 302 343\tnatural language processing (NLP) systems\n",
      "T7\tTask 350 368\ttext understanding\n",
      "T8\tMethod 391 397\tPAKTUS\n",
      "T9\tTask 433 456\tknowledge based systems\n",
      "T10\tMethod 492 502\tNLP system\n",
      "T11\tMaterial 543 568\telectronic message stream\n",
      "T12\tMaterial 581 590\tnews wire\n",
      "T13\tMethod 593 599\tPAKTUS\n",
      "T14\tMaterial 671 688\tJINTACCS messages\n",
      "T15\tMaterial 692 709\tRAINFORM messages\n",
      "T16\tOtherScientificTerm 713 725\tnews reports\n",
      "T17\tOtherScientificTerm 752 757\tevent\n",
      "T18\tMaterial 767 786\tfinancial transfers\n",
      "T19\tMaterial 790 804\tterrorist acts\n",
      "T20\tMethod 826 865\tsublanguage and domain-specific grammar\n",
      "T21\tGeneric 869 874\twords\n",
      "T22\tOtherScientificTerm 876 895\tconceptual mappings\n",
      "T23\tOtherScientificTerm 903 921\tdiscourse patterns\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R3\tCOREF Arg1:T2 Arg2:T1\n",
      "R4\tPART-OF Arg1:T3 Arg2:T2\n",
      "R5\tPART-OF Arg1:T4 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T2 Arg2:T6\n",
      "R7\tPART-OF Arg1:T5 Arg2:T2\n",
      "R8\tCOREF Arg1:T8 Arg2:T2\n",
      "R9\tCOREF Arg1:T10 Arg2:T6\n",
      "R10\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R11\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R12\tCOREF Arg1:T13 Arg2:T8\n",
      "R13\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R14\tUSED-FOR Arg1:T13 Arg2:T16\n",
      "R15\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R16\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R17\tHYPONYM-OF Arg1:T18 Arg2:T17\n",
      "R18\tHYPONYM-OF Arg1:T19 Arg2:T17\n",
      "R19\tUSED-FOR Arg1:T20 Arg2:T13\n",
      "R20\tUSED-FOR Arg1:T23 Arg2:T13\n",
      "R21\tUSED-FOR Arg1:T21 Arg2:T13\n",
      "R22\tUSED-FOR Arg1:T22 Arg2:T13\n",
      "R23\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R24\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "R25\tCONJUNCTION Arg1:T22 Arg2:T23\n",
      "R26\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R27\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R28\tFEATURE-OF Arg1:T17 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N01-1003.ann\n",
      "T1\tTask 2 19\tSentence planning\n",
      "T2\tGeneric 60 65\ttasks\n",
      "T3\tTask 84 100\tsentence scoping\n",
      "T4\tOtherScientificTerm 124 143\tsyntactic structure\n",
      "T5\tOtherScientificTerm 161 172\tspeech acts\n",
      "T6\tMethod 272 276\tSPoT\n",
      "T7\tMethod 283 299\tsentence planner\n",
      "T8\tGeneric 313 324\tmethodology\n",
      "T9\tMethod 353 357\tSPoT\n",
      "T10\tMethod 492 532\trandomized sentence-plan-generator (SPG)\n",
      "T11\tOtherScientificTerm 582 596\tsentence plans\n",
      "T12\tOtherScientificTerm 611 626\ttext-plan input\n",
      "T13\tMethod 643 669\tsentence-plan-ranker (SPR)\n",
      "T14\tOtherScientificTerm 697 711\tsentence plans\n",
      "T15\tMethod 761 764\tSPR\n",
      "T16\tOtherScientificTerm 772 785\tranking rules\n",
      "T17\tMethod 858 861\tSPR\n",
      "T18\tOtherScientificTerm 883 896\tsentence plan\n",
      "T19\tOtherScientificTerm 949 979\ttop human-ranked sentence plan\n",
      "R1\tCOMPARE Arg1:T18 Arg2:T19\n",
      "R2\tCOREF Arg1:T2 Arg2:T1\n",
      "R3\tPART-OF Arg1:T3 Arg2:T2\n",
      "R4\tHYPONYM-OF Arg1:T6 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R6\tCOREF Arg1:T9 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R10\tCOREF Arg1:T14 Arg2:T11\n",
      "R11\tCOREF Arg1:T15 Arg2:T13\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R13\tCOREF Arg1:T17 Arg2:T15\n",
      "R14\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R15\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-1001.ann\n",
      "T1\tGeneric 24 30\tmethod\n",
      "T2\tTask 36 60\tutterance classification\n",
      "T3\tMaterial 85 105\tmanual transcription\n",
      "T4\tGeneric 132 138\tmethod\n",
      "T5\tMethod 149 183\tdomain independent acoustic models\n",
      "T6\tMethod 205 216\tclassifiers\n",
      "T7\tTask 227 251\tutterance classification\n",
      "T8\tMethod 336 360\tword-trigram recognition\n",
      "T9\tMaterial 373 393\tmanual transcription\n",
      "T10\tGeneric 404 410\tmethod\n",
      "T11\tMethod 413 434\tunsupervised training\n",
      "T12\tMethod 462 480\tphone n-gram model\n",
      "T13\tGeneric 500 506\tdomain\n",
      "T14\tGeneric 551 556\tmodel\n",
      "T15\tMethod 579 602\tphone-string classifier\n",
      "T16\tMetric 611 634\tclassification accuracy\n",
      "T17\tGeneric 643 649\tmethod\n",
      "T18\tMaterial 683 713\tspoken language system domains\n",
      "R1\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tPART-OF Arg1:T5 Arg2:T4\n",
      "R6\tCONJUNCTION Arg1:T6 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T4\n",
      "R8\tCOREF Arg1:T10 Arg2:T4\n",
      "R9\tPART-OF Arg1:T11 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R11\tCOREF Arg1:T14 Arg2:T12\n",
      "R12\tCOREF Arg1:T17 Arg2:T10\n",
      "R13\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R14\tEVALUATE-FOR Arg1:T16 Arg2:T17\n",
      "R15\tUSED-FOR Arg1:T4 Arg2:T7\n",
      "R16\tCOREF Arg1:T7 Arg2:T2\n",
      "R17\tPART-OF Arg1:T6 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-1004.ann\n",
      "T1\tMethod 30 46\tensemble methods\n",
      "T2\tTask 52 68\tmachine learning\n",
      "T3\tTask 90 117\tnatural language processing\n",
      "T4\tMethod 137 177\tmulti-strategy and multi-source approach\n",
      "T5\tTask 181 199\tquestion answering\n",
      "T6\tMethod 257 273\tanswering agents\n",
      "T7\tMethod 328 344\tanswering agents\n",
      "T8\tGeneric 376 386\tstrategies\n",
      "T9\tGeneric 388 391\tone\n",
      "T10\tMethod 413 439\tknowledge-based mechanisms\n",
      "T11\tGeneric 449 454\tother\n",
      "T12\tMethod 465 487\tstatistical techniques\n",
      "T13\tMethod 507 546\tmulti-level answer resolution algorithm\n",
      "T14\tMethod 580 596\tanswering agents\n",
      "T15\tOtherScientificTerm 606 645\tquestion, passage, and/or answer levels\n",
      "T16\tMethod 698 725\tanswer resolution algorithm\n",
      "T17\tGeneric 771 786\tbaseline system\n",
      "T18\tMetric 880 904\taverage precision metric\n",
      "R1\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R4\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "R5\tHYPONYM-OF Arg1:T11 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R10\tCOREF Arg1:T16 Arg2:T13\n",
      "R11\tEVALUATE-FOR Arg1:T18 Arg2:T16\n",
      "R12\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R13\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R14\tCOREF Arg1:T7 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-1012.ann\n",
      "T1\tMethod 27 36\tONTOSCORE\n",
      "T2\tGeneric 42 48\tsystem\n",
      "T3\tOtherScientificTerm 100 108\tontology\n",
      "T4\tGeneric 125 131\tsystem\n",
      "T5\tOtherScientificTerm 170 205\tspeech recognition hypotheses (SRH)\n",
      "T6\tOtherScientificTerm 226 244\tsemantic coherence\n",
      "T7\tOtherScientificTerm 396 425\tspeech recognition hypotheses\n",
      "T8\tGeneric 450 456\tsystem\n",
      "T9\tGeneric 498 500\tit\n",
      "T10\tMaterial 537 550\tGerman corpus\n",
      "T11\tOtherScientificTerm 562 566\tSRHs\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tCOREF Arg1:T4 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tCOREF Arg1:T8 Arg2:T4\n",
      "R6\tCOREF Arg1:T8 Arg2:T9\n",
      "R7\tCOREF Arg1:T9 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-1017.ann\n",
      "T1\tMethod 19 49\tphrase-based translation model\n",
      "T2\tMethod 56 74\tdecoding algorithm\n",
      "T3\tMethod 146 177\tphrase-based translation models\n",
      "T4\tGeneric 192 201\tframework\n",
      "T5\tMethod 284 303\tphrase-based models\n",
      "T6\tMethod 317 334\tword-based models\n",
      "T7\tGeneric 497 502\tmeans\n",
      "T8\tMethod 505 548\theuristic learning  of  phrase translations\n",
      "T9\tMethod 556 577\tword-based alignments\n",
      "T10\tMethod 584 626\tlexical weighting  of  phrase translations\n",
      "T11\tMethod 718 759\thigh-accuracy word-level alignment models\n",
      "T12\tGeneric 887 894\tsystems\n",
      "R1\tCOMPARE Arg1:T5 Arg2:T6\n",
      "R2\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T5 Arg2:T3\n",
      "R4\tCOREF Arg1:T12 Arg2:T1\n",
      "R5\tCOREF Arg1:T4 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R7\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R8\tHYPONYM-OF Arg1:T10 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-1018.ann\n",
      "T1\tMethod 32 98\tgenerative probabilistic optical character recognition (OCR) model\n",
      "T2\tMethod 145 168\tnoisy channel framework\n",
      "T3\tOtherScientificTerm 273 283\tOCR system\n",
      "T4\tGeneric 292 297\tmodel\n",
      "T5\tTask 323 339\terror correction\n",
      "T6\tTask 360 375\tpost-processing\n",
      "T7\tOtherScientificTerm 382 415\toutput  of black-box  OCR systems\n",
      "T8\tOtherScientificTerm 404 415\tOCR systems\n",
      "T9\tGeneric 434 436\tit\n",
      "T10\tTask 454 463\tNLP tasks\n",
      "T11\tGeneric 504 509\tmodel\n",
      "T12\tMethod 521 540\tfinite-state models\n",
      "T13\tGeneric 561 566\tmodel\n",
      "T14\tMetric 604 633\tcharacter and word error rate\n",
      "T15\tTask 679 725\tautomatic extraction  of  translation lexicons\n",
      "T16\tMaterial 733 745\tprinted text\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R3\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R6\tPART-OF Arg1:T6 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R8\tCOREF Arg1:T11 Arg2:T4\n",
      "R9\tCOREF Arg1:T7 Arg2:T9\n",
      "R10\tCOREF Arg1:T3 Arg2:T8\n",
      "R11\tCOREF Arg1:T13 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R13\tEVALUATE-FOR Arg1:T15 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-1026.ann\n",
      "T1\tMethod 31 89\tambiguity packing and stochastic disambiguation techniques\n",
      "T2\tMethod 96 129\tLexical-Functional Grammars (LFG)\n",
      "T3\tTask 149 170\tsentence condensation\n",
      "T4\tGeneric 178 184\tsystem\n",
      "T5\tMethod 201 228\tlinguistic parser/generator\n",
      "T6\tMethod 235 238\tLFG\n",
      "T7\tMethod 245 263\ttransfer component\n",
      "T8\tTask 270 285\tparse reduction\n",
      "T9\tOtherScientificTerm 301 321\tpacked parse forests\n",
      "T10\tMethod 332 353\tmaximum-entropy model\n",
      "T11\tTask 360 387\tstochastic output selection\n",
      "T12\tMethod 436 461\tparser evaluation methods\n",
      "T13\tMetric 497 519\tsummarization  quality\n",
      "T14\tMethod 524 553\tsentence condensation systems\n",
      "T15\tMetric 590 612\tsummarization  quality\n",
      "T16\tMethod 652 684\tautomatic parse-based evaluation\n",
      "T17\tMethod 693 710\tmanual evaluation\n",
      "T18\tMetric 746 768\tsummarization  quality\n",
      "T19\tGeneric 785 791\tsystem\n",
      "T20\tMetric 830 844\tgrammaticality\n",
      "T21\tMethod 890 923\tconstraint-based parser/generator\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R6\tPART-OF Arg1:T5 Arg2:T4\n",
      "R7\tPART-OF Arg1:T7 Arg2:T4\n",
      "R8\tCONJUNCTION Arg1:T5 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R10\tCONJUNCTION Arg1:T7 Arg2:T10\n",
      "R11\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R12\tCOREF Arg1:T19 Arg2:T14\n",
      "R13\tUSED-FOR Arg1:T21 Arg2:T19\n",
      "R14\tCOREF Arg1:T12 Arg2:T16\n",
      "R15\tCOREF Arg1:T14 Arg2:T4\n",
      "R16\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "R17\tCOREF Arg1:T4 Arg2:T1\n",
      "R18\tCOREF Arg1:T15 Arg2:T18\n",
      "R19\tEVALUATE-FOR Arg1:T13 Arg2:T14\n",
      "R20\tEVALUATE-FOR Arg1:T12 Arg2:T13\n",
      "R21\tCOREF Arg1:T15 Arg2:T13\n",
      "R22\tCOREF Arg1:T15 Arg2:T13\n",
      "R23\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R24\tEVALUATE-FOR Arg1:T20 Arg2:T19\n",
      "R25\tCOREF Arg1:T2 Arg2:T6\n",
      "R26\tPART-OF Arg1:T10 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-1033.ann\n",
      "T1\tMethod 19 40\tpart-of-speech tagger\n",
      "T2\tOtherScientificTerm 131 143\ttag contexts\n",
      "T3\tMethod 152 185\tdependency network representation\n",
      "T4\tOtherScientificTerm 208 224\tlexical features\n",
      "T5\tOtherScientificTerm 263 289\tmultiple consecutive words\n",
      "T6\tOtherScientificTerm 317 357\tpriors  in  conditional loglinear models\n",
      "T7\tMethod 370 417\tfine-grained modeling of  unknown word features\n",
      "T8\tMethod 464 470\ttagger\n",
      "T9\tMetric 488 496\taccuracy\n",
      "T10\tMaterial 506 523\tPenn Treebank WSJ\n",
      "T11\tMetric 531 536\terror\n",
      "T12\tTask 607 614\ttagging\n",
      "R1\tEVALUATE-FOR Arg1:T9 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R3\tCOREF Arg1:T8 Arg2:T1\n",
      "R4\tEVALUATE-FOR Arg1:T10 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T1\n",
      "R7\tEVALUATE-FOR Arg1:T11 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-2003.ann\n",
      "T1\tMethod 42 59\tlanguage modeling\n",
      "T2\tMaterial 65 86\tconversational speech\n",
      "T3\tTask 251 267\trecognition task\n",
      "T4\tMethod 358 400\tclass-dependent interpolation  of  N-grams\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-2006.ann\n",
      "T1\tMethod 49 53\tEBMT\n",
      "T2\tMaterial 66 95\tsmall-sized  bilingual corpus\n",
      "T3\tMaterial 109 140\tout-of-domain  bilingual corpus\n",
      "T4\tMethod 165 179\tlanguage model\n",
      "T5\tMaterial 187 216\tin-domain  monolingual corpus\n",
      "T6\tMethod 254 265\tEBMT system\n",
      "T7\tMetric 278 297\tevaluation measures\n",
      "T8\tMetric 307 317\tBLEU score\n",
      "T9\tMetric 328 338\tNIST score\n",
      "T10\tMaterial 376 407\tout-of-domain  bilingual corpus\n",
      "T11\tMethod 443 457\tlanguage model\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R2\tCOREF Arg1:T6 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R4\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R5\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R6\tEVALUATE-FOR Arg1:T7 Arg2:T11\n",
      "R7\tCOREF Arg1:T11 Arg2:T4\n",
      "R8\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R10\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R11\tUSED-FOR Arg1:T7 Arg2:T10\n",
      "R12\tCOREF Arg1:T10 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-2015.ann\n",
      "T1\tMethod 23 45\tunsupervised technique\n",
      "T2\tTask 61 71\tmorphology\n",
      "T3\tOtherScientificTerm 89 93\thubs\n",
      "T4\tOtherScientificTerm 102 111\tautomaton\n",
      "T5\tOtherScientificTerm 136 139\thub\n",
      "T6\tOtherScientificTerm 147 151\tnode\n",
      "T7\tOtherScientificTerm 159 164\tgraph\n",
      "T8\tMethod 248 257\tword-trie\n",
      "T9\tGeneric 271 273\tit\n",
      "T10\tOtherScientificTerm 282 293\tminimal DFA\n",
      "T11\tOtherScientificTerm 312 316\thubs\n",
      "T12\tOtherScientificTerm 327 331\thubs\n",
      "T13\tOtherScientificTerm 360 364\troot\n",
      "T14\tOtherScientificTerm 371 377\tsuffix\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T5 Arg2:T3\n",
      "R4\tHYPONYM-OF Arg1:T5 Arg2:T6\n",
      "R5\tPART-OF Arg1:T6 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T11 Arg2:T5\n",
      "R9\tCOREF Arg1:T12 Arg2:T11\n",
      "R10\tPART-OF Arg1:T3 Arg2:T4\n",
      "R11\tCOREF Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-2017.ann\n",
      "T1\tOtherScientificTerm 15 38\tsyntax-based constraint\n",
      "T2\tTask 45 59\tword alignment\n",
      "T3\tOtherScientificTerm 77 96\tcohesion constraint\n",
      "T4\tGeneric 100 102\tIt\n",
      "T5\tMaterial 122 137\tEnglish phrases\n",
      "T6\tMaterial 189 204\tFrench sentence\n",
      "T7\tGeneric 241 251\tconstraint\n",
      "T8\tGeneric 270 280\talgorithms\n",
      "T9\tGeneric 304 306\tit\n",
      "T10\tMetric 349 366\talignment quality\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T4 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R5\tCOREF Arg1:T7 Arg2:T4\n",
      "R6\tCOREF Arg1:T9 Arg2:T7\n",
      "R7\tEVALUATE-FOR Arg1:T8 Arg2:T7\n",
      "R8\tEVALUATE-FOR Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-2025.ann\n",
      "T1\tMethod 10 32\tbootstrapping approach\n",
      "T2\tTask 38 63\tNamed Entity (NE) tagging\n",
      "T3\tOtherScientificTerm 72 91\tconcept-based seeds\n",
      "T4\tMethod 98 117\tsuccessive learners\n",
      "T5\tGeneric 138 146\tapproach\n",
      "T6\tOtherScientificTerm 253 255\tNE\n",
      "T7\tOtherScientificTerm 286 295\tPERSON NE\n",
      "T8\tMethod 304 327\tbootstrapping procedure\n",
      "T9\tMethod 361 380\tsuccessive learners\n",
      "T10\tOtherScientificTerm 392 405\tdecision list\n",
      "T11\tOtherScientificTerm 429 451\tparsing-based NE rules\n",
      "T12\tMethod 464 483\tHidden Markov Model\n",
      "T13\tGeneric 545 552\tlearner\n",
      "T14\tMethod 571 580\tNE system\n",
      "T15\tTask 594 607\tsupervised NE\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R5\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R6\tCOREF Arg1:T5 Arg2:T1\n",
      "R7\tHYPONYM-OF Arg1:T7 Arg2:T6\n",
      "R8\tCOREF Arg1:T8 Arg2:T5\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R11\tHYPONYM-OF Arg1:T13 Arg2:T9\n",
      "R12\tCOREF Arg1:T9 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-2036.ann\n",
      "T1\tMethod 31 57\tphrase-based unigram model\n",
      "T2\tTask 64 95\tstatistical machine translation\n",
      "T3\tOtherScientificTerm 130 146\tmodel parameters\n",
      "T4\tMethod 162 181\tphrase-based models\n",
      "T5\tOtherScientificTerm 217 223\tblocks\n",
      "T6\tTask 256 264\tdecoding\n",
      "T7\tMethod 278 297\tblock unigram model\n",
      "T8\tMethod 306 339\tword-based trigram language model\n",
      "T9\tTask 351 359\ttraining\n",
      "T10\tOtherScientificTerm 368 374\tblocks\n",
      "T11\tMethod 394 421\tsource interval projections\n",
      "T12\tMethod 444 458\tword alignment\n",
      "T13\tMetric 495 519\tblock selection criteria\n",
      "T14\tOtherScientificTerm 531 546\tunigram  counts\n",
      "T15\tOtherScientificTerm 552 566\tphrase  length\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tCOMPARE Arg1:T1 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R7\tCONJUNCTION Arg1:T8 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R9\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R11\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R12\tCOREF Arg1:T10 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-3010.ann\n",
      "T1\tMethod 36 53\tCooperative Model\n",
      "T2\tTask 60 90\tnatural language understanding\n",
      "T3\tTask 98 113\tdialogue system\n",
      "T4\tGeneric 126 130\tthis\n",
      "T5\tMethod 146 170\tFinite State Model (FSM)\n",
      "T6\tMethod 177 209\tStatistical Learning Model (SLM)\n",
      "T7\tMethod 214 217\tFSM\n",
      "T8\tTask 248 270\tlanguage understanding\n",
      "T9\tMethod 337 357\tStatistical approach\n",
      "T10\tMethod 399 416\tCooperative Model\n",
      "R1\tCOREF Arg1:T4 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R4\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R5\tCOREF Arg1:T7 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tCOREF Arg1:T9 Arg2:T6\n",
      "R8\tCOREF Arg1:T10 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R10\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-4004.ann\n",
      "T1\tTask 8 44\tTAP-XL Automated Analyst's Assistant\n",
      "T2\tMaterial 183 212\tmultilingual, multimedia data\n",
      "T3\tGeneric 216 218\tIt\n",
      "T4\tMethod 377 402\thuman language technology\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N03-4010.ann\n",
      "T1\tMethod 6 20\tJAVELIN system\n",
      "T2\tMethod 46 73\tplanning-based architecture\n",
      "T3\tMethod 94 121\tlanguage processing modules\n",
      "T4\tTask 138 179\topen-domain question answering capability\n",
      "T5\tMethod 235 242\tJAVELIN\n",
      "T6\tGeneric 368 374\tsystem\n",
      "T7\tGeneric 469 475\tsystem\n",
      "T8\tTask 489 507\tquestion answering\n",
      "R1\tPART-OF Arg1:T2 Arg2:T1\n",
      "R2\tPART-OF Arg1:T3 Arg2:T1\n",
      "R3\tCONJUNCTION Arg1:T3 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R5\tCOREF Arg1:T5 Arg2:T1\n",
      "R6\tCOREF Arg1:T6 Arg2:T5\n",
      "R7\tCOREF Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N04-1008.ann\n",
      "T1\tMethod 43 68\tQuestion Answering system\n",
      "T2\tMaterial 129 159\tFAQ-like questions and answers\n",
      "T3\tGeneric 177 183\tsystem\n",
      "T4\tMethod 194 220\tnoisy-channel architecture\n",
      "T5\tMethod 245 259\tlanguage model\n",
      "T6\tMethod 282 302\ttransformation model\n",
      "T7\tMaterial 411 414\tWeb\n",
      "R1\tCOREF Arg1:T3 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N04-1022.ann\n",
      "T1\tMethod 13 46\tMinimum Bayes-Risk (MBR) decoding\n",
      "T2\tTask 53 84\tstatistical machine translation\n",
      "T3\tMethod 92 112\tstatistical approach\n",
      "T4\tOtherScientificTerm 131 144\texpected loss\n",
      "T5\tOtherScientificTerm 150 168\ttranslation errors\n",
      "T6\tOtherScientificTerm 177 191\tloss functions\n",
      "T7\tTask 207 218\ttranslation\n",
      "T8\tOtherScientificTerm 261 275\tloss functions\n",
      "T9\tOtherScientificTerm 315 337\tlinguistic information\n",
      "T10\tOtherScientificTerm 361 384\tword-to-word alignments\n",
      "T11\tMethod 395 404\tMT system\n",
      "T12\tOtherScientificTerm 412 431\tsyntactic structure\n",
      "T13\tOtherScientificTerm 439 450\tparse-trees\n",
      "T14\tMethod 531 543\tMBR decoders\n",
      "T15\tTask 551 586\tChinese-to-English translation task\n",
      "T16\tMethod 612 624\tMBR decoding\n",
      "T17\tMethod 647 661\tstatistical MT\n",
      "T18\tOtherScientificTerm 689 703\tloss functions\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R3\tPART-OF Arg1:T10 Arg2:T11\n",
      "R4\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T8\n",
      "R6\tPART-OF Arg1:T13 Arg2:T12\n",
      "R7\tCOREF Arg1:T14 Arg2:T1\n",
      "R8\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R9\tCOREF Arg1:T16 Arg2:T14\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T18\n",
      "R11\tEVALUATE-FOR Arg1:T6 Arg2:T7\n",
      "R12\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R13\tCOREF Arg1:T3 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N04-1024.ann\n",
      "T1\tTask 2 45\tCriterionSM Online Essay Evaluation Service\n",
      "T2\tOtherScientificTerm 120 150\tessay-based discourse elements\n",
      "T3\tOtherScientificTerm 160 177\tthesis statements\n",
      "T4\tGeneric 200 206\tsystem\n",
      "T5\tOtherScientificTerm 222 246\tCriterion  's capability\n",
      "T6\tMetric 283 304\tcoherence  in  essays\n",
      "T7\tGeneric 313 319\tsystem\n",
      "T8\tOtherScientificTerm 332 340\tfeatures\n",
      "T9\tMetric 367 395\tsemantic similarity measures\n",
      "T10\tOtherScientificTerm 402 421\tdiscourse structure\n",
      "T11\tMethod 428 450\tsupport vector machine\n",
      "T12\tOtherScientificTerm 464 472\tfeatures\n",
      "T13\tOtherScientificTerm 486 509\tbreakdowns in coherence\n",
      "T14\tOtherScientificTerm 579 597\tdiscourse elements\n",
      "T15\tMetric 602 626\tIntra-sentential quality\n",
      "T16\tMethod 647 668\trule-based heuristics\n",
      "T17\tGeneric 698 704\tsystem\n",
      "T18\tGeneric 739 747\tbaseline\n",
      "R1\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R2\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "R3\tPART-OF Arg1:T2 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tCOREF Arg1:T7 Arg2:T4\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tCONJUNCTION Arg1:T10 Arg2:T9\n",
      "R8\tCOREF Arg1:T17 Arg2:T7\n",
      "R9\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R10\tCOMPARE Arg1:T17 Arg2:T18\n",
      "R11\tCOREF Arg1:T12 Arg2:T8\n",
      "R12\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R13\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R14\tEVALUATE-FOR Arg1:T6 Arg2:T4\n",
      "R15\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N04-2005.ann\n",
      "T1\tTask 6 81\ttranslation  of  English text  into  American Sign Language (ASL) animation\n",
      "T2\tMethod 116 140\tMT architectural designs\n",
      "T3\tMethod 150 173\tsemantic representation\n",
      "T4\tMethod 198 240\tvirtual reality 3D scene modeling software\n",
      "T5\tOtherScientificTerm 254 285\tspatially complex ASL phenomena\n",
      "T6\tOtherScientificTerm 296 317\tclassifier predicates\n",
      "T7\tGeneric 325 330\tmodel\n",
      "T8\tOtherScientificTerm 343 354\tinterlingua\n",
      "T9\tMethod 370 406\tmulti-pathway MT architecture design\n",
      "T10\tOtherScientificTerm 432 440\ttransfer\n",
      "T11\tGeneric 447 464\tdirect approaches\n",
      "T12\tGeneric 480 486\tsystem\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R3\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "R4\tPART-OF Arg1:T10 Arg2:T12\n",
      "R5\tPART-OF Arg1:T11 Arg2:T12\n",
      "R6\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R7\tCOREF Arg1:T12 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N04-4028.ann\n",
      "T1\tMethod 2 35\tInformation extraction techniques\n",
      "T2\tMaterial 59 79\tstructured databases\n",
      "T3\tMaterial 87 112\tunstructured data sources\n",
      "T4\tMaterial 127 130\tWeb\n",
      "T5\tMaterial 135 153\tnewswire documents\n",
      "T6\tGeneric 187 194\tsystems\n",
      "T7\tMetric 197 205\taccuracy\n",
      "T8\tGeneric 318 324\tsystem\n",
      "T9\tMethod 380 409\tinformation extraction system\n",
      "T10\tMethod 438 481\tlinear-chain conditional random field (CRF)\n",
      "T11\tMethod 487 506\tprobabilistic model\n",
      "T12\tTask 537 565\tinformation extraction tasks\n",
      "T13\tOtherScientificTerm 601 633\tarbitrary, overlapping  features\n",
      "T14\tGeneric 643 648\tinput\n",
      "T15\tMethod 656 668\tMarkov model\n",
      "T16\tGeneric 692 702\ttechniques\n",
      "T17\tGeneric 741 757\textracted fields\n",
      "T18\tMaterial 771 790\tmulti-field records\n",
      "T19\tMetric 807 824\taverage precision\n",
      "T20\tMaterial 877 896\tmulti-field records\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R5\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R6\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R7\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R8\tCOREF Arg1:T8 Arg2:T1\n",
      "R9\tCOREF Arg1:T6 Arg2:T1\n",
      "R10\tHYPONYM-OF Arg1:T10 Arg2:T11\n",
      "R11\tEVALUATE-FOR Arg1:T19 Arg2:T16\n",
      "R12\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R13\tCOREF Arg1:T20 Arg2:T18\n",
      "R14\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R15\tCOREF Arg1:T9 Arg2:T8\n",
      "R16\tFEATURE-OF Arg1:T13 Arg2:T14\n",
      "R17\tPART-OF Arg1:T13 Arg2:T15\n",
      "R18\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N06-1007.ann\n",
      "T1\tTask 37 84\tautomatic acquisition  of  entailment relations\n",
      "T2\tGeneric 114 118\ttask\n",
      "T3\tTask 144 167\tparaphrases acquisition\n",
      "T4\tOtherScientificTerm 193 213\tsemantic equivalence\n",
      "T5\tTask 255 277\tentailment acquisition\n",
      "T6\tOtherScientificTerm 294 331\tasymmetric, or directional, relations\n",
      "T7\tOtherScientificTerm 390 424\tlocal structure  of  coherent text\n",
      "T8\tGeneric 440 446\tmethod\n",
      "T9\tTask 463 478\tverb entailment\n",
      "T10\tOtherScientificTerm 502 521\tdiscourse relations\n",
      "T11\tMaterial 557 570\tparsed corpus\n",
      "T12\tGeneric 619 625\tmethod\n",
      "T13\tOtherScientificTerm 656 677\tverb entailment types\n",
      "T14\tTask 695 718\tmapping  between  verbs\n",
      "T15\tOtherScientificTerm 725 759\thighly varied  argument structures\n",
      "R1\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R2\tCOMPARE Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R6\tCOREF Arg1:T12 Arg2:T8\n",
      "R7\tCOREF Arg1:T2 Arg2:T1\n",
      "R8\tCOREF Arg1:T5 Arg2:T2\n",
      "R9\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R10\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R11\tFEATURE-OF Arg1:T15 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N06-1018.ann\n",
      "T1\tOtherScientificTerm 68 88\ttemporal information\n",
      "T2\tTask 93 122\tnatural language applications\n",
      "T3\tOtherScientificTerm 222 242\ttemporal expressions\n",
      "T4\tOtherScientificTerm 222 262\ttemporal expressions  in  newswire texts\n",
      "T5\tMaterial 248 262\tnewswire texts\n",
      "T6\tOtherScientificTerm 312 332\ttemporal expressions\n",
      "T7\tMaterial 354 360\temails\n",
      "T8\tGeneric 406 417\texpressions\n",
      "T9\tOtherScientificTerm 439 479\tconstraint-based representation  of time\n",
      "T10\tOtherScientificTerm 482 523\tTime Calculus for Natural Language (TCNL)\n",
      "T11\tMethod 561 595\tTemporal Expression Anchoror (TEA)\n",
      "T12\tGeneric 624 626\tit\n",
      "T13\tGeneric 667 675\tbaseline\n",
      "R1\tCOREF Arg1:T8 Arg2:T6\n",
      "R2\tHYPONYM-OF Arg1:T10 Arg2:T9\n",
      "R3\tCOREF Arg1:T11 Arg2:T12\n",
      "R4\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R5\tFEATURE-OF Arg1:T7 Arg2:T6\n",
      "R6\tFEATURE-OF Arg1:T5 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N06-1037.ann\n",
      "T1\tMethod 31 68\tconvolution kernel  over  parse trees\n",
      "T2\tOtherScientificTerm 80 111\tsyntactic structure information\n",
      "T3\tTask 118 137\trelation extraction\n",
      "T4\tOtherScientificTerm 168 196\tsyntactic structure features\n",
      "T5\tOtherScientificTerm 213 223\tparse tree\n",
      "T6\tTask 249 268\trelation extraction\n",
      "T7\tGeneric 280 288\tfeatures\n",
      "T8\tMethod 318 341\tconvolution tree kernel\n",
      "T9\tMaterial 363 378\tACE 2003 corpus\n",
      "T10\tMethod 396 433\tconvolution kernel  over  parse trees\n",
      "T11\tMethod 502 523\tfeature-based methods\n",
      "T12\tGeneric 582 588\tmethod\n",
      "T13\tMethod 633 656\tdependency tree kernels\n",
      "R1\tFEATURE-OF Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R4\tCOREF Arg1:T7 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R6\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R8\tCOREF Arg1:T1 Arg2:T8\n",
      "R9\tEVALUATE-FOR Arg1:T9 Arg2:T10\n",
      "R10\tCOREF Arg1:T12 Arg2:T10\n",
      "R11\tCOREF Arg1:T10 Arg2:T8\n",
      "R12\tCOMPARE Arg1:T11 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N06-2009.ann\n",
      "T1\tMethod 21 52\tQuestion Answering (QA) systems\n",
      "T2\tMethod 249 280\tMT-based paraphrasing technique\n",
      "T3\tMethod 298 307\tQA system\n",
      "T4\tMaterial 325 346\tparaphrased questions\n",
      "T5\tMetric 391 394\tMRR\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tCOREF Arg1:T3 Arg2:T1\n",
      "R3\tEVALUATE-FOR Arg1:T4 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N06-2038.ann\n",
      "T1\tGeneric 21 31\tapproaches\n",
      "T2\tTask 44 66\tinformation extraction\n",
      "T3\tTask 74 99\ttoken classification task\n",
      "T4\tMethod 118 136\ttagging strategies\n",
      "T5\tMethod 186 204\ttagging strategies\n",
      "T6\tGeneric 308 316\tstrategy\n",
      "T7\tMethod 326 345\tBegin/After tagging\n",
      "T8\tMethod 351 354\tBIA\n",
      "T9\tGeneric 372 374\tit\n",
      "T10\tGeneric 408 418\tstrategies\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T8 Arg2:T7\n",
      "R5\tCOREF Arg1:T7 Arg2:T6\n",
      "R6\tCOREF Arg1:T6 Arg2:T9\n",
      "R7\tCOMPARE Arg1:T9 Arg2:T10\n",
      "R8\tCOREF Arg1:T4 Arg2:T1\n",
      "R9\tCOREF Arg1:T5 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\N06-4001.ann\n",
      "T1\tMethod 23 58\tinteractive corpus exploration tool\n",
      "T2\tMethod 68 79\tInfoMagnets\n",
      "T3\tMethod 84 95\tInfoMagnets\n",
      "T4\tTask 113 140\texploratory corpus analysis\n",
      "T5\tTask 192 203\ttext mining\n",
      "T6\tGeneric 252 254\tit\n",
      "T7\tGeneric 390 397\tdomains\n",
      "T8\tMaterial 400 417\ttutorial dialogue\n",
      "T9\tMaterial 449 468\ton-line communities\n",
      "T10\tMethod 502 518\teducational tool\n",
      "T11\tGeneric 522 524\tit\n",
      "T12\tTask 561 578\tprotocol analysis\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R3\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R4\tCOREF Arg1:T3 Arg2:T2\n",
      "R5\tCOREF Arg1:T6 Arg2:T3\n",
      "R6\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R7\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R8\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R9\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R10\tCOREF Arg1:T10 Arg2:T3\n",
      "R11\tCOREF Arg1:T10 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_1996_15_abs.ann\n",
      "T1\tOtherScientificTerm 19 41\tanalytical expressions\n",
      "T2\tMethod 110 157\ttemporal difference value estimation algorithms\n",
      "T3\tOtherScientificTerm 211 224\tMarkov chains\n",
      "T4\tMethod 231 259\tlookup table representations\n",
      "T5\tOtherScientificTerm 286 309\tlearning curve behavior\n",
      "T6\tOtherScientificTerm 395 437\tstep-size and eligibility trace parameters\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_1996_22_abs.ann\n",
      "T1\tOtherScientificTerm 13 36\tnumber of hidden layers\n",
      "T2\tMethod 51 77\tmultilayer neu-ral network\n",
      "T3\tOtherScientificTerm 83 98\tthreshold units\n",
      "T4\tOtherScientificTerm 223 235\thidden layer\n",
      "T5\tOtherScientificTerm 538 550\thidden layer\n",
      "T6\tOtherScientificTerm 642 662\tglobal computability\n",
      "T7\tOtherScientificTerm 672 684\thidden layer\n",
      "T8\tOtherScientificTerm 706 729\tnon-local configuration\n",
      "T9\tOtherScientificTerm 735 751\t\"critical cycle\"\n",
      "T10\tOtherScientificTerm 801 813\thidden layer\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_1998_18_abs.ann\n",
      "T1\tOtherScientificTerm 0 38\tVisually-guided arm reaching movements\n",
      "T2\tMethod 55 82\tdistributed neural networks\n",
      "T3\tOtherScientificTerm 331 361\tcoordinated action of neu-rons\n",
      "T4\tOtherScientificTerm 388 420\tneuronal population vector (NPV)\n",
      "T5\tOtherScientificTerm 436 439\tNPV\n",
      "T6\tOtherScientificTerm 577 588\tarm posture\n",
      "T7\tGeneric 615 620\tmodel\n",
      "T8\tOtherScientificTerm 628 650\tcortical motor command\n",
      "T9\tOtherScientificTerm 784 787\tNPV\n",
      "T10\tOtherScientificTerm 791 803\tmotor cortex\n",
      "T11\tGeneric 809 814\tmodel\n",
      "T12\tMethod 820 860\ttwo-layer self-organizing neural network\n",
      "T13\tOtherScientificTerm 876 915\tbroadly-tuned (muscular) proprioceptive\n",
      "T14\tOtherScientificTerm 920 950\t(cartesian) visual information\n",
      "T15\tOtherScientificTerm 964 988\t(angular) motor commands\n",
      "T16\tOtherScientificTerm 1031 1043\ttwo-link arm\n",
      "T17\tGeneric 1049 1056\tnetwork\n",
      "T18\tGeneric 1135 1142\tnetwork\n",
      "T19\tOtherScientificTerm 1403 1406\tNPV\n",
      "T20\tOtherScientificTerm 1457 1460\tNPV\n",
      "T21\tOtherScientificTerm 1486 1514\timage of cortical processing\n",
      "T22\tOtherScientificTerm 1522 1544\tarm reaching movements\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R3\tCOREF Arg1:T5 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R5\tCOREF Arg1:T9 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R7\tCOREF Arg1:T11 Arg2:T7\n",
      "R8\tCOREF Arg1:T12 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T12 Arg2:T15\n",
      "R12\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R13\tCOREF Arg1:T17 Arg2:T12\n",
      "R14\tCOREF Arg1:T18 Arg2:T17\n",
      "R15\tCOREF Arg1:T19 Arg2:T9\n",
      "R16\tCOREF Arg1:T20 Arg2:T19\n",
      "R17\tFEATURE-OF Arg1:T22 Arg2:T21\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2001_10_abs.ann\n",
      "T1\tGeneric 26 34\tapproach\n",
      "T2\tTask 49 63\tfast detection\n",
      "T3\tOtherScientificTerm 85 97\tdistribution\n",
      "T4\tMaterial 101 131\tpositive and negative examples\n",
      "T5\tTask 155 169\tface detection\n",
      "T6\tTask 173 191\tdatabase retrieval\n",
      "T7\tMethod 212 241\tcascade of simple classifiers\n",
      "T8\tMethod 230 241\tclassifiers\n",
      "T9\tMetric 271 286\tdetection rates\n",
      "T10\tMetric 291 318\tmodest false positive rates\n",
      "T11\tGeneric 337 345\tdetector\n",
      "T12\tOtherScientificTerm 366 374\tfeatures\n",
      "T13\tMetric 391 406\tdetection rates\n",
      "T14\tMetric 417 437\tfalse positive rates\n",
      "T15\tMetric 443 459\tfast performance\n",
      "T16\tMetric 486 501\tdetection rates\n",
      "T17\tMetric 515 524\tlow error\n",
      "T18\tMethod 563 590\tmachine learning algorithms\n",
      "T19\tMethod 620 628\tAdaBoost\n",
      "T20\tOtherScientificTerm 668 679\tclassifiers\n",
      "T21\tGeneric 692 699\tcascade\n",
      "T22\tTask 739 753\tface detection\n",
      "T23\tMethod 763 781\ttraining algorithm\n",
      "T24\tMethod 847 855\tAdaBoost\n",
      "T25\tMethod 867 888\tface detection system\n",
      "T26\tMetric 941 950\tdetection\n",
      "T27\tMetric 958 977\tfalse positive rate\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R3\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R4\tFEATURE-OF Arg1:T12 Arg2:T11\n",
      "R5\tCOREF Arg1:T13 Arg2:T9\n",
      "R6\tCOREF Arg1:T16 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R8\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R9\tCOMPARE Arg1:T24 Arg2:T23\n",
      "R10\tUSED-FOR Arg1:T23 Arg2:T22\n",
      "R11\tUSED-FOR Arg1:T24 Arg2:T22\n",
      "R12\tEVALUATE-FOR Arg1:T9 Arg2:T8\n",
      "R13\tEVALUATE-FOR Arg1:T10 Arg2:T8\n",
      "R14\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R15\tUSED-FOR Arg1:T7 Arg2:T11\n",
      "R16\tCOREF Arg1:T21 Arg2:T7\n",
      "R17\tCOREF Arg1:T20 Arg2:T8\n",
      "R18\tCOREF Arg1:T22 Arg2:T5\n",
      "R19\tCOREF Arg1:T25 Arg2:T1\n",
      "R20\tCONJUNCTION Arg1:T26 Arg2:T27\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2001_11_abs.ann\n",
      "T1\tMethod 2 23\tmixed-signal paradigm\n",
      "T2\tTask 41 91\thigh-resolution parallel inner-product computation\n",
      "T3\tMethod 158 165\tkernels\n",
      "T4\tTask 169 185\timage processing\n",
      "T5\tMethod 206 237\texternally digital architecture\n",
      "T6\tOtherScientificTerm 243 279\thigh-density, low-power analog array\n",
      "T7\tMethod 291 341\tbinary-binary partial matrix-vector multiplication\n",
      "T8\tMetric 343 366\tFull digital resolution\n",
      "T9\tMethod 391 434\tlow-resolution analog-to-digital conversion\n",
      "T10\tOtherScientificTerm 445 462\trandom statistics\n",
      "T11\tOtherScientificTerm 470 505\tanalog summation of binary products\n",
      "T12\tMethod 509 533\trandom modulation scheme\n",
      "T13\tOtherScientificTerm 543 568\tnear-Bernoulli statistics\n",
      "T14\tMaterial 578 602\thighly correlated inputs\n",
      "T15\tGeneric 608 616\tapproach\n",
      "T16\tMaterial 635 650\treal image data\n",
      "T17\tOtherScientificTerm 689 720\tCID/DRAM analog array prototype\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tPART-OF Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R6\tPART-OF Arg1:T10 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R9\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "R10\tCOREF Arg1:T1 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2001_18_abs.ann\n",
      "T1\tMethod 0 15\tFactor analysis\n",
      "T2\tMethod 20 49\tprincipal components analysis\n",
      "T3\tOtherScientificTerm 71 118\tlinear relationships between observed variables\n",
      "T4\tMaterial 136 157\thigh-dimensional data\n",
      "T5\tOtherScientificTerm 163 193\tlower-dimensional hidden space\n",
      "T6\tMethod 198 213\tfactor analysis\n",
      "T7\tMethod 249 308\tlinear combination of normally distributed hidden variables\n",
      "T8\tMethod 324 367\tnonlinear generalization of factor analysis\n",
      "T9\tMethod 352 367\tfactor analysis\n",
      "T10\tMethod 377 396\t\"product analy-sis\"\n",
      "T11\tOtherScientificTerm 414 432\tobserved variables\n",
      "T12\tOtherScientificTerm 438 509\tlinear combination of products of normally distributed hidden variables\n",
      "T13\tMethod 519 534\tfactor analysis\n",
      "T14\tMethod 552 582\tunsupervised linear regression\n",
      "T15\tOtherScientificTerm 607 635\tdistributed hidden variables\n",
      "T16\tMethod 637 653\tproduct analysis\n",
      "T17\tMethod 671 701\tunsupervised linear regression\n",
      "T18\tOtherScientificTerm 738 766\tdistributed hidden variables\n",
      "T19\tOtherScientificTerm 805 817\thidden space\n",
      "T20\tMethod 845 878\tapproximate variational technique\n",
      "T21\tTask 883 892\tinference\n",
      "T22\tTask 897 905\tlearning\n",
      "T23\tMethod 913 929\tproduct analysis\n",
      "T24\tMethod 935 968\tgeneralization of factor analysis\n",
      "T25\tMethod 953 968\tfactor analysis\n",
      "T26\tMethod 970 986\tproduct analysis\n",
      "T27\tMethod 1030 1045\tfactor analysis\n",
      "T28\tTask 1066 1085\tpattern recognition\n",
      "T29\tTask 1090 1129\tillumination-invariant image clustering\n",
      "R1\tCOREF Arg1:T6 Arg2:T1\n",
      "R2\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R5\tCOREF Arg1:T9 Arg2:T6\n",
      "R6\tHYPONYM-OF Arg1:T10 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T8\n",
      "R9\tCOREF Arg1:T13 Arg2:T6\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R11\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R12\tUSED-FOR Arg1:T20 Arg2:T21\n",
      "R13\tCONJUNCTION Arg1:T21 Arg2:T22\n",
      "R14\tUSED-FOR Arg1:T20 Arg2:T22\n",
      "R15\tCOREF Arg1:T23 Arg2:T16\n",
      "R16\tCOREF Arg1:T16 Arg2:T10\n",
      "R17\tCOREF Arg1:T26 Arg2:T23\n",
      "R18\tHYPONYM-OF Arg1:T23 Arg2:T24\n",
      "R19\tCOREF Arg1:T25 Arg2:T27\n",
      "R20\tCOMPARE Arg1:T26 Arg2:T27\n",
      "R21\tCOREF Arg1:T25 Arg2:T13\n",
      "R22\tCONJUNCTION Arg1:T28 Arg2:T29\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2001_21_abs.ann\n",
      "T1\tTask 25 48\tblind source separation\n",
      "T2\tOtherScientificTerm 63 92\tinstantaneous linear mixtures\n",
      "T3\tOtherScientificTerm 104 117\tmixing matrix\n",
      "T4\tOtherScientificTerm 178 197\tsparsity of sources\n",
      "T5\tOtherScientificTerm 249 266\tsignal dictionary\n",
      "T6\tMetric 294 315\tquality of separation\n",
      "T7\tOtherScientificTerm 353 375\tmulti scale transforms\n",
      "T8\tOtherScientificTerm 385 411\twavelet or wavelet packets\n",
      "T9\tOtherScientificTerm 447 461\tlocal features\n",
      "T10\tOtherScientificTerm 486 494\tsparsity\n",
      "T11\tOtherScientificTerm 575 583\tfeatures\n",
      "T12\tGeneric 631 640\talgorithm\n",
      "T13\tMaterial 656 681\tnoise-free and noisy data\n",
      "T14\tMaterial 700 717\tsimulated signals\n",
      "T15\tMaterial 719 733\tmusical sounds\n",
      "T16\tMaterial 738 744\timages\n",
      "T17\tMetric 784 802\tseparation quality\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tEVALUATE-FOR Arg1:T6 Arg2:T4\n",
      "R4\tEVALUATE-FOR Arg1:T13 Arg2:T12\n",
      "R5\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R6\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R7\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R8\tEVALUATE-FOR Arg1:T16 Arg2:T17\n",
      "R9\tEVALUATE-FOR Arg1:T15 Arg2:T17\n",
      "R10\tEVALUATE-FOR Arg1:T14 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2002_10_abs.ann\n",
      "T1\tTask 0 20\tIdentity uncertainty\n",
      "T2\tTask 47 71\treal-world data analysis\n",
      "T3\tGeneric 128 139\tidentifiers\n",
      "T4\tGeneric 154 165\tidentifiers\n",
      "T5\tGeneric 307 314\tproblem\n",
      "T6\tTask 333 350\tcitation matching\n",
      "T7\tOtherScientificTerm 381 390\tcitations\n",
      "T8\tOtherScientificTerm 414 425\tpublication\n",
      "T9\tGeneric 431 439\tapproach\n",
      "T10\tMethod 465 493\trelational probability model\n",
      "T11\tMethod 506 522\tgenerative model\n",
      "T12\tGeneric 531 537\tdomain\n",
      "T13\tMethod 549 586\tmodels of author and title corruption\n",
      "T14\tMethod 593 623\tprobabilistic citation grammar\n",
      "T15\tTask 625 645\tIdentity uncertainty\n",
      "T16\tGeneric 679 685\tmodels\n",
      "T17\tOtherScientificTerm 733 741\tmappings\n",
      "T18\tOtherScientificTerm 791 797\tdomain\n",
      "T19\tTask 799 808\tInference\n",
      "T20\tMethod 821 845\tMarkov chain Monte Carlo\n",
      "T21\tGeneric 871 878\tmethods\n",
      "T22\tMaterial 972 990\tcitation data sets\n",
      "T23\tGeneric 1005 1011\tmethod\n",
      "T24\tMethod 1024 1042\tcurrent algorithms\n",
      "T25\tTask 1047 1064\tcitation matching\n",
      "T26\tGeneric 1108 1113\tmodel\n",
      "T27\tGeneric 1134 1143\talgorithm\n",
      "T28\tOtherScientificTerm 1158 1180\tobject characteristics\n",
      "T29\tOtherScientificTerm 1189 1201\tauthor names\n",
      "T30\tOtherScientificTerm 1224 1233\tcitations\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R3\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R4\tCOMPARE Arg1:T23 Arg2:T24\n",
      "R5\tUSED-FOR Arg1:T23 Arg2:T25\n",
      "R6\tUSED-FOR Arg1:T24 Arg2:T25\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R8\tPART-OF Arg1:T13 Arg2:T10\n",
      "R9\tPART-OF Arg1:T14 Arg2:T10\n",
      "R10\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R11\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R12\tCOREF Arg1:T12 Arg2:T6\n",
      "R13\tCOREF Arg1:T5 Arg2:T1\n",
      "R14\tCOREF Arg1:T4 Arg2:T3\n",
      "R15\tCOREF Arg1:T15 Arg2:T1\n",
      "R16\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R17\tEVALUATE-FOR Arg1:T22 Arg2:T23\n",
      "R18\tCOREF Arg1:T25 Arg2:T6\n",
      "R19\tCOREF Arg1:T23 Arg2:T9\n",
      "R20\tCOREF Arg1:T26 Arg2:T23\n",
      "R21\tCOREF Arg1:T27 Arg2:T26\n",
      "R22\tHYPONYM-OF Arg1:T29 Arg2:T28\n",
      "R23\tUSED-FOR Arg1:T27 Arg2:T28\n",
      "R24\tUSED-FOR Arg1:T21 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2002_11_abs.ann\n",
      "T1\tTask 22 32\tclustering\n",
      "T2\tMethod 124 141\tunified framework\n",
      "T3\tTask 146 155\treasoning\n",
      "T4\tMethod 342 353\tunification\n",
      "T5\tMethod 373 394\timpossibility theorem\n",
      "T6\tOtherScientificTerm 459 478\tclustering function\n",
      "T7\tMethod 604 638\twell-studied clustering techniques\n",
      "T8\tMethod 647 661\tsingle-linkage\n",
      "T9\tMethod 663 675\tsum-of-pairs\n",
      "T10\tMethod 677 684\tk-means\n",
      "T11\tMethod 690 698\tk-median\n",
      "R1\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R2\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R3\tHYPONYM-OF Arg1:T10 Arg2:T7\n",
      "R4\tHYPONYM-OF Arg1:T11 Arg2:T7\n",
      "R5\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R6\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R7\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R9\tCOREF Arg1:T2 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2002_18_abs.ann\n",
      "T1\tMethod 2 20\tbio-inspired model\n",
      "T2\tTask 28 70\tanalog programmable array processor (APAP)\n",
      "T3\tOtherScientificTerm 96 113\tvertebrate retina\n",
      "T4\tOtherScientificTerm 148 193\tcomplex programmable spatio-temporal dynamics\n",
      "T5\tTask 197 201\tVLSI\n",
      "T6\tGeneric 208 213\tmodel\n",
      "T7\tMaterial 238 244\timages\n",
      "T8\tMethod 266 280\tvisual pathway\n",
      "T9\tTask 347 366\tvision applications\n",
      "T10\tOtherScientificTerm 395 409\tprototype chip\n",
      "T11\tOtherScientificTerm 463 475\tCMOS process\n",
      "T12\tMetric 477 501\tComputing power per area\n",
      "T13\tMetric 506 523\tpower consumption\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tFEATURE-OF Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R5\tCOREF Arg1:T6 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R7\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2003_10_abs.ann\n",
      "T1\tTask 25 46\tvisual classification\n",
      "T2\tMethod 68 115\tpsy-chophysical and machine learning techniques\n",
      "T3\tOtherScientificTerm 117 145\tFrontal views of human faces\n",
      "T4\tTask 162 188\tgender classification task\n",
      "T5\tOtherScientificTerm 236 251\tgender judgment\n",
      "T6\tOtherScientificTerm 253 266\treaction time\n",
      "T7\tOtherScientificTerm 271 288\tconfidence rating\n",
      "T8\tMethod 312 342\thyperplane learning algorithms\n",
      "T9\tTask 365 384\tclassification task\n",
      "T10\tOtherScientificTerm 395 430\tPrincipal Components of the texture\n",
      "T11\tMethod 435 472\tflowfield representation of the faces\n",
      "T12\tTask 478 492\tclassification\n",
      "T13\tMethod 512 531\tlearning algorithms\n",
      "T14\tTask 556 569\tface database\n",
      "T15\tOtherScientificTerm 755 792\thyperplane of the learning algorithms\n",
      "T16\tMethod 773 792\tlearning algorithms\n",
      "T17\tTask 819 839\thuman classification\n",
      "T18\tMethod 863 884\thyperplane algorithms\n",
      "T19\tOtherScientificTerm 892 905\tfeature space\n",
      "T20\tTask 919 933\tclassification\n",
      "T21\tOtherScientificTerm 994 1004\thyperplane\n",
      "T22\tGeneric 1014 1019\tthose\n",
      "R1\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R2\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R7\tCONJUNCTION Arg1:T11 Arg2:T10\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T8\n",
      "R9\tCOREF Arg1:T12 Arg2:T9\n",
      "R10\tCOREF Arg1:T9 Arg2:T1\n",
      "R11\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R12\tCOREF Arg1:T16 Arg2:T13\n",
      "R13\tCOREF Arg1:T13 Arg2:T8\n",
      "R14\tCOREF Arg1:T20 Arg2:T17\n",
      "R15\tCOREF Arg1:T21 Arg2:T15\n",
      "R16\tFEATURE-OF Arg1:T19 Arg2:T18\n",
      "R17\tCOMPARE Arg1:T21 Arg2:T22\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2003_18_abs.ann\n",
      "T1\tGeneric 23 32\talgorithm\n",
      "T2\tTask 37 93\tlearning the time-varying shape of a non-rigid 3D object\n",
      "T3\tMaterial 99 128\tuncalibrated 2D tracking data\n",
      "T4\tOtherScientificTerm 139 151\tshape motion\n",
      "T5\tMethod 157 172\trigid component\n",
      "T6\tOtherScientificTerm 174 182\trotation\n",
      "T7\tOtherScientificTerm 187 198\ttranslation\n",
      "T8\tOtherScientificTerm 216 237\tnon-rigid deformation\n",
      "T9\tOtherScientificTerm 239 253\tReconstruction\n",
      "T10\tOtherScientificTerm 270 292\tarbitrary deformations\n",
      "T11\tOtherScientificTerm 352 364\tobject shape\n",
      "T12\tMethod 402 423\tGaussian distribution\n",
      "T13\tGeneric 455 464\talgorithm\n",
      "T14\tOtherScientificTerm 490 509\t3D shape and motion\n",
      "T15\tMethod 560 568\tGaussian\n",
      "T16\tGeneric 632 641\talgorithm\n",
      "T17\tOtherScientificTerm 651 686\ttemporal smoothness in object shape\n",
      "T18\tGeneric 702 704\tit\n",
      "T19\tMaterial 731 743\tmissing data\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R3\tCOREF Arg1:T13 Arg2:T1\n",
      "R4\tCOREF Arg1:T15 Arg2:T12\n",
      "R5\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R6\tCOREF Arg1:T16 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R8\tCOREF Arg1:T16 Arg2:T18\n",
      "R9\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2014_10_abs.ann\n",
      "T1\tMethod 13 60\treweighted version of the Kikuchi approximation\n",
      "T2\tMethod 39 60\tKikuchi approximation\n",
      "T3\tTask 80 128\tlog partition function of a product distribution\n",
      "T4\tOtherScientificTerm 144 156\tregion graph\n",
      "T5\tOtherScientificTerm 201 210\tconcavity\n",
      "T6\tOtherScientificTerm 218 247\treweighted objective function\n",
      "T7\tOtherScientificTerm 260 278\tweight assignments\n",
      "T8\tOtherScientificTerm 286 303\tKikuchi expansion\n",
      "T9\tMethod 321 368\treweighted version of the sum product algorithm\n",
      "T10\tOtherScientificTerm 384 404\tKikuchi region graph\n",
      "T11\tOtherScientificTerm 418 431\tglobal optima\n",
      "T12\tMethod 439 460\tKikuchi approximation\n",
      "T13\tGeneric 474 483\talgorithm\n",
      "T14\tOtherScientificTerm 504 516\tregion graph\n",
      "T15\tMethod 552 571\tBethe approximation\n",
      "T16\tOtherScientificTerm 616 625\tconcavity\n",
      "T17\tOtherScientificTerm 714 723\tconcavity\n",
      "T18\tOtherScientificTerm 740 755\tcycle structure\n",
      "T19\tOtherScientificTerm 763 775\tregion graph\n",
      "T20\tMethod 845 872\treweighted Kikuchi approach\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R4\tFEATURE-OF Arg1:T11 Arg2:T12\n",
      "R5\tCOREF Arg1:T12 Arg2:T2\n",
      "R6\tFEATURE-OF Arg1:T18 Arg2:T19\n",
      "R7\tCOREF Arg1:T1 Arg2:T20\n",
      "R8\tFEATURE-OF Arg1:T5 Arg2:T6\n",
      "R9\tCOREF Arg1:T9 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2014_18_abs.ann\n",
      "T1\tTask 15 77\tclassical decision-theoretic problem of weighted expert voting\n",
      "T2\tMethod 85 117\tstatistical learning perspective\n",
      "T3\tOtherScientificTerm 207 239\tNitzan-Paroush weighted majority\n",
      "T4\tOtherScientificTerm 280 304\texpert competence levels\n",
      "T5\tMethod 314 335\tsharp error estimates\n",
      "T6\tOtherScientificTerm 344 356\toptimal rule\n",
      "T7\tOtherScientificTerm 367 384\tcompetence levels\n",
      "T8\tMethod 461 478\tBayesian analyses\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2014_21_abs.ann\n",
      "T1\tTask 3 41\treal-world action recognition problems\n",
      "T2\tOtherScientificTerm 43 61\tlow-level features\n",
      "T3\tOtherScientificTerm 97 129\trich spatial-temporal structures\n",
      "T4\tMaterial 133 146\taction videos\n",
      "T5\tOtherScientificTerm 226 245\thigh-level concepts\n",
      "T6\tOtherScientificTerm 324 341\taction attributes\n",
      "T7\tOtherScientificTerm 355 372\taction attributes\n",
      "T8\tOtherScientificTerm 416 438\tdata-driven attributes\n",
      "T9\tMethod 474 501\tdictionary learning methods\n",
      "T10\tMethod 503 533\tAttribute-based representation\n",
      "T11\tOtherScientificTerm 567 597\tnoisy and redundant attributes\n",
      "T12\tMethod 612 669\tdiscriminative and compact attribute-based representation\n",
      "T13\tOtherScientificTerm 695 720\tdiscriminative attributes\n",
      "T14\tMetric 755 783\tattribute selection criteria\n",
      "T15\tTask 817 848\tsubmodular optimization problem\n",
      "T16\tMethod 852 881\tgreedy optimization algorithm\n",
      "T17\tMaterial 991 1025\tOlympic Sports and UCF101 datasets\n",
      "T18\tMethod 1056 1086\tattribute-based representation\n",
      "T19\tMethod 1130 1159\taction recognition algorithms\n",
      "T20\tMethod 1198 1220\trecognition approaches\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R3\tEVALUATE-FOR Arg1:T17 Arg2:T18\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R6\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R7\tCOMPARE Arg1:T19 Arg2:T20\n",
      "R8\tCOREF Arg1:T18 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2015_10_abs.ann\n",
      "T1\tMethod 23 54\tnon-uniform sampling strategies\n",
      "T2\tMethod 87 121\tstochastic optimization algorithms\n",
      "T3\tOtherScientificTerm 127 145\tlinear convergence\n",
      "T4\tMethod 156 199\tStochastic Variance Reduced Gradient (SVRG)\n",
      "T5\tMethod 204 244\tStochastic Dual Coordinate Ascent (SDCA)\n",
      "T6\tTask 268 314\tpenalized empirical risk minimization problems\n",
      "T7\tGeneric 321 328\tmethods\n",
      "T8\tOtherScientificTerm 337 368\tdata dependent local smoothness\n",
      "T9\tOtherScientificTerm 376 390\tloss functions\n",
      "T10\tOtherScientificTerm 400 407\toptimum\n",
      "T11\tOtherScientificTerm 427 449\tconvergence guarantees\n",
      "T12\tOtherScientificTerm 514 530\tlocal smoothness\n",
      "T13\tGeneric 659 665\ttheory\n",
      "T14\tGeneric 691 701\talgorithms\n",
      "T15\tOtherScientificTerm 713 729\tlocal smoothness\n",
      "R1\tFEATURE-OF Arg1:T3 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R3\tHYPONYM-OF Arg1:T4 Arg2:T2\n",
      "R4\tHYPONYM-OF Arg1:T5 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tFEATURE-OF Arg1:T8 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R10\tCOREF Arg1:T7 Arg2:T1\n",
      "R11\tCOREF Arg1:T13 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2015_18_abs.ann\n",
      "T1\tTask 15 32\tmodeling problems\n",
      "T2\tMaterial 41 54\tdiscrete data\n",
      "T3\tMethod 95 135\tmultinomial or categorical distributions\n",
      "T4\tMaterial 150 179\tnucleotides in a DNA sequence\n",
      "T5\tMaterial 229 243\ttext documents\n",
      "T6\tMethod 274 299\tmultinomial distributions\n",
      "T7\tOtherScientificTerm 381 391\tnucleotide\n",
      "T8\tOtherScientificTerm 415 425\tDNA strand\n",
      "T9\tOtherScientificTerm 444 465\tpreceding nucleotides\n",
      "T10\tMethod 636 669\tDirichlet-multinomial formulation\n",
      "T11\tMethod 691 729\tlogistic stick-breaking representation\n",
      "T12\tTask 756 780\tPÃ³lya-gamma augmentation\n",
      "T13\tMethod 801 825\tmultinomial distribution\n",
      "T14\tOtherScientificTerm 838 854\tlatent variables\n",
      "T15\tOtherScientificTerm 860 888\tjointly Gaussian likelihoods\n",
      "T16\tMethod 933 962\tBayesian inference techniques\n",
      "T17\tMethod 967 982\tGaussian models\n",
      "T18\tOtherScientificTerm 988 1004\tminimal overhead\n",
      "R1\tHYPONYM-OF Arg1:T6 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R5\tFEATURE-OF Arg1:T18 Arg2:T17\n",
      "R6\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R8\tFEATURE-OF Arg1:T15 Arg2:T14\n",
      "R9\tPART-OF Arg1:T14 Arg2:T13\n",
      "R10\tCOREF Arg1:T13 Arg2:T6\n",
      "R11\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R12\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2015_21_abs.ann\n",
      "T1\tMethod 23 52\tconvolutional neural networks\n",
      "T2\tGeneric 91 95\tthey\n",
      "T3\tMethod 130 163\tStochastic attention-based models\n",
      "T4\tMetric 191 215\tcomputational efficiency\n",
      "T5\tGeneric 234 238\tthey\n",
      "T6\tTask 276 307\tintractable posterior inference\n",
      "T7\tTask 333 362\tstochastic gradient estimates\n",
      "T8\tMethod 364 384\tBorrowing techniques\n",
      "T9\tMethod 417 439\tdeep generative models\n",
      "T10\tMethod 456 492\tWake-Sleep Recurrent Attention Model\n",
      "T11\tGeneric 496 502\tmethod\n",
      "T12\tMethod 516 545\tstochastic attention networks\n",
      "T13\tTask 561 580\tposterior inference\n",
      "T14\tOtherScientificTerm 622 642\tstochastic gradients\n",
      "T15\tGeneric 661 667\tmethod\n",
      "T16\tMetric 693 706\ttraining time\n",
      "T17\tMethod 711 740\tstochastic attention networks\n",
      "T18\tTask 759 779\timage classification\n",
      "T19\tTask 784 802\tcaption generation\n",
      "R1\tEVALUATE-FOR Arg1:T4 Arg2:T3\n",
      "R2\tCOREF Arg1:T10 Arg2:T11\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R6\tCOREF Arg1:T10 Arg2:T15\n",
      "R7\tEVALUATE-FOR Arg1:T18 Arg2:T15\n",
      "R8\tEVALUATE-FOR Arg1:T19 Arg2:T15\n",
      "R9\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R10\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R11\tCOREF Arg1:T3 Arg2:T5\n",
      "R12\tCOREF Arg1:T1 Arg2:T2\n",
      "R13\tCOREF Arg1:T3 Arg2:T12\n",
      "R14\tCOREF Arg1:T17 Arg2:T12\n",
      "R15\tFEATURE-OF Arg1:T16 Arg2:T17\n",
      "R16\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2016_560_abs.ann\n",
      "T1\tTask 0 30\tJoint matrix triangularization\n",
      "T2\tOtherScientificTerm 64 84\tjoint eigenstructure\n",
      "T3\tTask 130 147\tsignal processing\n",
      "T4\tTask 152 168\tmachine learning\n",
      "T5\tTask 197 239\tapproximate joint matrix triangularization\n",
      "T6\tOtherScientificTerm 400 423\tfirst-order upper bound\n",
      "T7\tMethod 452 484\tapproximate joint triangularizer\n",
      "T8\tMethod 515 541\texact joint triangularizer\n",
      "T9\tGeneric 568 573\tbound\n",
      "T10\tMethod 718 732\ttriangularizer\n",
      "T11\tOtherScientificTerm 869 885\tposteriori bound\n",
      "T12\tTask 890 916\tjoint matrix decomposition\n",
      "T13\tMaterial 946 960\tsynthetic data\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "R5\tHYPONYM-OF Arg1:T5 Arg2:T1\n",
      "R6\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R7\tCOREF Arg1:T9 Arg2:T6\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\NIPS_2016_80_abs.ann\n",
      "T1\tGeneric 0 15\tFast algorithms\n",
      "T2\tTask 20 48\tnearest neighbor (NN) search\n",
      "T3\tOtherScientificTerm 81 89\tdistance\n",
      "T4\tGeneric 110 118\tapproach\n",
      "T5\tOtherScientificTerm 123 133\t1 distance\n",
      "T6\tOtherScientificTerm 175 204\tdistance-preserving embedding\n",
      "T7\tGeneric 241 245\tthis\n",
      "T8\tMethod 279 310\trandom-projection based methods\n",
      "T9\tTask 317 326\tNN search\n",
      "T10\tMethod 336 368\tlocality-sensitive hashing (LSH)\n",
      "T11\tMethod 372 395\trandom projection trees\n",
      "T12\tMethod 490 493\tLSH\n",
      "T13\tGeneric 499 501\tit\n",
      "T14\tGeneric 544 556\talternatives\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tCOREF Arg1:T2 Arg2:T9\n",
      "R4\tCOREF Arg1:T4 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R6\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R7\tHYPONYM-OF Arg1:T10 Arg2:T8\n",
      "R8\tHYPONYM-OF Arg1:T11 Arg2:T8\n",
      "R9\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R10\tCOREF Arg1:T10 Arg2:T12\n",
      "R11\tCOREF Arg1:T12 Arg2:T13\n",
      "R12\tCOMPARE Arg1:T13 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P01-1004.ann\n",
      "T1\tOtherScientificTerm 52 65\tsegment order\n",
      "T2\tOtherScientificTerm 70 82\tsegmentation\n",
      "T3\tOtherScientificTerm 89 107\tsegment contiguity\n",
      "T4\tTask 117 126\tretrieval\n",
      "T5\tMethod 146 171\ttranslation memory system\n",
      "T6\tMethod 204 270\tbag-of-words and segment order-sensitive string comparison methods\n",
      "T7\tMaterial 298 332\tcharacter- and word-segmented data\n",
      "T8\tMethod 368 399\tlocal segment contiguity models\n",
      "T9\tMethod 418 425\tN-grams\n",
      "T10\tTask 475 483\tindexing\n",
      "T11\tMethod 506 523\tcharacter bigrams\n",
      "T12\tMetric 537 555\tretrieval accuracy\n",
      "T13\tMethod 588 606\tword N-gram models\n",
      "T14\tMethod 654 674\tbag-of-words methods\n",
      "T15\tMethod 707 738\tsegment order-sensitive methods\n",
      "T16\tMetric 753 771\tretrieval accuracy\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R3\tCOMPARE Arg1:T14 Arg2:T15\n",
      "R4\tEVALUATE-FOR Arg1:T4 Arg2:T5\n",
      "R5\tCONJUNCTION Arg1:T8 Arg2:T6\n",
      "R6\tFEATURE-OF Arg1:T9 Arg2:T8\n",
      "R7\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R8\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R9\tUSED-FOR Arg1:T1 Arg2:T5\n",
      "R10\tUSED-FOR Arg1:T2 Arg2:T5\n",
      "R11\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R12\tCOMPARE Arg1:T11 Arg2:T13\n",
      "R13\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "R14\tEVALUATE-FOR Arg1:T16 Arg2:T14\n",
      "R15\tCOREF Arg1:T16 Arg2:T12\n",
      "R16\tEVALUATE-FOR Arg1:T12 Arg2:T13\n",
      "R17\tEVALUATE-FOR Arg1:T12 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P01-1007.ann\n",
      "T1\tMethod 31 74\trange concatenation grammar [RCG] formalism\n",
      "T2\tTask 138 141\tNLP\n",
      "T3\tOtherScientificTerm 161 196\trange concatenation languages [RCL]\n",
      "T4\tOtherScientificTerm 216 231\tpolynomial time\n",
      "T5\tMethod 253 275\tgrammatical formalisms\n",
      "T6\tMethod 312 316\tRCGs\n",
      "T7\tMetric 344 378\tworst-case parsing time complexity\n",
      "T8\tMethod 435 438\tRCG\n",
      "T9\tMethod 447 469\ttree adjoining grammar\n",
      "T10\tOtherScientificTerm 489 499\tO(n6) time\n",
      "T11\tMethod 530 547\tparsing technique\n",
      "T12\tMethod 606 617\tRCL parsers\n",
      "T13\tMethod 626 651\tnon-deterministic parsing\n",
      "T14\tMethod 669 680\tmain parser\n",
      "T15\tOtherScientificTerm 689 699\tlanguage L\n",
      "T16\tOtherScientificTerm 743 767\tshared derivation forest\n",
      "T17\tMethod 788 798\tRCL parser\n",
      "T18\tGeneric 879 885\tmethod\n",
      "T19\tMethod 892 921\twide coverage English grammar\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "R3\tFEATURE-OF Arg1:T10 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R5\tCOREF Arg1:T1 Arg2:T6\n",
      "R6\tEVALUATE-FOR Arg1:T7 Arg2:T5\n",
      "R7\tCOREF Arg1:T6 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R9\tEVALUATE-FOR Arg1:T19 Arg2:T18\n",
      "R10\tCOREF Arg1:T12 Arg2:T17\n",
      "R11\tCOREF Arg1:T11 Arg2:T18\n",
      "R12\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P01-1008.ann\n",
      "T1\tMethod 8 20\tparaphrasing\n",
      "T2\tTask 44 93\tinterpretation and generation of natural language\n",
      "T3\tGeneric 105 112\tsystems\n",
      "T4\tMethod 117 149\tmanual or semi-automatic methods\n",
      "T5\tOtherScientificTerm 162 173\tparaphrases\n",
      "T6\tMethod 192 223\tunsupervised learning algorithm\n",
      "T7\tTask 230 259\tidentification of paraphrases\n",
      "T8\tMaterial 269 308\tcorpus of multiple English translations\n",
      "T9\tGeneric 342 350\tapproach\n",
      "T10\tOtherScientificTerm 359 402\tphrasal and single word lexical paraphrases\n",
      "T11\tOtherScientificTerm 416 437\tsyntactic paraphrases\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T11\n",
      "R7\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R9\tCOREF Arg1:T6 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P01-1009.ann\n",
      "T1\tMethod 24 39\tformal analysis\n",
      "T2\tOtherScientificTerm 78 97\talternative markers\n",
      "T3\tGeneric 170 175\twords\n",
      "T4\tOtherScientificTerm 206 212\tdialog\n",
      "T5\tMethod 260 291\tnatural language search engines\n",
      "T6\tGeneric 332 336\tthem\n",
      "T7\tMethod 374 387\tsearch engine\n",
      "T8\tMethod 438 475\tapproximation of the  formal analysis\n",
      "T9\tMethod 460 475\tformal analysis\n",
      "T10\tMethod 506 519\tsearch engine\n",
      "T11\tOtherScientificTerm 525 546\toperational semantics\n",
      "T12\tGeneric 568 576\tapproach\n",
      "T13\tOtherScientificTerm 593 614\toperational semantics\n",
      "T14\tTask 620 649\tnatural language applications\n",
      "R1\tPART-OF Arg1:T13 Arg2:T14\n",
      "R2\tCOREF Arg1:T1 Arg2:T9\n",
      "R3\tPART-OF Arg1:T11 Arg2:T10\n",
      "R4\tPART-OF Arg1:T8 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tCOREF Arg1:T1 Arg2:T12\n",
      "R7\tCOREF Arg1:T7 Arg2:T10\n",
      "R8\tCOREF Arg1:T5 Arg2:T7\n",
      "R9\tCOREF Arg1:T2 Arg2:T3\n",
      "R10\tCOREF Arg1:T3 Arg2:T6\n",
      "R11\tPART-OF Arg1:T3 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P01-1047.ann\n",
      "T1\tMethod 15 58\tlogical definition  of  Minimalist grammars\n",
      "T2\tMethod 72 129\tStabler's formalization  of  Chomsky's minimalist program\n",
      "T3\tMethod 138 156\tlogical definition\n",
      "T4\tMethod 187 205\tcategorial grammar\n",
      "T5\tOtherScientificTerm 235 253\tMontague semantics\n",
      "T6\tMethod 261 281\tparsing-as-deduction\n",
      "T7\tOtherScientificTerm 289 313\tresource sensitive logic\n",
      "T8\tMethod 324 342\tlearning algorithm\n",
      "T9\tMaterial 350 365\tstructured data\n",
      "T10\tMethod 380 396\ttyping-algorithm\n",
      "T11\tMethod 403 419\ttype-unification\n",
      "T12\tOtherScientificTerm 461 479\tMontague semantics\n",
      "T13\tOtherScientificTerm 507 547\tformal computation  of the  logical form\n",
      "T14\tOtherScientificTerm 535 547\tlogical form\n",
      "R1\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R2\tCOREF Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T8\n",
      "R5\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R6\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R7\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R8\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P01-1056.ann\n",
      "T1\tGeneric 2 12\tTechniques\n",
      "T2\tMethod 17 48\tautomatically training  modules\n",
      "T3\tMethod 55 81\tnatural language generator\n",
      "T4\tMetric 154 177\tquality  of  utterances\n",
      "T5\tOtherScientificTerm 167 177\tutterances\n",
      "T6\tMethod 194 214\ttrainable components\n",
      "T7\tMethod 234 286\thand-crafted template-based or rule-based approaches\n",
      "T8\tMethod 334 360\ttrainable sentence planner\n",
      "T9\tMethod 369 391\tspoken dialogue system\n",
      "T10\tOtherScientificTerm 407 433\tsubjective human judgments\n",
      "T11\tMethod 503 551\thand-crafted template-based generation component\n",
      "T12\tMethod 560 588\trule-based sentence planners\n",
      "T13\tMethod 601 627\tbaseline sentence planners\n",
      "T14\tMethod 649 675\ttrainable sentence planner\n",
      "T15\tMethod 703 721\trule-based systems\n",
      "T16\tGeneric 732 741\tbaselines\n",
      "T17\tMethod 765 784\thand-crafted system\n",
      "R1\tCOMPARE Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R3\tCOMPARE Arg1:T14 Arg2:T15\n",
      "R4\tEVALUATE-FOR Arg1:T5 Arg2:T6\n",
      "R5\tPART-OF Arg1:T2 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R7\tEVALUATE-FOR Arg1:T10 Arg2:T8\n",
      "R8\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R9\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R10\tCOMPARE Arg1:T14 Arg2:T17\n",
      "R11\tCOMPARE Arg1:T14 Arg2:T16\n",
      "R12\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R13\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R14\tCOREF Arg1:T12 Arg2:T15\n",
      "R15\tCOREF Arg1:T13 Arg2:T16\n",
      "R16\tCOREF Arg1:T11 Arg2:T17\n",
      "R17\tCOREF Arg1:T8 Arg2:T14\n",
      "R18\tEVALUATE-FOR Arg1:T5 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P01-1070.ann\n",
      "T1\tMethod 23 50\tsupervised machine learning\n",
      "T2\tMethod 98 134\tstatistical models  of  WH-questions\n",
      "T3\tGeneric 145 151\tmodels\n",
      "T4\tOtherScientificTerm 177 219\tshallow linguistic features  of  questions\n",
      "T5\tOtherScientificTerm 283 309\tuser's informational goals\n",
      "T6\tGeneric 384 390\tmodels\n",
      "T7\tOtherScientificTerm 430 458\ttraining and testing factors\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R4\tCOREF Arg1:T3 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P02-1023.ann\n",
      "T1\tTask 1 35\tReducing  language model (LM) size\n",
      "T2\tMethod 74 76\tLM\n",
      "T3\tOtherScientificTerm 115 134\tmemory constraints.\n",
      "T4\tTask 197 207\tLM pruning\n",
      "T5\tOtherScientificTerm 233 237\trank\n",
      "T6\tOtherScientificTerm 245 252\tentropy\n",
      "T7\tOtherScientificTerm 298 314\tpruning criteria\n",
      "T8\tMaterial 342 360\tChinese text input\n",
      "T9\tMetric 375 401\tcharacter error rate (CER)\n",
      "T10\tOtherScientificTerm 460 464\trank\n",
      "T11\tOtherScientificTerm 542 546\trank\n",
      "T12\tMetric 585 595\terror rate\n",
      "T13\tGeneric 622 628\tmethod\n",
      "T14\tTask 659 672\tmodel pruning\n",
      "T15\tMetric 843 846\tCER\n",
      "R1\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R3\tEVALUATE-FOR Arg1:T9 Arg2:T7\n",
      "R4\tEVALUATE-FOR Arg1:T12 Arg2:T11\n",
      "R5\tCOREF Arg1:T15 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P02-1059.ann\n",
      "T1\tMethod 65 84\tsupervised learning\n",
      "T2\tMethod 92 113\tunsupervised learning\n",
      "T3\tTask 128 158\thuman biases in  summarization\n",
      "T4\tOtherScientificTerm 199 226\tprobabilistic decision tree\n",
      "T5\tMethod 239 259\tclustering framework\n",
      "T6\tMaterial 315 338\thuman created summaries\n",
      "T7\tMaterial 346 379\tcorpus  of human created extracts\n",
      "T8\tMaterial 399 415\tnewspaper corpus\n",
      "T9\tOtherScientificTerm 451 479\tprobabilistic decision trees\n",
      "T10\tGeneric 524 528\tthem\n",
      "T11\tMethod 538 558\tclustering framework\n",
      "T12\tGeneric 582 588\tcorpus\n",
      "R1\tCONJUNCTION Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R4\tFEATURE-OF Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R6\tCOREF Arg1:T7 Arg2:T12\n",
      "R7\tCOREF Arg1:T9 Arg2:T10\n",
      "R8\tCONJUNCTION Arg1:T11 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P02-1060.ann\n",
      "T1\tMethod 24 49\tHidden Markov Model (HMM)\n",
      "T2\tMethod 59 81\tHMM-based chunk tagger\n",
      "T3\tMethod 98 140\tnamed entity (NE) recognition (NER) system\n",
      "T4\tOtherScientificTerm 178 183\tnames\n",
      "T5\tOtherScientificTerm 187 217\ttimes and numerical quantities\n",
      "T6\tMethod 233 236\tHMM\n",
      "T7\tOtherScientificTerm 339 383\tdeterministic internal feature of the  words\n",
      "T8\tOtherScientificTerm 395 409\tcapitalization\n",
      "T9\tOtherScientificTerm 415 429\tdigitalization\n",
      "T10\tOtherScientificTerm 491 517\tinternal gazetteer feature\n",
      "T11\tOtherScientificTerm 524 554\texternal macro context feature\n",
      "T12\tTask 575 586\tNER problem\n",
      "T13\tGeneric 636 642\tsystem\n",
      "T14\tMaterial 648 680\tMUC-6 and MUC-7 English NE tasks\n",
      "T15\tMetric 692 702\tF-measures\n",
      "T16\tMethod 819 842\tmachine-learning system\n",
      "T17\tOtherScientificTerm 922 939\thandcrafted rules\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T1 Arg2:T6\n",
      "R5\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R6\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R7\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R8\tEVALUATE-FOR Arg1:T15 Arg2:T13\n",
      "R9\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R10\tCOREF Arg1:T3 Arg2:T13\n",
      "R11\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R12\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R13\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1002.ann\n",
      "T1\tMethod 51 62\tIE paradigm\n",
      "T2\tOtherScientificTerm 89 118\tpredicate-argument structures\n",
      "T3\tTask 153 209\tautomatically identifying  predicate argument structures\n",
      "T4\tMethod 238 249\tIE paradigm\n",
      "T5\tGeneric 253 255\tIt\n",
      "T6\tOtherScientificTerm 293 301\tfeatures\n",
      "T7\tMethod 314 346\tinductive decision tree learning\n",
      "T8\tOtherScientificTerm 406 435\tpredicate-argument structures\n",
      "T9\tTask 458 460\tIE\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R3\tCOREF Arg1:T5 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1005.ann\n",
      "T1\tMethod 26 75\tHierarchical Directed Acyclic Graph (HDAG) Kernel\n",
      "T2\tMaterial 82 114\tstructured natural language data\n",
      "T3\tMethod 123 134\tHDAG Kernel\n",
      "T4\tMethod 311 316\tHDAGs\n",
      "T5\tGeneric 344 350\tmethod\n",
      "T6\tTask 355 409\tquestion classification  and  sentence alignment tasks\n",
      "T7\tMetric 445 463\tsimilarity measure\n",
      "T8\tMethod 472 487\tkernel function\n",
      "T9\tMethod 544 555\tHDAG Kernel\n",
      "T10\tMethod 579 595\tkernel functions\n",
      "T11\tGeneric 602 618\tbaseline methods\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOMPARE Arg1:T9 Arg2:T10\n",
      "R3\tCOREF Arg1:T3 Arg2:T1\n",
      "R4\tCOREF Arg1:T3 Arg2:T4\n",
      "R5\tCOREF Arg1:T4 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R7\tCOREF Arg1:T5 Arg2:T9\n",
      "R8\tCOMPARE Arg1:T9 Arg2:T11\n",
      "R9\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R10\tEVALUATE-FOR Arg1:T7 Arg2:T5\n",
      "R11\tEVALUATE-FOR Arg1:T8 Arg2:T5\n",
      "R12\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1009.ann\n",
      "T1\tMethod 52 62\tclustering\n",
      "T2\tTask 67 98\tinducing  semantic verb classes\n",
      "T3\tMaterial 105 133\tundisambiguated  corpus data\n",
      "T4\tGeneric 155 163\tapproach\n",
      "T5\tTask 179 235\tclustering  subcategorization frame (SCF)  distributions\n",
      "T6\tMethod 247 302\tInformation Bottleneck  and  nearest neighbour  methods\n",
      "T7\tTask 359 386\tclustering  polysemic verbs\n",
      "T8\tOtherScientificTerm 371 386\tpolysemic verbs\n",
      "T9\tGeneric 399 416\tevaluation scheme\n",
      "T10\tOtherScientificTerm 464 472\tpolysemy\n",
      "T11\tOtherScientificTerm 482 490\tclusters\n",
      "T12\tTask 560 611\tsemantically classifying   undisambiguated SCF data\n",
      "R1\tFEATURE-OF Arg1:T10 Arg2:T11\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tPART-OF Arg1:T5 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R7\tEVALUATE-FOR Arg1:T9 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1022.ann\n",
      "T1\tMethod 13 41\tdecision tree based approach\n",
      "T2\tTask 47 65\tpronoun resolution\n",
      "T3\tTask 71 86\tspoken dialogue\n",
      "T4\tGeneric 94 100\tsystem\n",
      "T5\tOtherScientificTerm 113 121\tpronouns\n",
      "T6\tOtherScientificTerm 129 155\tNP- and non-NP-antecedents\n",
      "T7\tOtherScientificTerm 180 188\tfeatures\n",
      "T8\tTask 204 222\tpronoun resolution\n",
      "T9\tTask 228 243\tspoken dialogue\n",
      "T10\tOtherScientificTerm 279 287\tfeatures\n",
      "T11\tGeneric 307 313\tsystem\n",
      "T12\tMaterial 325 346\tSwitchboard dialogues\n",
      "T13\tGeneric 362 364\tit\n",
      "T14\tMethod 383 419\tByron's (2002) manually tuned system\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R6\tCOREF Arg1:T1 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R8\tCOREF Arg1:T4 Arg2:T11\n",
      "R9\tEVALUATE-FOR Arg1:T12 Arg2:T11\n",
      "R10\tCOREF Arg1:T11 Arg2:T13\n",
      "R11\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R12\tCOREF Arg1:T3 Arg2:T9\n",
      "R13\tCOREF Arg1:T2 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1030.ann\n",
      "T1\tTask 2 16\tLink detection\n",
      "T2\tTask 66 125\tTopic Detection and Tracking tasks  of  new event detection\n",
      "T3\tTask 157 177\tstory link detection\n",
      "T4\tTask 184 203\tnew event detection\n",
      "T5\tTask 209 235\tinformation retrieval task\n",
      "T6\tMetric 271 280\tprecision\n",
      "T7\tMetric 287 293\trecall\n",
      "T8\tGeneric 303 310\tsystems\n",
      "T9\tMethod 371 403\tperformance enhancing techniques\n",
      "T10\tMethod 415 437\tpart of speech tagging\n",
      "T11\tMethod 446 465\tsimilarity measures\n",
      "T12\tOtherScientificTerm 471 491\texpanded  stop lists\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T3\n",
      "R4\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R5\tHYPONYM-OF Arg1:T4 Arg2:T8\n",
      "R6\tHYPONYM-OF Arg1:T3 Arg2:T8\n",
      "R7\tEVALUATE-FOR Arg1:T7 Arg2:T8\n",
      "R8\tEVALUATE-FOR Arg1:T6 Arg2:T8\n",
      "R9\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R10\tPART-OF Arg1:T10 Arg2:T9\n",
      "R11\tPART-OF Arg1:T11 Arg2:T9\n",
      "R12\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R13\tPART-OF Arg1:T12 Arg2:T9\n",
      "R14\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1031.ann\n",
      "T1\tTask 26 57\tdiscourse understanding process\n",
      "T2\tMethod 63 86\tspoken dialogue systems\n",
      "T3\tGeneric 115 121\tsystem\n",
      "T4\tMaterial 137 152\tuser utterances\n",
      "T5\tMaterial 277 291\tuser utterance\n",
      "T6\tOtherScientificTerm 305 340\tambiguity  of  speech understanding\n",
      "T7\tOtherScientificTerm 423 437\tuser utterance\n",
      "T8\tGeneric 521 530\tambiguity\n",
      "T9\tMetric 567 599\tdiscourse understanding accuracy\n",
      "T10\tGeneric 640 646\tmethod\n",
      "T11\tGeneric 667 676\tambiguity\n",
      "T12\tOtherScientificTerm 688 711\tstatistical information\n",
      "T13\tMaterial 728 744\tdialogue corpora\n",
      "T14\tGeneric 768 775\tmethods\n",
      "T15\tOtherScientificTerm 786 804\thand-crafted rules\n",
      "T16\tGeneric 821 827\tmethod\n",
      "T17\tTask 856 887\tdiscourse understanding process\n",
      "T18\tGeneric 928 934\tsystem\n",
      "T19\tGeneric 962 968\tmethod\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R3\tCOREF Arg1:T2 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R5\tCOREF Arg1:T6 Arg2:T8\n",
      "R6\tCOREF Arg1:T8 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R10\tCOREF Arg1:T10 Arg2:T16\n",
      "R11\tCOREF Arg1:T1 Arg2:T17\n",
      "R12\tCOREF Arg1:T16 Arg2:T19\n",
      "R13\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1033.ann\n",
      "T1\tMethod 25 38\tuser modeling\n",
      "T2\tOtherScientificTerm 62 83\tcooperative responses\n",
      "T3\tTask 104 127\tspoken dialogue systems\n",
      "T4\tGeneric 147 154\tstudies\n",
      "T5\tMethod 226 236\tuser model\n",
      "T6\tMethod 317 328\tuser models\n",
      "T7\tGeneric 449 455\tmodels\n",
      "T8\tMethod 487 509\tdecision tree learning\n",
      "T9\tMaterial 517 536\treal  dialogue data\n",
      "T10\tGeneric 555 561\tsystem\n",
      "T11\tMetric 587 610\tclassification accuracy\n",
      "T12\tMethod 633 652\tDialogue strategies\n",
      "T13\tMethod 668 681\tuser modeling\n",
      "T14\tMethod 703 736\tKyoto city bus information system\n",
      "T15\tOtherScientificTerm 821 842\tcooperative responses\n",
      "T16\tOtherScientificTerm 941 958\tdialogue duration\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R4\tPART-OF Arg1:T1 Arg2:T3\n",
      "R5\tCOREF Arg1:T5 Arg2:T1\n",
      "R6\tCOREF Arg1:T5 Arg2:T6\n",
      "R7\tCOREF Arg1:T6 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R10\tCOREF Arg1:T7 Arg2:T13\n",
      "R11\tCOMPARE Arg1:T4 Arg2:T5\n",
      "R12\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1034.ann\n",
      "T1\tMethod 2 53\tPipelined Natural Language Generation (NLG) systems\n",
      "T2\tMethod 91 112\tarchitectural modules\n",
      "T3\tOtherScientificTerm 137 161\tlanguage functionalities\n",
      "T4\tOtherScientificTerm 172 193\treferring expressions\n",
      "T5\tOtherScientificTerm 197 211\tlexical choice\n",
      "T6\tOtherScientificTerm 219 227\trevision\n",
      "T7\tGeneric 308 315\tmodules\n",
      "T8\tGeneric 324 345\toverall  architecture\n",
      "T9\tMaterial 382 402\tmulti-paragraph text\n",
      "T10\tOtherScientificTerm 406 423\tdiscourse markers\n",
      "T11\tMethod 468 504\tdiscourse marker insertion algorithm\n",
      "T12\tMethod 560 586\tpipelined NLG architecture\n",
      "T13\tGeneric 598 606\tapproach\n",
      "T14\tGeneric 626 628\tit\n",
      "T15\tMethod 635 653\trevision component\n",
      "T16\tGeneric 681 689\tapproach\n",
      "T17\tTask 704 721\tmulti-page system\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tPART-OF Arg1:T15 Arg2:T12\n",
      "R3\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R4\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R5\tHYPONYM-OF Arg1:T6 Arg2:T3\n",
      "R6\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R7\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R8\tCOREF Arg1:T2 Arg2:T7\n",
      "R9\tPART-OF Arg1:T7 Arg2:T8\n",
      "R10\tCOREF Arg1:T1 Arg2:T8\n",
      "R11\tCOREF Arg1:T8 Arg2:T12\n",
      "R12\tEVALUATE-FOR Arg1:T17 Arg2:T16\n",
      "R13\tCOREF Arg1:T11 Arg2:T14\n",
      "R14\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R15\tCOREF Arg1:T13 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1050.ann\n",
      "T1\tMethod 25 55\tunsupervised learning approach\n",
      "T2\tTask 72 100\tnon-English (Arabic) stemmer\n",
      "T3\tMethod 109 123\tstemming model\n",
      "T4\tMethod 138 169\tstatistical machine translation\n",
      "T5\tGeneric 175 177\tit\n",
      "T6\tMethod 187 202\tEnglish stemmer\n",
      "T7\tMaterial 233 248\tparallel corpus\n",
      "T8\tMaterial 289 302\tparallel text\n",
      "T9\tMaterial 344 373\tMonolingual, unannotated text\n",
      "T10\tMethod 411 418\tstemmer\n",
      "T11\tGeneric 432 434\tit\n",
      "T12\tMaterial 519 525\tArabic\n",
      "T13\tGeneric 537 545\tapproach\n",
      "T14\tOtherScientificTerm 590 603\taffix removal\n",
      "T15\tMethod 612 636\tresource-frugal approach\n",
      "T16\tMetric 656 665\tagreement\n",
      "T17\tMethod 705 719\tArabic stemmer\n",
      "T18\tOtherScientificTerm 734 739\trules\n",
      "T19\tMaterial 744 755\taffix lists\n",
      "T20\tMaterial 764 784\thuman annotated text\n",
      "T21\tMethod 807 829\tunsupervised component\n",
      "T22\tMethod 834 855\tTask-based evaluation\n",
      "T23\tTask 864 892\tArabic information retrieval\n",
      "T24\tMetric 933 950\taverage precision\n",
      "T25\tMaterial 958 972\tunstemmed text\n",
      "T26\tMethod 1023 1030\tstemmer\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R3\tCOREF Arg1:T3 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R7\tCOREF Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T2 Arg2:T3\n",
      "R9\tCOREF Arg1:T5 Arg2:T10\n",
      "R10\tCOREF Arg1:T1 Arg2:T13\n",
      "R11\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R12\tUSED-FOR Arg1:T19 Arg2:T17\n",
      "R13\tUSED-FOR Arg1:T20 Arg2:T17\n",
      "R14\tCONJUNCTION Arg1:T18 Arg2:T19\n",
      "R15\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R16\tUSED-FOR Arg1:T21 Arg2:T17\n",
      "R17\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R18\tCOMPARE Arg1:T15 Arg2:T17\n",
      "R19\tEVALUATE-FOR Arg1:T16 Arg2:T17\n",
      "R20\tEVALUATE-FOR Arg1:T16 Arg2:T15\n",
      "R21\tCOREF Arg1:T13 Arg2:T15\n",
      "R22\tCOREF Arg1:T17 Arg2:T26\n",
      "R23\tUSED-FOR Arg1:T23 Arg2:T22\n",
      "R24\tEVALUATE-FOR Arg1:T24 Arg2:T22\n",
      "R25\tEVALUATE-FOR Arg1:T24 Arg2:T25\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1058.ann\n",
      "T1\tTask 24 55\tword sense disambiguation (WSD)\n",
      "T2\tMaterial 73 99\tmanually sense-tagged data\n",
      "T3\tMethod 115 134\tsupervised learning\n",
      "T4\tGeneric 168 176\tapproach\n",
      "T5\tMaterial 203 229\tsense-tagged training data\n",
      "T6\tMaterial 237 269\tEnglish-Chinese parallel corpora\n",
      "T7\tOtherScientificTerm 317 322\tnouns\n",
      "T8\tMaterial 332 370\tSENSEVAL-2 English lexical sample task\n",
      "T9\tGeneric 411 417\tmethod\n",
      "T10\tTask 421 448\tacquiring sense-tagged data\n",
      "T11\tOtherScientificTerm 499 515\tSENSEVAL-2 nouns\n",
      "T12\tMetric 524 532\taccuracy\n",
      "T13\tMaterial 671 697\tmanually sense-tagged data\n",
      "T14\tMetric 714 728\tsense coverage\n",
      "T15\tOtherScientificTerm 793 810\tdomain dependence\n",
      "T16\tTask 815 839\tevaluating  WSD programs\n",
      "T17\tTask 827 839\tWSD programs\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T7\n",
      "R5\tPART-OF Arg1:T7 Arg2:T8\n",
      "R6\tCOREF Arg1:T1 Arg2:T17\n",
      "R7\tFEATURE-OF Arg1:T15 Arg2:T16\n",
      "R8\tFEATURE-OF Arg1:T14 Arg2:T13\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R10\tCOREF Arg1:T4 Arg2:T9\n",
      "R11\tCOREF Arg1:T2 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1068.ann\n",
      "T1\tMaterial 51 80\tsemantically annotated corpus\n",
      "T2\tTask 117 170\tlarge-scale  acquisition of word-semantic information\n",
      "T3\tTask 183 225\tconstruction of  domain-independent lexica\n",
      "T4\tOtherScientificTerm 250 260\tannotation\n",
      "T5\tOtherScientificTerm 267 281\tsemantic roles\n",
      "T6\tMethod 291 315\tframe semantics paradigm\n",
      "T7\tMaterial 359 373\tannotated data\n",
      "T8\tOtherScientificTerm 448 457\tvagueness\n",
      "T9\tOtherScientificTerm 464 473\tambiguity\n",
      "T10\tMethod 479 498\tsemantic annotation\n",
      "R1\tPART-OF Arg1:T5 Arg2:T6\n",
      "R2\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R3\tFEATURE-OF Arg1:T9 Arg2:T10\n",
      "R4\tFEATURE-OF Arg1:T8 Arg2:T10\n",
      "R5\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-1070.ann\n",
      "T1\tMethod 21 47\tverbal and nonverbal means\n",
      "T2\tTask 54 63\tgrounding\n",
      "T3\tGeneric 81 87\tdesign\n",
      "T4\tMethod 93 123\tembodied conversational agents\n",
      "T5\tTask 178 191\tcommon ground\n",
      "T6\tTask 197 223\thuman-computer interaction\n",
      "T7\tOtherScientificTerm 240 248\teye gaze\n",
      "T8\tOtherScientificTerm 253 262\thead nods\n",
      "T9\tOtherScientificTerm 269 286\tattentional focus\n",
      "T10\tTask 309 330\tdirection-giving task\n",
      "T11\tOtherScientificTerm 355 374\tnonverbal behaviors\n",
      "T12\tOtherScientificTerm 411 424\tdialogue move\n",
      "T13\tOtherScientificTerm 501 518\tnegative feedback\n",
      "T14\tMethod 561 564\tECA\n",
      "T15\tOtherScientificTerm 577 612\tverbal and nonverbal grounding acts\n",
      "T16\tOtherScientificTerm 625 639\tdialogue state\n",
      "R1\tPART-OF Arg1:T9 Arg2:T10\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R5\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R7\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R8\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R9\tPART-OF Arg1:T8 Arg2:T10\n",
      "R10\tPART-OF Arg1:T7 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P03-2036.ann\n",
      "T1\tMethod 29 53\tCFG filtering techniques\n",
      "T2\tMethod 60 64\tLTAG\n",
      "T3\tMethod 71 75\tHPSG\n",
      "T4\tMethod 114 136\tapproximation of  HPSG\n",
      "T5\tMethod 132 136\tHPSG\n",
      "T6\tMethod 165 175\tCFG filter\n",
      "T7\tGeneric 182 186\tthat\n",
      "T8\tMethod 191 195\tLTAG\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R3\tCOMPARE Arg1:T2 Arg2:T3\n",
      "R4\tCOMPARE Arg1:T6 Arg2:T7\n",
      "R5\tCOREF Arg1:T5 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R8\tCOREF Arg1:T2 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P04-1030.ann\n",
      "T1\tMethod 42 79\thead-driven statistical parsing model\n",
      "T2\tMethod 105 132\tsimultaneous language model\n",
      "T3\tMethod 139 145\tparser\n",
      "T4\tTask 152 187\tlarge-vocabulary speech recognition\n",
      "T5\tGeneric 194 199\tmodel\n",
      "T6\tMethod 218 251\tonline left to right chart-parser\n",
      "T7\tOtherScientificTerm 258 271\tword lattices\n",
      "T8\tOtherScientificTerm 286 328\tacoustic, n-gram, and parser probabilities\n",
      "T9\tMethod 335 341\tparser\n",
      "T10\tOtherScientificTerm 349 384\tstructural and lexical dependencies\n",
      "T11\tMethod 405 418\tn-gram models\n",
      "T12\tMaterial 513 541\tWall Street Journal treebank\n",
      "T13\tMaterial 547 562\tlattice corpora\n",
      "T14\tMetric 569 585\tword error rates\n",
      "T15\tMethod 618 639\tn-gram language model\n",
      "T16\tOtherScientificTerm 670 692\tstructural information\n",
      "T17\tTask 706 726\tspeech understanding\n",
      "R1\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R2\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T1 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R7\tPART-OF Arg1:T8 Arg2:T6\n",
      "R8\tCOREF Arg1:T6 Arg2:T9\n",
      "R9\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R10\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "R11\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R12\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R13\tEVALUATE-FOR Arg1:T14 Arg2:T15\n",
      "R14\tEVALUATE-FOR Arg1:T13 Arg2:T15\n",
      "R15\tEVALUATE-FOR Arg1:T12 Arg2:T15\n",
      "R16\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P04-2005.ann\n",
      "T1\tGeneric 20 28\tapproach\n",
      "T2\tTask 33 82\tautomatically acquiring  English topic signatures\n",
      "T3\tOtherScientificTerm 105 112\tconcept\n",
      "T4\tOtherScientificTerm 119 129\tword sense\n",
      "T5\tOtherScientificTerm 135 150\ttopic signature\n",
      "T6\tOtherScientificTerm 204 220\tTopic signatures\n",
      "T7\tTask 252 298\tNatural Language Processing (NLP) applications\n",
      "T8\tTask 310 341\tWord Sense Disambiguation (WSD)\n",
      "T9\tTask 348 366\tText Summarisation\n",
      "T10\tGeneric 373 379\tmethod\n",
      "T11\tOtherScientificTerm 427 438\tword senses\n",
      "T12\tMaterial 460 467\tEnglish\n",
      "T13\tMaterial 474 481\tChinese\n",
      "T14\tMaterial 523 535\tChinese text\n",
      "T15\tGeneric 551 558\tcorpora\n",
      "T16\tMaterial 571 574\tWeb\n",
      "T17\tOtherScientificTerm 594 610\ttopic signatures\n",
      "T18\tTask 618 626\tWSD task\n",
      "T19\tMethod 649 691\tsecond-order vector cooccurrence algorithm\n",
      "T20\tMaterial 706 718\tWSD datasets\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R2\tPART-OF Arg1:T14 Arg2:T15\n",
      "R3\tEVALUATE-FOR Arg1:T18 Arg2:T17\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T9\n",
      "R7\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R8\tCOREF Arg1:T1 Arg2:T10\n",
      "R9\tPART-OF Arg1:T14 Arg2:T16\n",
      "R10\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R11\tUSED-FOR Arg1:T20 Arg2:T19\n",
      "R12\tCOREF Arg1:T8 Arg2:T18\n",
      "R13\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R14\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P04-2010.ann\n",
      "T1\tMethod 30 56\tensemble learning approach\n",
      "T2\tOtherScientificTerm 72 87\tGerman pronouns\n",
      "T3\tMethod 91 99\tBoosting\n",
      "T4\tMethod 184 195\tclassifiers\n",
      "T5\tGeneric 255 263\tapproach\n",
      "T6\tMethod 289 313\tdecision-tree classifier\n",
      "T7\tMethod 343 360\tstandalone system\n",
      "T8\tOtherScientificTerm 377 385\tpronouns\n",
      "T9\tMaterial 391 407\tunannotated text\n",
      "T10\tMethod 449 470\tpreprocessing modules\n",
      "T11\tTask 489 514\tmanual annotation process\n",
      "T12\tGeneric 530 536\tsystem\n",
      "T13\tMaterial 569 583\ttextual domain\n",
      "T14\tGeneric 621 623\tit\n",
      "T15\tTask 639 669\topen-domain question answering\n",
      "T16\tTask 676 694\ttext summarisation\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T9\n",
      "R3\tCOMPARE Arg1:T13 Arg2:T15\n",
      "R4\tCOREF Arg1:T3 Arg2:T5\n",
      "R5\tCOMPARE Arg1:T5 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tPART-OF Arg1:T8 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T10 Arg2:T7\n",
      "R10\tCOREF Arg1:T7 Arg2:T12\n",
      "R11\tEVALUATE-FOR Arg1:T13 Arg2:T12\n",
      "R12\tCOREF Arg1:T12 Arg2:T14\n",
      "R13\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R14\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R15\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R16\tCOREF Arg1:T1 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1010.ann\n",
      "T1\tMethod 23 70\tgenerative probabilistic model  of  parse trees\n",
      "T2\tMethod 88 95\tPCFG-LA\n",
      "T3\tGeneric 104 109\tmodel\n",
      "T4\tMethod 131 135\tPCFG\n",
      "T5\tOtherScientificTerm 147 167\tnon-terminal symbols\n",
      "T6\tOtherScientificTerm 189 205\tlatent variables\n",
      "T7\tOtherScientificTerm 208 230\tFinegrained  CFG rules\n",
      "T8\tMaterial 266 279\tparsed corpus\n",
      "T9\tMethod 298 311\tPCFG-LA model\n",
      "T10\tMethod 323 335\tEM-algorithm\n",
      "T11\tTask 346 360\texact  parsing\n",
      "T12\tMethod 370 377\tPCFG-LA\n",
      "T13\tMaterial 484 499\tPenn WSJ corpus\n",
      "T14\tGeneric 529 534\tmodel\n",
      "T15\tMetric 567 569\tF1\n",
      "T16\tMethod 633 658\tunlexicalized PCFG parser\n",
      "T17\tMethod 685 709\tmanual feature selection\n",
      "R1\tUSED-FOR Arg1:T17 Arg2:T16\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R3\tCOREF Arg1:T1 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R6\tPART-OF Arg1:T5 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R10\tCOMPARE Arg1:T14 Arg2:T16\n",
      "R11\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R12\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R13\tEVALUATE-FOR Arg1:T13 Arg2:T14\n",
      "R14\tEVALUATE-FOR Arg1:T13 Arg2:T16\n",
      "R15\tCOREF Arg1:T2 Arg2:T9\n",
      "R16\tCOREF Arg1:T9 Arg2:T12\n",
      "R17\tCOREF Arg1:T12 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1018.ann\n",
      "T1\tTask 37 77\tautomatic assessment of  local coherence\n",
      "T2\tMethod 100 142\tentity-based representation  of  discourse\n",
      "T3\tMethod 166 182\tCentering Theory\n",
      "T4\tMaterial 224 232\traw text\n",
      "T5\tTask 244 264\tcoherence assessment\n",
      "T6\tTask 272 296\tranking learning problem\n",
      "T7\tMethod 326 350\tdiscourse representation\n",
      "T8\tOtherScientificTerm 390 406\tranking function\n",
      "T9\tMethod 447 460\tinduced model\n",
      "T10\tMetric 493 501\taccuracy\n",
      "T11\tMethod 528 543\tcoherence model\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T2\n",
      "R4\tCOREF Arg1:T1 Arg2:T5\n",
      "R5\tCOREF Arg1:T2 Arg2:T7\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tEVALUATE-FOR Arg1:T10 Arg2:T9\n",
      "R8\tCOMPARE Arg1:T9 Arg2:T11\n",
      "R9\tEVALUATE-FOR Arg1:T10 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1028.ann\n",
      "T1\tTask 24 36\tcorpus study\n",
      "T2\tOtherScientificTerm 135 154\tinformation graphic\n",
      "T3\tMethod 190 219\tgraphic interpretation system\n",
      "T4\tMaterial 259 280\tcommunicative signals\n",
      "T5\tMethod 344 362\tshallow processing\n",
      "T6\tMaterial 371 388\tgraphic's caption\n",
      "T7\tGeneric 421 427\tsystem\n",
      "T8\tOtherScientificTerm 503 523\tsight-impaired users\n",
      "T9\tOtherScientificTerm 551 571\tinformation graphics\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R4\tCOREF Arg1:T3 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1032.ann\n",
      "T1\tOtherScientificTerm 36 50\tdata structure\n",
      "T2\tTask 57 101\tphrase-based statistical machine translation\n",
      "T3\tTask 125 164\tretrieval  of arbitrarily long  phrases\n",
      "T4\tOtherScientificTerm 199 205\tmemory\n",
      "T5\tMethod 236 243\tdecoder\n",
      "T6\tMetric 277 301\tcomputational complexity\n",
      "T7\tMetric 308 331\taverage retrieval times\n",
      "T8\tOtherScientificTerm 349 368\tphrase translations\n",
      "T9\tOtherScientificTerm 378 411\tsuffix array-based data structure\n",
      "T10\tMethod 428 436\tsampling\n",
      "T11\tMetric 465 479\tretrieval time\n",
      "T12\tMetric 521 540\ttranslation quality\n",
      "R1\tPART-OF Arg1:T8 Arg2:T9\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R4\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R5\tEVALUATE-FOR Arg1:T11 Arg2:T10\n",
      "R6\tEVALUATE-FOR Arg1:T12 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1034.ann\n",
      "T1\tGeneric 21 29\tapproach\n",
      "T2\tTask 34 65\tstatistical machine translation\n",
      "T3\tOtherScientificTerm 82 103\tsyntactic information\n",
      "T4\tTask 155 174\tphrasal translation\n",
      "T5\tGeneric 183 189\tmethod\n",
      "T6\tMethod 202 237\tsource-language   dependency parser\n",
      "T7\tMethod 242 277\ttarget language   word segmentation\n",
      "T8\tMethod 287 324\tunsupervised word alignment component\n",
      "T9\tMaterial 340 355\tparallel corpus\n",
      "T10\tOtherScientificTerm 372 395\tsource dependency parse\n",
      "T11\tOtherScientificTerm 435 471\tdependency treelet translation pairs\n",
      "T12\tMethod 488 513\ttree-based ordering model\n",
      "T13\tMethod 543 550\tdecoder\n",
      "T14\tMethod 579 596\ttree-based models\n",
      "T15\tMethod 632 642\tSMT models\n",
      "T16\tGeneric 665 673\tapproach\n",
      "T17\tMethod 706 717\tphrasal SMT\n",
      "T18\tOtherScientificTerm 728 749\tlinguistic generality\n",
      "T19\tMethod 766 772\tparser\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R3\tPART-OF Arg1:T3 Arg2:T1\n",
      "R4\tPART-OF Arg1:T4 Arg2:T1\n",
      "R5\tCOREF Arg1:T1 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R7\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T5\n",
      "R9\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R10\tCONJUNCTION Arg1:T6 Arg2:T7\n",
      "R11\tCOREF Arg1:T12 Arg2:T14\n",
      "R12\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R13\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R14\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R15\tUSED-FOR Arg1:T17 Arg2:T19\n",
      "R16\tFEATURE-OF Arg1:T18 Arg2:T19\n",
      "R17\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1039.ann\n",
      "T1\tMethod 31 51\tunlexicalized parser\n",
      "T2\tMaterial 58 64\tGerman\n",
      "T3\tMethod 81 90\tsmoothing\n",
      "T4\tMethod 97 112\tsuffix analysis\n",
      "T5\tMetric 128 152\tlabelled bracket F-score\n",
      "T6\tMaterial 211 223\tNEGRA corpus\n",
      "T7\tMetric 251 259\taccuracy\n",
      "T8\tGeneric 268 273\tmodel\n",
      "T9\tMethod 287 296\tsmoothing\n",
      "T10\tMethod 305 325\tunlexicalized parser\n",
      "T11\tMethod 378 387\tsmoothing\n",
      "T12\tMethod 394 401\tparsing\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R5\tEVALUATE-FOR Arg1:T5 Arg2:T1\n",
      "R6\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R7\tEVALUATE-FOR Arg1:T7 Arg2:T8\n",
      "R8\tCOREF Arg1:T1 Arg2:T8\n",
      "R9\tCOREF Arg1:T8 Arg2:T10\n",
      "R10\tEVALUATE-FOR Arg1:T6 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1046.ann\n",
      "T1\tMethod 36 69\tinformation extraction techniques\n",
      "T2\tMaterial 108 132\tsupervised training data\n",
      "T3\tTask 169 202\tfield structured extraction tasks\n",
      "T4\tMaterial 213 238\tclassified advertisements\n",
      "T5\tMaterial 243 266\tbibliographic citations\n",
      "T6\tOtherScientificTerm 286 301\tprior knowledge\n",
      "T7\tMethod 388 415\thidden Markov models (HMMs)\n",
      "T8\tMethod 437 453\tgenerative model\n",
      "T9\tMaterial 460 481\tfield structured text\n",
      "T10\tMethod 493 518\tunsupervised HMM learning\n",
      "T11\tOtherScientificTerm 675 690\tprior knowledge\n",
      "T12\tMethod 750 770\tunsupervised methods\n",
      "T13\tMetric 784 794\taccuracies\n",
      "T14\tMaterial 806 824\tunlabeled examples\n",
      "T15\tMethod 859 877\tsupervised methods\n",
      "T16\tMaterial 886 902\tlabeled examples\n",
      "T17\tMethod 915 938\tsemi-supervised methods\n",
      "T18\tMaterial 979 991\tlabeled data\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R5\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R6\tHYPONYM-OF Arg1:T4 Arg2:T3\n",
      "R7\tHYPONYM-OF Arg1:T5 Arg2:T3\n",
      "R8\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R9\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R10\tEVALUATE-FOR Arg1:T13 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R12\tCOMPARE Arg1:T12 Arg2:T15\n",
      "R13\tEVALUATE-FOR Arg1:T13 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1048.ann\n",
      "T1\tMethod 62 93\tword sense disambigation models\n",
      "T2\tMetric 101 142\tstatistical machine translation   quality\n",
      "T3\tMethod 257 296\tChinese word sense disambiguation model\n",
      "T4\tOtherScientificTerm 309 331\ttranslation candidates\n",
      "T5\tMethod 348 373\tIBM statistical MT system\n",
      "T6\tMethod 391 416\tword sense disambiguation\n",
      "T7\tMetric 455 474\ttranslation quality\n",
      "T8\tMethod 486 524\tstatistical machine translation system\n",
      "T9\tMethod 534 548\tError analysis\n",
      "T10\tMethod 654 682\tstatistical MT architectures\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tCOREF Arg1:T1 Arg2:T6\n",
      "R4\tCOMPARE Arg1:T6 Arg2:T8\n",
      "R5\tEVALUATE-FOR Arg1:T7 Arg2:T8\n",
      "R6\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1056.ann\n",
      "T1\tTask 2 29\tSentence boundary detection\n",
      "T2\tMaterial 35 41\tspeech\n",
      "T3\tOtherScientificTerm 71 97\tspeech recognition  output\n",
      "T4\tGeneric 106 108\tit\n",
      "T5\tMethod 207 273\thidden Markov model (HMM) and maximum entropy (Maxent) classifiers\n",
      "T6\tMaterial 290 329\ttextual and prosodic  knowledge sources\n",
      "T7\tTask 335 365\tdetecting  sentence boundaries\n",
      "T8\tMethod 409 439\tconditional random field (CRF)\n",
      "T9\tGeneric 450 454\ttask\n",
      "T10\tGeneric 484 489\tmodel\n",
      "T11\tGeneric 532 539\tcorpora\n",
      "T12\tMaterial 541 573\tconversational  telephone speech\n",
      "T13\tMaterial 580 601\tbroadcast news speech\n",
      "T14\tOtherScientificTerm 613 633\thuman transcriptions\n",
      "T15\tOtherScientificTerm 640 666\tspeech recognition  output\n",
      "T16\tMethod 685 695\tCRF  model\n",
      "T17\tMetric 711 721\terror rate\n",
      "T18\tMethod 732 754\tHMM and Max-ent models\n",
      "T19\tMaterial 764 801\tNIST sentence boundary detection task\n",
      "T20\tMaterial 807 813\tspeech\n",
      "T21\tMethod 890 906\tthree-way voting\n",
      "T22\tMethod 919 930\tclassifiers\n",
      "T23\tGeneric 968 973\tmodel\n",
      "T24\tMaterial 1032 1049\tknowledge sources\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R2\tCOREF Arg1:T1 Arg2:T7\n",
      "R3\tCOREF Arg1:T7 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R5\tCOREF Arg1:T8 Arg2:T10\n",
      "R6\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R7\tHYPONYM-OF Arg1:T13 Arg2:T11\n",
      "R8\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R9\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R10\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R11\tCOREF Arg1:T3 Arg2:T4\n",
      "R12\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R13\tEVALUATE-FOR Arg1:T11 Arg2:T14\n",
      "R14\tEVALUATE-FOR Arg1:T11 Arg2:T15\n",
      "R15\tCOREF Arg1:T8 Arg2:T16\n",
      "R16\tEVALUATE-FOR Arg1:T17 Arg2:T16\n",
      "R17\tEVALUATE-FOR Arg1:T17 Arg2:T18\n",
      "R18\tCOMPARE Arg1:T16 Arg2:T18\n",
      "R19\tFEATURE-OF Arg1:T20 Arg2:T19\n",
      "R20\tEVALUATE-FOR Arg1:T19 Arg2:T18\n",
      "R21\tEVALUATE-FOR Arg1:T19 Arg2:T16\n",
      "R22\tUSED-FOR Arg1:T23 Arg2:T24\n",
      "R23\tUSED-FOR Arg1:T5 Arg2:T7\n",
      "R24\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1057.ann\n",
      "T1\tGeneric 14 23\tframework\n",
      "T2\tTask 29 43\tword alignment\n",
      "T3\tMethod 55 72\tlog-linear models\n",
      "T4\tMaterial 80 97\tknowledge sources\n",
      "T5\tOtherScientificTerm 115 132\tfeature functions\n",
      "T6\tMethod 250 267\tLog-linear models\n",
      "T7\tMethod 276 304\tstatistical alignment models\n",
      "T8\tOtherScientificTerm 346 367\tsyntactic information\n",
      "T9\tOtherScientificTerm 393 428\tIBM Model 3 alignment probabilities\n",
      "T10\tOtherScientificTerm 432 450\tPOS correspondence\n",
      "T11\tOtherScientificTerm 458 487\tbilingual dictionary coverage\n",
      "T12\tOtherScientificTerm 493 501\tfeatures\n",
      "T13\tMethod 531 548\tlog-linear models\n",
      "T14\tMethod 576 598\tIBM translation models\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R4\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R8\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T12\n",
      "R10\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R11\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R12\tCOREF Arg1:T6 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1058.ann\n",
      "T1\tMethod 25 54\talignment adaptation approach\n",
      "T2\tTask 68 110\tdomain-specific (in-domain) word alignment\n",
      "T3\tMethod 132 152\talignment adaptation\n",
      "T4\tMaterial 165 185\tout-of-domain corpus\n",
      "T5\tTask 199 223\tin-domain word alignment\n",
      "T6\tMethod 269 302\tstatistical word alignment models\n",
      "T7\tMaterial 313 346\tlarge-scale  out-of-domain corpus\n",
      "T8\tMaterial 356 385\tsmall-scale  in-domain corpus\n",
      "T9\tGeneric 432 438\tmodels\n",
      "T10\tTask 455 485\tdomain-specific word alignment\n",
      "T11\tGeneric 523 531\tapproach\n",
      "T12\tTask 542 572\tdomain-specific word alignment\n",
      "T13\tMetric 592 601\tprecision\n",
      "T14\tMetric 608 614\trecall\n",
      "T15\tMetric 630 659\trelative error rate reduction\n",
      "T16\tGeneric 691 720\tstate-of-the-art technologies\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T1 Arg2:T3\n",
      "R3\tCOREF Arg1:T2 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R7\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R9\tCOREF Arg1:T6 Arg2:T9\n",
      "R10\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R11\tCOREF Arg1:T5 Arg2:T10\n",
      "R12\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R13\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R14\tEVALUATE-FOR Arg1:T13 Arg2:T11\n",
      "R15\tEVALUATE-FOR Arg1:T14 Arg2:T11\n",
      "R16\tCOMPARE Arg1:T11 Arg2:T16\n",
      "R17\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "R18\tEVALUATE-FOR Arg1:T15 Arg2:T11\n",
      "R19\tCOREF Arg1:T12 Arg2:T5\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1067.ann\n",
      "T1\tTask 2 51\tSyntax-based statistical machine translation (MT)\n",
      "T2\tMethod 71 89\tstatistical models\n",
      "T3\tMaterial 95 110\tstructured data\n",
      "T4\tTask 143 194\tsyntax-based statistical machine translation system\n",
      "T5\tMethod 208 262\tprobabilistic synchronous dependency insertion grammar\n",
      "T6\tMethod 267 308\tSynchronous dependency insertion grammars\n",
      "T7\tMethod 328 348\tsynchronous grammars\n",
      "T8\tOtherScientificTerm 362 378\tdependency trees\n",
      "T9\tGeneric 405 413\tapproach\n",
      "T10\tMethod 434 441\tgrammar\n",
      "T11\tMaterial 449 465\tparallel corpora\n",
      "T12\tMethod 494 509\tgraphical model\n",
      "T13\tTask 520 544\tmachine translation task\n",
      "T14\tMethod 579 613\tstochastic tree-to-tree transducer\n",
      "T15\tMethod 633 667\tpolynomial time decoding algorithm\n",
      "T16\tGeneric 678 683\tmodel\n",
      "T17\tMethod 719 728\tMT system\n",
      "T18\tMetric 741 787\tNIST and Bleu automatic MT evaluation software\n",
      "T19\tGeneric 817 823\tsystem\n",
      "T20\tGeneric 841 856\tbaseline system\n",
      "T21\tMethod 872 882\tIBM models\n",
      "T22\tMetric 893 922\ttranslation speed and quality\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R4\tUSED-FOR Arg1:T21 Arg2:T20\n",
      "R5\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R6\tCOREF Arg1:T1 Arg2:T4\n",
      "R7\tHYPONYM-OF Arg1:T6 Arg2:T7\n",
      "R8\tCOREF Arg1:T6 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R11\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R12\tCOREF Arg1:T12 Arg2:T16\n",
      "R13\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R14\tCOREF Arg1:T17 Arg2:T1\n",
      "R15\tUSED-FOR Arg1:T18 Arg2:T17\n",
      "R16\tCOREF Arg1:T17 Arg2:T19\n",
      "R17\tCOMPARE Arg1:T19 Arg2:T20\n",
      "R18\tEVALUATE-FOR Arg1:T22 Arg2:T20\n",
      "R19\tEVALUATE-FOR Arg1:T22 Arg2:T19\n",
      "R20\tCOREF Arg1:T5 Arg2:T6\n",
      "R21\tFEATURE-OF Arg1:T8 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1069.ann\n",
      "T1\tMethod 36 51\ttraining method\n",
      "T2\tMethod 60 99\tlocalized phrase-based prediction model\n",
      "T3\tTask 106 143\tstatistical machine translation (SMT)\n",
      "T4\tGeneric 152 157\tmodel\n",
      "T5\tTask 205 229\tlocal phrase re-ordering\n",
      "T6\tOtherScientificTerm 243 271\tmaximum likelihood criterion\n",
      "T7\tMethod 285 314\tlog-linear block bigram model\n",
      "T8\tOtherScientificTerm 328 348\treal-valued features\n",
      "T9\tOtherScientificTerm 359 379\tlanguage model score\n",
      "T10\tOtherScientificTerm 395 410\tbinary features\n",
      "T11\tMethod 489 507\ttraining algorithm\n",
      "T12\tOtherScientificTerm 540 548\tfeatures\n",
      "T13\tGeneric 561 567\tsystem\n",
      "T14\tGeneric 606 614\tbaseline\n",
      "T15\tTask 631 662\tArabic-English translation task\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T2 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R6\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R8\tCOREF Arg1:T11 Arg2:T1\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R10\tCOMPARE Arg1:T13 Arg2:T14\n",
      "R11\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R12\tEVALUATE-FOR Arg1:T15 Arg2:T13\n",
      "R13\tUSED-FOR Arg1:T10 Arg2:T7\n",
      "R14\tCONJUNCTION Arg1:T8 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1073.ann\n",
      "T1\tTask 43 65\tsemantic role labeling\n",
      "T2\tMethod 100 123\tindependent classifiers\n",
      "T3\tMethod 159 180\tlabel sequence models\n",
      "T4\tMethod 187 203\tViterbi decoding\n",
      "T5\tOtherScientificTerm 274 293\tcore argument frame\n",
      "T6\tMethod 389 421\tjoint model  of  argument frames\n",
      "T7\tOtherScientificTerm 445 453\tfeatures\n",
      "T8\tMethod 491 523\tdiscriminative log-linear models\n",
      "T9\tGeneric 531 537\tsystem\n",
      "T10\tMetric 551 566\terror reduction\n",
      "T11\tMethod 646 669\tindependent  classifier\n",
      "T12\tOtherScientificTerm 676 701\tgold-standard parse trees\n",
      "T13\tMaterial 707 715\tPropBank\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tPART-OF Arg1:T7 Arg2:T8\n",
      "R3\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R4\tCOREF Arg1:T6 Arg2:T9\n",
      "R5\tCOMPARE Arg1:T11 Arg2:T9\n",
      "R6\tPART-OF Arg1:T12 Arg2:T13\n",
      "R7\tCOREF Arg1:T2 Arg2:T11\n",
      "R8\tEVALUATE-FOR Arg1:T10 Arg2:T9\n",
      "R9\tEVALUATE-FOR Arg1:T10 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R11\tEVALUATE-FOR Arg1:T12 Arg2:T11\n",
      "R12\tEVALUATE-FOR Arg1:T12 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1074.ann\n",
      "T1\tMaterial 25 53\tmonolingual parallel corpora\n",
      "T2\tOtherScientificTerm 80 91\tparaphrases\n",
      "T3\tGeneric 113 117\ttask\n",
      "T4\tMaterial 137 163\tbilingual parallel corpora\n",
      "T5\tMethod 218 238\talignment techniques\n",
      "T6\tTask 246 290\tphrase-based statistical machine translation\n",
      "T7\tOtherScientificTerm 307 318\tparaphrases\n",
      "T8\tOtherScientificTerm 418 440\tparaphrase probability\n",
      "T9\tOtherScientificTerm 455 466\tparaphrases\n",
      "T10\tMaterial 486 511\tbilingual parallel corpus\n",
      "T11\tOtherScientificTerm 533 558\ttranslation probabilities\n",
      "T12\tGeneric 575 577\tit\n",
      "T13\tOtherScientificTerm 602 624\tcontextual information\n",
      "T14\tMethod 657 698\tparaphrase extraction and ranking methods\n",
      "T15\tMaterial 716 738\tmanual word alignments\n",
      "T16\tMetric 760 767\tquality\n",
      "T17\tOtherScientificTerm 775 786\tparaphrases\n",
      "T18\tOtherScientificTerm 804 824\tautomatic alignments\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tPART-OF Arg1:T9 Arg2:T10\n",
      "R3\tPART-OF Arg1:T17 Arg2:T18\n",
      "R4\tCOREF Arg1:T4 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R6\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T11 Arg2:T9\n",
      "R8\tCOREF Arg1:T8 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R10\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R11\tEVALUATE-FOR Arg1:T16 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-1076.ann\n",
      "T1\tGeneric 31 37\tsystem\n",
      "T2\tTask 44 99\tacquiring adjectival subcategorization frames  ( scfs )\n",
      "T3\tOtherScientificTerm 65 99\tsubcategorization frames  ( scfs )\n",
      "T4\tMaterial 143 164\tEnglish   corpus data\n",
      "T5\tGeneric 172 178\tsystem\n",
      "T6\tMethod 196 220\tdecision-tree classifier\n",
      "T7\tOtherScientificTerm 274 304\tgrammatical relations  ( grs )\n",
      "T8\tMethod 326 352\trobust  statistical parser\n",
      "T9\tGeneric 355 357\tIt\n",
      "T10\tOtherScientificTerm 375 400\tpattern-matching language\n",
      "T11\tOtherScientificTerm 415 418\tgrs\n",
      "T12\tOtherScientificTerm 472 496\tinheritance-based lexica\n",
      "T13\tGeneric 532 538\tsystem\n",
      "T14\tMetric 580 589\tprecision\n",
      "T15\tMetric 600 606\trecall\n",
      "T16\tGeneric 621 625\ttool\n",
      "T17\tTask 632 663\tlinguistic annotation  of  scfs\n",
      "T18\tOtherScientificTerm 659 663\tscfs\n",
      "T19\tMaterial 760 782\ttraining and test data\n",
      "T20\tTask 789 818\tsubcategorization acquisition\n",
      "R1\tPART-OF Arg1:T6 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T19 Arg2:T20\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T1 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tCOREF Arg1:T11 Arg2:T7\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R8\tCOREF Arg1:T5 Arg2:T9\n",
      "R9\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R10\tCOREF Arg1:T13 Arg2:T9\n",
      "R11\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "R12\tEVALUATE-FOR Arg1:T15 Arg2:T13\n",
      "R13\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R14\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R15\tCOREF Arg1:T3 Arg2:T18\n",
      "R16\tCOREF Arg1:T2 Arg2:T20\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-2008.ann\n",
      "T1\tTask 2 26\tSentiment Classification\n",
      "T2\tMethod 171 198\tmachine learning techniques\n",
      "T3\tGeneric 226 233\tproblem\n",
      "T4\tMaterial 342 364\ttraining and test data\n",
      "T5\tMaterial 520 533\ttraining data\n",
      "T6\tOtherScientificTerm 549 558\temoticons\n",
      "R1\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "R2\tCOREF Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-2013.ann\n",
      "T1\tTask 36 106\tautomatically inducing a  Combinatory Categorial Grammar (CCG) lexicon\n",
      "T2\tOtherScientificTerm 62 106\tCombinatory Categorial Grammar (CCG) lexicon\n",
      "T3\tMaterial 116 143\tTurkish dependency treebank\n",
      "T4\tMaterial 161 168\tTurkish\n",
      "T5\tMaterial 177 215\tagglutinating free word order language\n",
      "T6\tMethod 243 260\tlanguage theories\n",
      "T7\tOtherScientificTerm 302 317\tcompact lexicon\n",
      "T8\tMethod 337 351\tCCG principles\n",
      "T9\tGeneric 362 370\ttreebank\n",
      "T10\tMaterial 417 425\tPenn WSJ\n",
      "R1\tPART-OF Arg1:T2 Arg2:T3\n",
      "R2\tHYPONYM-OF Arg1:T4 Arg2:T5\n",
      "R3\tCOMPARE Arg1:T9 Arg2:T10\n",
      "R4\tPART-OF Arg1:T7 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-2016.ann\n",
      "T1\tMethod 15 67\tCzech-English statistical machine translation system\n",
      "T2\tTask 85 136\ttree-to-tree translation  of  dependency structures\n",
      "T3\tMaterial 150 168\tbilingual resource\n",
      "T4\tMaterial 185 217\tsentence-aligned parallel corpus\n",
      "T5\tGeneric 328 334\tsystem\n",
      "T6\tGeneric 353 369\tbenchmark system\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R3\tCOMPARE Arg1:T5 Arg2:T6\n",
      "R4\tCOREF Arg1:T1 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-3001.ann\n",
      "T1\tMethod 16 31\tdialogue system\n",
      "T2\tMethod 115 145\tconcise,  modular architecture\n",
      "T3\tTask 177 190\tunderstanding\n",
      "T4\tTask 197 207\tgeneration\n",
      "T5\tMethod 214 250\tinformation-state model of reference\n",
      "T6\tOtherScientificTerm 281 290\tsemantics\n",
      "T7\tTask 297 326\tcollaborative problem solving\n",
      "R1\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-3025.ann\n",
      "T1\tGeneric 26 32\tmethod\n",
      "T2\tTask 37 105\tinteractively visualizing and directing the process  of  translating\n",
      "T3\tGeneric 124 130\tmethod\n",
      "T4\tGeneric 161 166\tmodel\n",
      "T5\tTask 172 221\tsyntax-based statistical machine translation (MT)\n",
      "T6\tGeneric 244 249\tmodel\n",
      "T7\tGeneric 295 297\tit\n",
      "T8\tMethod 308 318\tMT systems\n",
      "T9\tMethod 334 354\tvisualization method\n",
      "T10\tMethod 423 432\tMT system\n",
      "T11\tMethod 506 526\tsyntax-based decoder\n",
      "R1\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R6\tCOREF Arg1:T6 Arg2:T7\n",
      "R7\tCOMPARE Arg1:T7 Arg2:T8\n",
      "R8\tCOREF Arg1:T4 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P05-3030.ann\n",
      "T1\tGeneric 14 20\tmethod\n",
      "T2\tTask 24 52\torganizing reading materials\n",
      "T3\tTask 58 77\tvocabulary learning\n",
      "T4\tGeneric 80 82\tIt\n",
      "T5\tOtherScientificTerm 185 202\ttarget vocabulary\n",
      "T6\tMaterial 325 342\tEnglish Wikipedia\n",
      "T7\tMaterial 347 372\tfree-content encyclopedia\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R3\tCOREF Arg1:T1 Arg2:T4\n",
      "R4\tHYPONYM-OF Arg1:T6 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-1012.ann\n",
      "T1\tOtherScientificTerm 74 86\tsense priors\n",
      "T2\tMetric 170 178\taccuracy\n",
      "T3\tMethod 183 222\tword sense disambiguation (WSD) systems\n",
      "T4\tGeneric 290 296\tmethod\n",
      "T5\tOtherScientificTerm 314 337\tsense priors  of  words\n",
      "T6\tMaterial 352 363\tnew  domain\n",
      "T7\tOtherScientificTerm 406 435\twell calibrated probabilities\n",
      "T8\tGeneric 460 471\testimations\n",
      "T9\tOtherScientificTerm 484 513\twell calibrated probabilities\n",
      "T10\tOtherScientificTerm 545 557\tsense priors\n",
      "T11\tMetric 611 623\tWSD accuracy\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R2\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R3\tEVALUATE-FOR Arg1:T2 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-1013.ann\n",
      "T1\tMethod 2 21\tCombination methods\n",
      "T2\tMethod 117 135\tsystem combination\n",
      "T3\tTask 142 158\tunsupervised WSD\n",
      "T4\tMethod 186 234\tvoting- and arbiter-based combination strategies\n",
      "T5\tMethod 260 284\tunsupervised WSD systems\n",
      "T6\tMethod 293 312\tcombination methods\n",
      "T7\tOtherScientificTerm 323 341\tpredominant senses\n",
      "T8\tMaterial 381 389\traw text\n",
      "T9\tMaterial 416 449\tSemCor  and  Senseval-3 data sets\n",
      "T10\tGeneric 472 481\tensembles\n",
      "T11\tGeneric 536 552\tstate-of-the-art\n",
      "R1\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R5\tCOREF Arg1:T6 Arg2:T10\n",
      "R6\tCOREF Arg1:T10 Arg2:T11\n",
      "R7\tEVALUATE-FOR Arg1:T9 Arg2:T10\n",
      "R8\tEVALUATE-FOR Arg1:T9 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-1018.ann\n",
      "T1\tMethod 34 56\tmathematical formalism\n",
      "T2\tGeneric 90 100\tstructures\n",
      "T3\tOtherScientificTerm 105 112\tstrings\n",
      "T4\tOtherScientificTerm 117 122\ttrees\n",
      "T5\tOtherScientificTerm 127 131\tdags\n",
      "T6\tOtherScientificTerm 136 142\tgraphs\n",
      "T7\tGeneric 162 166\tthem\n",
      "T8\tOtherScientificTerm 173 185\tpolarization\n",
      "T9\tOtherScientificTerm 210 231\telementary structures\n",
      "T10\tGeneric 291 300\tformalism\n",
      "T11\tMethod 367 385\tgrammar formalisms\n",
      "T12\tMethod 398 415\trewriting systems\n",
      "T13\tMethod 420 439\tdependency grammars\n",
      "T14\tOtherScientificTerm 444 447\tTAG\n",
      "T15\tOtherScientificTerm 452 456\tHPSG\n",
      "T16\tOtherScientificTerm 463 466\tLFG\n",
      "R1\tHYPONYM-OF Arg1:T3 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T4 Arg2:T2\n",
      "R3\tHYPONYM-OF Arg1:T5 Arg2:T2\n",
      "R4\tHYPONYM-OF Arg1:T6 Arg2:T2\n",
      "R5\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R6\tCONJUNCTION Arg1:T4 Arg2:T5\n",
      "R7\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R8\tCOREF Arg1:T2 Arg2:T7\n",
      "R9\tCOREF Arg1:T1 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R11\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R12\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R13\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R14\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R15\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R16\tHYPONYM-OF Arg1:T13 Arg2:T11\n",
      "R17\tHYPONYM-OF Arg1:T14 Arg2:T11\n",
      "R18\tHYPONYM-OF Arg1:T15 Arg2:T11\n",
      "R19\tHYPONYM-OF Arg1:T16 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-1052.ann\n",
      "T1\tGeneric 25 34\talgorithm\n",
      "T2\tTask 44 74\tredundancy elimination problem\n",
      "T3\tMethod 88 132\tunderspecified semantic representation (USR)\n",
      "T4\tOtherScientificTerm 140 155\tscope ambiguity\n",
      "T5\tMethod 171 174\tUSR\n",
      "T6\tMaterial 197 216\tequivalent readings\n",
      "T7\tGeneric 224 233\talgorithm\n",
      "T8\tMethod 247 283\tunderspecified chart representations\n",
      "T9\tOtherScientificTerm 309 325\tdominance graphs\n",
      "T10\tGeneric 329 331\tit\n",
      "T11\tMethod 355 359\tUSRs\n",
      "T12\tMethod 374 394\tlarge-scale grammars\n",
      "T13\tGeneric 414 423\talgorithm\n",
      "T14\tGeneric 454 456\tit\n",
      "T15\tOtherScientificTerm 469 489\tdegree of  ambiguity\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tCOREF Arg1:T3 Arg2:T5\n",
      "R4\tCOREF Arg1:T13 Arg2:T14\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tCOREF Arg1:T1 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R9\tCOREF Arg1:T7 Arg2:T10\n",
      "R10\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R11\tCOREF Arg1:T3 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R13\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-1053.ann\n",
      "T1\tOtherScientificTerm 6 33\tpsycholinguistic literature\n",
      "T2\tOtherScientificTerm 58 75\tsyntactic priming\n",
      "T3\tGeneric 142 148\tmethod\n",
      "T4\tOtherScientificTerm 168 175\tpriming\n",
      "T5\tMethod 186 218\tincremental probabilistic parser\n",
      "T6\tOtherScientificTerm 263 270\tpriming\n",
      "T7\tOtherScientificTerm 276 281\trules\n",
      "T8\tOtherScientificTerm 336 357\tcoordinate structures\n",
      "T9\tOtherScientificTerm 414 433\tparallel structures\n",
      "T10\tMaterial 445 455\thuman data\n",
      "T11\tMetric 502 518\tparsing accuracy\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tPART-OF Arg1:T9 Arg2:T10\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R5\tCOREF Arg1:T2 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-1088.ann\n",
      "T1\tMetric 29 37\taccuracy\n",
      "T2\tMaterial 44 58\tnewspaper text\n",
      "T3\tTask 62 90\tpart of speech (pos) tagging\n",
      "T4\tMethod 177 183\tparser\n",
      "T5\tOtherScientificTerm 197 214\tpos tag ambiguity\n",
      "T6\tMethod 260 278\tgrammar formalisms\n",
      "T7\tOtherScientificTerm 296 331\tfine-grained grammatical categories\n",
      "T8\tOtherScientificTerm 347 350\ttag\n",
      "T9\tOtherScientificTerm 357 360\tccg\n",
      "T10\tMetric 364 380\ttagging accuracy\n",
      "T11\tGeneric 417 427\tformalisms\n",
      "T12\tOtherScientificTerm 430 461\tpremature  ambiguity resolution\n",
      "T13\tTask 470 477\tparsing\n",
      "T14\tMethod 506 528\tmulti-tagging approach\n",
      "T15\tOtherScientificTerm 567 593\tlexical category ambiguity\n",
      "T16\tTask 623 634\tccg parsing\n",
      "T17\tMethod 653 675\tmulti-tagging approach\n",
      "T18\tOtherScientificTerm 685 694\tpos level\n",
      "T19\tOtherScientificTerm 753 761\tpos tags\n",
      "T20\tMetric 774 794\tpos tagging accuracy\n",
      "T21\tOtherScientificTerm 826 843\tpos tag ambiguity\n",
      "T22\tMethod 853 881\tlanguage processing pipeline\n",
      "T23\tMethod 909 925\tccg supertagging\n",
      "R1\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R2\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R3\tUSED-FOR Arg1:T14 Arg2:T16\n",
      "R4\tEVALUATE-FOR Arg1:T1 Arg2:T3\n",
      "R5\tEVALUATE-FOR Arg1:T2 Arg2:T3\n",
      "R6\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R7\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R8\tEVALUATE-FOR Arg1:T10 Arg2:T6\n",
      "R9\tCOREF Arg1:T6 Arg2:T11\n",
      "R10\tUSED-FOR Arg1:T13 Arg2:T11\n",
      "R11\tFEATURE-OF Arg1:T15 Arg2:T14\n",
      "R12\tCOREF Arg1:T14 Arg2:T17\n",
      "R13\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R14\tFEATURE-OF Arg1:T21 Arg2:T22\n",
      "R15\tUSED-FOR Arg1:T21 Arg2:T23\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-1112.ann\n",
      "T1\tOtherScientificTerm 27 68\tcorrelation of  dependency relation paths\n",
      "T2\tTask 100 117\tanswer extraction\n",
      "T3\tMetric 131 150\tcorrelation measure\n",
      "T4\tOtherScientificTerm 165 185\tdependency relations\n",
      "T5\tMethod 349 385\tapproximate phrase mapping algorithm\n",
      "T6\tOtherScientificTerm 408 421\tmapping score\n",
      "T7\tMetric 433 452\tcorrelation measure\n",
      "T8\tGeneric 459 471\tcorrelations\n",
      "T9\tMethod 505 540\tMaximum Entropy-based ranking model\n",
      "T10\tGeneric 623 629\tmethod\n",
      "T11\tMethod 674 706\tsyntactic relation-based methods\n",
      "T12\tMetric 725 728\tMRR\n",
      "R1\tPART-OF Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T1 Arg2:T8\n",
      "R5\tPART-OF Arg1:T8 Arg2:T9\n",
      "R6\tCOMPARE Arg1:T10 Arg2:T11\n",
      "R7\tEVALUATE-FOR Arg1:T12 Arg2:T11\n",
      "R8\tEVALUATE-FOR Arg1:T12 Arg2:T10\n",
      "R9\tCOREF Arg1:T5 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-2001.ann\n",
      "T1\tMethod 48 75\tmachine learning techniques\n",
      "T2\tMethod 89 102\tcomma checker\n",
      "T3\tMethod 127 142\tgrammar checker\n",
      "T4\tMaterial 149 155\tBasque\n",
      "T5\tGeneric 246 252\tsystem\n",
      "T6\tMetric 300 309\tprecision\n",
      "T7\tMetric 325 331\trecall\n",
      "T8\tGeneric 341 343\tIt\n",
      "T9\tMetric 357 366\tprecision\n",
      "T10\tMetric 382 388\trecall\n",
      "T11\tTask 412 427\tplacing  commas\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R3\tPART-OF Arg1:T2 Arg2:T3\n",
      "R4\tCOREF Arg1:T2 Arg2:T5\n",
      "R5\tEVALUATE-FOR Arg1:T6 Arg2:T5\n",
      "R6\tEVALUATE-FOR Arg1:T7 Arg2:T5\n",
      "R7\tCOREF Arg1:T8 Arg2:T5\n",
      "R8\tEVALUATE-FOR Arg1:T9 Arg2:T8\n",
      "R9\tEVALUATE-FOR Arg1:T10 Arg2:T8\n",
      "R10\tUSED-FOR Arg1:T8 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-2012.ann\n",
      "T1\tMethod 25 55\tunsupervised learning approach\n",
      "T2\tOtherScientificTerm 81 114\trelations between  named entities\n",
      "T3\tOtherScientificTerm 135 165\tlexical and syntactic features\n",
      "T4\tGeneric 189 191\tIt\n",
      "T5\tOtherScientificTerm 214 226\teigenvectors\n",
      "T6\tOtherScientificTerm 235 265\tadjacency graph  's  Laplacian\n",
      "T7\tOtherScientificTerm 281 292\tsubmanifold\n",
      "T8\tOtherScientificTerm 310 335\thigh dimensionality space\n",
      "T9\tTask 358 383\tcluster number estimation\n",
      "T10\tOtherScientificTerm 393 405\teigenvectors\n",
      "T11\tMaterial 432 443\tACE corpora\n",
      "T12\tMethod 461 495\tspectral clustering based approach\n",
      "T13\tMethod 520 538\tclustering methods\n",
      "R1\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R2\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R3\tCOREF Arg1:T1 Arg2:T4\n",
      "R4\tFEATURE-OF Arg1:T6 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T7\n",
      "R7\tCOREF Arg1:T5 Arg2:T10\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R9\tEVALUATE-FOR Arg1:T11 Arg2:T12\n",
      "R10\tEVALUATE-FOR Arg1:T11 Arg2:T13\n",
      "R11\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R12\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R13\tUSED-FOR Arg1:T9 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-2059.ann\n",
      "T1\tGeneric 29 35\tmethod\n",
      "T2\tTask 39 71\tbuilding  polarity-tagged corpus\n",
      "T3\tMaterial 79 93\tHTML documents\n",
      "T4\tGeneric 125 131\tmethod\n",
      "T5\tGeneric 140 142\tit\n",
      "T6\tMaterial 195 209\tHTML documents\n",
      "T7\tGeneric 233 239\tmethod\n",
      "T8\tOtherScientificTerm 263 280\tlayout structures\n",
      "T9\tOtherScientificTerm 287 305\tlinguistic pattern\n",
      "T10\tGeneric 318 322\tthem\n",
      "T11\tGeneric 415 421\tmethod\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R3\tCOREF Arg1:T1 Arg2:T4\n",
      "R4\tCOREF Arg1:T4 Arg2:T5\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R6\tCOREF Arg1:T3 Arg2:T6\n",
      "R7\tCOREF Arg1:T4 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T9 Arg2:T7\n",
      "R10\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R11\tHYPONYM-OF Arg1:T8 Arg2:T10\n",
      "R12\tHYPONYM-OF Arg1:T9 Arg2:T10\n",
      "R13\tCOREF Arg1:T7 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-2067.ann\n",
      "T1\tMethod 66 84\tstatistical parser\n",
      "T2\tTask 103 139\tparsing  written and spoken language\n",
      "T3\tMaterial 112 139\twritten and spoken language\n",
      "T4\tTask 148 183\tgenerating  sub-categorization cues\n",
      "T5\tMaterial 191 218\twritten and spoken language\n",
      "T6\tMethod 231 245\tBikel's parser\n",
      "T7\tMetric 266 274\taccuracy\n",
      "T8\tTask 280 305\tparsing  written language\n",
      "T9\tMaterial 289 305\twritten language\n",
      "T10\tGeneric 308 310\tit\n",
      "T11\tMetric 330 338\taccuracy\n",
      "T12\tOtherScientificTerm 357 379\tsubcategorization cues\n",
      "T13\tMaterial 387 402\tspoken language\n",
      "T14\tGeneric 444 454\ttechnology\n",
      "T15\tTask 460 495\textracting subcategorization frames\n",
      "T16\tMaterial 521 534\twritten texts\n",
      "T17\tMaterial 560 575\tspoken language\n",
      "T18\tOtherScientificTerm 619 630\tpunctuation\n",
      "T19\tMethod 644 651\tparsing\n",
      "T20\tTask 658 696\textraction  of  subcategorization cues\n",
      "T21\tOtherScientificTerm 726 737\tpunctuation\n",
      "T22\tTask 760 784\tparsing  spoken language\n",
      "T23\tMaterial 769 784\tspoken language\n",
      "T24\tTask 790 824\textracting  subcategorization cues\n",
      "T25\tOtherScientificTerm 802 824\tsubcategorization cues\n",
      "T26\tMaterial 832 847\tspoken language\n",
      "T27\tOtherScientificTerm 895 906\tpunctuation\n",
      "T28\tMaterial 925 939\tspoken corpora\n",
      "T29\tMethod 966 973\tparsers\n",
      "R1\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R2\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R3\tPART-OF Arg1:T25 Arg2:T26\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R6\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R7\tCOREF Arg1:T1 Arg2:T6\n",
      "R8\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "R9\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R10\tCOREF Arg1:T6 Arg2:T10\n",
      "R11\tEVALUATE-FOR Arg1:T11 Arg2:T10\n",
      "R12\tPART-OF Arg1:T12 Arg2:T13\n",
      "R13\tUSED-FOR Arg1:T10 Arg2:T12\n",
      "R14\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R15\tUSED-FOR Arg1:T14 Arg2:T17\n",
      "R16\tCOMPARE Arg1:T16 Arg2:T17\n",
      "R17\tUSED-FOR Arg1:T18 Arg2:T20\n",
      "R18\tCONJUNCTION Arg1:T2 Arg2:T4\n",
      "R19\tUSED-FOR Arg1:T26 Arg2:T24\n",
      "R20\tCONJUNCTION Arg1:T22 Arg2:T24\n",
      "R21\tCOREF Arg1:T3 Arg2:T5\n",
      "R22\tCOREF Arg1:T23 Arg2:T13\n",
      "R23\tHYPONYM-OF Arg1:T9 Arg2:T5\n",
      "R24\tHYPONYM-OF Arg1:T23 Arg2:T5\n",
      "R25\tCOREF Arg1:T23 Arg2:T26\n",
      "R26\tCOREF Arg1:T17 Arg2:T26\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-2110.ann\n",
      "T1\tOtherScientificTerm 37 63\tsimilarity  between  words\n",
      "T2\tOtherScientificTerm 101 113\tword vectors\n",
      "T3\tMethod 123 141\tvector space model\n",
      "T4\tGeneric 177 184\tmethods\n",
      "T5\tTask 189 214\tconstructing word vectors\n",
      "T6\tMethod 225 283\tLSA-based, cooccurrence-based and dictionary-based methods\n",
      "T7\tGeneric 352 362\tsimilarity\n",
      "T8\tOtherScientificTerm 373 393\ttaxonomic similarity\n",
      "T9\tOtherScientificTerm 400 422\tassociative similarity\n",
      "T10\tOtherScientificTerm 469 498\tdictionary-based word vectors\n",
      "T11\tOtherScientificTerm 516 536\ttaxonomic similarity\n",
      "T12\tOtherScientificTerm 551 600\tLSA-based and the cooccurrence-based word vectors\n",
      "T13\tOtherScientificTerm 618 640\tassociative similarity\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R3\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R4\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R5\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R7\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R8\tHYPONYM-OF Arg1:T9 Arg2:T7\n",
      "R9\tCOREF Arg1:T6 Arg2:T4\n",
      "R10\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-3007.ann\n",
      "T1\tMethod 18 106\tindependent and relevant event-based extractive  mutli-document summarization approaches\n",
      "T2\tMethod 202 222\tindependent approach\n",
      "T3\tMethod 289 306\trelevant approach\n",
      "T4\tMethod 343 361\tPageRank algorithm\n",
      "T5\tOtherScientificTerm 371 380\tevent map\n",
      "T6\tMaterial 400 409\tdocuments\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R3\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-3008.ann\n",
      "T1\tOtherScientificTerm 7 27\trhetorical structure\n",
      "T2\tOtherScientificTerm 34 45\tpunctuation\n",
      "T3\tTask 69 89\tdiscourse processing\n",
      "T4\tTask 104 129\tcorpus annotation project\n",
      "T5\tTask 156 205\tdiscursive usage  of 6  Chinese punctuation marks\n",
      "T6\tOtherScientificTerm 180 205\tChinese punctuation marks\n",
      "T7\tMaterial 211 232\tnews commentary texts\n",
      "T8\tOtherScientificTerm 236 241\tColon\n",
      "T9\tOtherScientificTerm 245 249\tDash\n",
      "T10\tOtherScientificTerm 253 261\tEllipsis\n",
      "T11\tOtherScientificTerm 265 281\tExclamation Mark\n",
      "T12\tOtherScientificTerm 285 298\tQuestion Mark\n",
      "T13\tOtherScientificTerm 306 315\tSemicolon\n",
      "T14\tOtherScientificTerm 323 342\trhetorical patterns\n",
      "T15\tGeneric 353 358\tmarks\n",
      "T16\tOtherScientificTerm 381 410\tpatterns  around  cue phrases\n",
      "T17\tOtherScientificTerm 449 474\tChinese punctuation marks\n",
      "T18\tOtherScientificTerm 506 517\tcue phrases\n",
      "T19\tOtherScientificTerm 621 645\tindicators of nuclearity\n",
      "T20\tMaterial 650 663\tChinese texts\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R2\tCOMPARE Arg1:T17 Arg2:T18\n",
      "R3\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R5\tPART-OF Arg1:T6 Arg2:T7\n",
      "R6\tCONJUNCTION Arg1:T10 Arg2:T11\n",
      "R7\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R8\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R9\tHYPONYM-OF Arg1:T8 Arg2:T6\n",
      "R10\tHYPONYM-OF Arg1:T9 Arg2:T6\n",
      "R11\tHYPONYM-OF Arg1:T10 Arg2:T6\n",
      "R12\tHYPONYM-OF Arg1:T11 Arg2:T6\n",
      "R13\tHYPONYM-OF Arg1:T12 Arg2:T6\n",
      "R14\tHYPONYM-OF Arg1:T13 Arg2:T6\n",
      "R16\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R17\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R18\tCOREF Arg1:T6 Arg2:T15\n",
      "R19\tFEATURE-OF Arg1:T14 Arg2:T15\n",
      "R20\tCOMPARE Arg1:T14 Arg2:T16\n",
      "R21\tCOREF Arg1:T17 Arg2:T15\n",
      "R22\tFEATURE-OF Arg1:T20 Arg2:T19\n",
      "R23\tUSED-FOR Arg1:T17 Arg2:T19\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-4007.ann\n",
      "T1\tMethod 25 31\tFERRET\n",
      "T2\tMethod 39 82\tinteractive question-answering (Q/A) system\n",
      "T3\tTask 122 191\tintegrating  automatic Q/A  applications into real-world environments\n",
      "T4\tMethod 194 200\tFERRET\n",
      "T5\tGeneric 219 227\tapproach\n",
      "T6\tMethod 232 235\tQ/A\n",
      "T7\tMethod 247 269\tpredictive questioning\n",
      "R1\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T4 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R5\tCOREF Arg1:T7 Arg2:T5\n",
      "R6\tCOREF Arg1:T2 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-4011.ann\n",
      "T1\tGeneric 27 33\tmethod\n",
      "T2\tTask 39 80\tcomputational analysis of move structures\n",
      "T3\tMaterial 86 118\tabstracts  of  research articles\n",
      "T4\tGeneric 129 137\tapproach\n",
      "T5\tOtherScientificTerm 242 262\trhetorical functions\n",
      "T6\tGeneric 270 276\tmethod\n",
      "T7\tMaterial 329 338\tabstracts\n",
      "T8\tMaterial 350 353\tWeb\n",
      "T9\tMethod 371 385\tlanguage model\n",
      "T10\tMaterial 391 405\tabstract moves\n",
      "T11\tMethod 427 450\tprototype  concordancer\n",
      "T12\tMethod 455 459\tCARE\n",
      "T13\tMaterial 483 504\tmove-tagged abstracts\n",
      "T14\tTask 511 527\tdigital learning\n",
      "T15\tGeneric 536 542\tsystem\n",
      "T16\tGeneric 564 572\tapproach\n",
      "T17\tTask 577 621\tWeb-based computer-assisted academic writing\n",
      "R1\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R2\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R5\tCOREF Arg1:T1 Arg2:T4\n",
      "R6\tCOREF Arg1:T4 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R8\tUSED-FOR Arg1:T16 Arg2:T17\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R10\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R11\tCOREF Arg1:T15 Arg2:T12\n",
      "R12\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P06-4014.ann\n",
      "T1\tMethod 8 29\tLOGON MT demonstrator\n",
      "T2\tMethod 65 95\tgeneral-purpose NLP components\n",
      "T3\tMethod 105 133\tmachine translation pipeline\n",
      "T4\tTask 178 190\tdemonstrator\n",
      "T5\tMaterial 231 261\thand-built, symbolic resources\n",
      "T6\tMethod 268 288\tstochastic processes\n",
      "R1\tPART-OF Arg1:T2 Arg2:T3\n",
      "R2\tCOREF Arg1:T1 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R5\tPART-OF Arg1:T5 Arg2:T4\n",
      "R6\tPART-OF Arg1:T6 Arg2:T4\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P08-1105.ann\n",
      "T1\tTask 2 29\tTopical blog post retrieval\n",
      "T2\tTask 46 65\tranking  blog posts\n",
      "T3\tMaterial 55 65\tblog posts\n",
      "T4\tMetric 90 99\trelevance\n",
      "T5\tTask 134 161\ttopical blog post retrieval\n",
      "T6\tOtherScientificTerm 179 209\ttextual credibility indicators\n",
      "T7\tMethod 219 236\tretrieval process\n",
      "T8\tGeneric 266 276\tindicators\n",
      "T9\tMaterial 338 348\tblog posts\n",
      "T10\tMaterial 422 427\tblogs\n",
      "T11\tGeneric 466 476\tindicators\n",
      "T12\tGeneric 499 503\tthem\n",
      "T13\tMethod 512 530\tretrieval approach\n",
      "T14\tMethod 542 557\tlanguage models\n",
      "T15\tMaterial 580 604\tTREC Blog track test set\n",
      "T16\tOtherScientificTerm 632 654\tcredibility indicators\n",
      "T17\tMetric 679 702\tretrieval effectiveness\n",
      "R1\tFEATURE-OF Arg1:T4 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R3\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R4\tCOREF Arg1:T1 Arg2:T5\n",
      "R5\tPART-OF Arg1:T6 Arg2:T7\n",
      "R6\tCOREF Arg1:T6 Arg2:T8\n",
      "R7\tCOREF Arg1:T8 Arg2:T11\n",
      "R8\tCOREF Arg1:T11 Arg2:T12\n",
      "R9\tPART-OF Arg1:T12 Arg2:T13\n",
      "R10\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R11\tCOREF Arg1:T11 Arg2:T16\n",
      "R12\tEVALUATE-FOR Arg1:T17 Arg2:T16\n",
      "R13\tEVALUATE-FOR Arg1:T15 Arg2:T16\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P08-2034.ann\n",
      "T1\tTask 2 43\tLyric-based song sentiment classification\n",
      "T2\tMethod 157 216\tvector space model (VSM)-based text classification approach\n",
      "T3\tMaterial 255 266\tsong lyrics\n",
      "T4\tOtherScientificTerm 299 308\tsentiment\n",
      "T5\tOtherScientificTerm 381 390\tNegations\n",
      "T6\tOtherScientificTerm 397 406\tmodifiers\n",
      "T7\tOtherScientificTerm 420 438\tsentiment keywords\n",
      "T8\tOtherScientificTerm 474 483\tsentiment\n",
      "T9\tMaterial 490 500\tSong lyric\n",
      "T10\tMethod 557 593\tsentiment vector space model (s-VSM)\n",
      "T11\tMaterial 621 640\tsong lyric document\n",
      "T12\tMethod 687 698\ts-VSM model\n",
      "T13\tMethod 717 726\tVSM model\n",
      "T14\tTask 736 782\tlyric-based song sentiment classification task\n",
      "R1\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R2\tCOMPARE Arg1:T12 Arg2:T13\n",
      "R3\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R5\tUSED-FOR Arg1:T5 Arg2:T8\n",
      "R6\tCOREF Arg1:T3 Arg2:T9\n",
      "R7\tCOREF Arg1:T10 Arg2:T12\n",
      "R8\tEVALUATE-FOR Arg1:T14 Arg2:T12\n",
      "R9\tEVALUATE-FOR Arg1:T14 Arg2:T13\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P80-1004.ann\n",
      "T1\tTask 3 26\tInterpreting  metaphors\n",
      "T2\tTask 71 110\thuman understanding of natural language\n",
      "T3\tGeneric 138 144\tmethod\n",
      "T4\tTask 148 167\tanalyzing metaphors\n",
      "T5\tMethod 214 243\tgeneralized metaphor mappings\n",
      "T6\tOtherScientificTerm 253 273\tgeneralized metaphor\n",
      "T7\tMethod 287 306\trecognition network\n",
      "T8\tMethod 313 326\tbasic mapping\n",
      "T9\tMethod 342 359\ttransfer mappings\n",
      "T10\tMethod 371 399\timplicit intention component\n",
      "T11\tGeneric 425 431\tmethod\n",
      "T12\tTask 441 464\tmetaphor interpretation\n",
      "T13\tTask 474 488\treconstruction\n",
      "T14\tTask 496 512\trecognition task\n",
      "T15\tTask 568 585\tlanguage learning\n",
      "R1\tPART-OF Arg1:T7 Arg2:T6\n",
      "R2\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R5\tCONJUNCTION Arg1:T9 Arg2:T10\n",
      "R6\tCONJUNCTION Arg1:T9 Arg2:T8\n",
      "R7\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R8\tPART-OF Arg1:T8 Arg2:T6\n",
      "R9\tPART-OF Arg1:T9 Arg2:T6\n",
      "R10\tPART-OF Arg1:T10 Arg2:T6\n",
      "R11\tCOREF Arg1:T3 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T14 Arg2:T12\n",
      "R13\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R14\tCOREF Arg1:T12 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P80-1019.ann\n",
      "T1\tOtherScientificTerm 12 39\tnatural language interfaces\n",
      "T2\tMethod 148 156\tdecoding\n",
      "T3\tOtherScientificTerm 220 247\tnatural language interfaces\n",
      "T4\tGeneric 298 302\tthey\n",
      "T5\tMethod 330 366\tnon-literal aspects of communication\n",
      "T6\tMethod 378 410\trobust  communication procedures\n",
      "T7\tMethod 546 582\tnon-literal aspects of communication\n",
      "T8\tOtherScientificTerm 623 641\tpersonal computers\n",
      "T9\tOtherScientificTerm 658 675\tgraphics displays\n",
      "T10\tOtherScientificTerm 928 955\tnatural language interfaces\n",
      "R1\tPART-OF Arg1:T9 Arg2:T8\n",
      "R2\tCOREF Arg1:T3 Arg2:T4\n",
      "R3\tPART-OF Arg1:T5 Arg2:T4\n",
      "R4\tHYPONYM-OF Arg1:T6 Arg2:T5\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P80-1026.ann\n",
      "T1\tOtherScientificTerm 19 35\tnatural language\n",
      "T2\tGeneric 73 75\tit\n",
      "T3\tMethod 284 299\tcomputer system\n",
      "T4\tOtherScientificTerm 319 341\tnatural language input\n",
      "T5\tOtherScientificTerm 456 477\tparsing flexibilities\n",
      "T6\tGeneric 491 497\tsystem\n",
      "T7\tMethod 537 542\tFlexP\n",
      "T8\tMethod 549 582\tbottom-up pattern-matching parser\n",
      "T9\tGeneric 639 652\tflexibilities\n",
      "T10\tOtherScientificTerm 658 685\trestricted natural language\n",
      "T11\tMethod 698 728\tlimited-domain computer system\n",
      "R1\tCOREF Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T3 Arg2:T6\n",
      "R3\tHYPONYM-OF Arg1:T7 Arg2:T8\n",
      "R4\tCOREF Arg1:T5 Arg2:T9\n",
      "R5\tFEATURE-OF Arg1:T9 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R7\tUSED-FOR Arg1:T10 Arg2:T8\n",
      "R8\tPART-OF Arg1:T9 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P81-1032.ann\n",
      "T1\tTask 9 40\tnatural language interpretation\n",
      "T2\tMethod 59 81\tsemantic domain models\n",
      "T3\tMethod 85 114\tfail-soft recovery heuristics\n",
      "T4\tOtherScientificTerm 136 154\tcontrol structures\n",
      "T5\tMethod 167 190\tsingle-strategy parsers\n",
      "T6\tMethod 231 254\tmulti-strategy approach\n",
      "T7\tOtherScientificTerm 347 377\ttask-specific domain knowledge\n",
      "T8\tOtherScientificTerm 396 424\tgeneral linguistic knowledge\n",
      "T9\tOtherScientificTerm 444 479\tgrammatical and ungrammatical input\n",
      "T10\tMethod 485 502\tparsing algorithm\n",
      "T11\tMethod 552 570\tparsing strategies\n",
      "T12\tOtherScientificTerm 579 603\tcase-frame instantiation\n",
      "T13\tMethod 632 650\tparsing strategies\n",
      "T14\tOtherScientificTerm 764 776\tconjunctions\n",
      "T15\tOtherScientificTerm 780 797\tfragmentary input\n",
      "T16\tOtherScientificTerm 805 829\tungrammatical structures\n",
      "T17\tOtherScientificTerm 848 884\texotic,  grammatically correct input\n",
      "T18\tMethod 896 915\tspecific heuristics\n",
      "T19\tOtherScientificTerm 931 950\tungrammatical input\n",
      "T20\tMethod 979 1003\tmulti-strategy framework\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R3\tPART-OF Arg1:T11 Arg2:T10\n",
      "R4\tPART-OF Arg1:T18 Arg2:T20\n",
      "R5\tCOREF Arg1:T11 Arg2:T13\n",
      "R6\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R7\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R8\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "R9\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R10\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R11\tCOMPARE Arg1:T5 Arg2:T6\n",
      "R12\tHYPONYM-OF Arg1:T12 Arg2:T11\n",
      "R13\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R14\tUSED-FOR Arg1:T13 Arg2:T15\n",
      "R15\tUSED-FOR Arg1:T13 Arg2:T16\n",
      "R16\tUSED-FOR Arg1:T13 Arg2:T17\n",
      "R17\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R18\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R19\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R20\tCOREF Arg1:T6 Arg2:T20\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P81-1033.ann\n",
      "T1\tMethod 4 19\tflexible parser\n",
      "T2\tGeneric 113 115\tit\n",
      "T3\tMethod 134 140\tparser\n",
      "T4\tOtherScientificTerm 431 440\tambiguity\n",
      "T5\tMethod 500 506\tparser\n",
      "T6\tMethod 687 717\tconstruction-specific approach\n",
      "T7\tTask 723 739\tflexible parsing\n",
      "T8\tMethod 748 778\tspecialized parsing techniques\n",
      "T9\tTask 798 810\tconstruction\n",
      "T10\tMethod 830 855\tambiguity representations\n",
      "T11\tOtherScientificTerm 875 884\tambiguity\n",
      "T12\tTask 905 917\tconstruction\n",
      "T13\tMethod 940 970\tconstruction-specific approach\n",
      "T14\tTask 986 1020\ttask-specific language development\n",
      "T15\tMethod 1159 1184\tuniform grammar formalism\n",
      "R1\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R3\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R4\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R5\tCOREF Arg1:T1 Arg2:T2\n",
      "R6\tCOREF Arg1:T1 Arg2:T3\n",
      "R7\tCOREF Arg1:T3 Arg2:T5\n",
      "R8\tCONJUNCTION Arg1:T6 Arg2:T8\n",
      "R9\tCONJUNCTION Arg1:T8 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P83-1003.ann\n",
      "T1\tGeneric 4 13\textension\n",
      "T2\tMethod 22 48\tGPSG grammatical formalism\n",
      "T3\tOtherScientificTerm 73 86\tnon-terminals\n",
      "T4\tOtherScientificTerm 155 174\tschematic variables\n",
      "T5\tGeneric 210 219\textension\n",
      "T6\tMethod 278 285\tgrammar\n",
      "T7\tOtherScientificTerm 292 319\tcrossed serial dependencies\n",
      "T8\tOtherScientificTerm 340 365\tDutch subordinate clauses\n",
      "T9\tTask 401 414\tconstructions\n",
      "T10\tGeneric 526 535\textension\n",
      "T11\tGeneric 573 582\textension\n",
      "T12\tMethod 599 613\tparsing method\n",
      "T13\tMethod 620 624\tGPSG\n",
      "R1\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R2\tCOREF Arg1:T1 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R4\tCOREF Arg1:T5 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R7\tCOREF Arg1:T2 Arg2:T13\n",
      "R8\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R9\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P83-1004.ann\n",
      "T1\tMethod 2 28\tMetagrammatical formalisms\n",
      "T2\tOtherScientificTerm 44 79\tcontext-free phrase structure rules\n",
      "T3\tOtherScientificTerm 86 110\tmetarules (MPS grammars)\n",
      "T4\tOtherScientificTerm 166 195\tsyntax  of  natural languages\n",
      "T5\tMethod 199 225\tUnconstrained MPS grammars\n",
      "T6\tGeneric 320 324\tthem\n",
      "T7\tMetric 352 403\tcomputational tractability and explanatory adequacy\n",
      "T8\tGeneric 427 431\tthem\n",
      "T9\tGeneric 447 455\tcriteria\n",
      "T10\tMethod 513 539\tmetagrammatical formalisms\n",
      "R1\tPART-OF Arg1:T2 Arg2:T1\n",
      "R2\tCONJUNCTION Arg1:T2 Arg2:T3\n",
      "R3\tPART-OF Arg1:T3 Arg2:T1\n",
      "R4\tCOREF Arg1:T5 Arg2:T6\n",
      "R5\tCOREF Arg1:T6 Arg2:T8\n",
      "R6\tCOREF Arg1:T7 Arg2:T9\n",
      "R7\tEVALUATE-FOR Arg1:T7 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P84-1020.ann\n",
      "T1\tMethod 30 53\tnatural language system\n",
      "T2\tOtherScientificTerm 82 101\tungrammatical input\n",
      "T3\tGeneric 159 161\tit\n",
      "T4\tTask 166 205\tcomputer aided second language learning\n",
      "T5\tGeneric 218 222\tthis\n",
      "T6\tGeneric 275 281\tsystem\n",
      "T7\tGeneric 321 323\tit\n",
      "T8\tGeneric 446 448\tit\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T1 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tCOREF Arg1:T1 Arg2:T6\n",
      "R5\tCOREF Arg1:T4 Arg2:T5\n",
      "R6\tUSED-FOR Arg1:T6 Arg2:T5\n",
      "R7\tCOREF Arg1:T6 Arg2:T7\n",
      "R8\tCOREF Arg1:T7 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P84-1047.ann\n",
      "T1\tMethod 7 31\tentity-oriented approach\n",
      "T2\tTask 35 60\trestricted-domain parsing\n",
      "T3\tGeneric 83 91\tapproach\n",
      "T4\tOtherScientificTerm 117 176\tstructure  and  surface representation  of  domain entities\n",
      "T5\tMethod 206 222\tsemantic grammar\n",
      "T6\tGeneric 226 230\tthis\n",
      "T7\tOtherScientificTerm 260 284\tlimited domain semantics\n",
      "T8\tGeneric 301 303\tit\n",
      "T9\tTask 317 340\tfragmentary recognition\n",
      "T10\tMethod 358 385\tmultiple parsing strategies\n",
      "T11\tOtherScientificTerm 431 469\trecognition of extra-grammatical input\n",
      "T12\tOtherScientificTerm 588 623\tentity-oriented language definition\n",
      "T13\tOtherScientificTerm 654 671\tcontrol structure\n",
      "T14\tMethod 681 703\tentity-oriented parser\n",
      "T15\tMethod 713 731\tparsing strategies\n",
      "T16\tOtherScientificTerm 747 764\tcontrol structure\n",
      "T17\tMethod 805 811\tparser\n",
      "T18\tOtherScientificTerm 832 849\tcontrol structure\n",
      "T19\tMethod 860 878\tparsing strategies\n",
      "R1\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R2\tUSED-FOR Arg1:T13 Arg2:T14\n",
      "R3\tUSED-FOR Arg1:T16 Arg2:T15\n",
      "R4\tPART-OF Arg1:T18 Arg2:T17\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R6\tCOREF Arg1:T6 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R8\tUSED-FOR Arg1:T8 Arg2:T10\n",
      "R10\tCOREF Arg1:T16 Arg2:T13\n",
      "R11\tCOREF Arg1:T18 Arg2:T16\n",
      "R12\tCOREF Arg1:T19 Arg2:T15\n",
      "R14\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R15\tCOREF Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P84-1078.ann\n",
      "T1\tMethod 26 30\tPaul\n",
      "T2\tMethod 37 68\tcomputer text generation system\n",
      "T3\tMaterial 90 103\tcohesive text\n",
      "T4\tOtherScientificTerm 125 146\tlexical substitutions\n",
      "T5\tGeneric 169 175\tsystem\n",
      "T6\tOtherScientificTerm 225 242\tpronominalization\n",
      "T7\tOtherScientificTerm 247 273\tsuperordinate substitution\n",
      "T8\tOtherScientificTerm 281 314\tdefinite  noun phrase reiteration\n",
      "T9\tGeneric 322 328\tsystem\n",
      "T10\tTask 355 375\tantecedence recovery\n",
      "T11\tOtherScientificTerm 394 415\tlexical substitutions\n",
      "R1\tCOMPARE Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R3\tHYPONYM-OF Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R5\tCOREF Arg1:T1 Arg2:T5\n",
      "R6\tCOREF Arg1:T5 Arg2:T9\n",
      "R7\tCOMPARE Arg1:T7 Arg2:T8\n",
      "R8\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T4 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P85-1019.ann\n",
      "T1\tMethod 24 48\trestricted domain parser\n",
      "T2\tMethod 58 63\tPlume\n",
      "T3\tMethod 139 155\tPlume's approach\n",
      "T4\tTask 159 166\tparsing\n",
      "T5\tOtherScientificTerm 181 213\tsemantic caseframe instantiation\n",
      "T6\tOtherScientificTerm 260 277\tgrammatical input\n",
      "T7\tMetric 285 295\trobustness\n",
      "T8\tOtherScientificTerm 313 332\tungrammatical input\n",
      "T9\tMethod 342 347\tPlume\n",
      "T10\tMaterial 376 413\tdeclarative and imperative utterances\n",
      "T11\tGeneric 416 418\tit\n",
      "T12\tOtherScientificTerm 428 436\tpassives\n",
      "T13\tOtherScientificTerm 440 456\trelative clauses\n",
      "T14\tOtherScientificTerm 463 477\tinterrogatives\n",
      "T15\tOtherScientificTerm 510 536\tpatchy  syntactic coverage\n",
      "T16\tMethod 560 565\tPlume\n",
      "T17\tGeneric 570 572\tit\n",
      "T18\tMethod 639 644\tPlume\n",
      "T19\tOtherScientificTerm 657 665\tpassives\n",
      "T20\tOtherScientificTerm 669 685\trelative clauses\n",
      "T21\tOtherScientificTerm 693 707\tinterrogatives\n",
      "R1\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T2 Arg2:T3\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R4\tUSED-FOR Arg1:T5 Arg2:T3\n",
      "R5\tCOREF Arg1:T3 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R7\tCOREF Arg1:T9 Arg2:T11\n",
      "R8\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R9\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R10\tUSED-FOR Arg1:T11 Arg2:T14\n",
      "R11\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R12\tCONJUNCTION Arg1:T13 Arg2:T14\n",
      "R13\tCOREF Arg1:T9 Arg2:T16\n",
      "R14\tCOREF Arg1:T16 Arg2:T17\n",
      "R15\tCOREF Arg1:T17 Arg2:T18\n",
      "R16\tUSED-FOR Arg1:T18 Arg2:T19\n",
      "R17\tUSED-FOR Arg1:T18 Arg2:T20\n",
      "R18\tUSED-FOR Arg1:T18 Arg2:T21\n",
      "R19\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R20\tCONJUNCTION Arg1:T20 Arg2:T21\n",
      "R21\tFEATURE-OF Arg1:T8 Arg2:T7\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\P86-1011.ann\n",
      "T1\tMethod 48 70\tgrammatical formalisms\n",
      "T2\tMethod 75 98\tTree Adjoining Grammars\n",
      "T3\tMethod 105 118\tHead Grammars\n",
      "T4\tGeneric 180 190\tformalisms\n",
      "T5\tOtherScientificTerm 238 263\tlinguistic expressiveness\n",
      "T6\tGeneric 277 287\tformalisms\n",
      "R1\tCOMPARE Arg1:T2 Arg2:T3\n",
      "R2\tFEATURE-OF Arg1:T5 Arg2:T6\n",
      "R3\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R4\tHYPONYM-OF Arg1:T3 Arg2:T1\n",
      "R5\tCOREF Arg1:T1 Arg2:T4\n",
      "R6\tCOREF Arg1:T4 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W02-1403.ann\n",
      "T1\tTask 2 25\tTerminology structuring\n",
      "T2\tMaterial 193 199\tcorpus\n",
      "T3\tOtherScientificTerm 215 257\thierarchical (or other types of) relations\n",
      "T4\tTask 313 336\tterminology structuring\n",
      "T5\tMethod 342 357\tlexical methods\n",
      "T6\tOtherScientificTerm 427 449\tmorphological variants\n",
      "T7\tMaterial 543 580\thierarchically-structured terminology\n",
      "T8\tMaterial 610 656\tUS National Library of Medicine MeSH thesaurus\n",
      "T9\tOtherScientificTerm 675 702\tlexically-induced relations\n",
      "T10\tOtherScientificTerm 723 737\tMeSH relations\n",
      "T11\tMetric 801 829\trecall and precision metrics\n",
      "T12\tOtherScientificTerm 917 921\tMeSH\n",
      "T13\tMethod 981 1007\tlexical structuring method\n",
      "T14\tOtherScientificTerm 1117 1121\tMeSH\n",
      "T15\tTask 1197 1218\tautomatic structuring\n",
      "R1\tHYPONYM-OF Arg1:T8 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tCOREF Arg1:T12 Arg2:T10\n",
      "R4\tCOMPARE Arg1:T9 Arg2:T10\n",
      "R5\tEVALUATE-FOR Arg1:T11 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W02-1404.ann\n",
      "T1\tMethod 30 58\tknowledge-independent method\n",
      "T2\tMaterial 124 153\tsmall, domain-specific corpus\n",
      "T3\tMaterial 170 214\tparallel English and Chinese court judgments\n",
      "T4\tMaterial 240 263\tsentence-aligned corpus\n",
      "T5\tOtherScientificTerm 267 291\ttranslation equivalences\n",
      "T6\tGeneric 325 343\tfrequency profiles\n",
      "T7\tOtherScientificTerm 349 370\tparallel concordances\n",
      "T8\tGeneric 377 383\tmethod\n",
      "T9\tMethod 427 446\tstatistical methods\n",
      "T10\tMaterial 463 476\tlarge corpora\n",
      "T11\tMethod 500 518\tlexical approaches\n",
      "T12\tMaterial 546 568\tbilingual dictionaries\n",
      "T13\tMaterial 591 606\tparallel corpus\n",
      "T14\tMetric 689 698\tprecision\n",
      "T15\tMetric 709 715\trecall\n",
      "T16\tGeneric 756 765\talgorithm\n",
      "T17\tOtherScientificTerm 817 836\ttranslation lexicon\n",
      "T18\tMaterial 843 860\tlegal terminology\n",
      "R1\tPART-OF Arg1:T6 Arg2:T7\n",
      "R2\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R3\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R4\tCONJUNCTION Arg1:T14 Arg2:T15\n",
      "R5\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R6\tPART-OF Arg1:T3 Arg2:T2\n",
      "R7\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R8\tCOREF Arg1:T8 Arg2:T1\n",
      "R9\tCOMPARE Arg1:T8 Arg2:T9\n",
      "R10\tCOMPARE Arg1:T8 Arg2:T11\n",
      "R11\tCOREF Arg1:T16 Arg2:T8\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W02-1602.ann\n",
      "T1\tTask 2 11\tCoedition\n",
      "T2\tMaterial 19 40\tnatural language text\n",
      "T3\tOtherScientificTerm 135 148\ttext revision\n",
      "T4\tMaterial 158 167\tlanguages\n",
      "T5\tOtherScientificTerm 192 202\tUNL graphs\n",
      "T6\tOtherScientificTerm 428 433\tgraph\n",
      "T7\tOtherScientificTerm 450 455\tgraph\n",
      "T8\tMethod 478 496\tUNL-L0 deconverter\n",
      "T9\tOtherScientificTerm 580 585\tgraph\n",
      "T10\tMethod 600 611\tdeconverter\n",
      "T11\tOtherScientificTerm 623 628\tgraph\n",
      "T12\tMethod 642 654\tdeconverters\n",
      "T13\tMaterial 880 910\toriginal multilingual document\n",
      "T14\tOtherScientificTerm 1019 1027\tliaisons\n",
      "T15\tGeneric 1118 1127\tresources\n",
      "T16\tMaterial 1139 1179\tLO-English or better a L0-UNL dictionary\n",
      "T17\tMethod 1185 1213\tmorphosyntactic parser of L0\n",
      "T18\tOtherScientificTerm 1223 1258\tcanonical graph2tree transformation\n",
      "T19\tOtherScientificTerm 1312 1323\tUNL-tree+L0\n",
      "T20\tOtherScientificTerm 1336 1351\tMS-L0 structure\n",
      "T21\tOtherScientificTerm 1358 1365\tlattice\n",
      "T22\tMaterial 1391 1401\tdictionary\n",
      "T23\tOtherScientificTerm 1477 1494\tcrossing liaisons\n",
      "T24\tTask 1570 1578\tpivot MT\n",
      "T25\tTask 1582 1596\tinteractive MT\n",
      "T26\tTask 1604 1631\tmultilingual text authoring\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R2\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R3\tCONJUNCTION Arg1:T17 Arg2:T18\n",
      "R4\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R7\tCOREF Arg1:T8 Arg2:T10\n",
      "R8\tCOREF Arg1:T10 Arg2:T12\n",
      "R9\tCONJUNCTION Arg1:T25 Arg2:T26\n",
      "R10\tCONJUNCTION Arg1:T24 Arg2:T25\n",
      "R11\tHYPONYM-OF Arg1:T16 Arg2:T15\n",
      "R12\tHYPONYM-OF Arg1:T17 Arg2:T15\n",
      "R13\tHYPONYM-OF Arg1:T18 Arg2:T15\n",
      "R14\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R15\tUSED-FOR Arg1:T22 Arg2:T21\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W03-0406.ann\n",
      "T1\tMethod 31 59\tunsupervised learning method\n",
      "T2\tMethod 72 111\tExpectation-Maximization (EM) algorithm\n",
      "T3\tTask 143 171\ttext classification problems\n",
      "T4\tGeneric 191 193\tit\n",
      "T5\tTask 198 238\tword sense disambiguation (WSD) problems\n",
      "T6\tGeneric 254 260\tmethod\n",
      "T7\tMethod 272 284\tEM algorithm\n",
      "T8\tOtherScientificTerm 294 318\toptimum iteration number\n",
      "T9\tGeneric 338 344\tnumber\n",
      "T10\tTask 400 417\tnoun WSD problems\n",
      "T11\tTask 427 451\tJapanese Dictionary Task\n",
      "T12\tMaterial 455 464\tSENSEVAL2\n",
      "T13\tGeneric 484 490\tmethod\n",
      "T14\tGeneric 536 540\ttask\n",
      "T15\tGeneric 559 566\tmethods\n",
      "T16\tTask 608 625\tverb WSD problems\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R3\tCOREF Arg1:T4 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R5\tCOREF Arg1:T6 Arg2:T1\n",
      "R6\tCOREF Arg1:T9 Arg2:T8\n",
      "R7\tFEATURE-OF Arg1:T11 Arg2:T12\n",
      "R8\tCOREF Arg1:T14 Arg2:T11\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R10\tCOREF Arg1:T15 Arg2:T13\n",
      "R11\tCOREF Arg1:T13 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W03-2907.ann\n",
      "T1\tGeneric 24 32\tapproach\n",
      "T2\tTask 41 83\tunsupervised learning  of  parts of speech\n",
      "T3\tOtherScientificTerm 102 141\tmorphological and syntactic information\n",
      "T4\tGeneric 155 160\tmodel\n",
      "T5\tGeneric 183 188\tthose\n",
      "T6\tTask 219 265\tunsupervised learning  of  POS tags in English\n",
      "T7\tOtherScientificTerm 284 305\tsyntactic information\n",
      "T8\tOtherScientificTerm 375 385\tmorphology\n",
      "T9\tOtherScientificTerm 418 428\tmorphology\n",
      "T10\tOtherScientificTerm 479 489\tword order\n",
      "T11\tGeneric 508 527\tcomputational model\n",
      "T12\tTask 534 546\tPOS learning\n",
      "T13\tGeneric 582 584\tit\n",
      "T14\tMaterial 589 598\tBulgarian\n",
      "T15\tMaterial 604 619\tSlavic language\n",
      "T16\tOtherScientificTerm 638 653\tfree word order\n",
      "T17\tOtherScientificTerm 660 675\trich morphology\n",
      "R1\tUSED-FOR Arg1:T11 Arg2:T12\n",
      "R2\tHYPONYM-OF Arg1:T14 Arg2:T15\n",
      "R3\tCOMPARE Arg1:T9 Arg2:T10\n",
      "R4\tCONJUNCTION Arg1:T16 Arg2:T17\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R7\tCOREF Arg1:T4 Arg2:T1\n",
      "R8\tCOMPARE Arg1:T4 Arg2:T5\n",
      "R9\tUSED-FOR Arg1:T5 Arg2:T6\n",
      "R10\tUSED-FOR Arg1:T7 Arg2:T5\n",
      "R11\tCOREF Arg1:T11 Arg2:T4\n",
      "R12\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R13\tFEATURE-OF Arg1:T16 Arg2:T14\n",
      "R14\tFEATURE-OF Arg1:T17 Arg2:T14\n",
      "R15\tCOREF Arg1:T13 Arg2:T11\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W04-1307.ann\n",
      "T1\tMethod 25 44\tcomputational model\n",
      "T2\tTask 50 67\tword segmentation\n",
      "T3\tTask 105 126\trealistic acquisition\n",
      "T4\tMethod 188 219\tstatistical learning mechanisms\n",
      "T5\tMaterial 262 282\tcognitive psychology\n",
      "T6\tMaterial 289 300\tlinguistics\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T6 Arg2:T4\n",
      "R4\tCONJUNCTION Arg1:T5 Arg2:T6\n",
      "R5\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W04-2204.ann\n",
      "T1\tMaterial 44 63\ttransfer dictionary\n",
      "T2\tTask 81 104\tDictionary construction\n",
      "T3\tTask 156 182\tmachine translation system\n",
      "T4\tGeneric 253 263\tdictionary\n",
      "T5\tMaterial 281 301\tlinguistic resources\n",
      "T6\tMaterial 404 433\tKorean-to-Japanese dictionary\n",
      "T7\tMaterial 442 449\tEnglish\n",
      "T8\tTask 491 513\tautomatic construction\n",
      "T9\tOtherScientificTerm 549 581\tdirectionality  of  dictionaries\n",
      "T10\tGeneric 569 581\tdictionaries\n",
      "T11\tMethod 605 630\t\"one-time look up\" method\n",
      "T12\tMaterial 641 695\tKorean-to-English and a Japanese-to-English dictionary\n",
      "T13\tGeneric 716 722\tmethod\n",
      "T14\tOtherScientificTerm 730 754\t\"overlapping constraint\"\n",
      "T15\tMaterial 764 792\tKorean-to-English dictionary\n",
      "T16\tMaterial 802 832\tEnglish-to-Japanese dictionary\n",
      "T17\tGeneric 874 880\tmethod\n",
      "T18\tGeneric 909 919\tdictionary\n",
      "T19\tMaterial 926 954\tEnglish-to-Korean dictionary\n",
      "T20\tMaterial 961 991\tEnglish-to-Japanese dictionary\n",
      "T21\tGeneric 1018 1024\tmethod\n",
      "R1\tPART-OF Arg1:T2 Arg2:T3\n",
      "R2\tUSED-FOR Arg1:T5 Arg2:T4\n",
      "R3\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R4\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R5\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R6\tCONJUNCTION Arg1:T19 Arg2:T20\n",
      "R7\tCOREF Arg1:T4 Arg2:T1\n",
      "R8\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R9\tUSED-FOR Arg1:T15 Arg2:T13\n",
      "R10\tUSED-FOR Arg1:T16 Arg2:T13\n",
      "R11\tCOREF Arg1:T21 Arg2:T11\n",
      "R12\tUSED-FOR Arg1:T17 Arg2:T18\n",
      "R13\tHYPONYM-OF Arg1:T19 Arg2:T18\n",
      "R14\tHYPONYM-OF Arg1:T20 Arg2:T18\n",
      "R15\tCOREF Arg1:T10 Arg2:T4\n",
      "R16\tEVALUATE-FOR Arg1:T8 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W04-2703.ann\n",
      "T1\tTask 30 68\tlarge scale discourse-level annotation\n",
      "T2\tMaterial 85 115\tPenn Discourse TreeBank (PDTB)\n",
      "T3\tGeneric 132 140\tapproach\n",
      "T4\tOtherScientificTerm 167 186\tdiscourse structure\n",
      "T5\tOtherScientificTerm 218 239\tdiscourse connectives\n",
      "T6\tMaterial 269 273\tPDTB\n",
      "T7\tMaterial 314 327\tPenn TreeBank\n",
      "T8\tMaterial 334 342\tPropbank\n",
      "T9\tTask 365 418\textraction of useful  syntactic and semantic features\n",
      "T10\tMethod 492 512\tpractical algorithms\n",
      "T11\tMetric 562 587\tinter-annotator agreement\n",
      "T12\tMetric 601 619\tlevel of agreement\n",
      "T13\tOtherScientificTerm 639 664\tinter-annotator variation\n",
      "R1\tCOREF Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T6 Arg2:T2\n",
      "R3\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R7\tUSED-FOR Arg1:T5 Arg2:T3\n",
      "R8\tEVALUATE-FOR Arg1:T6 Arg2:T10\n",
      "R9\tUSED-FOR Arg1:T6 Arg2:T9\n",
      "R10\tFEATURE-OF Arg1:T12 Arg2:T11\n",
      "R11\tFEATURE-OF Arg1:T13 Arg2:T11\n",
      "R12\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in ./benchmarking/input/sciERC_raw\\W05-1308.ann\n",
      "T1\tMethod 30 63\tfully automated extraction system\n",
      "T2\tMethod 73 78\tIntEx\n",
      "T3\tTask 94 123\tgene and protein interactions\n",
      "T4\tMaterial 129 144\tbiomedical text\n",
      "T5\tGeneric 151 159\tapproach\n",
      "T6\tOtherScientificTerm 253 268\tsyntactic roles\n",
      "T7\tOtherScientificTerm 286 305\tbiological entities\n",
      "T8\tOtherScientificTerm 325 361\tbiomedical and linguistic ontologies\n",
      "T9\tOtherScientificTerm 447 462\tsyntactic roles\n",
      "T10\tMethod 520 537\textraction system\n",
      "T11\tOtherScientificTerm 581 613\tmultiple and nested interactions\n",
      "T12\tMethod 700 718\textraction systems\n",
      "T13\tMethod 739 751\tIntEx system\n",
      "T14\tOtherScientificTerm 812 843\tpattern engineering requirement\n",
      "R1\tCOMPARE Arg1:T13 Arg2:T12\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T1\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T3\n",
      "R4\tUSED-FOR Arg1:T4 Arg2:T3\n",
      "R5\tCOREF Arg1:T5 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T8 Arg2:T7\n",
      "R7\tCOREF Arg1:T10 Arg2:T5\n",
      "R8\tUSED-FOR Arg1:T10 Arg2:T11\n",
      "R9\tCOREF Arg1:T13 Arg2:T10\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W06-1605.ann\n",
      "T1\tGeneric 14 23\tframework\n",
      "T2\tOtherScientificTerm 58 66\tconcepts\n",
      "T3\tMethod 74 120\tdistributional measures of word co-occurrences\n",
      "T4\tOtherScientificTerm 178 201\tcoarse-grained concepts\n",
      "T5\tOtherScientificTerm 263 285\tconcept-concept matrix\n",
      "T6\tMethod 379 404\tconcept-distance measures\n",
      "T7\tMethod 430 467\tdistributional word-distance measures\n",
      "T8\tGeneric 476 481\ttasks\n",
      "T9\tTask 489 540\tranking  word pairs  in order of  semantic distance\n",
      "T10\tTask 551 588\tcorrecting  real-word spelling errors\n",
      "T11\tGeneric 605 609\ttask\n",
      "T12\tMethod 623 645\tWordNet-based measures\n",
      "T13\tMethod 710 750\tdistributional concept-distance measures\n",
      "R1\tCOMPARE Arg1:T7 Arg2:T6\n",
      "R2\tCOMPARE Arg1:T13 Arg2:T12\n",
      "R3\tUSED-FOR Arg1:T3 Arg2:T1\n",
      "R4\tHYPONYM-OF Arg1:T9 Arg2:T8\n",
      "R5\tHYPONYM-OF Arg1:T10 Arg2:T8\n",
      "R6\tUSED-FOR Arg1:T7 Arg2:T8\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R8\tCOREF Arg1:T11 Arg2:T10\n",
      "R9\tCOREF Arg1:T6 Arg2:T1\n",
      "R10\tCONJUNCTION Arg1:T10 Arg2:T9\n",
      "R11\tEVALUATE-FOR Arg1:T11 Arg2:T12\n",
      "R12\tEVALUATE-FOR Arg1:T11 Arg2:T13\n",
      "R13\tCOREF Arg1:T13 Arg2:T6\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W07-0208.ann\n",
      "T1\tMethod 38 60\tlabeled directed graph\n",
      "T2\tOtherScientificTerm 93 114\tlinguistic structures\n",
      "T3\tGeneric 136 140\tthis\n",
      "T4\tTask 161 170\tNLP tasks\n",
      "T5\tTask 176 197\tgraph transformations\n",
      "T6\tMethod 221 227\tmethod\n",
      "T7\tGeneric 247 262\ttransformations\n",
      "T8\tMaterial 273 289\tannotated corpus\n",
      "T9\tGeneric 325 337\tapplications\n",
      "T10\tGeneric 345 351\tmethod\n",
      "T11\tTask 354 393\tidentification of non-local depenencies\n",
      "T12\tMaterial 403 421\tPenn Treebank data\n",
      "T13\tTask 429 451\tsemantic role labeling\n",
      "T14\tMaterial 461 482\tProposition Bank data\n",
      "R1\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R2\tUSED-FOR Arg1:T14 Arg2:T13\n",
      "R3\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R4\tUSED-FOR Arg1:T1 Arg2:T4\n",
      "R5\tCOREF Arg1:T3 Arg2:T1\n",
      "R6\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R7\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R8\tCOREF Arg1:T7 Arg2:T5\n",
      "R9\tUSED-FOR Arg1:T8 Arg2:T6\n",
      "R10\tCOREF Arg1:T10 Arg2:T6\n",
      "R11\tHYPONYM-OF Arg1:T11 Arg2:T9\n",
      "R12\tHYPONYM-OF Arg1:T13 Arg2:T9\n",
      "R13\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W08-2122.ann\n",
      "T1\tTask 48 70\tCoNLL 2008 shared task\n",
      "T2\tMethod 85 131\tgenerative history-based latent variable model\n",
      "T3\tTask 179 208\tsynchronous dependency parser\n",
      "T4\tOtherScientificTerm 220 255\tsyntactic and semantic dependencies\n",
      "T5\tGeneric 273 278\tmodel\n",
      "T6\tMetric 294 322\tmacro-average F1 performance\n",
      "T7\tGeneric 339 343\ttask\n",
      "T8\tMetric 352 378\tsyntactic dependencies LAS\n",
      "T9\tMetric 391 415\tsemantic dependencies F1\n",
      "T10\tGeneric 428 433\tmodel\n",
      "T11\tMetric 478 494\tmacro-average F1\n",
      "T12\tMetric 504 530\tsyntactic dependencies LAS\n",
      "T13\tMetric 544 568\tsemantic dependencies F1\n",
      "R1\tUSED-FOR Arg1:T2 Arg2:T1\n",
      "R2\tCOREF Arg1:T5 Arg2:T2\n",
      "R3\tEVALUATE-FOR Arg1:T6 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R5\tUSED-FOR Arg1:T2 Arg2:T3\n",
      "R6\tCOREF Arg1:T7 Arg2:T1\n",
      "R7\tEVALUATE-FOR Arg1:T6 Arg2:T7\n",
      "R8\tEVALUATE-FOR Arg1:T8 Arg2:T7\n",
      "R9\tEVALUATE-FOR Arg1:T9 Arg2:T7\n",
      "R10\tCONJUNCTION Arg1:T8 Arg2:T9\n",
      "R11\tEVALUATE-FOR Arg1:T11 Arg2:T10\n",
      "R12\tEVALUATE-FOR Arg1:T12 Arg2:T10\n",
      "R13\tEVALUATE-FOR Arg1:T13 Arg2:T10\n",
      "R14\tCONJUNCTION Arg1:T12 Arg2:T13\n",
      "R15\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\W99-0408.ann\n",
      "T1\tMethod 38 74\tuser knowledge modeling architecture\n",
      "T2\tTask 85 98\tICICLE system\n",
      "T3\tTask 104 133\tlanguage tutoring application\n",
      "T4\tOtherScientificTerm 139 152\tdeaf learners\n",
      "T5\tMaterial 157 172\twritten English\n",
      "T6\tGeneric 179 184\tmodel\n",
      "T7\tTask 285 301\twriting analysis\n",
      "T8\tTask 308 327\tfeedback production\n",
      "T9\tGeneric 347 359\tmodel design\n",
      "T10\tTask 393 440\tsecond language and cognitive skill acquisition\n",
      "T11\tGeneric 510 516\tdesign\n",
      "T12\tGeneric 551 557\tdesign\n",
      "T13\tTask 613 657\tlanguage assessment / correction application\n",
      "T14\tOtherScientificTerm 671 687\tuser proficiency\n",
      "T15\tMetric 708 719\tgranularity\n",
      "T16\tMetric 724 735\tspecificity\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tHYPONYM-OF Arg1:T2 Arg2:T3\n",
      "R3\tCOREF Arg1:T6 Arg2:T1\n",
      "R4\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R5\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R6\tCONJUNCTION Arg1:T7 Arg2:T8\n",
      "R7\tCOREF Arg1:T9 Arg2:T6\n",
      "R8\tUSED-FOR Arg1:T10 Arg2:T9\n",
      "R9\tCOREF Arg1:T11 Arg2:T9\n",
      "R10\tCOREF Arg1:T12 Arg2:T11\n",
      "R11\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R12\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R13\tUSED-FOR Arg1:T5 Arg2:T3\n",
      "R14\tUSED-FOR Arg1:T3 Arg2:T4\n",
      "R15\tCONJUNCTION Arg1:T15 Arg2:T16\n",
      "R16\tEVALUATE-FOR Arg1:T15 Arg2:T14\n",
      "R17\tEVALUATE-FOR Arg1:T16 Arg2:T14\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\X96-1041.ann\n",
      "T1\tMethod 6 26\tTIPSTER Architecture\n",
      "T2\tTask 80 97\ttext applications\n",
      "T3\tMethod 116 146\tcommon text processing modules\n",
      "T4\tOtherScientificTerm 156 171\tuser interfaces\n",
      "T5\tGeneric 215 227\tapplications\n",
      "T6\tOtherScientificTerm 270 306\tuser interface styles or conventions\n",
      "T7\tOtherScientificTerm 330 364\tTIPSTER Architecture specification\n",
      "T8\tTask 443 463\tTIPSTER applications\n",
      "T9\tOtherScientificTerm 504 544\tGraphical User Interface (GUI) functions\n",
      "T10\tOtherScientificTerm 554 558\tGUIs\n",
      "T11\tMethod 584 627\tCRL's TIPSTER User Interface Toolkit (TUIT)\n",
      "T12\tMethod 631 635\tTUIT\n",
      "T13\tMethod 643 659\tsoftware library\n",
      "T14\tOtherScientificTerm 692 728\tmultilingual TIPSTER user interfaces\n",
      "T15\tMethod 779 783\tTUIT\n",
      "T16\tMethod 821 836\tTIPSTER modules\n",
      "T17\tMethod 976 980\tTUIT\n",
      "R1\tUSED-FOR Arg1:T1 Arg2:T2\n",
      "R2\tUSED-FOR Arg1:T3 Arg2:T2\n",
      "R3\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T8\n",
      "R5\tCOREF Arg1:T10 Arg2:T9\n",
      "R6\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R7\tCOREF Arg1:T12 Arg2:T11\n",
      "R8\tHYPONYM-OF Arg1:T12 Arg2:T13\n",
      "R9\tUSED-FOR Arg1:T12 Arg2:T14\n",
      "R10\tCOREF Arg1:T15 Arg2:T12\n",
      "R11\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R12\tCOREF Arg1:T17 Arg2:T15\n",
      "R13\tCOREF Arg1:T16 Arg2:T1\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\X96-1059.ann\n",
      "T1\tTask 2 29\tRecognition of proper nouns\n",
      "T2\tOtherScientificTerm 17 29\tproper nouns\n",
      "T3\tMaterial 35 48\tJapanese text\n",
      "T4\tTask 109 131\tmorphological analysis\n",
      "T5\tTask 137 161\tJapanese text processing\n",
      "T6\tGeneric 174 176\tIt\n",
      "T7\tTask 220 251\tJapanese information extraction\n",
      "T8\tGeneric 280 288\tapproach\n",
      "T9\tTask 296 331\tMulti-lingual Evaluation Task (MET)\n",
      "T10\tMaterial 337 350\tJapanese text\n",
      "T11\tGeneric 377 381\ttask\n",
      "T12\tTask 388 418\tmorphological analysis problem\n",
      "T13\tMaterial 424 432\tJapanese\n",
      "T14\tMethod 440 462\tmorphological analyzer\n",
      "T15\tTask 505 587\trecognition and classification of proper names, numerical and temporal expressions\n",
      "T16\tOtherScientificTerm 539 587\tproper names, numerical and temporal expressions\n",
      "T17\tOtherScientificTerm 594 617\tNamed Entity (NE) items\n",
      "T18\tMaterial 627 640\tJapanese text\n",
      "T19\tGeneric 648 656\tanalyzer\n",
      "T20\tMethod 668 676\t\"Amorph\"\n",
      "T21\tMethod 678 684\tAmorph\n",
      "T22\tOtherScientificTerm 697 705\tNE items\n",
      "T23\tMethod 723 740\tdictionary lookup\n",
      "T24\tMethod 747 763\trule application\n",
      "T25\tGeneric 773 775\tit\n",
      "T26\tOtherScientificTerm 799 811\tdictionaries\n",
      "T27\tOtherScientificTerm 833 859\tJapanese character strings\n",
      "T28\tMethod 915 938\tdictionary lookup stage\n",
      "T29\tOtherScientificTerm 951 956\trules\n",
      "T30\tOtherScientificTerm 1018 1026\tNE items\n",
      "T31\tOtherScientificTerm 1065 1072\tNE item\n",
      "R1\tPART-OF Arg1:T1 Arg2:T4\n",
      "R2\tUSED-FOR Arg1:T4 Arg2:T5\n",
      "R3\tUSED-FOR Arg1:T8 Arg2:T9\n",
      "R4\tUSED-FOR Arg1:T9 Arg2:T10\n",
      "R5\tCOREF Arg1:T9 Arg2:T11\n",
      "R6\tUSED-FOR Arg1:T12 Arg2:T11\n",
      "R7\tUSED-FOR Arg1:T13 Arg2:T12\n",
      "R8\tCOREF Arg1:T12 Arg2:T4\n",
      "R9\tCOREF Arg1:T10 Arg2:T3\n",
      "R10\tCOREF Arg1:T10 Arg2:T13\n",
      "R11\tCOREF Arg1:T1 Arg2:T6\n",
      "R12\tUSED-FOR Arg1:T7 Arg2:T6\n",
      "R13\tCOREF Arg1:T19 Arg2:T14\n",
      "R14\tCOREF Arg1:T20 Arg2:T19\n",
      "R15\tCOREF Arg1:T21 Arg2:T20\n",
      "R16\tUSED-FOR Arg1:T21 Arg2:T22\n",
      "R17\tCONJUNCTION Arg1:T23 Arg2:T24\n",
      "R18\tPART-OF Arg1:T23 Arg2:T21\n",
      "R19\tPART-OF Arg1:T24 Arg2:T21\n",
      "R20\tCOREF Arg1:T21 Arg2:T25\n",
      "R21\tUSED-FOR Arg1:T26 Arg2:T27\n",
      "R22\tUSED-FOR Arg1:T26 Arg2:T25\n",
      "R23\tCOREF Arg1:T28 Arg2:T23\n",
      "R24\tUSED-FOR Arg1:T14 Arg2:T15\n",
      "R25\tHYPONYM-OF Arg1:T17 Arg2:T16\n",
      "R26\tPART-OF Arg1:T17 Arg2:T18\n",
      "R27\tCOREF Arg1:T13 Arg2:T18\n",
      "R28\tUSED-FOR Arg1:T29 Arg2:T30\n",
      "R29\tPART-OF Arg1:T2 Arg2:T3\n",
      "R30\tUSED-FOR Arg1:T28 Arg2:T29\n",
      "R31\tCOREF Arg1:T17 Arg2:T30\n",
      "R32\tCOREF Arg1:T31 Arg2:T30\n",
      "R33\tCOREF Arg1:T22 Arg2:T17\n",
      "-----------\n",
      "Annotations in ./benchmarking/input/sciERC_raw\\X98-1022.ann\n",
      "T1\tTask 2 25\tAutomatic summarization\n",
      "T2\tTask 32 54\tinformation extraction\n",
      "T3\tMaterial 94 97\tMUC\n",
      "T4\tMaterial 104 110\tSUMMAC\n",
      "T5\tTask 201 224\tautomatic summarization\n",
      "T6\tGeneric 253 259\tmodels\n",
      "T7\tTask 288 306\tsummary generation\n",
      "T8\tGeneric 318 323\ttasks\n",
      "T9\tMaterial 338 346\tSUMMAC-1\n",
      "T10\tTask 354 373\tcategorization task\n",
      "T11\tOtherScientificTerm 377 401\tpositive feature vectors\n",
      "T12\tOtherScientificTerm 408 432\tnegative feature vectors\n",
      "T13\tOtherScientificTerm 470 500\tgeneric, indicative  summaries\n",
      "T14\tTask 507 517\tadhoc task\n",
      "T15\tMethod 522 532\ttext model\n",
      "T16\tOtherScientificTerm 618 635\tdiscourse segment\n",
      "T17\tOtherScientificTerm 689 712\tuser-directed summaries\n",
      "T18\tMetric 742 747\tNormF\n",
      "T19\tTask 803 814\tadhoc tasks\n",
      "T20\tMetric 842 847\tNormF\n",
      "T21\tTask 904 923\tcategorization task\n",
      "T22\tGeneric 952 958\tsystem\n",
      "T23\tGeneric 983 989\tsystem\n",
      "T24\tTask 994 1013\tcategorization task\n",
      "T25\tTask 1040 1050\tadhoc task\n",
      "R1\tCONJUNCTION Arg1:T1 Arg2:T2\n",
      "R2\tCOREF Arg1:T1 Arg2:T5\n",
      "R3\tCONJUNCTION Arg1:T11 Arg2:T12\n",
      "R4\tUSED-FOR Arg1:T11 Arg2:T10\n",
      "R5\tUSED-FOR Arg1:T12 Arg2:T10\n",
      "R6\tUSED-FOR Arg1:T15 Arg2:T16\n",
      "R7\tUSED-FOR Arg1:T15 Arg2:T17\n",
      "R8\tUSED-FOR Arg1:T15 Arg2:T14\n",
      "R9\tCOREF Arg1:T20 Arg2:T18\n",
      "R10\tEVALUATE-FOR Arg1:T20 Arg2:T21\n",
      "R11\tCOREF Arg1:T21 Arg2:T10\n",
      "R12\tCOREF Arg1:T14 Arg2:T19\n",
      "R13\tCOREF Arg1:T24 Arg2:T21\n",
      "R14\tEVALUATE-FOR Arg1:T24 Arg2:T23\n",
      "R15\tEVALUATE-FOR Arg1:T24 Arg2:T22\n",
      "R16\tCOMPARE Arg1:T22 Arg2:T23\n",
      "R17\tUSED-FOR Arg1:T12 Arg2:T13\n",
      "R18\tUSED-FOR Arg1:T11 Arg2:T13\n",
      "R19\tUSED-FOR Arg1:T6 Arg2:T7\n",
      "R20\tEVALUATE-FOR Arg1:T18 Arg2:T19\n",
      "R21\tEVALUATE-FOR Arg1:T25 Arg2:T24\n",
      "R22\tEVALUATE-FOR Arg1:T25 Arg2:T22\n",
      "R23\tCOREF Arg1:T19 Arg2:T25\n",
      "R24\tCONJUNCTION Arg1:T3 Arg2:T4\n",
      "R25\tPART-OF Arg1:T8 Arg2:T9\n",
      "R26\tHYPONYM-OF Arg1:T10 Arg2:T8\n",
      "R27\tHYPONYM-OF Arg1:T14 Arg2:T8\n",
      "R28\tUSED-FOR Arg1:T6 Arg2:T8\n",
      "R29\tCOREF Arg1:T6 Arg2:T22\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# Directory path:\n",
    "directory_path = './benchmarking/input/sciERC_raw'\n",
    "\n",
    "# Get the list of .ann files in the directory\n",
    "ann_files = glob.glob(os.path.join(directory_path, '*.ann'))\n",
    "\n",
    "# Iterate over each .ann file\n",
    "for ann_file in ann_files:\n",
    "    # Load the .ann file\n",
    "    with open(ann_file, 'r') as f:\n",
    "        annotations = f.readlines()\n",
    "\n",
    "    # Print the .ann file name\n",
    "    print(\"Annotations in\", ann_file)\n",
    "\n",
    "    # Print the annotations\n",
    "    for annotation in annotations:\n",
    "        print(annotation.strip())\n",
    "\n",
    "    print(\"-----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2164da23",
   "metadata": {},
   "source": [
    "## Extract entities and relationships data into separate cols, corresponding to the .ann file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "598fcfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory path where your files are stored\n",
    "directory_path = './benchmarking/input/sciERC_raw'\n",
    "\n",
    "# Initialize empty lists to store the data\n",
    "abstracts = []\n",
    "entities = []\n",
    "relationships = []\n",
    "\n",
    "# Get the list of .ann files in the directory\n",
    "ann_files = glob.glob(os.path.join(directory_path, '*.ann'))\n",
    "\n",
    "# Iterate over each .ann file\n",
    "for ann_file in ann_files:\n",
    "    # Load the .ann file\n",
    "    with open(ann_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Extract the abstract (title of .ann file)\n",
    "    abstract = os.path.splitext(os.path.basename(ann_file))[0]\n",
    "\n",
    "    # Store the annotations in a dictionary\n",
    "    ann_dict = {}\n",
    "    rel_dict = {}\n",
    "    for line in lines:\n",
    "        line_parts = line.strip().split('\\t')\n",
    "        if line_parts[0].startswith('T'):\n",
    "            ann_id = line_parts[0]\n",
    "            ann_type = line_parts[1].split()[0]\n",
    "            start_offset = int(line_parts[1].split()[1])\n",
    "            end_offset = int(line_parts[1].split()[2])\n",
    "            annotated_text = line_parts[2]\n",
    "            ann_dict[ann_id] = {\n",
    "                'Annotation ID': ann_id,\n",
    "                'Entity': ann_type,\n",
    "                'Start Offset': start_offset,\n",
    "                'End Offset': end_offset,\n",
    "                'Annotated Text': annotated_text\n",
    "            }\n",
    "        elif line_parts[0].startswith('R'):\n",
    "            rel_id = line_parts[0]\n",
    "            rel_type = line_parts[1].split()[0]\n",
    "            arg1_id = line_parts[1].split()[1].split(':')[1]\n",
    "            arg2_id = line_parts[1].split()[2].split(':')[1]\n",
    "            rel_dict[rel_id] = {\n",
    "                'Relationship ID': rel_id,\n",
    "                'Type': rel_type,\n",
    "                'Arg1': arg1_id,\n",
    "                'Arg2': arg2_id\n",
    "            }\n",
    "\n",
    "    # Append the data to the lists\n",
    "    abstracts.append(abstract)\n",
    "    entities.append(ann_dict)\n",
    "    relationships.append(rel_dict)\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "data = {\n",
    "    'abstract_id': abstracts,\n",
    "    'entities': entities,\n",
    "    'relationships': relationships\n",
    "}\n",
    "\n",
    "annotations_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "176aea5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "1    A00-2023   \n",
       "2    A88-1001   \n",
       "3    A88-1003   \n",
       "4    A92-1010   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "1  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "2  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "3  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "4  {'T1': {'Annotation ID': 'T1', 'Entity': 'Task...   \n",
       "\n",
       "                                       relationships  \n",
       "0  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...  \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Type': 'COMP...  \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...  \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Type': 'PART...  \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(annotations_df))\n",
    "annotations_df.head()\n",
    "\n",
    "# export to excel to view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105dfba6",
   "metadata": {},
   "source": [
    "### Create populated_rels column, replacing entity IDs in the relationships col."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4da029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'populated_rels' in annotations_df\n",
    "annotations_df['populated_rels'] = None\n",
    "\n",
    "# Iterate over each row in annotations_df\n",
    "for index, row in annotations_df.iterrows():\n",
    "    # Get the entities and relationships dictionaries for the current row\n",
    "    entities_dict = row['entities']\n",
    "    relationships_dict = row['relationships']\n",
    "    \n",
    "    # Create a new dictionary to store the populated relationships\n",
    "    populated_rels_dict = {}\n",
    "    \n",
    "    # Iterate over each relationship in relationships_dict\n",
    "    for rel_id, rel_info in relationships_dict.items():\n",
    "        # Get the argument IDs\n",
    "        arg1_id = rel_info['Arg1']\n",
    "        arg2_id = rel_info['Arg2']\n",
    "        \n",
    "        # Get the corresponding annotated texts from entities_dict\n",
    "        arg1_text = entities_dict[arg1_id]['Annotated Text']\n",
    "        arg2_text = entities_dict[arg2_id]['Annotated Text']\n",
    "        \n",
    "        # Create the populated relationship string\n",
    "        rel_text = f\"{arg1_text} {rel_info['Type']} {arg2_text}\"\n",
    "        \n",
    "        # Store the populated relationship in the new dictionary\n",
    "        populated_rels_dict[rel_id] = {\n",
    "            'Relationship ID': rel_id,\n",
    "            'Rel': rel_text\n",
    "        }\n",
    "    \n",
    "    # Assign the populated relationships dictionary to the 'populated_rels' column\n",
    "    annotations_df.at[index, 'populated_rels'] = populated_rels_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e41bbb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMP...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'prono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'displ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "1    A00-2023   \n",
       "2    A88-1001   \n",
       "3    A88-1003   \n",
       "4    A92-1010   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "1  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "2  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "3  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "4  {'T1': {'Annotation ID': 'T1', 'Entity': 'Task...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Type': 'COMP...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Type': 'PART...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "\n",
       "                                      populated_rels  \n",
       "0  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...  \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...  \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...  \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Rel': 'prono...  \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Rel': 'displ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(annotations_df))\n",
    "annotations_df.head()\n",
    "\n",
    "# export to excel to view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a10c632",
   "metadata": {},
   "source": [
    "### Create a simplified populated_rels col, and a count_of_rels col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dcdb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'simplified_populated_rels' in annotations_df\n",
    "annotations_df['simplified_populated_rels'] = None\n",
    "\n",
    "# Iterate over each row in annotations_df\n",
    "for index, row in annotations_df.iterrows():\n",
    "    # Get the populated relationships dictionary for the current row\n",
    "    populated_rels_dict = row['populated_rels']\n",
    "    \n",
    "    # Extract the relationship strings from populated_rels_dict\n",
    "    rel_strings = [rel_info['Rel'] for rel_info in populated_rels_dict.values()]\n",
    "    \n",
    "    # Assign the simplified relationship strings to the 'simplified_populated_rels' column\n",
    "    annotations_df.at[index, 'simplified_populated_rels'] = rel_strings\n",
    "    \n",
    "# Create a new column 'rel_count' in annotations_df\n",
    "annotations_df['rel_count'] = annotations_df['simplified_populated_rels'].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "683988b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMP...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...</td>\n",
       "      <td>[ranking algorithm COMPARE lattice-based appro...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...</td>\n",
       "      <td>[feedback FEATURE-OF discourse, videodisc imag...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'prono...</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'displ...</td>\n",
       "      <td>[display of graphical information USED-FOR cog...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "1    A00-2023   \n",
       "2    A88-1001   \n",
       "3    A88-1003   \n",
       "4    A92-1010   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "1  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "2  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "3  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "4  {'T1': {'Annotation ID': 'T1', 'Entity': 'Task...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Type': 'COMP...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Type': 'PART...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "\n",
       "                                      populated_rels  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Rel': 'prono...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Rel': 'displ...   \n",
       "\n",
       "                           simplified_populated_rels  \\\n",
       "0  [multi-component architecture USED-FOR system,...   \n",
       "1  [ranking algorithm COMPARE lattice-based appro...   \n",
       "2  [feedback FEATURE-OF discourse, videodisc imag...   \n",
       "3  [pronominal anaphora resolution module PART-OF...   \n",
       "4  [display of graphical information USED-FOR cog...   \n",
       "\n",
       "   rel_count  \n",
       "0         13  \n",
       "1          9  \n",
       "2          9  \n",
       "3          3  \n",
       "4          3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(annotations_df))\n",
    "annotations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20db4404",
   "metadata": {},
   "source": [
    "## Load .txt files (same name as corresponding .ann files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cf4d21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>\\nThis paper presents a new approach to  stati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>\\n This paper describes a domain independent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>\\n In this paper, we describe the  pronominal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>\\nIn our current research into the design of  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "1    A00-2023   \n",
       "2    A88-1001   \n",
       "3    A88-1003   \n",
       "4    A92-1010   \n",
       "\n",
       "                                                text  \n",
       "0  \\nThis paper introduces a  system for categori...  \n",
       "1  \\nThis paper presents a new approach to  stati...  \n",
       "2   \\n This paper describes a domain independent ...  \n",
       "3   \\n In this paper, we describe the  pronominal...  \n",
       "4  \\nIn our current research into the design of  ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the directory containing the .txt files\n",
    "txt_directory = './benchmarking/input/sciERC_raw'\n",
    "\n",
    "# Create an empty DataFrame to store the text data\n",
    "text_df = pd.DataFrame(columns=['abstract_id', 'text'])\n",
    "\n",
    "# Iterate over the rows of annotations_df\n",
    "for index, row in annotations_df.iterrows():\n",
    "    # Extract the abstract name\n",
    "    abstract = row['abstract_id']\n",
    "    \n",
    "    # Construct the path to the corresponding .txt file\n",
    "    txt_file_path = os.path.join(txt_directory, f'{abstract}.txt')\n",
    "    \n",
    "    # Load the text from the .txt file\n",
    "    with open(txt_file_path, 'r') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # Append the abstract name and text to text_df\n",
    "    text_df = pd.concat([text_df, pd.DataFrame({'abstract_id': [abstract], 'text': [text]})], ignore_index=True)\n",
    "    \n",
    "print(len(text_df))\n",
    "text_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f677612e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categori...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>\\nThis paper presents a new approach to  stati...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMP...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...</td>\n",
       "      <td>[ranking algorithm COMPARE lattice-based appro...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>\\n This paper describes a domain independent ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...</td>\n",
       "      <td>[feedback FEATURE-OF discourse, videodisc imag...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>\\n In this paper, we describe the  pronominal...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'prono...</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>\\nIn our current research into the design of  ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'displ...</td>\n",
       "      <td>[display of graphical information USED-FOR cog...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "1    A00-2023   \n",
       "2    A88-1001   \n",
       "3    A88-1003   \n",
       "4    A92-1010   \n",
       "\n",
       "                                                text  \\\n",
       "0  \\nThis paper introduces a  system for categori...   \n",
       "1  \\nThis paper presents a new approach to  stati...   \n",
       "2   \\n This paper describes a domain independent ...   \n",
       "3   \\n In this paper, we describe the  pronominal...   \n",
       "4  \\nIn our current research into the design of  ...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "1  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "2  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "3  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "4  {'T1': {'Annotation ID': 'T1', 'Entity': 'Task...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Type': 'COMP...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Type': 'PART...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "\n",
       "                                      populated_rels  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Rel': 'prono...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Rel': 'displ...   \n",
       "\n",
       "                           simplified_populated_rels  \\\n",
       "0  [multi-component architecture USED-FOR system,...   \n",
       "1  [ranking algorithm COMPARE lattice-based appro...   \n",
       "2  [feedback FEATURE-OF discourse, videodisc imag...   \n",
       "3  [pronominal anaphora resolution module PART-OF...   \n",
       "4  [display of graphical information USED-FOR cog...   \n",
       "\n",
       "   rel_count  \n",
       "0         13  \n",
       "1          9  \n",
       "2          9  \n",
       "3          3  \n",
       "4          3  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform an inner join between annotations_df and text_df based on the 'Abstract' column\n",
    "scierc_full = pd.merge(text_df, annotations_df, on='abstract_id', how='inner')\n",
    "\n",
    "print(len(scierc_full))\n",
    "scierc_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61754d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "316\n"
     ]
    }
   ],
   "source": [
    "scierc_full['word_count'] = scierc_full['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "smallest_word_count = scierc_full['word_count'].min()\n",
    "largest_word_count = scierc_full['word_count'].max()\n",
    "\n",
    "print(smallest_word_count)\n",
    "print(largest_word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00110a3a",
   "metadata": {},
   "source": [
    "### Distinct relationship types\n",
    "\n",
    "* Seems as if EVALUATE-FOR is not mentioned in the annotation_guideline.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfb1e163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USED-FOR\n",
      "PART-OF\n",
      "HYPONYM-OF\n",
      "COREF\n",
      "EVALUATE-FOR\n",
      "CONJUNCTION\n",
      "COMPARE\n",
      "FEATURE-OF\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# Extract unique 'Types' from the 'relationships' column\n",
    "unique_types = scierc_full['relationships'].apply(lambda x: [rel_info['Type'] for rel_info in x.values()]).explode().unique().tolist()\n",
    "\n",
    "# Print the list of unique 'Types' prettily\n",
    "for type in unique_types:\n",
    "    print(type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87080b9f",
   "metadata": {},
   "source": [
    "# Prompt generation to detect rels\n",
    "* Attempting to use similar prompt format as used in main KG_construction, for consistency.\n",
    "* Aim is to benchmark against a rel-annotated dataset (scierc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1708c661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categori...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>\\nThis paper presents a new approach to  stati...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMP...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...</td>\n",
       "      <td>[ranking algorithm COMPARE lattice-based appro...</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>\\n This paper describes a domain independent ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...</td>\n",
       "      <td>[feedback FEATURE-OF discourse, videodisc imag...</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>\\n In this paper, we describe the  pronominal...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'prono...</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF...</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>\\nIn our current research into the design of  ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'displ...</td>\n",
       "      <td>[display of graphical information USED-FOR cog...</td>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "1    A00-2023   \n",
       "2    A88-1001   \n",
       "3    A88-1003   \n",
       "4    A92-1010   \n",
       "\n",
       "                                                text  \\\n",
       "0  \\nThis paper introduces a  system for categori...   \n",
       "1  \\nThis paper presents a new approach to  stati...   \n",
       "2   \\n This paper describes a domain independent ...   \n",
       "3   \\n In this paper, we describe the  pronominal...   \n",
       "4  \\nIn our current research into the design of  ...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "1  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "2  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "3  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "4  {'T1': {'Annotation ID': 'T1', 'Entity': 'Task...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Type': 'COMP...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Type': 'PART...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "\n",
       "                                      populated_rels  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Rel': 'prono...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Rel': 'displ...   \n",
       "\n",
       "                           simplified_populated_rels  \\\n",
       "0  [multi-component architecture USED-FOR system,...   \n",
       "1  [ranking algorithm COMPARE lattice-based appro...   \n",
       "2  [feedback FEATURE-OF discourse, videodisc imag...   \n",
       "3  [pronominal anaphora resolution module PART-OF...   \n",
       "4  [display of graphical information USED-FOR cog...   \n",
       "\n",
       "   rel_count  word_count  \n",
       "0         13          86  \n",
       "1          9          85  \n",
       "2          9          58  \n",
       "3          3          77  \n",
       "4          3          84  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(scierc_full))\n",
    "scierc_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63048ab8",
   "metadata": {},
   "source": [
    "#### Previous prompt used in main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e355259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d67e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed article to sentence.\n",
    "# simplified.\n",
    "\n",
    "# rel types:\n",
    "# USED-FOR\n",
    "# FEATURE-OF\n",
    "# HYPONYM-OF\n",
    "# PART-OF\n",
    "# EVALUATE-FOR\n",
    "# COMPARE\n",
    "# CONJUNCTION\n",
    "# COREF\n",
    "\n",
    "# Create a function to generate the prompt based on the row values\n",
    "def generate_prompt(row):\n",
    "\n",
    "    input_text = row['text']\n",
    "    \n",
    "    prompt = f'''Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\n",
    "    ###\n",
    "    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\n",
    "    ###\n",
    "    Here are some examples of each type of entity that may be detected:\n",
    "    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\n",
    "    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\n",
    "    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\n",
    "    time complexity.\n",
    "    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\n",
    "    Panntreebank, WordNet, Wikipedia.\n",
    "    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\n",
    "    discourse structure, tree, node, tree kernel, features, noise, criteria.\n",
    "    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\n",
    "    ###\n",
    "    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
    "    ###\n",
    "    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\n",
    "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
    "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
    "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
    "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
    "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
    "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
    "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
    "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
    "    ###\n",
    "    Desired response format: ###\n",
    "    [triple1, triple2, triple3]\n",
    "    ###\n",
    "    Example response: ###\n",
    "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
    "    ###\n",
    "    The provided abstract is: ###\n",
    "    {input_text}\n",
    "    ###\n",
    "    '''\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Add a new 'prompt' column by applying the generate_prompt function to each row\n",
    "scierc_full['prompt'] = scierc_full.apply(generate_prompt, axis=1)\n",
    "scierc_full['prompt'] = scierc_full['prompt'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56b933e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Generic', 'Start Offset': 26, 'End Offset': 32, 'Annotated Text': 'system'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 37, 'End Offset': 63, 'Annotated Text': 'categorizing unknown words'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'Generic', 'Start Offset': 71, 'End Offset': 77, 'Annotated Text': 'system'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Method', 'Start Offset': 94, 'End Offset': 122, 'Annotated Text': 'multi-component architecture'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 136, 'End Offset': 145, 'Annotated Text': 'component'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'OtherScientificTerm', 'Start Offset': 192, 'End Offset': 205, 'Annotated Text': 'unknown words'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'Generic', 'Start Offset': 240, 'End Offset': 250, 'Annotated Text': 'components'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'OtherScientificTerm', 'Start Offset': 267, 'End Offset': 272, 'Annotated Text': 'names'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'OtherScientificTerm', 'Start Offset': 279, 'End Offset': 294, 'Annotated Text': 'spelling errors'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'Generic', 'Start Offset': 303, 'End Offset': 312, 'Annotated Text': 'component'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Method', 'Start Offset': 322, 'End Offset': 348, 'Annotated Text': 'decision tree architecture'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'OtherScientificTerm', 'Start Offset': 401, 'End Offset': 413, 'Annotated Text': 'unknown word'}, 'T13': {'Annotation ID': 'T13', 'Entity': 'Generic', 'Start Offset': 421, 'End Offset': 427, 'Annotated Text': 'system'}, 'T14': {'Annotation ID': 'T14', 'Entity': 'Material', 'Start Offset': 459, 'End Offset': 479, 'Annotated Text': 'live closed captions'}, 'T15': {'Annotation ID': 'T15', 'Entity': 'OtherScientificTerm', 'Start Offset': 523, 'End Offset': 536, 'Annotated Text': 'unknown words'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED-FOR', 'Arg1': 'T4', 'Arg2': 'T3'}, 'R2': {'Relationship ID': 'R2', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T8'}, 'R3': {'Relationship ID': 'R3', 'Type': 'USED-FOR', 'Arg1': 'T11', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'PART-OF', 'Arg1': 'T5', 'Arg2': 'T4'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T9'}, 'R6': {'Relationship ID': 'R6', 'Type': 'HYPONYM-OF', 'Arg1': 'T7', 'Arg2': 'T5'}, 'R7': {'Relationship ID': 'R7', 'Type': 'COREF', 'Arg1': 'T13', 'Arg2': 'T3'}, 'R8': {'Relationship ID': 'R8', 'Type': 'USED-FOR', 'Arg1': 'T5', 'Arg2': 'T6'}, 'R9': {'Relationship ID': 'R9', 'Type': 'EVALUATE-FOR', 'Arg1': 'T14', 'Arg2': 'T13'}, 'R10': {'Relationship ID': 'R10', 'Type': 'CONJUNCTION', 'Arg1': 'T8', 'Arg2': 'T9'}, 'R11': {'Relationship ID': 'R11', 'Type': 'COREF', 'Arg1': 'T10', 'Arg2': 'T7'}, 'R12': {'Relationship ID': 'R12', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R13': {'Relationship ID': 'R13', 'Type': 'COREF', 'Arg1': 'T1', 'Arg2': 'T3'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi-component architecture USED-FOR system'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'components USED-FOR names'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'decision tree architecture USED-FOR component'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'component PART-OF multi-component architecture'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'components USED-FOR spelling errors'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'components HYPONYM-OF component'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'system COREF system'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'component USED-FOR unknown words'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'live closed captions EVALUATE-FOR system'}, 'R10': {'Relationship ID': 'R10', 'Rel': 'names CONJUNCTION spelling errors'}, 'R11': {'Relationship ID': 'R11', 'Rel': 'component COREF components'}, 'R12': {'Relationship ID': 'R12', 'Rel': 'system USED-FOR categorizing unknown words'}, 'R13': {'Relationship ID': 'R13', 'Rel': 'system COREF system'}}</td>\n",
       "      <td>[multi-component architecture USED-FOR system, components USED-FOR names, decision tree architecture USED-FOR component, component PART-OF multi-component architecture, components USED-FOR spelling errors, components HYPONYM-OF component, system COREF system, component USED-FOR unknown words, live closed captions EVALUATE-FOR system, names CONJUNCTION spelling errors, component COREF components, system USED-FOR categorizing unknown words, system COREF system]</td>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "      <td>Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\\n    ###\\n    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\\n    ###\\n    Here are some examples of each type of entity that may be detected:\\n    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\\n    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\\n    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\\n    time complexity.\\n    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\\n    Panntreebank, WordNet, Wikipedia.\\n    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\\n    discourse structure, tree, node, tree kernel, features, noise, criteria.\\n    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\\n    ###\\n    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [triple1, triple2, triple3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n\\n    ###\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>\\nThis paper presents a new approach to  statistical sentence generation  in which alternative  phrases  are represented as packed sets of  trees , or  forests , and then ranked statistically to choose the best one. This representation offers advantages in compactness and in the ability to represent  syntactic information . It also facilitates more efficient  statistical ranking  than a previous approach to  statistical generation . An efficient  ranking algorithm  is described, together with experimental results showing significant improvements over simple enumeration or a  lattice-based approach .\\n</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Generic', 'Start Offset': 27, 'End Offset': 35, 'Annotated Text': 'approach'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 40, 'End Offset': 71, 'Annotated Text': 'statistical sentence generation'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 139, 'End Offset': 144, 'Annotated Text': 'trees'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'OtherScientificTerm', 'Start Offset': 151, 'End Offset': 158, 'Annotated Text': 'forests'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 220, 'End Offset': 234, 'Annotated Text': 'representation'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'OtherScientificTerm', 'Start Offset': 301, 'End Offset': 322, 'Annotated Text': 'syntactic information'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'Generic', 'Start Offset': 325, 'End Offset': 327, 'Annotated Text': 'It'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'Method', 'Start Offset': 361, 'End Offset': 380, 'Annotated Text': 'statistical ranking'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'Generic', 'Start Offset': 398, 'End Offset': 406, 'Annotated Text': 'approach'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'Task', 'Start Offset': 411, 'End Offset': 433, 'Annotated Text': 'statistical generation'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Method', 'Start Offset': 450, 'End Offset': 467, 'Annotated Text': 'ranking algorithm'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'Method', 'Start Offset': 563, 'End Offset': 574, 'Annotated Text': 'enumeration'}, 'T13': {'Annotation ID': 'T13', 'Entity': 'Method', 'Start Offset': 581, 'End Offset': 603, 'Annotated Text': 'lattice-based approach'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMPARE', 'Arg1': 'T11', 'Arg2': 'T13'}, 'R2': {'Relationship ID': 'R2', 'Type': 'COMPARE', 'Arg1': 'T11', 'Arg2': 'T12'}, 'R3': {'Relationship ID': 'R3', 'Type': 'USED-FOR', 'Arg1': 'T9', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'COREF', 'Arg1': 'T7', 'Arg2': 'T5'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R6': {'Relationship ID': 'R6', 'Type': 'COREF', 'Arg1': 'T5', 'Arg2': 'T1'}, 'R7': {'Relationship ID': 'R7', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T8'}, 'R8': {'Relationship ID': 'R8', 'Type': 'COMPARE', 'Arg1': 'T7', 'Arg2': 'T9'}, 'R9': {'Relationship ID': 'R9', 'Type': 'CONJUNCTION', 'Arg1': 'T12', 'Arg2': 'T13'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'ranking algorithm COMPARE lattice-based approach'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'ranking algorithm COMPARE enumeration'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'approach USED-FOR statistical generation'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'It COREF representation'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'approach USED-FOR statistical sentence generation'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'representation COREF approach'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'It USED-FOR statistical ranking'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'It COMPARE approach'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'enumeration CONJUNCTION lattice-based approach'}}</td>\n",
       "      <td>[ranking algorithm COMPARE lattice-based approach, ranking algorithm COMPARE enumeration, approach USED-FOR statistical generation, It COREF representation, approach USED-FOR statistical sentence generation, representation COREF approach, It USED-FOR statistical ranking, It COMPARE approach, enumeration CONJUNCTION lattice-based approach]</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\\n    ###\\n    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\\n    ###\\n    Here are some examples of each type of entity that may be detected:\\n    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\\n    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\\n    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\\n    time complexity.\\n    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\\n    Panntreebank, WordNet, Wikipedia.\\n    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\\n    discourse structure, tree, node, tree kernel, features, noise, criteria.\\n    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\\n    ###\\n    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [triple1, triple2, triple3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nThis paper presents a new approach to  statistical sentence generation  in which alternative  phrases  are represented as packed sets of  trees , or  forests , and then ranked statistically to choose the best one. This representation offers advantages in compactness and in the ability to represent  syntactic information . It also facilitates more efficient  statistical ranking  than a previous approach to  statistical generation . An efficient  ranking algorithm  is described, together with experimental results showing significant improvements over simple enumeration or a  lattice-based approach .\\n\\n    ###\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>\\n This paper describes a domain independent strategy for the  multimedia articulation of answers  elicited by a  natural language interface  to  database query applications  .  Multimedia answers  include  videodisc images  and heuristically-produced complete  sentences  in  text  or  text-to-speech form  .  Deictic reference  and  feedback  about the  discourse  are enabled. The  interface  thus presents the application as cooperative and conversational.</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Method', 'Start Offset': 26, 'End Offset': 53, 'Annotated Text': 'domain independent strategy'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 63, 'End Offset': 97, 'Annotated Text': 'multimedia articulation of answers'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 114, 'End Offset': 140, 'Annotated Text': 'natural language interface'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Task', 'Start Offset': 146, 'End Offset': 173, 'Annotated Text': 'database query applications'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Material', 'Start Offset': 178, 'End Offset': 196, 'Annotated Text': 'Multimedia answers'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'Material', 'Start Offset': 207, 'End Offset': 223, 'Annotated Text': 'videodisc images'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'OtherScientificTerm', 'Start Offset': 287, 'End Offset': 306, 'Annotated Text': 'text-to-speech form'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'OtherScientificTerm', 'Start Offset': 311, 'End Offset': 328, 'Annotated Text': 'Deictic reference'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'OtherScientificTerm', 'Start Offset': 335, 'End Offset': 343, 'Annotated Text': 'feedback'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'OtherScientificTerm', 'Start Offset': 356, 'End Offset': 365, 'Annotated Text': 'discourse'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Generic', 'Start Offset': 385, 'End Offset': 394, 'Annotated Text': 'interface'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'Generic', 'Start Offset': 414, 'End Offset': 425, 'Annotated Text': 'application'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEATURE-OF', 'Arg1': 'T9', 'Arg2': 'T10'}, 'R2': {'Relationship ID': 'R2', 'Type': 'PART-OF', 'Arg1': 'T6', 'Arg2': 'T5'}, 'R3': {'Relationship ID': 'R3', 'Type': 'FEATURE-OF', 'Arg1': 'T8', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'COREF', 'Arg1': 'T11', 'Arg2': 'T3'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R6': {'Relationship ID': 'R6', 'Type': 'USED-FOR', 'Arg1': 'T3', 'Arg2': 'T4'}, 'R7': {'Relationship ID': 'R7', 'Type': 'COREF', 'Arg1': 'T12', 'Arg2': 'T4'}, 'R8': {'Relationship ID': 'R8', 'Type': 'CONJUNCTION', 'Arg1': 'T8', 'Arg2': 'T9'}, 'R9': {'Relationship ID': 'R9', 'Type': 'USED-FOR', 'Arg1': 'T2', 'Arg2': 'T3'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'feedback FEATURE-OF discourse'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'videodisc images PART-OF Multimedia answers'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'Deictic reference FEATURE-OF discourse'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'interface COREF natural language interface'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'domain independent strategy USED-FOR multimedia articulation of answers'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'natural language interface USED-FOR database query applications'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'application COREF database query applications'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'Deictic reference CONJUNCTION feedback'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'multimedia articulation of answers USED-FOR natural language interface'}}</td>\n",
       "      <td>[feedback FEATURE-OF discourse, videodisc images PART-OF Multimedia answers, Deictic reference FEATURE-OF discourse, interface COREF natural language interface, domain independent strategy USED-FOR multimedia articulation of answers, natural language interface USED-FOR database query applications, application COREF database query applications, Deictic reference CONJUNCTION feedback, multimedia articulation of answers USED-FOR natural language interface]</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "      <td>Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\\n    ###\\n    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\\n    ###\\n    Here are some examples of each type of entity that may be detected:\\n    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\\n    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\\n    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\\n    time complexity.\\n    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\\n    Panntreebank, WordNet, Wikipedia.\\n    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\\n    discourse structure, tree, node, tree kernel, features, noise, criteria.\\n    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\\n    ###\\n    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [triple1, triple2, triple3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n     \\n This paper describes a domain independent strategy for the  multimedia articulation of answers  elicited by a  natural language interface  to  database query applications  .  Multimedia answers  include  videodisc images  and heuristically-produced complete  sentences  in  text  or  text-to-speech form  .  Deictic reference  and  feedback  about the  discourse  are enabled. The  interface  thus presents the application as cooperative and conversational. \\n    ###\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>\\n In this paper, we describe the  pronominal anaphora resolution module  of  Lucy  , a portable  English understanding system  . The design of this module was motivated by the observation that, although there exist many theories of  anaphora resolution  , no one of these theories is complete. Thus we have implemented a  blackboard-like architecture  in which individual  partial theories  can be encoded as separate modules that can interact to propose candidate  antecedents  and to evaluate each other's proposals.</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Method', 'Start Offset': 35, 'End Offset': 72, 'Annotated Text': 'pronominal anaphora resolution module'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Method', 'Start Offset': 78, 'End Offset': 82, 'Annotated Text': 'Lucy'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'Method', 'Start Offset': 98, 'End Offset': 126, 'Annotated Text': 'English understanding system'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Generic', 'Start Offset': 149, 'End Offset': 155, 'Annotated Text': 'module'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Task', 'Start Offset': 234, 'End Offset': 253, 'Annotated Text': 'anaphora resolution'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'Method', 'Start Offset': 323, 'End Offset': 351, 'Annotated Text': 'blackboard-like architecture'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART-OF', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R2': {'Relationship ID': 'R2', 'Type': 'COREF', 'Arg1': 'T4', 'Arg2': 'T1'}, 'R3': {'Relationship ID': 'R3', 'Type': 'HYPONYM-OF', 'Arg1': 'T2', 'Arg2': 'T3'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'pronominal anaphora resolution module PART-OF Lucy'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'module COREF pronominal anaphora resolution module'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'Lucy HYPONYM-OF English understanding system'}}</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF Lucy, module COREF pronominal anaphora resolution module, Lucy HYPONYM-OF English understanding system]</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\\n    ###\\n    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\\n    ###\\n    Here are some examples of each type of entity that may be detected:\\n    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\\n    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\\n    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\\n    time complexity.\\n    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\\n    Panntreebank, WordNet, Wikipedia.\\n    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\\n    discourse structure, tree, node, tree kernel, features, noise, criteria.\\n    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\\n    ###\\n    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [triple1, triple2, triple3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n     \\n In this paper, we describe the  pronominal anaphora resolution module  of  Lucy  , a portable  English understanding system  . The design of this module was motivated by the observation that, although there exist many theories of  anaphora resolution  , no one of these theories is complete. Thus we have implemented a  blackboard-like architecture  in which individual  partial theories  can be encoded as separate modules that can interact to propose candidate  antecedents  and to evaluate each other's proposals. \\n    ###\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>\\nIn our current research into the design of  cognitively well-motivated interfaces  relying primarily on the  display of graphical information , we have observed that  graphical information  alone does not provide sufficient support to users - particularly when situations arise that do not simply conform to the users' expectations. This can occur due to too much  information  being requested, too little,  information  of the wrong kind, etc. To solve this problem, we are working towards the integration of  natural language generation  to augment the  interaction</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task', 'Start Offset': 45, 'End Offset': 82, 'Annotated Text': 'cognitively well-motivated interfaces'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'OtherScientificTerm', 'Start Offset': 110, 'End Offset': 142, 'Annotated Text': 'display of graphical information'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 168, 'End Offset': 189, 'Annotated Text': 'graphical information'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Task', 'Start Offset': 512, 'End Offset': 539, 'Annotated Text': 'natural language generation'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 557, 'End Offset': 568, 'Annotated Text': 'interaction'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED-FOR', 'Arg1': 'T2', 'Arg2': 'T1'}, 'R2': {'Relationship ID': 'R2', 'Type': 'USED-FOR', 'Arg1': 'T4', 'Arg2': 'T5'}, 'R3': {'Relationship ID': 'R3', 'Type': 'COREF', 'Arg1': 'T3', 'Arg2': 'T2'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'display of graphical information USED-FOR cognitively well-motivated interfaces'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'natural language generation USED-FOR interaction'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'graphical information COREF display of graphical information'}}</td>\n",
       "      <td>[display of graphical information USED-FOR cognitively well-motivated interfaces, natural language generation USED-FOR interaction, graphical information COREF display of graphical information]</td>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\\n    ###\\n    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\\n    ###\\n    Here are some examples of each type of entity that may be detected:\\n    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\\n    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\\n    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\\n    time complexity.\\n    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\\n    Panntreebank, WordNet, Wikipedia.\\n    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\\n    discourse structure, tree, node, tree kernel, features, noise, criteria.\\n    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\\n    ###\\n    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [triple1, triple2, triple3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nIn our current research into the design of  cognitively well-motivated interfaces  relying primarily on the  display of graphical information , we have observed that  graphical information  alone does not provide sufficient support to users - particularly when situations arise that do not simply conform to the users' expectations. This can occur due to too much  information  being requested, too little,  information  of the wrong kind, etc. To solve this problem, we are working towards the integration of  natural language generation  to augment the  interaction \\n    ###\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 entities                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               relationships                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             populated_rels                                                                                                                                                                                                                                                                                                                                                                                                                                                        simplified_populated_rels  rel_count  word_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          prompt\n",
       "0    A00-1024                                                                     \\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n  {'T1': {'Annotation ID': 'T1', 'Entity': 'Generic', 'Start Offset': 26, 'End Offset': 32, 'Annotated Text': 'system'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 37, 'End Offset': 63, 'Annotated Text': 'categorizing unknown words'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'Generic', 'Start Offset': 71, 'End Offset': 77, 'Annotated Text': 'system'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Method', 'Start Offset': 94, 'End Offset': 122, 'Annotated Text': 'multi-component architecture'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 136, 'End Offset': 145, 'Annotated Text': 'component'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'OtherScientificTerm', 'Start Offset': 192, 'End Offset': 205, 'Annotated Text': 'unknown words'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'Generic', 'Start Offset': 240, 'End Offset': 250, 'Annotated Text': 'components'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'OtherScientificTerm', 'Start Offset': 267, 'End Offset': 272, 'Annotated Text': 'names'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'OtherScientificTerm', 'Start Offset': 279, 'End Offset': 294, 'Annotated Text': 'spelling errors'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'Generic', 'Start Offset': 303, 'End Offset': 312, 'Annotated Text': 'component'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Method', 'Start Offset': 322, 'End Offset': 348, 'Annotated Text': 'decision tree architecture'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'OtherScientificTerm', 'Start Offset': 401, 'End Offset': 413, 'Annotated Text': 'unknown word'}, 'T13': {'Annotation ID': 'T13', 'Entity': 'Generic', 'Start Offset': 421, 'End Offset': 427, 'Annotated Text': 'system'}, 'T14': {'Annotation ID': 'T14', 'Entity': 'Material', 'Start Offset': 459, 'End Offset': 479, 'Annotated Text': 'live closed captions'}, 'T15': {'Annotation ID': 'T15', 'Entity': 'OtherScientificTerm', 'Start Offset': 523, 'End Offset': 536, 'Annotated Text': 'unknown words'}}  {'R1': {'Relationship ID': 'R1', 'Type': 'USED-FOR', 'Arg1': 'T4', 'Arg2': 'T3'}, 'R2': {'Relationship ID': 'R2', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T8'}, 'R3': {'Relationship ID': 'R3', 'Type': 'USED-FOR', 'Arg1': 'T11', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'PART-OF', 'Arg1': 'T5', 'Arg2': 'T4'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T9'}, 'R6': {'Relationship ID': 'R6', 'Type': 'HYPONYM-OF', 'Arg1': 'T7', 'Arg2': 'T5'}, 'R7': {'Relationship ID': 'R7', 'Type': 'COREF', 'Arg1': 'T13', 'Arg2': 'T3'}, 'R8': {'Relationship ID': 'R8', 'Type': 'USED-FOR', 'Arg1': 'T5', 'Arg2': 'T6'}, 'R9': {'Relationship ID': 'R9', 'Type': 'EVALUATE-FOR', 'Arg1': 'T14', 'Arg2': 'T13'}, 'R10': {'Relationship ID': 'R10', 'Type': 'CONJUNCTION', 'Arg1': 'T8', 'Arg2': 'T9'}, 'R11': {'Relationship ID': 'R11', 'Type': 'COREF', 'Arg1': 'T10', 'Arg2': 'T7'}, 'R12': {'Relationship ID': 'R12', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R13': {'Relationship ID': 'R13', 'Type': 'COREF', 'Arg1': 'T1', 'Arg2': 'T3'}}  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi-component architecture USED-FOR system'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'components USED-FOR names'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'decision tree architecture USED-FOR component'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'component PART-OF multi-component architecture'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'components USED-FOR spelling errors'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'components HYPONYM-OF component'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'system COREF system'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'component USED-FOR unknown words'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'live closed captions EVALUATE-FOR system'}, 'R10': {'Relationship ID': 'R10', 'Rel': 'names CONJUNCTION spelling errors'}, 'R11': {'Relationship ID': 'R11', 'Rel': 'component COREF components'}, 'R12': {'Relationship ID': 'R12', 'Rel': 'system USED-FOR categorizing unknown words'}, 'R13': {'Relationship ID': 'R13', 'Rel': 'system COREF system'}}  [multi-component architecture USED-FOR system, components USED-FOR names, decision tree architecture USED-FOR component, component PART-OF multi-component architecture, components USED-FOR spelling errors, components HYPONYM-OF component, system COREF system, component USED-FOR unknown words, live closed captions EVALUATE-FOR system, names CONJUNCTION spelling errors, component COREF components, system USED-FOR categorizing unknown words, system COREF system]         13          86                                                                     Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\\n    ###\\n    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\\n    ###\\n    Here are some examples of each type of entity that may be detected:\\n    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\\n    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\\n    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\\n    time complexity.\\n    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\\n    Panntreebank, WordNet, Wikipedia.\\n    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\\n    discourse structure, tree, node, tree kernel, features, noise, criteria.\\n    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\\n    ###\\n    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [triple1, triple2, triple3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n\\n    ###\\n    \n",
       "1    A00-2023  \\nThis paper presents a new approach to  statistical sentence generation  in which alternative  phrases  are represented as packed sets of  trees , or  forests , and then ranked statistically to choose the best one. This representation offers advantages in compactness and in the ability to represent  syntactic information . It also facilitates more efficient  statistical ranking  than a previous approach to  statistical generation . An efficient  ranking algorithm  is described, together with experimental results showing significant improvements over simple enumeration or a  lattice-based approach .\\n                                                                                                                                                                                                                                                                                      {'T1': {'Annotation ID': 'T1', 'Entity': 'Generic', 'Start Offset': 27, 'End Offset': 35, 'Annotated Text': 'approach'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 40, 'End Offset': 71, 'Annotated Text': 'statistical sentence generation'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 139, 'End Offset': 144, 'Annotated Text': 'trees'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'OtherScientificTerm', 'Start Offset': 151, 'End Offset': 158, 'Annotated Text': 'forests'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 220, 'End Offset': 234, 'Annotated Text': 'representation'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'OtherScientificTerm', 'Start Offset': 301, 'End Offset': 322, 'Annotated Text': 'syntactic information'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'Generic', 'Start Offset': 325, 'End Offset': 327, 'Annotated Text': 'It'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'Method', 'Start Offset': 361, 'End Offset': 380, 'Annotated Text': 'statistical ranking'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'Generic', 'Start Offset': 398, 'End Offset': 406, 'Annotated Text': 'approach'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'Task', 'Start Offset': 411, 'End Offset': 433, 'Annotated Text': 'statistical generation'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Method', 'Start Offset': 450, 'End Offset': 467, 'Annotated Text': 'ranking algorithm'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'Method', 'Start Offset': 563, 'End Offset': 574, 'Annotated Text': 'enumeration'}, 'T13': {'Annotation ID': 'T13', 'Entity': 'Method', 'Start Offset': 581, 'End Offset': 603, 'Annotated Text': 'lattice-based approach'}}                                                                                                                                                                                                                                                                                                                                                  {'R1': {'Relationship ID': 'R1', 'Type': 'COMPARE', 'Arg1': 'T11', 'Arg2': 'T13'}, 'R2': {'Relationship ID': 'R2', 'Type': 'COMPARE', 'Arg1': 'T11', 'Arg2': 'T12'}, 'R3': {'Relationship ID': 'R3', 'Type': 'USED-FOR', 'Arg1': 'T9', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'COREF', 'Arg1': 'T7', 'Arg2': 'T5'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R6': {'Relationship ID': 'R6', 'Type': 'COREF', 'Arg1': 'T5', 'Arg2': 'T1'}, 'R7': {'Relationship ID': 'R7', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T8'}, 'R8': {'Relationship ID': 'R8', 'Type': 'COMPARE', 'Arg1': 'T7', 'Arg2': 'T9'}, 'R9': {'Relationship ID': 'R9', 'Type': 'CONJUNCTION', 'Arg1': 'T12', 'Arg2': 'T13'}}                                                                                                                                                                                                                                                                                                             {'R1': {'Relationship ID': 'R1', 'Rel': 'ranking algorithm COMPARE lattice-based approach'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'ranking algorithm COMPARE enumeration'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'approach USED-FOR statistical generation'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'It COREF representation'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'approach USED-FOR statistical sentence generation'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'representation COREF approach'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'It USED-FOR statistical ranking'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'It COMPARE approach'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'enumeration CONJUNCTION lattice-based approach'}}                                                                                                                             [ranking algorithm COMPARE lattice-based approach, ranking algorithm COMPARE enumeration, approach USED-FOR statistical generation, It COREF representation, approach USED-FOR statistical sentence generation, representation COREF approach, It USED-FOR statistical ranking, It COMPARE approach, enumeration CONJUNCTION lattice-based approach]          9          85  Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\\n    ###\\n    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\\n    ###\\n    Here are some examples of each type of entity that may be detected:\\n    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\\n    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\\n    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\\n    time complexity.\\n    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\\n    Panntreebank, WordNet, Wikipedia.\\n    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\\n    discourse structure, tree, node, tree kernel, features, noise, criteria.\\n    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\\n    ###\\n    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [triple1, triple2, triple3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nThis paper presents a new approach to  statistical sentence generation  in which alternative  phrases  are represented as packed sets of  trees , or  forests , and then ranked statistically to choose the best one. This representation offers advantages in compactness and in the ability to represent  syntactic information . It also facilitates more efficient  statistical ranking  than a previous approach to  statistical generation . An efficient  ranking algorithm  is described, together with experimental results showing significant improvements over simple enumeration or a  lattice-based approach .\\n\\n    ###\\n    \n",
       "2    A88-1001                                                                                                                                                     \\n This paper describes a domain independent strategy for the  multimedia articulation of answers  elicited by a  natural language interface  to  database query applications  .  Multimedia answers  include  videodisc images  and heuristically-produced complete  sentences  in  text  or  text-to-speech form  .  Deictic reference  and  feedback  about the  discourse  are enabled. The  interface  thus presents the application as cooperative and conversational.                                                                                                                                                                                                                                                                                                                                            {'T1': {'Annotation ID': 'T1', 'Entity': 'Method', 'Start Offset': 26, 'End Offset': 53, 'Annotated Text': 'domain independent strategy'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 63, 'End Offset': 97, 'Annotated Text': 'multimedia articulation of answers'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 114, 'End Offset': 140, 'Annotated Text': 'natural language interface'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Task', 'Start Offset': 146, 'End Offset': 173, 'Annotated Text': 'database query applications'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Material', 'Start Offset': 178, 'End Offset': 196, 'Annotated Text': 'Multimedia answers'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'Material', 'Start Offset': 207, 'End Offset': 223, 'Annotated Text': 'videodisc images'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'OtherScientificTerm', 'Start Offset': 287, 'End Offset': 306, 'Annotated Text': 'text-to-speech form'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'OtherScientificTerm', 'Start Offset': 311, 'End Offset': 328, 'Annotated Text': 'Deictic reference'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'OtherScientificTerm', 'Start Offset': 335, 'End Offset': 343, 'Annotated Text': 'feedback'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'OtherScientificTerm', 'Start Offset': 356, 'End Offset': 365, 'Annotated Text': 'discourse'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Generic', 'Start Offset': 385, 'End Offset': 394, 'Annotated Text': 'interface'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'Generic', 'Start Offset': 414, 'End Offset': 425, 'Annotated Text': 'application'}}                                                                                                                                                                                                                                                                                                                                               {'R1': {'Relationship ID': 'R1', 'Type': 'FEATURE-OF', 'Arg1': 'T9', 'Arg2': 'T10'}, 'R2': {'Relationship ID': 'R2', 'Type': 'PART-OF', 'Arg1': 'T6', 'Arg2': 'T5'}, 'R3': {'Relationship ID': 'R3', 'Type': 'FEATURE-OF', 'Arg1': 'T8', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'COREF', 'Arg1': 'T11', 'Arg2': 'T3'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R6': {'Relationship ID': 'R6', 'Type': 'USED-FOR', 'Arg1': 'T3', 'Arg2': 'T4'}, 'R7': {'Relationship ID': 'R7', 'Type': 'COREF', 'Arg1': 'T12', 'Arg2': 'T4'}, 'R8': {'Relationship ID': 'R8', 'Type': 'CONJUNCTION', 'Arg1': 'T8', 'Arg2': 'T9'}, 'R9': {'Relationship ID': 'R9', 'Type': 'USED-FOR', 'Arg1': 'T2', 'Arg2': 'T3'}}                                                                                                                                                                                        {'R1': {'Relationship ID': 'R1', 'Rel': 'feedback FEATURE-OF discourse'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'videodisc images PART-OF Multimedia answers'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'Deictic reference FEATURE-OF discourse'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'interface COREF natural language interface'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'domain independent strategy USED-FOR multimedia articulation of answers'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'natural language interface USED-FOR database query applications'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'application COREF database query applications'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'Deictic reference CONJUNCTION feedback'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'multimedia articulation of answers USED-FOR natural language interface'}}        [feedback FEATURE-OF discourse, videodisc images PART-OF Multimedia answers, Deictic reference FEATURE-OF discourse, interface COREF natural language interface, domain independent strategy USED-FOR multimedia articulation of answers, natural language interface USED-FOR database query applications, application COREF database query applications, Deictic reference CONJUNCTION feedback, multimedia articulation of answers USED-FOR natural language interface]          9          58                                                                                                                                                    Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\\n    ###\\n    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\\n    ###\\n    Here are some examples of each type of entity that may be detected:\\n    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\\n    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\\n    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\\n    time complexity.\\n    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\\n    Panntreebank, WordNet, Wikipedia.\\n    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\\n    discourse structure, tree, node, tree kernel, features, noise, criteria.\\n    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\\n    ###\\n    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [triple1, triple2, triple3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n     \\n This paper describes a domain independent strategy for the  multimedia articulation of answers  elicited by a  natural language interface  to  database query applications  .  Multimedia answers  include  videodisc images  and heuristically-produced complete  sentences  in  text  or  text-to-speech form  .  Deictic reference  and  feedback  about the  discourse  are enabled. The  interface  thus presents the application as cooperative and conversational. \\n    ###\\n    \n",
       "3    A88-1003                                                                                          \\n In this paper, we describe the  pronominal anaphora resolution module  of  Lucy  , a portable  English understanding system  . The design of this module was motivated by the observation that, although there exist many theories of  anaphora resolution  , no one of these theories is complete. Thus we have implemented a  blackboard-like architecture  in which individual  partial theories  can be encoded as separate modules that can interact to propose candidate  antecedents  and to evaluate each other's proposals.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                {'T1': {'Annotation ID': 'T1', 'Entity': 'Method', 'Start Offset': 35, 'End Offset': 72, 'Annotated Text': 'pronominal anaphora resolution module'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Method', 'Start Offset': 78, 'End Offset': 82, 'Annotated Text': 'Lucy'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'Method', 'Start Offset': 98, 'End Offset': 126, 'Annotated Text': 'English understanding system'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Generic', 'Start Offset': 149, 'End Offset': 155, 'Annotated Text': 'module'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Task', 'Start Offset': 234, 'End Offset': 253, 'Annotated Text': 'anaphora resolution'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'Method', 'Start Offset': 323, 'End Offset': 351, 'Annotated Text': 'blackboard-like architecture'}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {'R1': {'Relationship ID': 'R1', 'Type': 'PART-OF', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R2': {'Relationship ID': 'R2', 'Type': 'COREF', 'Arg1': 'T4', 'Arg2': 'T1'}, 'R3': {'Relationship ID': 'R3', 'Type': 'HYPONYM-OF', 'Arg1': 'T2', 'Arg2': 'T3'}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       {'R1': {'Relationship ID': 'R1', 'Rel': 'pronominal anaphora resolution module PART-OF Lucy'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'module COREF pronominal anaphora resolution module'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'Lucy HYPONYM-OF English understanding system'}}                                                                                                                                                                                                                                                                                                                           [pronominal anaphora resolution module PART-OF Lucy, module COREF pronominal anaphora resolution module, Lucy HYPONYM-OF English understanding system]          3          77                                                                                         Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\\n    ###\\n    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\\n    ###\\n    Here are some examples of each type of entity that may be detected:\\n    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\\n    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\\n    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\\n    time complexity.\\n    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\\n    Panntreebank, WordNet, Wikipedia.\\n    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\\n    discourse structure, tree, node, tree kernel, features, noise, criteria.\\n    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\\n    ###\\n    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [triple1, triple2, triple3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n     \\n In this paper, we describe the  pronominal anaphora resolution module  of  Lucy  , a portable  English understanding system  . The design of this module was motivated by the observation that, although there exist many theories of  anaphora resolution  , no one of these theories is complete. Thus we have implemented a  blackboard-like architecture  in which individual  partial theories  can be encoded as separate modules that can interact to propose candidate  antecedents  and to evaluate each other's proposals. \\n    ###\\n    \n",
       "4    A92-1010                                        \\nIn our current research into the design of  cognitively well-motivated interfaces  relying primarily on the  display of graphical information , we have observed that  graphical information  alone does not provide sufficient support to users - particularly when situations arise that do not simply conform to the users' expectations. This can occur due to too much  information  being requested, too little,  information  of the wrong kind, etc. To solve this problem, we are working towards the integration of  natural language generation  to augment the  interaction                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                {'T1': {'Annotation ID': 'T1', 'Entity': 'Task', 'Start Offset': 45, 'End Offset': 82, 'Annotated Text': 'cognitively well-motivated interfaces'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'OtherScientificTerm', 'Start Offset': 110, 'End Offset': 142, 'Annotated Text': 'display of graphical information'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'OtherScientificTerm', 'Start Offset': 168, 'End Offset': 189, 'Annotated Text': 'graphical information'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Task', 'Start Offset': 512, 'End Offset': 539, 'Annotated Text': 'natural language generation'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 557, 'End Offset': 568, 'Annotated Text': 'interaction'}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            {'R1': {'Relationship ID': 'R1', 'Type': 'USED-FOR', 'Arg1': 'T2', 'Arg2': 'T1'}, 'R2': {'Relationship ID': 'R2', 'Type': 'USED-FOR', 'Arg1': 'T4', 'Arg2': 'T5'}, 'R3': {'Relationship ID': 'R3', 'Type': 'COREF', 'Arg1': 'T3', 'Arg2': 'T2'}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            {'R1': {'Relationship ID': 'R1', 'Rel': 'display of graphical information USED-FOR cognitively well-motivated interfaces'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'natural language generation USED-FOR interaction'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'graphical information COREF display of graphical information'}}                                                                                                                                                                                                                                                                                [display of graphical information USED-FOR cognitively well-motivated interfaces, natural language generation USED-FOR interaction, graphical information COREF display of graphical information]          3          84                                        Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\\n    ###\\n    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\\n    ###\\n    Here are some examples of each type of entity that may be detected:\\n    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\\n    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\\n    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\\n    time complexity.\\n    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\\n    Panntreebank, WordNet, Wikipedia.\\n    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\\n    discourse structure, tree, node, tree kernel, features, noise, criteria.\\n    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\\n    ###\\n    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [triple1, triple2, triple3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nIn our current research into the design of  cognitively well-motivated interfaces  relying primarily on the  display of graphical information , we have observed that  graphical information  alone does not provide sufficient support to users - particularly when situations arise that do not simply conform to the users' expectations. This can occur due to too much  information  being requested, too little,  information  of the wrong kind, etc. To solve this problem, we are working towards the integration of  natural language generation  to augment the  interaction \\n    ###\\n    "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(scierc_full))\n",
    "scierc_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7358ddd",
   "metadata": {},
   "source": [
    "# Exploring prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f67b1b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\n",
      "    ###\n",
      "    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\n",
      "    ###\n",
      "    Here are some examples of each type of entity that may be detected:\n",
      "    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\n",
      "    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\n",
      "    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\n",
      "    time complexity.\n",
      "    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\n",
      "    Panntreebank, WordNet, Wikipedia.\n",
      "    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\n",
      "    discourse structure, tree, node, tree kernel, features, noise, criteria.\n",
      "    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\n",
      "    ###\n",
      "    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [triple1, triple2, triple3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    \n",
      "This paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\n",
      "\n",
      "    ###\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the display options to show all text and split by newline\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# Iterate over each row in the 'prompt' column\n",
    "for prompt in scierc_full['prompt'][:1]:\n",
    "    print(prompt)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "035ef90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "# convert to list to explore\n",
    "all_prompts = scierc_full['prompt'].tolist()\n",
    "print(len(all_prompts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8f872",
   "metadata": {},
   "source": [
    "## Investigate average length of tokens\n",
    "\n",
    "* Important for pricing forecast and LLM API restrictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8829216",
   "metadata": {},
   "source": [
    "### with tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "300088e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "#encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09f259c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fns to count strings in list of prompts:\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def count_tokens_in_list(prompt_list: list, encoding_name: str) -> list:\n",
    "    \"\"\"Returns a list of integers representing the number of tokens in each string in the input list.\"\"\"\n",
    "    token_counts = []\n",
    "    for prompt in prompt_list:\n",
    "        num_tokens = num_tokens_from_string(prompt, encoding_name)\n",
    "        token_counts.append(num_tokens)\n",
    "    return token_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aec8734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_name = \"cl100k_base\" # used for gpt-3.5-turbo\n",
    "token_counts = count_tokens_in_list(all_prompts, encoding_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab58f212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens on the smallest prompt: 758\n",
      "Number of tokens on the largest prompt: 1178\n",
      "Total number of tokens for all prompts: 443434\n",
      "Average number of tokens in all_prompts: 886.868\n"
     ]
    }
   ],
   "source": [
    "min_tokens = min(token_counts)\n",
    "max_tokens = max(token_counts)\n",
    "total_tokens = sum(i for i in token_counts if isinstance(i, int))\n",
    "average_tokens = total_tokens / len(all_prompts)\n",
    "\n",
    "print(f\"Number of tokens on the smallest prompt: {min_tokens}\")\n",
    "print(f\"Number of tokens on the largest prompt: {max_tokens}\")\n",
    "print(f\"Total number of tokens for all prompts: {total_tokens}\")\n",
    "print(f\"Average number of tokens in all_prompts: {average_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07607a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimating max response tokens if prompt works correctly (update to reflect prompt used)\n",
    "\n",
    "#num_tokens_from_string(\"facing risk: yes. type of risk: thisis some text for a risk type.\", \"cl100k_base\")\n",
    "\n",
    "num_tokens_from_string(\n",
    "    \n",
    "    '''\n",
    "[\"NL evaluations COMPARE Message Understanding Conferences\", \"evaluation methodology USED-FOR mature, practical applications\", \"methodology USED-FOR comparative evaluation of SLS systems\", \"evaluation methodology EVALUATE-FOR competing claims and identifying promising technical approaches\", \"methodology USED-FOR automatic evaluation of question-answering NL systems\", \"methodology can be used with speech or text input\", \"methodology FEATURE-OF heart\", \"DARPA SLS program PART-OF methodology implementation\", \"NL interfaces HYPONYM-OF speech understanding\", \"SLS systems HYPONYM-OF question-answering NL systems\", \"SLS systems PART-OF DARPA Spoken Language Systems program\", \"SLS systems COMPARE NL evaluations other than Message Understanding Conferences\", \"researchers COREF they\"]\n",
    "    '''\n",
    "                       ,\"cl100k_base\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ece9ae",
   "metadata": {},
   "source": [
    "### Truncate tokens of long prompts\n",
    "\n",
    "**** NO NEED TO TRUNCATE PROMPTS WORKING WITH scierc_full ****\n",
    "**** All are below token input threshold ****\n",
    "\n",
    "* gpt-3.5-turbo has max tokens of 4,096 tokens\n",
    "* This includes prompt and response tokens combined.\n",
    "* response tokens should be short due to the attempt at prompt restrictions;\n",
    "    * i.e. Provide answers only in the format of <facing risk: <'yes'/'no'>. type of risk: < risk type >.> and nothing else.\n",
    "* so a generous estimate of response tokens would be 100, providing gpt-3.5-turbo successfully adheres to above prompting.\n",
    "* Therefore truncate prompt tokens to 3500 to be safe."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5b88ae8",
   "metadata": {},
   "source": [
    "def truncate_prompt(prompt: str, encoding_name: str, max_tokens: int) -> str:\n",
    "    \"\"\"Truncates a text string to the specified number of tokens.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    tokens = encoding.encode(prompt)[:max_tokens]\n",
    "    return encoding.decode(tokens)\n",
    "\n",
    "\n",
    "def count_tokens_for_truncating(prompt_list: list, encoding_name: str, max_tokens: int) -> list:\n",
    "    \"\"\"Returns a list of strings with a maximum of max_tokens tokens.\"\"\"\n",
    "    token_counts = []\n",
    "    truncated_prompts = []\n",
    "    for prompt in prompt_list:\n",
    "        num_tokens = num_tokens_from_string(prompt, encoding_name)\n",
    "        if num_tokens > max_tokens:\n",
    "            truncated_prompt = truncate_prompt(prompt, encoding_name, max_tokens)\n",
    "            token_counts.append(max_tokens)\n",
    "        else:\n",
    "            truncated_prompt = prompt\n",
    "            token_counts.append(num_tokens)\n",
    "        truncated_prompts.append(truncated_prompt)\n",
    "    return truncated_prompts, token_counts\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d79bb2a7",
   "metadata": {},
   "source": [
    "encoding_name = \"cl100k_base\" # used for gpt-3.5-turbo\n",
    "# encoding_name = \"r50k_base\" # used for GPT-3 models. todo check this.\n",
    "max_tokens = 3500 # Update this based on model to be used in 'Generating responses' section to correspond to token limitations.\n",
    "#all_prompts = # your list of prompts here\n",
    "\n",
    "truncated_prompts, token_counts = count_tokens_for_truncating(all_prompts, encoding_name, max_tokens)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4018a089",
   "metadata": {},
   "source": [
    "# Compare output to previous token counts.\n",
    "\n",
    "token_counts_truncated_prompts = count_tokens_in_list(truncated_prompts, encoding_name)\n",
    "min_tokens_truncated_prompts = min(token_counts_truncated_prompts)\n",
    "max_tokens_truncated_prompts = max(token_counts_truncated_prompts)\n",
    "total_tokens_truncated_prompts = sum(i for i in token_counts_truncated_prompts if isinstance(i, int))\n",
    "average_tokens_truncated_prompts = total_tokens_truncated_prompts / len(truncated_prompts)\n",
    "\n",
    "print(f\"Number of tokens on the smallest prompt: {min_tokens_truncated_prompts}\")\n",
    "print(f\"Number of tokens on the largest prompt: {max_tokens_truncated_prompts}\")\n",
    "print(f\"Total number of tokens for all prompts: {total_tokens_truncated_prompts}\")\n",
    "print(f\"Average number of tokens in all_prompts: {average_tokens_truncated_prompts}\")\n",
    "\n",
    "# Compare output to previous output (prior to truncation)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "95772e7a",
   "metadata": {},
   "source": [
    "print(\"Total number of truncated prompts: \",len(truncated_prompts))\n",
    "\n",
    "print(truncated_prompts[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2db20b",
   "metadata": {},
   "source": [
    "# Feed prompts into LLM\n",
    "\n",
    "* Initially was working from a list of prompts.\n",
    "* Modified to work from df and append response directly to df in new 'responses' col.\n",
    "    * Allows for linking to sent_id without feeding id into prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8737d98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Generic', 'Start Offset': 26, 'End Offset': 32, 'Annotated Text': 'system'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 37, 'End Offset': 63, 'Annotated Text': 'categorizing unknown words'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'Generic', 'Start Offset': 71, 'End Offset': 77, 'Annotated Text': 'system'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Method', 'Start Offset': 94, 'End Offset': 122, 'Annotated Text': 'multi-component architecture'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 136, 'End Offset': 145, 'Annotated Text': 'component'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'OtherScientificTerm', 'Start Offset': 192, 'End Offset': 205, 'Annotated Text': 'unknown words'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'Generic', 'Start Offset': 240, 'End Offset': 250, 'Annotated Text': 'components'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'OtherScientificTerm', 'Start Offset': 267, 'End Offset': 272, 'Annotated Text': 'names'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'OtherScientificTerm', 'Start Offset': 279, 'End Offset': 294, 'Annotated Text': 'spelling errors'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'Generic', 'Start Offset': 303, 'End Offset': 312, 'Annotated Text': 'component'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Method', 'Start Offset': 322, 'End Offset': 348, 'Annotated Text': 'decision tree architecture'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'OtherScientificTerm', 'Start Offset': 401, 'End Offset': 413, 'Annotated Text': 'unknown word'}, 'T13': {'Annotation ID': 'T13', 'Entity': 'Generic', 'Start Offset': 421, 'End Offset': 427, 'Annotated Text': 'system'}, 'T14': {'Annotation ID': 'T14', 'Entity': 'Material', 'Start Offset': 459, 'End Offset': 479, 'Annotated Text': 'live closed captions'}, 'T15': {'Annotation ID': 'T15', 'Entity': 'OtherScientificTerm', 'Start Offset': 523, 'End Offset': 536, 'Annotated Text': 'unknown words'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED-FOR', 'Arg1': 'T4', 'Arg2': 'T3'}, 'R2': {'Relationship ID': 'R2', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T8'}, 'R3': {'Relationship ID': 'R3', 'Type': 'USED-FOR', 'Arg1': 'T11', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'PART-OF', 'Arg1': 'T5', 'Arg2': 'T4'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T9'}, 'R6': {'Relationship ID': 'R6', 'Type': 'HYPONYM-OF', 'Arg1': 'T7', 'Arg2': 'T5'}, 'R7': {'Relationship ID': 'R7', 'Type': 'COREF', 'Arg1': 'T13', 'Arg2': 'T3'}, 'R8': {'Relationship ID': 'R8', 'Type': 'USED-FOR', 'Arg1': 'T5', 'Arg2': 'T6'}, 'R9': {'Relationship ID': 'R9', 'Type': 'EVALUATE-FOR', 'Arg1': 'T14', 'Arg2': 'T13'}, 'R10': {'Relationship ID': 'R10', 'Type': 'CONJUNCTION', 'Arg1': 'T8', 'Arg2': 'T9'}, 'R11': {'Relationship ID': 'R11', 'Type': 'COREF', 'Arg1': 'T10', 'Arg2': 'T7'}, 'R12': {'Relationship ID': 'R12', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R13': {'Relationship ID': 'R13', 'Type': 'COREF', 'Arg1': 'T1', 'Arg2': 'T3'}}</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi-component architecture USED-FOR system'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'components USED-FOR names'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'decision tree architecture USED-FOR component'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'component PART-OF multi-component architecture'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'components USED-FOR spelling errors'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'components HYPONYM-OF component'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'system COREF system'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'component USED-FOR unknown words'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'live closed captions EVALUATE-FOR system'}, 'R10': {'Relationship ID': 'R10', 'Rel': 'names CONJUNCTION spelling errors'}, 'R11': {'Relationship ID': 'R11', 'Rel': 'component COREF components'}, 'R12': {'Relationship ID': 'R12', 'Rel': 'system USED-FOR categorizing unknown words'}, 'R13': {'Relationship ID': 'R13', 'Rel': 'system COREF system'}}</td>\n",
       "      <td>[multi-component architecture USED-FOR system, components USED-FOR names, decision tree architecture USED-FOR component, component PART-OF multi-component architecture, components USED-FOR spelling errors, components HYPONYM-OF component, system COREF system, component USED-FOR unknown words, live closed captions EVALUATE-FOR system, names CONJUNCTION spelling errors, component COREF components, system USED-FOR categorizing unknown words, system COREF system]</td>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "      <td>Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\\n    ###\\n    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\\n    ###\\n    Here are some examples of each type of entity that may be detected:\\n    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\\n    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\\n    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\\n    time complexity.\\n    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\\n    Panntreebank, WordNet, Wikipedia.\\n    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\\n    discourse structure, tree, node, tree kernel, features, noise, criteria.\\n    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\\n    ###\\n    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [triple1, triple2, triple3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n\\n    ###\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 entities                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               relationships                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             populated_rels                                                                                                                                                                                                                                                                                                                                                                                                                                                        simplified_populated_rels  rel_count  word_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       prompt\n",
       "0    A00-1024  \\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n  {'T1': {'Annotation ID': 'T1', 'Entity': 'Generic', 'Start Offset': 26, 'End Offset': 32, 'Annotated Text': 'system'}, 'T2': {'Annotation ID': 'T2', 'Entity': 'Task', 'Start Offset': 37, 'End Offset': 63, 'Annotated Text': 'categorizing unknown words'}, 'T3': {'Annotation ID': 'T3', 'Entity': 'Generic', 'Start Offset': 71, 'End Offset': 77, 'Annotated Text': 'system'}, 'T4': {'Annotation ID': 'T4', 'Entity': 'Method', 'Start Offset': 94, 'End Offset': 122, 'Annotated Text': 'multi-component architecture'}, 'T5': {'Annotation ID': 'T5', 'Entity': 'Generic', 'Start Offset': 136, 'End Offset': 145, 'Annotated Text': 'component'}, 'T6': {'Annotation ID': 'T6', 'Entity': 'OtherScientificTerm', 'Start Offset': 192, 'End Offset': 205, 'Annotated Text': 'unknown words'}, 'T7': {'Annotation ID': 'T7', 'Entity': 'Generic', 'Start Offset': 240, 'End Offset': 250, 'Annotated Text': 'components'}, 'T8': {'Annotation ID': 'T8', 'Entity': 'OtherScientificTerm', 'Start Offset': 267, 'End Offset': 272, 'Annotated Text': 'names'}, 'T9': {'Annotation ID': 'T9', 'Entity': 'OtherScientificTerm', 'Start Offset': 279, 'End Offset': 294, 'Annotated Text': 'spelling errors'}, 'T10': {'Annotation ID': 'T10', 'Entity': 'Generic', 'Start Offset': 303, 'End Offset': 312, 'Annotated Text': 'component'}, 'T11': {'Annotation ID': 'T11', 'Entity': 'Method', 'Start Offset': 322, 'End Offset': 348, 'Annotated Text': 'decision tree architecture'}, 'T12': {'Annotation ID': 'T12', 'Entity': 'OtherScientificTerm', 'Start Offset': 401, 'End Offset': 413, 'Annotated Text': 'unknown word'}, 'T13': {'Annotation ID': 'T13', 'Entity': 'Generic', 'Start Offset': 421, 'End Offset': 427, 'Annotated Text': 'system'}, 'T14': {'Annotation ID': 'T14', 'Entity': 'Material', 'Start Offset': 459, 'End Offset': 479, 'Annotated Text': 'live closed captions'}, 'T15': {'Annotation ID': 'T15', 'Entity': 'OtherScientificTerm', 'Start Offset': 523, 'End Offset': 536, 'Annotated Text': 'unknown words'}}  {'R1': {'Relationship ID': 'R1', 'Type': 'USED-FOR', 'Arg1': 'T4', 'Arg2': 'T3'}, 'R2': {'Relationship ID': 'R2', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T8'}, 'R3': {'Relationship ID': 'R3', 'Type': 'USED-FOR', 'Arg1': 'T11', 'Arg2': 'T10'}, 'R4': {'Relationship ID': 'R4', 'Type': 'PART-OF', 'Arg1': 'T5', 'Arg2': 'T4'}, 'R5': {'Relationship ID': 'R5', 'Type': 'USED-FOR', 'Arg1': 'T7', 'Arg2': 'T9'}, 'R6': {'Relationship ID': 'R6', 'Type': 'HYPONYM-OF', 'Arg1': 'T7', 'Arg2': 'T5'}, 'R7': {'Relationship ID': 'R7', 'Type': 'COREF', 'Arg1': 'T13', 'Arg2': 'T3'}, 'R8': {'Relationship ID': 'R8', 'Type': 'USED-FOR', 'Arg1': 'T5', 'Arg2': 'T6'}, 'R9': {'Relationship ID': 'R9', 'Type': 'EVALUATE-FOR', 'Arg1': 'T14', 'Arg2': 'T13'}, 'R10': {'Relationship ID': 'R10', 'Type': 'CONJUNCTION', 'Arg1': 'T8', 'Arg2': 'T9'}, 'R11': {'Relationship ID': 'R11', 'Type': 'COREF', 'Arg1': 'T10', 'Arg2': 'T7'}, 'R12': {'Relationship ID': 'R12', 'Type': 'USED-FOR', 'Arg1': 'T1', 'Arg2': 'T2'}, 'R13': {'Relationship ID': 'R13', 'Type': 'COREF', 'Arg1': 'T1', 'Arg2': 'T3'}}  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi-component architecture USED-FOR system'}, 'R2': {'Relationship ID': 'R2', 'Rel': 'components USED-FOR names'}, 'R3': {'Relationship ID': 'R3', 'Rel': 'decision tree architecture USED-FOR component'}, 'R4': {'Relationship ID': 'R4', 'Rel': 'component PART-OF multi-component architecture'}, 'R5': {'Relationship ID': 'R5', 'Rel': 'components USED-FOR spelling errors'}, 'R6': {'Relationship ID': 'R6', 'Rel': 'components HYPONYM-OF component'}, 'R7': {'Relationship ID': 'R7', 'Rel': 'system COREF system'}, 'R8': {'Relationship ID': 'R8', 'Rel': 'component USED-FOR unknown words'}, 'R9': {'Relationship ID': 'R9', 'Rel': 'live closed captions EVALUATE-FOR system'}, 'R10': {'Relationship ID': 'R10', 'Rel': 'names CONJUNCTION spelling errors'}, 'R11': {'Relationship ID': 'R11', 'Rel': 'component COREF components'}, 'R12': {'Relationship ID': 'R12', 'Rel': 'system USED-FOR categorizing unknown words'}, 'R13': {'Relationship ID': 'R13', 'Rel': 'system COREF system'}}  [multi-component architecture USED-FOR system, components USED-FOR names, decision tree architecture USED-FOR component, component PART-OF multi-component architecture, components USED-FOR spelling errors, components HYPONYM-OF component, system COREF system, component USED-FOR unknown words, live closed captions EVALUATE-FOR system, names CONJUNCTION spelling errors, component COREF components, system USED-FOR categorizing unknown words, system COREF system]         13          86  Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\\n    ###\\n    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\\n    ###\\n    Here are some examples of each type of entity that may be detected:\\n    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\\n    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\\n    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\\n    time complexity.\\n    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\\n    Panntreebank, WordNet, Wikipedia.\\n    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\\n    discourse structure, tree, node, tree kernel, features, noise, criteria.\\n    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\\n    ###\\n    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\\n    ###\\n    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\\n    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\\n    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\\n    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\\n    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\\n    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\\n    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\\n    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\\n    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\\n    ###\\n    Desired response format: ###\\n    [triple1, triple2, triple3]\\n    ###\\n    Example response: ###\\n    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\\n    ###\\n    The provided abstract is: ###\\n    \\nThis paper introduces a  system for categorizing unknown words . The  system  is based on a  multi-component architecture  where each  component  is responsible for identifying one class of  unknown words . The focus of this paper is the  components  that identify  names  and  spelling errors . Each  component  uses a  decision tree architecture  to combine multiple types of  evidence  about the  unknown word . The  system  is evaluated using data from  live closed captions  - a genre replete with a wide variety of  unknown words .\\n\\n    ###\\n    "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new df to contain responses at corresponding rows.\n",
    "# MODIFY TO SPECIFY AMOUNT OF INPUT.\n",
    "\n",
    "scierc_full_responses = scierc_full.copy()\n",
    "scierc_full_responses.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3007230",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf38fcb",
   "metadata": {},
   "source": [
    "## Prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "350fca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model:\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "# Retry parameters\n",
    "max_retries = 3\n",
    "retry_delay = 5  # in seconds\n",
    "\n",
    "# Initialize a new column 'responses' in the dataframe\n",
    "scierc_full_responses.loc[:, 'responses'] = ''\n",
    "\n",
    "def generate_responses(input_df):\n",
    "    for idx, row in tqdm(input_df.iterrows(), total=len(input_df), desc=\"Generating responses\"):\n",
    "        try:\n",
    "            query = row['prompt']\n",
    "\n",
    "            if query is None or query.strip() == '':\n",
    "                print(f\"Empty prompt at index {idx}. Skipping this row.\")\n",
    "                continue\n",
    "\n",
    "            retries = 0\n",
    "            while retries < max_retries:\n",
    "                try:\n",
    "                    response = openai.ChatCompletion.create(\n",
    "                        model=GPT_MODEL,\n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": \"You will perform triple detection, adhering to the restricted types of entities and relations listed in the query.\"},\n",
    "                            {\"role\": \"user\", \"content\": query}, # In general, gpt-3.5-turbo-0301 does not pay strong attention to the system message, and therefore important instructions are often better placed in a user message.\n",
    "                        ],\n",
    "                        temperature=0,\n",
    "                        max_tokens=1000,  # max tokens in response. token limit (4096) must be < largest query + message content + max_tokens\n",
    "                    )\n",
    "\n",
    "                    response_content = response['choices'][0]['message']['content']\n",
    "                    print(response_content)  # Print just the message content\n",
    "\n",
    "                    # Add the response to the 'responses' column of the dataframe\n",
    "                    input_df.loc[idx, 'responses'] = response_content\n",
    "\n",
    "                    break  # Break out of the retry loop if successful\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating response for prompt at index {idx}: {str(e)}\")\n",
    "                    print(f\"Query: {query}\")\n",
    "                    retries += 1\n",
    "                    print(f\"Retrying in {retry_delay} seconds...\")\n",
    "                    time.sleep(retry_delay)\n",
    "\n",
    "            if retries == max_retries:\n",
    "                print(f\"Max retries reached for prompt at index {idx}. Skipping this row.\")\n",
    "\n",
    "            # Add a delay between requests to avoid overwhelming the API\n",
    "            time.sleep(random.uniform(0.5, 1.5))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating response for prompt at index {idx}: {str(e)}\")\n",
    "            print(f\"Query: {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d2340a",
   "metadata": {},
   "source": [
    "## Run prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2605f8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"system categorizing unknown words USED-FOR identifying names and spelling errors\", \"multi-component architecture PART-OF system\", \"component responsible for identifying one class of unknown words FEATURE-OF decision tree architecture\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   0%|          | 1/500 [00:04<34:49,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach USED-FOR statistical sentence generation\", \"alternative phrases FEATURE-OF packed sets\", \"packed sets FEATURE-OF trees\", \"packed sets FEATURE-OF forests\", \"representation OFFERS-ADVANTAGES-IN compactness\", \"representation OFFERS-ADVANTAGES-IN ability to represent syntactic information\", \"ranking algorithm FEATURE-OF efficient ranking\", \"previous approach COMPARE lattice-based approach\", \"experimental results EVALUATE-FOR improvements over simple enumeration or a lattice-based approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   0%|          | 2/500 [00:10<45:32,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"natural language interface USED-FOR database query applications\", \"multimedia answers FEATURE-OF videodisc images\", \"multimedia answers FEATURE-OF complete sentences\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   1%|          | 3/500 [00:13<37:08,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"pronominal anaphora resolution module PART-OF Lucy\", \"English understanding system USED-FOR pronominal anaphora resolution\", \"anaphora resolution FEATURE-OF Lucy\", \"theories COMPARE blackboard-like architecture\", \"partial theories PART-OF blackboard-like architecture\", \"modules INTERACT modules\", \"candidate antecedents EVALUATE-FOR proposals\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   1%|          | 4/500 [00:19<40:15,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"design cognitively well-motivated interfaces USED-FOR display of graphical information\", \"graphical information not sufficient support FOR users\", \"integration of natural language generation PART-OF interaction\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   1%|          | 5/500 [00:23<37:09,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"evaluation methodology ADVANCE state-of-the-art\", \"evaluation crucial to assessing competing claims\", \"evaluation methodology permit comparison among various systems\", \"methodology for comparative evaluation of SLS systems AGREED\", \"methodology PUT INTO PRACTICE several times\", \"NL evaluations DEVELOPED by a group of researchers\", \"black-box methodology for automatic evaluation of question-answering NL systems DESCRIBED\", \"methodology HEART DOMAIN-INDEPENDENT\", \"methodology USED WITH speech or text input\", \"implementation of methodology in DARPA SLS community PRESENTED\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   1%|          | 6/500 [00:30<45:17,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"natural language processing MEETS real world\", \"TACITUS USED-FOR MUC-3 evaluation\", \"techniques FOR making syntactic analysis more robust FEATURE-OF agenda-based scheduling parser, recovery technique for failed parses, terminal substring parsing\", \"method of abductive inference inherently robust\", \"interpretation ALWAYS possible\", \"performance DEGRADES gracefully IN ABSENCE OF required world knowledge\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   1%|▏         | 7/500 [00:35<43:42,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm REDUCTION search space\", \"chart-based phrase structure parsing USED-FOR natural language\", \"parser GAINS algorithmic efficiency\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   2%|▏         | 8/500 [00:38<37:17,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"spelling correction USED-FOR agglutinative languages\", \"two-level morphology FEATURE-OF approach\", \"dynamic-programming based search algorithm FEATURE-OF approach\", \"spelling correction EVALUATE-FOR Turkish\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   2%|▏         | 9/500 [00:42<36:49,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"GLOSSER SUPPORT reading\", \"language pairs SUPPORTED BY GLOSSER English-Bulgarian\", \"language pairs SUPPORTED BY GLOSSER English-Estonian\", \"language pairs SUPPORTED BY GLOSSER English-Hungarian\", \"program operational ON UNIX\", \"program operational ON Windows '95 platforms\", \"demonstration emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis\", \"disambiguated morphological analysis FEATURE-OF ICALL\", \"lemmatized indexing FEATURE-OF ICALL\", \"aligned bilingual corpus PART-OF word examples\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   2%|▏         | 10/500 [00:49<42:49,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"building large repositories FEATURE-OF lexical conceptual structure representations\", \"LEXICALL USED-FOR LCS representations\", \"lexicons PART-OF operational foreign language tutoring\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   2%|▏         | 11/500 [00:53<38:05,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"NLP-system USED-FOR Dutch\", \"morphological component PART-OF NLP-system\", \"output COMPARE language independent developments\", \"DMLP USED-FOR idiosyncrasies\", \"LSP-MLP system FEATURE-OF language independent modules\", \"practical application EVALUATE-FOR highlighting of relevant information\", \"patient discharge summary USED-FOR highlighting of relevant information\", \"HyperText Mark-Up Language FEATURE-OF modern technology\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   2%|▏         | 12/500 [00:58<40:00,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Named Entity task PART-OF information extraction task\", \"corpora FEATURE-OF Named Entity task\", \"algorithm USED-FOR lower bound estimation\", \"cross-lingual comparisons FEATURE-OF analysis\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   3%|▎         | 13/500 [01:02<36:17,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"problem IDENTIFYING-TOPICS texts\", \"Optimal Position Policy METHOD-OF locating positions topic-bearing sentences\", \"genre-specific regularities FEATURE-OF discourse structure\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   3%|▎         | 14/500 [01:05<33:56,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm USED-FOR translation lexicon acquisition\", \"SABLE FEATURE-OF translation lexicons\", \"corpus PART-OF translation lexicon acquisition\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   3%|▎         | 15/500 [01:08<30:29,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"subcategorization dictionary USED-FOR parser\", \"subcategorization classes PART-OF dictionary entry\", \"technique COMPARE previous approaches\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   3%|▎         | 16/500 [01:10<27:08,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Rete algorithm USED-FOR Forward Chaining rule systems\", \"Treat algorithm USED-FOR Forward Chaining rule systems\", \"Assertions not allowed to contain variables\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   3%|▎         | 17/500 [01:14<26:45,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"propositional logic of context extends classical propositional logic in two ways\", \"modality ist(;) USED-FOR expressing that sentence holds in context\", \"each context has its own vocabulary PART-OF set of propositional atoms\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   4%|▎         | 18/500 [01:18<29:42,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"causal graph USED-FOR construction\", \"conditional independencies FEATURE-OF causal induction algorithms\", \"Verma constraints COMPARE conditional independencies\", \"dormant independencies FEATURE-OF Verma constraints\", \"conditional independencies PART-OF dormant independencies\", \"algorithm USED-FOR determining dormant independence\", \"two sets of variables PART-OF dormant independence\", \"causal graph EVALUATE-FOR dormant independencies\", \"interventional distribution PART-OF dormant independence\", \"dormant independencies USED-FOR model testing\", \"algorithm USED-FOR pruning extraneous edges\", \"given causal graph PART-OF pruning extraneous edges\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   4%|▍         | 19/500 [01:25<37:50,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ensemble construction resampling pairwise constraints\", \"base classifiers built with new data representation\", \"pairwise constraints used for ensemble construction\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   4%|▍         | 20/500 [01:29<34:17,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Yoopick IMPLEMENTS flexible betting language\", \"Yoopick FACILITATES probabilistic estimation of outcomes\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   4%|▍         | 21/500 [01:32<31:15,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"machine reading system COREF system\", \"machine reading system USED-FOR fact assertions extraction\", \"natural language processing PART-OF machine reading system\", \"information extraction PART-OF machine reading system\", \"cognitive architecture FEATURE-OF machine reading system\", \"knowledge levels FEATURE-OF machine reading system\", \"construction grammar FEATURE-OF machine reading system\", \"cognitive semantics FEATURE-OF machine reading system\", \"tools FEATURE-OF machine reading system\", \"family history domain EVALUATE-FOR machine reading system\", \"architecture FEATURE-OF machine reading system\", \"performance EVALUATE-FOR machine reading system\", \"evaluations PART-OF machine reading system\", \"future directions FEATURE-OF possible\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   4%|▍         | 22/500 [01:40<41:41,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"convex optimization problem USED-FOR segmenting sequential data\", \"outliers FEATURE-OF presence\", \"two algorithms DESCRIBE solving problem\", \"one exact algorithm\", \"one top-down novel approach algorithm\", \"consistency results DERIVE case of two segments and no outliers\", \"Robustness EVALUATE-FOR outliers\", \"two real-world tasks RELATED-TO speech segmentation\", \"algorithms OUTPERFORM baseline segmentation algorithms\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   5%|▍         | 23/500 [01:45<40:43,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Semantic Web documents encode facts ABOUT entities\", \"automatic summarization techniques CHARACTERIZE entity\", \"diversity-aware entity summarization approach MIMICS human conceptual clustering techniques\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   5%|▍         | 24/500 [01:49<37:39,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"multimodal interfaces REQUIRE effective parsing\", \"approach PRESENTS strategies for multimodal integration\", \"unification-based grammar USED-BY multidimensional chart parser\", \"approach significantly MORE EFFICIENT\", \"weighted finite-state device TAKES speech and gesture streams\", \"approach PROVIDES probabilistic framework for multimodal ambiguity resolution\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   5%|▌         | 25/500 [01:54<38:59,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"statistical machine translation USED-FOR Verbmobil task\", \"dynamic programming USED-FOR search procedure\", \"word reordering FEATURE-OF translation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   5%|▌         | 26/500 [01:58<35:48,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"deep processing USED-FOR NLP system\", \"linguistic PoS tagger FEATURE-OF preprocessing module\", \"broad coverage unification based grammar PART-OF NLP system\", \"efficiency EVALUATE-FOR overall analysis\", \"robustness EVALUATE-FOR linguistic processing\", \"accuracy EVALUATE-FOR grammar\", \"precision EVALUATE-FOR grammar\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   5%|▌         | 27/500 [02:03<38:03,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"unsupervised learning method USED-FOR associative relationships\", \"verb phrases FEATURE-OF associative relationships\", \"Q&A systems EVALUATE-FOR reliability\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   6%|▌         | 28/500 [02:06<34:17,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Kullback-Leibler distance COMPUTE between probabilistic context-free grammar AND probabilistic finite automaton\", \"closed-form solution EXIST for cross-entropy\", \"distributional approximation of probabilistic context-free grammars achieved by means of probabilistic finite automata\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   6%|▌         | 29/500 [02:13<40:02,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"language modeling tasks EVALUATE-FOR Arabic\", \"language modeling tasks EVALUATE-FOR Turkish\", \"factored language models FEATURE-OF approaches\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   6%|▌         | 30/500 [02:17<35:55,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"bit-vector-based CKY-style parser USED-FOR context-free parsing\", \"parser computes parse forest representation FEATURE-OF complete set of possible analyses\", \"parser uses bit-vector operations to parallelise basic parsing operations\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   6%|▌         | 31/500 [02:20<34:16,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"machine learning approach USED-FOR bare slice disambiguation\", \"heuristic principles FEATURE-OF corpus-based sample\", \"probabilistic Horn clauses FEATURE-OF heuristic principles\", \"predicates PART-OF Horn clauses\", \"domain independent features FEATURE-OF input dataset\", \"machine learning algorithms USED-FOR bare slice disambiguation\", \"SLIPPER METHOD machine learning algorithm\", \"TiMBL METHOD memory-based system\", \"success rates EVALUATE-FOR bare slice disambiguation\", \"features FEATURE-OF heuristic principles\", \"rules HYPONYM-OF Horn clauses\", \"Horn clauses COMPARE rules\", \"features CONJUNCTION heuristic principles\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   6%|▋         | 32/500 [02:28<42:02,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"word similarity measures USED-FOR semantic-oriented NLP applications\", \"meaning-entailing substitutability EVALUATE-FOR word similarity measures\", \"distributional word feature vectors FEATURE-OF word similarity results\", \"feature weighting and selection function FEATURE-OF feature vectors\", \"feature weighting and selection function USED-FOR word similarity performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   7%|▋         | 33/500 [02:34<42:06,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"maximum entropy classifiers USED-FOR language processing tasks\", \"boosting USED-FOR language processing tasks\", \"SVMs USED-FOR language processing tasks\", \"error correction mechanisms FEATURE-OF language processing tasks\", \"base classifier FEATURE-OF error correction mechanisms\", \"N-fold Templated Piped Correction USED-FOR error correction\", \"NTPC COMPARE complex models\", \"NTPC EVALUATE-FOR accuracy\", \"base models FEATURE-OF NTPC\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   7%|▋         | 34/500 [02:40<43:23,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"project AIMS-TO cluster electronic discussions\", \"summaries ASSIST help-desk users and operators\", \"features INFLUENCE clustering process\", \"filtering mechanism REMOVES undesirable influences\", \"clustering and filtering processes TESTED ON electronic newsgroup discussions\", \"performance EVALUATED BY means of two experiments: coarse-level clustering, simple information retrieval\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   7%|▋         | 35/500 [02:48<50:47,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"HMM tagger USED-FOR part-of-speech tagging\", \"lexicon FEATURE-OF accuracy\", \"HMM training IMPROVES accuracy\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   7%|▋         | 36/500 [02:52<43:14,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"generation algorithm BASED-ON results\", \"psychological experiments CONDUCTED-WITH 42 subjects\", \"proposed method EFFECTIVELY-GENERATE proper referring expressions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   7%|▋         | 37/500 [02:55<38:04,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"detection method USED-FOR orthographic variants\", \"transliteration CAUSED orthographic variants\", \"method employs string similarity FEATURE-OF edit distance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   8%|▊         | 38/500 [02:58<34:03,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"machine transliteration/back-transliteration USED-FOR multilingual speech and language applications\", \"direct orthographical mapping FEATURE-OF novel framework\", \"joint source-channel transliteration model FEATURE-OF direct orthographical mapping\", \"n-gram transliteration model HYPONYM-OF joint source-channel transliteration model\", \"transliteration process FEATURE-OF n-gram transliteration model\", \"transliteration/backtransliteration experiments EVALUATE-FOR transliteration accuracy\", \"proposed method USED-FOR transliteration/backtransliteration experiments\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   8%|▊         | 39/500 [03:05<39:31,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"computational linguists dubious ABOUT analogies BETWEEN sentences\", \"experiments conducted ON multilingual corpus TO estimate number OF analogies AMONG sentences\", \"translation PRESERVE meaning TO test FOR similar meanings\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   8%|▊         | 40/500 [03:09<36:28,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"corpus-based supervised word sense disambiguation system USED-FOR Dutch\", \"maximum entropy FEATURE-OF statistical classification\", \"lemma-based approach PART-OF classifier\", \"inflected forms PART-OF ambiguous word\", \"training material FEATURE-OF algorithm\", \"lemma-based model EVALUATE-FOR Dutch Senseval-2 test data accuracy\", \"wordform model COMPARE lemma-based model\", \"WSD system based on lemmas COMPARE wordform model\", \"WSD system based on lemmas FEATURE-OF smaller and more robust\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   8%|▊         | 41/500 [03:16<40:51,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"text mining method USED-FOR finding synonymous expressions\", \"distributional hypothesis FEATURE-OF text mining method\", \"corpora PART-OF distributional hypothesis\", \"methodology USED-FOR improving accuracy of term aggregation system\", \"author's text PART-OF coherent corpus\", \"person tends to use one expression for one meaning\", \"words with similar context features tend not to be synonymous expressions\", \"proposed method EVALUATE-FOR accuracy of term aggregation system\", \"approach COMPARE successful\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   8%|▊         | 42/500 [03:21<41:02,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"sentence extraction USED-FOR summarization\", \"email communication GENERIC utterances\", \"email conversation PART-OF email summarization\", \"question-answer pairs USED-FOR email summarization\", \"features FEATURE-OF email-threads\", \"lexical similarity FEATURE-OF discourse segments\", \"question-answer pairing EVALUATE-FOR email summarization\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   9%|▊         | 43/500 [03:27<41:12,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"lexical affinity models USED-FOR natural language tests\", \"algorithm USED-FOR compute co-occurrence distribution\", \"independence model FEATURE-OF framework\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   9%|▉         | 44/500 [03:31<37:56,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method based-on word alignment USED-FOR word sense disambiguation\", \"wordnets aligned-to Princeton Wordnet HYPONYM-OF EuroWordNet\", \"WSD system EVALUATE-FOR encouraging results\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   9%|▉         | 45/500 [03:34<34:50,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"source language FEATURE-OF speeches\", \"EUROPARL corpus PART-OF speeches\", \"frequency counts FEATURE-OF word n-grams\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   9%|▉         | 46/500 [03:39<35:24,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Chinese word segmenter USED-FOR machine translation systems\", \"Bayesian semi-supervised Chinese word segmentation model FEATURE-OF segmentation\", \"method EVALUATE-FOR state-of-the-art MT system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:   9%|▉         | 47/500 [03:43<34:06,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Language resource quality FEATURE-OF NLP\", \"resources USED-FOR MT and reference translations\", \"automatic evaluations EVALUATE-FOR comparison of automatic and human translations\", \"data PART-OF automatic evaluations\", \"different-quality references FEATURE-OF evaluation\", \"automatic metrics LIMITATIONS-OF MT\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  10%|▉         | 48/500 [03:48<33:14,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"search tool USED-FOR linguistic knowledge discovery\", \"wildcards FEATURE-OF queries\", \"system PART-OF Linux PC\", \"memory FEATURE-OF system\", \"disk space FEATURE-OF system\", \"NLP tasks USED-FOR linguistic knowledge discovery\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  10%|▉         | 49/500 [03:52<32:54,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"FROFF system USED-FOR making fair copy of texts, graphs and tables\", \"fonts FEATURE-OF FROFF system\", \"character PART-OF line length\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  10%|█         | 50/500 [03:56<31:29,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Augmented Transition Network USED-FOR procedural dialog model\", \"dialog schemata FEATURE-OF empirical conversation analysis\", \"models of verbal interaction FEATURE-OF procedural dialog model\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  10%|█         | 51/500 [03:59<29:52,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"left corner parsing algorithm USED-FOR context-free grammars\", \"resulting algorithm FEATURE-OF parser\", \"parser USED-FOR natural language interface\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  10%|█         | 52/500 [04:02<27:03,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"interlingual approach HYPONYM-OF MT\", \"natural language understanding FEATURE-OF machine translation\", \"Mu-project USED-FOR MT\", \"transfer approach USED-FOR MT\", \"transfer phase PART-OF Mu-project system\", \"Japanese PART-OF transfer phase\", \"English PART-OF transfer phase\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  11%|█         | 53/500 [04:07<29:42,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"determiners ROLE-IN conveying meaning\", \"methods devise TO grasp global meaning\", \"determiners ambiguity PROBLEM-WITH\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  11%|█         | 54/500 [04:09<26:22,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"hierarchical relations PART-OF thesaurus construction\", \"Japanese language dictionary PART-OF pilot system\", \"definition sentences FEATURE-OF dictionary\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  11%|█         | 55/500 [04:12<24:38,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"RAREAS synthesizes marine weather forecasts directly from formatted weather data\", \"approach can easily be adapted to synthesize bilingual or multi-lingual texts\", \"linguistic and non-linguistic knowledge FEATURE-OF RAREAS\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  11%|█         | 56/500 [04:16<24:51,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Unification Categorial Grammar USED-FOR Machine Translation\", \"Isomorphic Grammars PART-OF Machine Translation\", \"Source language PART-OF Isomorphic Grammars\", \"Target language PART-OF Isomorphic Grammars\", \"translation relation PART-OF Isomorphic Grammars\", \"isomorphic derivations PART-OF Isomorphic Grammars\", \"translation equivalence COMPARE semantic questions\", \"translation relation EVALUATE-FOR textual representation\", \"monolingual UCG PART-OF MT system design\", \"bi-directional English-Spanish fragment PART-OF MT system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  11%|█▏        | 57/500 [04:22<30:48,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"demonstrative expressions USED-FOR discourse processing algorithms\", \"demonstrative forms and functions PART-OF texts\", \"anaphoric expressions PART-OF larger study\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  12%|█▏        | 58/500 [04:26<30:55,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Category Cooccurrence Restrictions (CCRs) DESCRIBES parsing algorithms\", \"CCR Boolean conditions on cooccurrence of categories in local trees ALLOW statement of generalizations\", \"CCR leads to syntactic descriptions formulated entirely with restrictive statements\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  12%|█▏        | 59/500 [04:32<35:53,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"theory of natural language presuppositions PRESENTED-IN Gazdar 1979\", \"Soames 1979 PROVIDES counterexamples to theory of natural language presuppositions\", \"Soames 1982 PROVIDES theory which explains counterexamples\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  12%|█▏        | 60/500 [04:36<33:05,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"computational model PART-OF APT program\", \"discourse task HYPONYM-OF layout description\", \"organizational and discourse strategies FEATURE-OF computational model\", \"corpus FEATURE-OF organizational and discourse strategies\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  12%|█▏        | 61/500 [04:40<30:56,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"chart parsing PART-OF directional\", \"chart PART-OF islands\", \"chart PART-OF sentence\", \"fragments PART-OF sentence\", \"fragments PART-OF islands\", \"fragments PART-OF sentence\", \"left context FEATURE-OF missing fragments\", \"right context FEATURE-OF missing fragments\", \"heuristics USED-FOR predicting missing fragments\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  12%|█▏        | 62/500 [04:45<33:58,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Interactive Machine Translation USED-FOR creation or modification of document\", \"ambiguity FEATURE-OF sentence\", \"translation process PART-OF interactive disambiguation scheme\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  13%|█▎        | 63/500 [04:49<31:17,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"computer programs MODELING language acquisition\", \"learning methodology NOT APPLICABLE IN linguistic domain\", \"linguistic representation GEARED TO learning\", \"Dynamic Hierarchical Phrasal Lexicon FACILITATE language acquisition\", \"language learning model IMPLEMENTED IN RINA\", \"linguistic concepts ACQUIRED FROM training examples\", \"linguistic concepts ORGANIZED IN hierarchy\", \"lexical hierarchy ENHANCED BY RINA\", \"lexical hierarchy USED IN predicting new linguistic concepts\", \"program DOES NOT STALL IN presence of lexical unknown\", \"hypothesis PRODUCED FOR covering lexical gap\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  13%|█▎        | 64/500 [04:56<37:04,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 64: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e11a10563bc93a0b1a729eddcb36ee49 in your message.)\n",
      "Query: Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\n",
      "    ###\n",
      "    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\n",
      "    ###\n",
      "    Here are some examples of each type of entity that may be detected:\n",
      "    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\n",
      "    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\n",
      "    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\n",
      "    time complexity.\n",
      "    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\n",
      "    Panntreebank, WordNet, Wikipedia.\n",
      "    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\n",
      "    discourse structure, tree, node, tree kernel, features, noise, criteria.\n",
      "    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\n",
      "    ###\n",
      "    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [triple1, triple2, triple3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "     \n",
      " Although every  natural language system  needs a  computational lexicon  , each system puts different amounts and types of information into its  lexicon  according to its individual needs. However, some of the information needed across systems is shared or identical information. This paper presents our experience in planning and building  COMPLEX  , a  computational lexicon  designed to be a repository of  shared lexical information  for use by  Natural Language Processing (NLP) systems  . We have drawn primarily on explicit and implicit information from  machine-readable dictionaries (MRD's)  to create a  broad coverage lexicon  . \n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"natural language system NEEDS computational lexicon\", \"system PUTS information INTO lexicon\", \"information NEEDED ACROSS systems SHARED\", \"COMPLEX computational lexicon DESIGNED-FOR repository\", \"COMPLEX computational lexicon DESIGNED-FOR Natural Language Processing systems\", \"MRD's PROVIDE information FOR lexicon\", \"MRD's PROVIDE explicit information FOR lexicon\", \"MRD's PROVIDE implicit information FOR lexicon\", \"broad coverage lexicon CREATED-FROM MRD's\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  13%|█▎        | 65/500 [05:37<1:56:03, 16.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"deterministic parser COMBINES symbolic and connectionist components\", \"connectionist component TRAINED-FROM patterns derived from rules of deterministic grammar\", \"hybrid architecture SUPERIOR-TO known deterministic parser\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  13%|█▎        | 66/500 [05:41<1:28:36, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"bidirectional grammar generation system FEATURE-OF dialogue translation system\", \"typed feature structures USED-FOR top-down derivation\", \"disjunctive feature structures FEATURE-OF derivation tree\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  13%|█▎        | 67/500 [05:44<1:10:07,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"DoPS system USED-FOR disambiguation of dependency structure\", \"DoPS system FEATURE-OF preference knowledge\", \"target document PART-OF DoPS system\", \"documents PART-OF DoPS system\", \"Sentence ambiguities EVALUATE-FOR domain targeted preference knowledge\", \"large knowledgebases COMPARE domain targeted preference knowledge\", \"analysis of dependency structures EVALUATE-FOR Japanese patent claim sentences\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  14%|█▎        | 68/500 [05:51<1:02:08,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"feature-based partial descriptions PART-OF Halliday's systemic networks\", \"consistency checking USED-FOR feature-based partial descriptions\", \"algorithms EVALUATE-FOR consistency checking\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  14%|█▍        | 69/500 [05:54<51:35,  7.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Korean Phonology Structure Grammar (KPSG) PART-OF computational phonological system\", \"KPSG USED-FOR speech recognition and synthesis system\", \"traditional generative phonological approach COMPARE proposed approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  14%|█▍        | 70/500 [05:58<43:24,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"TAGs USED-FOR semantic interpretation\", \"TAGs USED-FOR automatic translation of natural language\", \"synchronous TAGs HYPONYM-OF TAGs\", \"synchronous TAGs USED-FOR relating expressions of natural languages to their associated semantics\", \"synchronous TAGs USED-FOR translating natural language\", \"synchronous TAGs USED-FOR using TAGs beyond syntax proper\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  14%|█▍        | 71/500 [06:03<41:06,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"sentence analysis TREATED-AS defeasible reasoning\", \"Japanese sentence analyses USED-FOR argumentation system\", \"argumentation system PART-OF formalization of defeasible reasoning\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  14%|█▍        | 72/500 [06:06<35:23,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"semantic constraints FEATURE-OF statistics\", \"statistics USED-FOR disambiguation tool\", \"pronoun 'it' COREF anaphora references\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  15%|█▍        | 73/500 [06:09<31:20,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"spelling-checkers USED-FOR text processing software\", \"dictionaries FEATURE-OF spelling-checkers\", \"inflection FEATURE-OF Czech\", \"inflection FEATURE-OF Russian\", \"inflection FEATURE-OF Slovak\", \"method USED-FOR building spelling-checkers\", \"program EVALUATE-FOR speed\", \"program EVALUATE-FOR existing spelling-checkers\", \"dictionary PART-OF program\", \"word forms EVALUATE-FOR number\", \"word forms EVALUATE-FOR Czech\", \"method USED-FOR word classification\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  15%|█▍        | 74/500 [06:15<35:26,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"discourse segments DEFINED\", \"method PROPOSED for discourse segmentation\", \"method BASED-ON abduction of temporal relations\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  15%|█▌        | 75/500 [06:19<31:30,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"adaptive learning procedure USED-FOR syntactic ambiguity resolution\", \"training data INSUFFICIENT-FOR statistical approaches\", \"language model FEATURE-OF statistical approaches\", \"statistical approaches USED-FOR ambiguities\", \"maximum likelihood method FEATURE-OF statistical approaches\", \"accuracy rate EVALUATE-FOR syntactic disambiguation\", \"proposed algorithm FEATURE-OF accuracy rate\", \"training corpus PART-OF proposed algorithm\", \"separation margin FEATURE-OF proposed algorithm\", \"candidate COMPETES-WITH competing members\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  15%|█▌        | 76/500 [06:25<35:38,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"unification-based grammar parsing USED-FOR Graph unification\", \"structure-sharing FEATURE-OF method\", \"redundant copying ELIMINATES quasi-destructive scheme's ability\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  15%|█▌        | 77/500 [06:31<36:36,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"transfer phase PART-OF machine translation systems\", \"lexical rules PART-OF transfer phase\", \"case-based reasoning USED-FOR machine translation\", \"translation examples FEATURE-OF case-based reasoning\", \"Similarity-driven Transfer System (SimTran) PART-OF transfer system\", \"case-based MT (CBMT) USED-FOR Similarity-driven Transfer System (SimTran)\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  16%|█▌        | 78/500 [06:35<35:35,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"generalized LR parsing FEATURE-OF speech understanding\", \"parser PART-OF approach\", \"fake non-terminal symbol USED-FOR skipping noisy portion\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  16%|█▌        | 79/500 [06:39<31:35,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Word Identification USED-FOR Chinese Natural Language Processing\", \"mechanism FEATURE-OF identifying unknown words\", \"sublanguage HYPONYM-OF language\", \"personal names HYPONYM-OF unknown words\", \"Chinese newspapers PART-OF corpora\", \"title-driven name recognition FEATURE-OF mechanism\", \"adaptive dynamic word formation FEATURE-OF mechanism\", \"2-character Chinese names HYPONYM-OF personal names\", \"3-character Chinese names HYPONYM-OF personal names\", \"experimental results EVALUATE-FOR WI systems\", \"corpora PART-OF experimental results\", \"NTHU's statistic-based system COMPARE proposed mechanism\", \"name identification FEATURE-OF WI systems\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  16%|█▌        | 80/500 [06:46<38:19,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SPRINT USED-FOR natural language texts\", \"SPRINT FEATURE-OF model\", \"qualitative spatial constraints FEATURE-OF spatial concepts\", \"numerical constraints FEATURE-OF spatial attributes\", \"entities PART-OF numerical constraints\", \"interpretation EVALUATE-FOR maximally plausible interpretation\", \"temporary belief EVALUATE-FOR world\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  16%|█▌        | 81/500 [06:51<37:40,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Chinese collocation system USED-FOR Chinese text corpora\", \"character-based collocation system USED-FOR avoiding pre-processing distortion\", \"character-based collocation system USED-FOR accessing sub-lexical information\", \"word-based collocational properties PART-OF auxiliary module\", \"automatic segmentation PART-OF auxiliary module\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  16%|█▋        | 82/500 [06:55<34:31,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm USED-FOR selecting classifier word\", \"classifier selection FEATURE-OF rule-based approach\", \"default rule FEATURE-OF pick up classifier\", \"corpus-based method USED-FOR generating Noun Classifier Associations\", \"Noun Classifier Associations PART-OF semantic construction of noun phrase\", \"Noun Classifier Associations PART-OF classifier assignment\", \"Noun Classifier Associations COMPARE concept hierarchy constraints\", \"Noun Classifier Associations COMPARE frequency of occurrences\", \"corpus PART-OF corpus-based method\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  17%|█▋        | 83/500 [07:02<37:07,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"word-sense ambiguity FEATURE-OF extraction\", \"machine-readable resources PART-OF construction\", \"semantic classification EVALUATE-FOR verbs\", \"Levin COMPARE word-sense distinctions\", \"verb semantics HYPONYM-OF syntactic behavior\", \"syntactic cues PART-OF distinct groupings\", \"distinct groupings HYPONYM-OF word senses\", \"effective acquisition techniques USED-FOR novel word senses\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  17%|█▋        | 84/500 [07:08<38:10,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"model ACCOUNT-FOR rules of interpretation\", \"model APPLY-TO compounds in real texts\", \"semantic principles DISTINGUISH generalizable from domain-specific\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  17%|█▋        | 85/500 [07:10<32:23,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Natural Language Processing system PART-OF syntactic parsing\", \"lexicon PART-OF lexicalized grammar\", \"traditional knowledge-based techniques USED-FOR fitting a lexicalized grammar to a domain\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  17%|█▋        | 86/500 [07:13<28:42,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm USED-FOR labeling curvilinear structure\", \"CURVE-ELEMENT tokens FEATURE-OF image description\", \"tokens computed VIA grouping procedure\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  17%|█▋        | 87/500 [07:16<25:18,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 87: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ede6e009eca05db494fe32288ff1a654 in your message.)\n",
      "Query: Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\n",
      "    ###\n",
      "    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\n",
      "    ###\n",
      "    Here are some examples of each type of entity that may be detected:\n",
      "    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\n",
      "    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\n",
      "    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\n",
      "    time complexity.\n",
      "    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\n",
      "    Panntreebank, WordNet, Wikipedia.\n",
      "    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\n",
      "    discourse structure, tree, node, tree kernel, features, noise, criteria.\n",
      "    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\n",
      "    ###\n",
      "    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [triple1, triple2, triple3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    A model-based approach to on-line cursive handwriting analysis and recognition is presented and evaluated. In this model, on-line handwriting is considered as a modulation of a simple cycloidal pen motion, described by two coupled oscillations with a constant linear drift along the line of the writing. By slow modulations of the amplitudes and phase lags of the two oscillators, a general pen trajectory can be efficiently encoded. These parameters are then quantized into a small number of values without altering the writing intelligibility. A general procedure for the estimation and quantization of these cycloidal motion parameters for arbitrary handwriting is presented. The result is a discrete motor control representation of the continuous pen motion, via the quantized levels of the model parameters. This motor control representation enables successful word spotting and matching of cursive scripts. Our experiments clearly indicate the potential of this dynamic representation for complete cursive handwriting recognition.\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "Error generating response for prompt at index 87: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f0d580d4eff96039944b514d41e091df in your message.)\n",
      "Query: Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\n",
      "    ###\n",
      "    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\n",
      "    ###\n",
      "    Here are some examples of each type of entity that may be detected:\n",
      "    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\n",
      "    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\n",
      "    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\n",
      "    time complexity.\n",
      "    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\n",
      "    Panntreebank, WordNet, Wikipedia.\n",
      "    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\n",
      "    discourse structure, tree, node, tree kernel, features, noise, criteria.\n",
      "    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\n",
      "    ###\n",
      "    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [triple1, triple2, triple3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    A model-based approach to on-line cursive handwriting analysis and recognition is presented and evaluated. In this model, on-line handwriting is considered as a modulation of a simple cycloidal pen motion, described by two coupled oscillations with a constant linear drift along the line of the writing. By slow modulations of the amplitudes and phase lags of the two oscillators, a general pen trajectory can be efficiently encoded. These parameters are then quantized into a small number of values without altering the writing intelligibility. A general procedure for the estimation and quantization of these cycloidal motion parameters for arbitrary handwriting is presented. The result is a discrete motor control representation of the continuous pen motion, via the quantized levels of the model parameters. This motor control representation enables successful word spotting and matching of cursive scripts. Our experiments clearly indicate the potential of this dynamic representation for complete cursive handwriting recognition.\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"model-based approach USED-FOR on-line cursive handwriting analysis and recognition\", \"on-line handwriting PART-OF modulation of cycloidal pen motion\", \"two coupled oscillations FEATURE-OF cycloidal pen motion\", \"general pen trajectory FEATURE-OF slow modulations of amplitudes and phase lags\", \"parameters QUANTIZED-INTO small number of values\", \"estimation and quantization procedure FEATURE-OF cycloidal motion parameters\", \"discrete motor control representation FEATURE-OF motor control representation\", \"quantized levels of model parameters FEATURE-OF motor control representation\", \"word spotting EVALUATE-FOR cursive scripts\", \"matching EVALUATE-FOR cursive scripts\", \"dynamic representation COMPARE complete cursive handwriting recognition\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  18%|█▊        | 88/500 [08:37<3:04:13, 26.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"MINPRAN nds good ts USED-FOR data sets where more than 50% of the points are outliers\", \"MINPRAN does not rely on a known error bound FEATURE-OF good data\", \"bad data are randomly distributed PART-OF dynamic range of the sensor\", \"MINPRAN uses random sampling to search for the t and the number of inliers to the t that are least likely to have occurred randomly\", \"MINPRAN distinguishes good ts from ts to random data EVALUATE-FOR\", \"MINPRAN nds accurate ts and nearly the correct number of inliers EVALUATE-FOR\", \"MINPRAN's properties are connrmed experimentally COMPARE least median of squares\", \"MINPRAN applies to complex range and intensity data USED-FOR\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  18%|█▊        | 89/500 [08:45<2:26:08, 21.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"framework USED-FOR segmentation of complex scenes\", \"physical hypotheses USED-FOR simple image regions\", \"approach USED-FOR segmentation of complex scenes\", \"segmentations EVALUATE-FOR scenes containing multi-colored piece-wise uniform objects\", \"approach USED-FOR segmentations\", \"scenes PART-OF segmentations\", \"physical models USED-FOR segmentations\", \"segmentations COMPARE segmentations found using only color\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  18%|█▊        | 90/500 [08:51<1:53:20, 16.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"video sequence compact description USED-FOR video browsing and retrieval\", \"single image map PART-OF compact description\", \"dominant motion PART-OF compact description\", \"representation BUILD-FOR video browsing and retrieval, compression, mosaicing, visual summarization\", \"capability TO-REGISTER frames WITH-RESPECT-TO dominant object\", \"task ADDRESSED-THROUGH temporally localized motion estimates\", \"lack OF temporal consistency UNDERMINE validity OF dominant motion assumption\", \"oscillation BETWEEN different scene interpretations\", \"poor registration RESULT-OF lack OF temporal consistency\", \"motion model AUGMENTED-WITH generic temporal constraint\", \"robustness INCREASED-AGAINST competing interpretations\", \"meaningful content summarization RESULT-OF robustness increase\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  18%|█▊        | 91/500 [08:59<1:35:25, 14.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"projective unifocal tensor SPECIALIZATION-OF affine case\", \"bifocal tensor SPECIALIZATION-OF affine case\", \"trifocal tensor SPECIALIZATION-OF affine case\", \"tensors obtained RELATE-TO registered tensors\", \"known projective relations CONNECT points and lines across views\", \"neccessary constraints ON components of trifocal tensor\", \"sufficient constraints ON components of trifocal tensor\", \"geometric interpretation OF trifocal tensor components\", \"estimation of tensors ACHIEVED-THROUGH factorization\", \"estimation of tensors from line correspondences DISCUSSED\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  18%|█▊        | 92/500 [09:05<1:20:02, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach USED-FOR video compression\", \"approach USED-FOR motion analysis\", \"approach USED-FOR 3D scene analysis\", \"images PART-OF input images\", \"layers PART-OF images\", \"homographies FEATURE-OF planar patches\", \"planar patches HYPONYM-OF valid regions\", \"layers MAPPED-IN subspace\", \"layers FORM-CLUSTERS subspace\", \"mean-shift clustering algorithm FEATURE-OF identifying layers\", \"optimality ACHIEVED global\", \"noise REDUCED enforcing subspace constraint\", \"layer descriptions EVALUATE-FOR experimental results\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  19%|█▊        | 93/500 [09:12<1:09:11, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"local non-negative matrix factorization USED-FOR learning spatially localized, parts-based subspace representation\", \"LNMF COMPARE NMF and PCA methods for face representation and recognition\", \"algorithm PART-OF learning of basis components\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  19%|█▉        | 94/500 [09:15<55:23,  8.19s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ROD-TV USED-FOR reconstruction\", \"tensor voting USED-FOR local reconstruction algorithm\", \"per-vertex normals FEATURE-OF interpolative shading\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  19%|█▉        | 95/500 [09:18<45:08,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Markov random field models FEATURE-OF image textures\", \"ACGMRF model USED-FOR modelling rotated image textures\", \"ALSE method USED-FOR estimating parameters of ACGMRF model\", \"rotation-invariant features EVALUATE-FOR classifying SAR sea ice and Brodatz imagery\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  19%|█▉        | 96/500 [09:23<40:02,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method learn intrinsic object structure\", \"parameterized object state lies on low dimensional manifold\", \"dimensionality reduction algorithm FEATURE-OF unsupervised learning\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  19%|█▉        | 97/500 [09:26<35:16,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"projective reconstruction USED-FOR determination\", \"3D geometrical configuration PART-OF set of 3D points and cameras\", \"correspondences FEATURE-OF points in the images\", \"configuration critical EVALUATE-FOR unique determination\", \"number of cameras PART-OF critical configuration\", \"number of points PART-OF critical configuration\", \"straight line HYPONYM-OF rational quartic curve\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  20%|█▉        | 98/500 [09:32<35:19,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"representation PART-OF objects\", \"affine-invariant image patches FEATURE-OF representation\", \"spatial relationships FEATURE-OF affine-invariant image patches\", \"Multi-view constraints USED-FOR matching and reconstruction\", \"normalized representation FEATURE-OF appearance\", \"acquisition EVALUATE-FOR true three-dimensional affine and Euclidean models\", \"multiple images USED-FOR acquisition\", \"recognition EVALUATE-FOR true three-dimensional affine and Euclidean models\", \"photograph EVALUATE-FOR recognition\", \"proposed approach USED-FOR modeling and recognition\", \"separate segmentation stage COMPARE cluttered scenes\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  20%|█▉        | 99/500 [09:39<39:02,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Image composition USED-FOR video analysis\", \"global alignment PART-OF image composition\", \"super-resolution PART-OF image composition\", \"quality EVALUATE-FOR resulting mosaic\", \"blurring FEATURE-OF resulting mosaic\", \"graph-based technique USED-FOR global registration\", \"topological structure FEATURE-OF sequence induced by spatial overlap\", \"bundle adjustment USED-FOR global registration\", \"homographies FEATURE-OF bundle adjustment\", \"experimental comparison COMPARE effectiveness of approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  20%|██        | 100/500 [09:45<40:43,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"image segmentation USED-FOR segmentation of images\", \"method FEATURE-OF shape constrained image segmentation\", \"Bayesian statistics PART-OF the combined approach\", \"image data EVALUATE-FOR ambiguous segmentations\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  20%|██        | 101/500 [09:49<35:43,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"measurement information FEATURE-OF tracking performance\", \"user initialization REQUIRED-FOR tracking process\", \"boosted shape detection USED-FOR generic measurement process\", \"local detection uncertainties FEATURE-OF shape alignment\", \"predicted shape prior FEATURE-OF posterior shape model\", \"subspace constraints FEATURE-OF posterior shape model\", \"sources of information TREATED-IN unified way\", \"maximum likelihood DERIVED-FROM posterior shape model\", \"endocardium TRACKED-IN ultrasound sequences\", \"reliable detection ACHIEVED-WHEN compared to existing approaches and inter-expert variations\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  20%|██        | 102/500 [09:56<38:22,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Background modeling USED-FOR vision systems\", \"optical flow FEATURE-OF higher dimensional space\", \"density estimation PART-OF computation of features\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  21%|██        | 103/500 [09:59<32:09,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"human motion model FEATURE-OF probabilistic models\", \"human motion recognition USED-FOR human motion model\", \"positions, velocities and appearance FEATURE-OF human motion model\", \"global variables PART-OF model\", \"translation, scale or viewpoint FEATURE-OF global variables\", \"hybrid probabilistic model COMPARE previous approaches\", \"global variables COMPARE local variables\", \"learning phase EVALUATE-FOR convergence\", \"robustness EVALUATE-FOR occlusions\", \"recognition rate EVALUATE-FOR hybrid probabilistic model\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  21%|██        | 104/500 [10:05<35:42,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"system USED-FOR object tracking\", \"system COPES-WITH long-duration occlusion\", \"system COPES-WITH complete occlusion\", \"system DOES-NOT-REQUIRE prior knowledge\", \"system PRODUCES good segment results\", \"system PRODUCES good tracking results\", \"system HAS-FRAME-RATE 15-20 fps\", \"system HAS-IMAGE-SIZE 320x240\", \"experiments PERFORMED-ON video sequences\", \"experiments PERFORMED-UNDER different conditions\", \"experiments PERFORMED-INDOOR\", \"experiments PERFORMED-OUTDOOR\", \"occlusions ARE-LONG-DURATION\", \"occlusions ARE-COMPLETE\", \"background IS-CHANGING\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  21%|██        | 105/500 [10:14<41:34,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"embedding methods COMPARE subspace-segmentation methods\", \"homographies FEATURE-OF complex bilinear form or real quadratic form\", \"segmentation solution USED-FOR piece-wise planar scene\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  21%|██        | 106/500 [10:18<38:23,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"active shape models FEATURE-OF tool\", \"models of shape variation USED-FOR search algorithms\", \"non-linear extensions of active shape models COMPARE application specific solutions\", \"minimum description length principle FEATURE-OF algorithm\", \"data PART-OF sub-parts\", \"proposed method EVALUATE-FOR better model\", \"synthetic data MATERIAL synthetic data\", \"medical images MATERIAL medical images\", \"hand contours MATERIAL hand contours\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  21%|██▏       | 107/500 [10:25<40:03,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"object detection USED-FOR support vector machines\", \"training examples PART-OF object detection\", \"prior FEATURE-OF distribution of natural images\", \"support vector machines FEATURE-OF detectors\", \"training examples COMPARE structure of the class\", \"separating hyperplane FEATURE-OF positive half space\", \"positive half space EVALUATE-FOR natural images\", \"background HYPONYM-OF natural images\", \"experiments EVALUATE-FOR resulting detector\", \"training examples EVALUATE-FOR linear SVM\", \"training examples EVALUATE-FOR kernel SVM\", \"positive examples PART-OF training examples\", \"negative examples PART-OF training examples\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  22%|██▏       | 108/500 [10:32<41:42,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"recognition scheme scales efficiently USED-FOR large number of objects\", \"scheme builds upon popular techniques FEATURE-OF indexing descriptors\", \"local region descriptors hierarchically quantized PART-OF vocabulary tree\", \"vocabulary tree allows larger and more discriminatory vocabulary to be used efficiently USED-FOR dramatic improvement in retrieval quality\", \"quantization and indexing fully integrated PART-OF vocabulary tree approach\", \"recognition quality EVALUATE-FOR retrieval on database with ground truth\", \"vocabulary tree approach COMPARE high retrieval quality\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  22%|██▏       | 109/500 [10:39<41:25,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"image completion FEATURE-OF exemplar-based framework\", \"texture synthesis FEATURE-OF exemplar-based framework\", \"image inpainting FEATURE-OF exemplar-based framework\", \"Priority-BP METHOD-OF solving optimization problem\", \"Priority-BP FEATURE-OF optimization scheme\", \"message scheduling FEATURE-OF Priority-BP\", \"label pruning FEATURE-OF Priority-BP\", \"BP COMPARE Priority-BP\", \"MRF energy function PART-OF Priority-BP\", \"method EFFECTIVE-FOR image completion examples\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  22%|██▏       | 110/500 [10:44<40:00,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 110: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID adc0f92a9c481b32a8294e1624ec4de2 in your message.)\n",
      "Query: Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\n",
      "    ###\n",
      "    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\n",
      "    ###\n",
      "    Here are some examples of each type of entity that may be detected:\n",
      "    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\n",
      "    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\n",
      "    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\n",
      "    time complexity.\n",
      "    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\n",
      "    Panntreebank, WordNet, Wikipedia.\n",
      "    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\n",
      "    discourse structure, tree, node, tree kernel, features, noise, criteria.\n",
      "    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\n",
      "    ###\n",
      "    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [triple1, triple2, triple3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    The introduction of prior knowledge has greatly enhanced numerous purely low-level driven image processing algorithms. In this work, we focus on the problem of non-rigid image registration. A number of powerful registration criteria have been developed in the last decade, most prominently the criterion of maximum mutual information. Although this criterion provides for good registration results in many applications, it remains a purely low-level criterion. As a consequence, registration results will deteriorate once this low-level information is corrupted, due to noise, partial occlusions or missing image structure. In this paper , we will develop a Bayesian framework that allows to impose statistically learned prior knowledge about the joint intensity distribution into image registration methods. The prior is given by a kernel density estimate on the space of joint intensity distributions computed from a representative set of pre-registered image pairs. This nonparametric prior accurately models previously learned intensity relations between various image modalities and slice locations. Experimental results demonstrate that the resulting registration process is more robust to missing low-level information as it favors intensity correspondences statistically consistent with the learned intensity distributions.\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"prior knowledge FEATURE-OF image registration methods\", \"maximum mutual information USED-FOR good registration results\", \"Bayesian framework USED-FOR image registration methods\", \"kernel density estimate FEATURE-OF nonparametric prior\", \"pre-registered image pairs PART-OF representative set\", \"intensity correspondences EVALUATE-FOR learned intensity distributions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  22%|██▏       | 111/500 [11:25<1:46:39, 16.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"traditional linear Fukunaga-Koontz Transform USED-FOR discriminative subspaces building approach\", \"previous work extended FKT to deal with small-sample-size\", \"traditional linear FKT extended to work in multi-class problem and higher dimensional subspaces FEATURE-OF enhanced discrimination ability\", \"proposed Kernel Fukunaga-Koontz Transform EVALUATE-FOR face recognition applications\", \"proposed non-linear generalization can be applied to any other domain specific problems\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  22%|██▏       | 112/500 [11:31<1:26:36, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Lagrangian Particle Dynamics USED-FOR segmentation\", \"high density crowd flows PART-OF flow field\", \"numerical integration scheme FEATURE-OF advected particles\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  23%|██▎       | 113/500 [11:35<1:08:31, 10.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"human action recognition system USED-FOR embedded computer vision applications\", \"system BASED-ON linear Support Vector Machine classifier\", \"classification progress IMPLEMENTED-IN embedded hardware\", \"motion features OBTAINED-FROM videos\", \"Motion History Image LIMITATIONS-ADDRESSED\", \"Hierarchical Motion History Histogram FEATURE-OF motion information\", \"MHI and HMHH COMBINED-TOGETHER\", \"low dimension feature vector EXTRACTED-FROM MHI and HMHH\", \"system ACHIEVES-IMPROVEMENT recognition performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  23%|██▎       | 114/500 [11:42<1:00:33,  9.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"images partitioned into regions USED-FOR classification of outdoor scenes\", \"one-class classifiers model regions FEATURE-OF relatively uniform color and texture properties\", \"clustering of patches PART-OF partitioning algorithm\", \"regions clustered to obtain codebook USED-FOR scene representation\", \"bag of individual regions REPRESENTATION-OF scene representation\", \"bag of region pairs REPRESENTATION-OF scene representation\", \"Bayesian classifiers EVALUATE-FOR scene classification\", \"region selection algorithm USED-FOR identifying region types\", \"region types OCCUR-TOGETHER frequently in particular class of scenes\", \"proposed models OUT-PERFORM baseline approach COMPARE\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  23%|██▎       | 115/500 [11:49<57:00,  8.88s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"structured-light methods USED-FOR 3D reconstruction\", \"Photogeometric Structured Light FEATURE-OF standard structured light method\", \"photometric processing USED-FOR increasing recovered surface detail\", \"photometric processing USED-FOR enabling structured-light setup to be robustly self-calibrated\", \"framework PART-OF photogeometric optimization\", \"photogeometric optimization USED-FOR multi-view 3D model\", \"photogeometric optimization EVALUATE-FOR compliance with photometric and geometric data\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  23%|██▎       | 116/500 [11:55<50:49,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"partially-blurred-image classification USED-FOR detecting images containing blurred regions\", \"blur features FEATURE-OF image color, gradient, and spectrum information\", \"blur detection PART-OF image patches\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  23%|██▎       | 117/500 [12:00<44:00,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"object model USED-FOR visual object tracking\", \"local optimization USED-FOR track local mode of similarity measure\", \"object detection USED-FOR global optimization problem\", \"Adaptive Simulated Annealing USED-FOR solve global optimization problem\", \"ASA stochastically samples parameter space\", \"cluster analysis USED-FOR redetect object\", \"local tracker PART-OF hybrid local and global mode-seeking tracker\", \"state-of-the-art trackers COMPARE approach\", \"VIVID benchmark datasets EVALUATE-FOR approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  24%|██▎       | 118/500 [12:06<43:40,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Bayesian Networks USED-FOR computer vision problems\", \"learning BN model parameters USED-FOR reliable and representative training data\", \"qualitative prior knowledge FEATURE-OF model\", \"domain experts PROVIDE qualitative prior knowledge\", \"physical or geometric constraints PROVIDE qualitative prior knowledge\", \"quantitative prior COMPARE qualitative prior\", \"closed-form solution USED-FOR combining limited training data with qualitative knowledge\", \"Maximum Likelihood estimation method COMPARE closed-form solution\", \"Expectation Maximization algorithm COMPARE closed-form solution\", \"BN model PART-OF facial Action Unit recognition system\", \"real image data USED-FOR facial Action Unit recognition\", \"method EVALUATE-FOR robust and accurate estimation of BN model parameters\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  24%|██▍       | 119/500 [12:15<46:29,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"unsupervised object discovery EVALUATE-FOR current work\", \"spectral clustering USED-FOR unsupervised object discovery\", \"image matting USED-FOR unsupervised object discovery\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  24%|██▍       | 120/500 [12:19<39:44,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"geometric framework DEVELOP discriminant subspace learning\", \"class structures CONCEPTUALIZED semi-Riemannian manifold\", \"class structures CHARACTERIZED local metrics semi-Riemannian space\", \"semi-Riemannian metrics DETERMINED smoothing discrete functions\", \"optimizing class structures EQUIVALENT maximizing quadratic quantities metric tensors semi-Riemannian space\", \"supervised discriminant subspace learning REDUCES unsupervised semi-Riemannian manifold learning\", \"algorithm PRESENTED Semi-Riemannian Discriminant Analysis (SRDA)\", \"performance SRDA TESTED face recognition handwritten capital letter classification\", \"semi-Riemannian geometry PROMISING tool pattern recognition machine learning\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  24%|██▍       | 121/500 [12:27<43:25,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"probabilistic framework USED-FOR learning visual models\", \"3D object categories PART-OF objects\", \"ensemble of parts PART-OF objects\", \"salient image features FEATURE-OF parts\", \"generative framework USED-FOR learning model\", \"relative position FEATURE-OF parts\", \"discretized viewpoints FEATURE-OF model\", \"explicit correspondences FEATURE-OF model\", \"detection and classification EVALUATE-FOR position and viewpoint\", \"recognition scores FEATURE-OF candidate objects\", \"generative probabilistic framework USED-FOR 3D object categorization\", \"detection task EVALUATE-FOR car category\", \"viewpoint classification task EVALUATE-FOR car category\", \"Savarese et al. 2007 dataset PART-OF detection and viewpoint classification tasks\", \"PASCAL VOC 2006 dataset PART-OF detection and viewpoint classification tasks\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  24%|██▍       | 122/500 [12:36<47:35,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"automated surveillance systems USED-FOR PTZ cameras\", \"algorithms REQUIRE prior knowledge intrinsic parameters PTZ camera\", \"mapping algorithm DERIVES relative positioning orientation two PTZ cameras\", \"unified polynomial model FEATURE-OF mapping algorithm\", \"experimental results DEMONSTRATE reduced computational complexity\", \"experimental results DEMONSTRATE improved flexibility\", \"pixel accuracy DECREASED slightly COMPARED-WITH work of Chen and Wang\", \"consistent labeling approaches EVALUATE-FOR compensation of decreased pixel accuracy\", \"automated surveillance systems EVALUATE-FOR changing configurations\", \"automated surveillance systems EVALUATE-FOR larger number of PTZ cameras\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  25%|██▍       | 123/500 [12:44<48:56,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method detecting interest points FEATURE-OF detectors\", \"interest point detectors USED-FOR matching textured scenes\", \"proposed detectors exhibit invariance to rotation, illumination variation, and blur\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  25%|██▍       | 124/500 [12:47<39:39,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"computer vision applications MULTI-LABEL-CLASSIFICATION-PROBLEMS\", \"instance ASSIGNED-TO category\", \"hypergraph REGULARIZATION ADDRESSED correlations\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  25%|██▌       | 125/500 [12:51<34:31,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach USED-FOR building classifier\", \"classifier FEATURE-OF two class problem\", \"objects PART-OF image\", \"orientation HYPONYM-OF specific orientation\", \"methodology USED-FOR reducing time complexity\", \"algorithm EVALUATE-FOR classification results\", \"classifier USED-FOR both stages\", \"Random Ferns FEATURE-OF classifier\", \"local histograms FEATURE-OF Random Ferns\", \"HOGs FEATURE-OF local histograms\", \"supervised learning FEATURE-OF approach\", \"gradient space FEATURE-OF approach\", \"approach EVALUATE-FOR robustness and efficiency\", \"databases EVALUATE-FOR testing\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  25%|██▌       | 126/500 [12:57<36:22,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"dimensionality reduction USED-FOR classification\", \"supervised dimensionality reduction FEATURE-OF existing methods\", \"data densely sampled HYPONYM-OF neighborhood graph structure\", \"S-KDR METHOD-OF sequence kernel dimension reduction approach\", \"input data HYPONYM-OF distribution\", \"spatial information FEATURE-OF S-KDR\", \"temporal information FEATURE-OF S-KDR\", \"periodic information FEATURE-OF S-KDR\", \"optimal manifold PART-OF S-KDR\", \"human gesture discrimination EVALUATE-FOR S-KDR approach\", \"motion categories discrimination EVALUATE-FOR S-KDR approach\", \"dynamic textures discrimination EVALUATE-FOR S-KDR approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  25%|██▌       | 127/500 [13:05<40:02,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"graph-cuts optimization USED-FOR vision and graphics problems\", \"BK algorithm COMPARE adaptive bottom-up approach\", \"adaptive bottom-up approach USED-FOR parallelize BK algorithm\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  26%|██▌       | 128/500 [13:08<33:09,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Conditional Random Field models USED-FOR low-level computer vision problems\", \"Inference in Conditional Random Field models involves solving a combinatorial optimization problem\", \"graph cuts and belief propagation are methods used for inference in Conditional Random Field models\", \"Learning Conditional Random Field model parameters involves computing the partition function, which is intractable\", \"state-of-the-art structured learning methods frame the problem of learning Conditional Random Field model parameters as one of large margin estimation\", \"Iterative solutions have been proposed to solve the resulting convex optimization problem\", \"each iteration of structured learning methods involves solving an inference problem over all the labels\", \"large margin piece-wise learning method is a method for learning Conditional Random Field models\", \"the optimization problem in large margin piece-wise learning method can be reduced to an equivalent convex problem with a small number of constraints\", \"large margin piece-wise learning method is both memory and computationally efficient\", \"results are shown on publicly available standard datasets\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  26%|██▌       | 129/500 [13:17<40:10,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method accelerate evaluation object detection cascades\", \"divide-and-conquer procedure space candidate regions USED-FOR accelerate evaluation object detection cascades\", \"proposed method USED-FOR faster procedure cascade evaluation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  26%|██▌       | 130/500 [13:21<35:25,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"automated technique USED-FOR detecting reflections\", \"motion trajectories FEATURE-OF detection technique\", \"reflection HYPONYM-OF regions containing two different layers\", \"weak detectors PART-OF strong detector\", \"novel priors FEATURE-OF detection\", \"detection maps FEATURE-OF detection\", \"detection rate EVALUATE-FOR high detection rate\", \"pathological motion COMPARE occlusion\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  26%|██▌       | 131/500 [13:26<34:14,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach USED-FOR associate objects\", \"objects PART-OF PTZ cameras\", \"camera handoff EVALUATE-FOR wide-area surveillance scenarios\", \"approaches COMPARE limitations\", \"approaches COMPARE correlation-based information\", \"approaches COMPARE appearance-based information\", \"approaches COMPARE geometric-based information\", \"approach USED-FOR circumventing problems\", \"model transfer EVALUATE-FOR approach\", \"Multiple Instance Learning FEATURE-OF formulation\", \"logistic softmax function FEATURE-OF covariance-based region features\", \"MAP estimation framework FEATURE-OF formulation\", \"sequences PART-OF PTZ camera\", \"outdoor surveillance settings EVALUATE-FOR approach comparison\", \"state-of-the-art approaches COMPARE approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  26%|██▋       | 132/500 [13:35<39:09,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method estimating relative pose USED-FOR non-overlapping surveillance cameras\", \"moving object FEATURE-OF surveillance scenarios\", \"Quadratic Eigenvalue Problem PART-OF problem\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  27%|██▋       | 133/500 [13:38<33:43,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"video PROVIDES rich visual cues\", \"interactions AMONG objects\", \"spatio-temporal video segmentation algorithm USED-FOR video segmentation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  27%|██▋       | 134/500 [13:41<28:49,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"color discriminative FOR object recognition tasks\", \"traditional methods IMPROVE surface reflectance estimates\", \"output DEPENDS-ON background scene\", \"multi-view constraints IMPROVE estimates of scene illuminants and object color\", \"method EXPLOITS image correspondences\", \"correspondences OBTAINED-BY alignment techniques\", \"joint estimation OF surface properties and illuminants\", \"multi-view color constancy problem INTRODUCED\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  27%|██▋       | 135/500 [13:46<29:38,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm USED-FOR camera relative pose estimation\", \"lines FEATURE-OF camera relative pose estimation\", \"three lines PART-OF camera relative pose estimation\", \"relative rotation COMPUTED-FROM two images\", \"relative translation COMPUTED-FROM two intersection points\", \"lines DETECTED-BY framework\", \"performance EVALUATE-FOR algorithm\", \"synthetic data EVALUATE-FOR algorithm\", \"real data EVALUATE-FOR algorithm\", \"approach SUITABLE-FOR urban environments\", \"approach SUITABLE-FOR indoor environments\", \"lines PARALLEL-TO each other\", \"lines ORTHOGONAL-TO each other\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  27%|██▋       | 136/500 [13:53<33:18,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"co-occurrence pattern FEATURE-OF object recognition\", \"co-occurrence pattern FEATURE-OF scene recognition\", \"co-occurrence pattern FEATURE-OF action recognition\", \"AND pattern USED-FOR boosting\", \"OR pattern USED-FOR boosting\", \"mining procedure PART-OF boosting\", \"empirical error EVALUATE-FOR optimal co-occurrence pattern\", \"training dataset FEATURE-OF mining procedure\", \"boosting IMPROVES generalization ability\", \"discovered co-occurrence patterns EVALUATE-FOR object categorization\", \"discovered co-occurrence patterns EVALUATE-FOR scene categorization\", \"discovered co-occurrence patterns EVALUATE-FOR action categorization\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  27%|██▋       | 137/500 [14:02<38:23,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"facial expression recognition USED-FOR dynamic recognition and intensity estimation of facial expressions\", \"multidimensional continuous facial affect data FEATURE-OF ordinal manifold\", \"H-CORF framework PART-OF dynamic ordinal regression\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  28%|██▊       | 138/500 [14:05<33:42,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"motion estimation FEATURE-OF variational formulation\", \"segmentation FEATURE-OF variational formulation\", \"multi-label representation USED-FOR flow field\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  28%|██▊       | 139/500 [14:12<36:09,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"bispectral photo-metric stereo USED-FOR shape reconstruction\", \"fluorescence FEATURE-OF objects\", \"photometric stereo USED-FOR shape estimation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  28%|██▊       | 140/500 [14:15<30:37,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm USED-FOR estimating 3D geometric structure\", \"spatio-temporal video segmentation PART-OF dynamic scene\", \"region-classifiers FEATURE-OF predictions\", \"predictions HYPONYM-OF geometric classes\", \"predictions EVALUATE-FOR accuracy\", \"dataset MATERIAL geometric context of video\", \"dataset EVALUATE-FOR method\", \"semi-supervised learning framework USED-FOR expanding pool of labeled data\", \"system EVALUATE-FOR accuracy\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  28%|██▊       | 141/500 [14:21<31:40,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"image set classification algorithm USED-FOR unsupervised clustering\", \"labeled training data PART-OF image set classification algorithm\", \"unlabeled test data PART-OF image set classification algorithm\", \"probability distribution FEATURE-OF class\", \"similarity measure EVALUATE-FOR image set classification\", \"sparse spectral clustering algorithm METHOD image set classification\", \"proximity matrix PART-OF sparse spectral clustering algorithm\", \"local subspace structure FEATURE-OF proximity matrix\", \"Grass-mannian manifolds PART-OF image set representation\", \"Euclidean space PART-OF image set representation\", \"eigenvector solver METHOD spectral clustering\", \"computational cost FEATURE-OF eigenvector solver\", \"clustering quality FEATURE-OF eigenvector solver\", \"classification results EVALUATE-FOR image set classification\", \"standard datasets PART-OF experiments\", \"existing techniques COMPARE our algorithm\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  28%|██▊       | 142/500 [14:32<42:07,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"point cloud matching USED-FOR shape matching problem\", \"point clouds PART-OF point set matching\", \"Schrödinger distance transform representation FEATURE-OF point clouds\", \"Fisher-Rao metric FEATURE-OF space of densities\", \"geodesic distance EVALUATE-FOR performance of algorithm\", \"SDTM COMPARE state-of-the-art point set registration algorithms\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  29%|██▊       | 143/500 [14:37<38:18,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"object-category detection datasets POPULATED-WITH per-object 3D reconstructions\", \"algorithm ESTIMATES camera viewpoint\", \"object shapes RECONSTRUCTED by optimizing over visual hull proposals\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  29%|██▉       | 144/500 [14:41<33:44,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method captures high-quality scans\", \"template fitting techniques FEATURE-OF incomplete scan\", \"generic human template HYPONYM-OF human template\", \"scans PART-OF pose\", \"parametric model EVALUATE-FOR anim-itable avatar\", \"parametric model EVALUATE-FOR synthesizing dynamic 3D models\", \"experimental results EVALUATE-FOR effectiveness of system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  29%|██▉       | 145/500 [14:51<40:32,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"problem estimating location information IMAGE\", \"hierarchical sparse coding approach LEARNS-FEATURES useful discriminating images\", \"geometric prior CORRESPONDS-TO transformations between image appearance space and location grouping space\", \"approach accounts for availability of heterogeneous data modalities such as geo-tags and videos\", \"under-addressed problem transferring knowledge available from certain locations to infer grouping of data from novel locations\", \"evaluate approach on several standard datasets such as im2gps, San Francisco and MediaEval2010\", \"obtain state-of-the-art results EVALUATE-FOR standard datasets\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  29%|██▉       | 146/500 [14:57<39:24,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"action proposal generation FORMULATED-AS maximum set coverage problem\", \"appearance and motion cues UTILIZED-TO measure actionness of video tubes\", \"action proposals do not rely on video segmentation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  29%|██▉       | 147/500 [15:03<38:03,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method learning joint embeddings images text\", \"neural network two-branch\", \"large-margin objective combines cross-view ranking constraints within-view neighborhood structure preservation constraints\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  30%|██▉       | 148/500 [15:06<31:59,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"animated GIFs USED-FOR social media\", \"TGIF dataset PART-OF testbed for image sequence description systems\", \"natural language descriptions FEATURE-OF animated GIFs\", \"quality controls FEATURE-OF dataset validation\", \"visual content EVALUATE-FOR natural language descriptions\", \"dataset COMPARE image and video description datasets\", \"nearest neighbor USED-FOR animated GIF description task\", \"statistical machine translation USED-FOR animated GIF description task\", \"recurrent neural networks USED-FOR animated GIF description task\", \"models fine-tuned from dataset USED-FOR automatic movie description\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  30%|██▉       | 149/500 [15:13<33:51,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Image matching USED-FOR Computer Vision\", \"SIFT EXCELS IN feature-based matching\", \"variants OF SIFT EXCELS IN feature-based matching\", \"ultra-wide baselines COMPARE appearance variation\", \"SIFT and RANSAC HYPONYM-OF local correspondence\", \"deep learning-based approach USED-FOR classification task\", \"local correspondences FEATURE-OF probable matches\", \"models TRAINED-ON dataset of urban aerial imagery\", \"dataset CONSISTS-OF 'same' and 'different' pairs\", \"human study EVALUATE-FOR characterization of the problem\", \"models OUTPERFORM state-of-the-art on ultra-wide baseline matching\", \"models APPROACH human accuracy\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  30%|███       | 150/500 [15:24<44:21,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"confidence measures EVALUATE-FOR outlier removal\", \"confidence measures EVALUATE-FOR quality improvement\", \"training data USED-FOR outlier removal\", \"training data USED-FOR quality improvement\", \"training data PART-OF generating training data\", \"stereo images PART-OF generating training data\", \"view points FEATURE-OF reasoning\", \"depth maps FEATURE-OF generated\", \"stereo algorithm HYPONYM-OF depth maps\", \"approach USED-FOR generating training data\", \"approach COMPARE laser ground truth data\", \"approach COMPARE limited amount of laser ground truth data\", \"approach COMPARE vast amount of automatically generated training data\", \"KITTI2012 dataset EVALUATE-FOR performance boosting\", \"confidence measures FEATURE-OF performance boosting\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  30%|███       | 151/500 [15:33<46:03,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"fine-grained sketch-based image retrieval USED-FOR instance-level retrieval of images\", \"finger sketches FEATURE-OF fine-grained matching\", \"annotated cross-domain sketch-photo datasets MATERIAL for training\", \"database PART-OF sketch-photo pairs\", \"triplet-ranking model USED-FOR instance-level SBIR\", \"data augmentation FEATURE-OF deep triplet-ranking model\", \"pre-training strategy FEATURE-OF deep triplet-ranking model\", \"insufficient fine-grained training data EVALUATE-FOR data sufficiency\", \"over-fitting avoidance EVALUATE-FOR training deep networks\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  30%|███       | 152/500 [15:43<48:41,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Statistical Machine Translation HYPONYM-OF SMT\", \"SMT algorithms USED-FOR empirical testing\", \"computational complexity EVALUATE-FOR IBM Models 1-2\", \"hard problems EVALUATE-FOR polynomial time solution\", \"polynomial time approximations USED-FOR hard problems computations\", \"complexity FEATURE-OF hard problems\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  31%|███       | 153/500 [15:48<43:02,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"automatic parameter optimization EVALUATE-FOR WSI algorithm\", \"one sense per collocation observation FEATURE-OF clustering of word co-occurrences\", \"triplets of words USED-FOR one sense per collocation observation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  31%|███       | 154/500 [15:55<43:09,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"addressee identification FEATURE-OF Bayesian Network\", \"addressee identification FEATURE-OF Naive Bayes classifiers\", \"addressee HYPONYM-OF dialogue act\", \"gaze FEATURE-OF addressee identification\", \"utterance FEATURE-OF addressee identification\", \"conversational context FEATURE-OF addressee identification\", \"conversational context FEATURE-OF classifiers\", \"utterance features FEATURE-OF classifiers\", \"speaker's gaze information FEATURE-OF classifiers\", \"classifiers COMPARE gain from information about meeting context\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  31%|███       | 155/500 [16:02<41:12,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"evaluation measures IMPROVED-BY introduction of word-dependent substitution costs\", \"evaluation measure CORRELATES-WITH human judgment\", \"block reordering MODELED-AS edit operation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  31%|███       | 156/500 [16:05<34:13,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ASR output USED-FOR predicting segment boundaries\", \"human transcription USED-FOR predicting segment boundaries\", \"lexical cohesion-based approach FEATURE-OF predicting subtopic boundaries\", \"machine learning approach FEATURE-OF predicting top-level boundaries\", \"lexical-cohesion FEATURE-OF predicting top-level boundaries\", \"conversational features FEATURE-OF predicting top-level boundaries\", \"conversational cues FEATURE-OF top-level prediction task\", \"cue phrases FEATURE-OF top-level prediction task\", \"overlapping speech FEATURE-OF top-level prediction task\", \"transcription errors EVALUATE-FOR models that combine lexical-cohesion and conversational features\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  31%|███▏      | 157/500 [16:13<37:06,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"data-driven selection USED-FOR emphatic facial displays\", \"embodied conversational agent PART-OF dialogue system\", \"corpus PART-OF target dialogue system\", \"facial displays FEATURE-OF speaker\", \"models EVALUATE-FOR facial displays\", \"context FEATURE-OF models\", \"cross-validation EVALUATE-FOR models\", \"corpus EVALUATE-FOR models\", \"users EVALUATE-FOR output\", \"cross-validation COMPARE user study\", \"majority choice HYPONYM-OF models\", \"variation HYPONYM-OF models\", \"female subjects FEATURE-OF preference\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  32%|███▏      | 158/500 [16:20<38:39,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 158: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 269447ba28f41438efe91e940a95c3d1 in your message.)\n",
      "Query: Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\n",
      "    ###\n",
      "    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\n",
      "    ###\n",
      "    Here are some examples of each type of entity that may be detected:\n",
      "    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\n",
      "    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\n",
      "    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\n",
      "    time complexity.\n",
      "    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\n",
      "    Panntreebank, WordNet, Wikipedia.\n",
      "    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\n",
      "    discourse structure, tree, node, tree kernel, features, noise, criteria.\n",
      "    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\n",
      "    ###\n",
      "    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [triple1, triple2, triple3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    \n",
      "This article deals with the  interpretation  of  conceptual operations  underlying the communicative use of  natural language (NL)  within the  Structured Inheritance Network (SI-Nets) paradigm . The operations are reduced to  functions  of a  formal language , thus changing the level of abstraction of the operations to be performed on  SI-Nets . In this sense, operations on  SI-Nets  are not merely isomorphic to single epistemological objects, but can be viewed as a simulation of processes on a different level, that pertaining to the  conceptual system  of  NL . For this purpose, we have designed a version of  KL-ONE  which represents the  epistemological level , while the new experimental language,  KL-Conc , represents the  conceptual level . KL-Conc would seem to be a more natural and intuitive way of interacting with  SI-Nets . \n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "Error generating response for prompt at index 158: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 790e1da93a8bf41fdcabc862da47661c in your message.)\n",
      "Query: Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\n",
      "    ###\n",
      "    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\n",
      "    ###\n",
      "    Here are some examples of each type of entity that may be detected:\n",
      "    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\n",
      "    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\n",
      "    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\n",
      "    time complexity.\n",
      "    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\n",
      "    Panntreebank, WordNet, Wikipedia.\n",
      "    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\n",
      "    discourse structure, tree, node, tree kernel, features, noise, criteria.\n",
      "    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\n",
      "    ###\n",
      "    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [triple1, triple2, triple3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    \n",
      "This article deals with the  interpretation  of  conceptual operations  underlying the communicative use of  natural language (NL)  within the  Structured Inheritance Network (SI-Nets) paradigm . The operations are reduced to  functions  of a  formal language , thus changing the level of abstraction of the operations to be performed on  SI-Nets . In this sense, operations on  SI-Nets  are not merely isomorphic to single epistemological objects, but can be viewed as a simulation of processes on a different level, that pertaining to the  conceptual system  of  NL . For this purpose, we have designed a version of  KL-ONE  which represents the  epistemological level , while the new experimental language,  KL-Conc , represents the  conceptual level . KL-Conc would seem to be a more natural and intuitive way of interacting with  SI-Nets . \n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SI-Nets PART-OF operations\", \"formal language FEATURE-OF operations\", \"KL-Conc EVALUATE-FOR SI-Nets\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  32%|███▏      | 159/500 [17:39<2:40:51, 28.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"syntactic analyzer PART-OF system\", \"semantic analyzer PART-OF system\", \"dictionary PART-OF system\", \"Procedural Systemic Grammar FEATURE-OF syntactic analyzer\", \"Conceptual Dependency Theory FEATURE-OF semantic analyzer\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  32%|███▏      | 160/500 [17:43<1:59:47, 21.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"analytical inverses USED-FOR compositional syntax rules\", \"Definite Clause Grammar techniques USED-FOR parser construction\", \"parser MDCC FEATURE-OF augmented Friedman-Warren algorithm\", \"parser MDCC PART-OF post referencing\", \"parser MDCC PART-OF interfaces with language of intensional logic translator LILT\", \"reduced IL formulae EVALUATE-FOR derivational history\", \"Montague's PTQ USED-FOR familiarity\", \"basic DCG mechanism USED-FOR assumed knowledge\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  32%|███▏      | 161/500 [17:49<1:33:43, 16.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Systemic grammar USED-FOR AI text generation\", \"approach FEATURE-OF text generation\", \"systemic grammar HYPONYM-OF linguistic theory\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  32%|███▏      | 162/500 [17:52<1:10:14, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"model FEATURE-OF scheme\", \"communicative context PART-OF structure\", \"dialogue PART-OF system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  33%|███▎      | 163/500 [17:54<52:41,  9.38s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"formalisms utilize phrase-structure grammar as backbone\", \"processing of formalisms organized within chart-parsing framework\", \"declarative character of formalisms important for deciding optimal control strategy\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  33%|███▎      | 164/500 [17:57<41:19,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"event described PRESENT deictic information\", \"event described aspectual information\", \"verb form meanings express habituality\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  33%|███▎      | 165/500 [18:00<33:36,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"French tenses FEATURE-OF Discourse Representation Theory\", \"theory of tenses FEATURE-OF Reichenbachian point of view\", \"operators NOT-USED-FOR expressing tenses\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  33%|███▎      | 166/500 [18:03<28:36,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"evaluation of Natural Language systems EVALUATE-FOR task requiring data retrieval\", \"approaches neglected to evaluate systems in context of use EVALUATE-FOR task requiring data retrieval\", \"laboratory study USED-FOR identify NL requirements\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  33%|███▎      | 167/500 [18:06<25:45,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"anaphoric component PART-OF Mimo formalism\", \"anaphoric relations FEATURE-OF Mimo\", \"anaphoric relations EVALUATE-FOR strict compositionality\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  34%|███▎      | 168/500 [18:10<23:20,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"LR-parsers IMPLEMENTATION-FOR functional implementation\", \"correctness proof FEATURE-OF LR-parsers\", \"recursive descent parser GENERALIZATION-OF LR-parsers\", \"time-complexity OF parser CUBIC non-LR grammars\", \"memo-functions IMPLEMENTATION-OF functions\", \"compact representation CONSTRUCTION-OF parse forest\", \"LR(0) grammars RELATED-TO recursive ascent parsers\", \"Extended CF grammars PARSED-WITH modification OF LR-parser\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  34%|███▍      | 169/500 [18:16<26:18,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"model FEATURE-OF grammatical processing\", \"parsing USED-FOR natural language processing\", \"generation USED-FOR natural language processing\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  34%|███▍      | 170/500 [18:19<23:23,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Unification USED-FOR expressing relations between representations\", \"declarative formalism FEATURE-OF direct mappings\", \"feature structure PART-OF declarative formalism\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  34%|███▍      | 171/500 [18:22<22:24,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"modal language LT impose constraints trees\", \"extension LT (LF) impose constraints trees decorated feature structures\", \"constraint formalisms linguistic theorising discussed in detail\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  34%|███▍      | 172/500 [18:25<20:48,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"MORPA parser DEVELOPED-FOR text-to-speech conversion system\", \"PCFG COMBINES conventional context-free morphological grammar FILTER-OUT ungrammatical segmentations\", \"PCFG yields good results in morphological parsing\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  35%|███▍      | 173/500 [18:30<21:46,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ellipsis resolution FEATURE-OF discourse copying algorithm\", \"identity-of-relations analyses COMPARE discourse copying algorithm\", \"full NPs HYPONYM-OF referential elements\", \"referential elements COREF full NPs\", \"predictions EVALUATE-FOR problematic examples of ellipsis\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  35%|███▍      | 174/500 [18:34<21:30,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"morphological component PART-OF system\", \"two-level morphology FEATURE-OF system\", \"word grammar FEATURE-OF system\", \"lexicon PART-OF system\", \"compositional interpretation FEATURE-OF polymorphemic stems\", \"redundancy MINIMIZED-IN lexicon\", \"derived words NOT-STORED-EXPLICITLY-IN lexicon\", \"words formed ad-hoc RECOGNIZED-CORRECTLY-BY system\", \"system IMPLEMENTED-IN CommonLisp\", \"German derivation EVALUATE-FOR system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  35%|███▌      | 175/500 [18:40<25:03,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Turkish word structures PART-OF word structures\", \"PC-KIMMO environment USED-FOR implementing description\", \"root word lexicon FEATURE-OF description\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  35%|███▌      | 176/500 [18:44<23:18,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"part-of-speech tagging COMPARE statistical and constraint-based disambiguation\", \"French EVALUATE-FOR part-of-speech tagging\", \"constraint system PART-OF experiment\", \"statistical model USED-FOR part-of-speech tagging\", \"accuracy EVALUATE-FOR statistical method\", \"taggers COMPARE English\", \"constraint-based tagger COMPARE statistical method\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  35%|███▌      | 177/500 [18:49<25:24,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"anaphora resolution FEATURE-OF criteria\", \"anaphora resolution PART-OF sentence boundaries\", \"anaphora resolution PART-OF text-level anaphora\", \"dependency-based grammar model FEATURE-OF unified account\", \"GB's binding theory HYPONYM-OF major concepts\", \"Grosz-Sidner-style focus model FEATURE-OF text-level anaphora\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  36%|███▌      | 178/500 [18:55<26:34,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"quantification over events FEATURE-OF sentences\", \"temporal connective INTRODUCED-BY quantified sentences\", \"truth-conditions WRONG-GIVES temporal connective in subordinate clause\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  36%|███▌      | 179/500 [18:58<23:49,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach USED-FOR full parsing\", \"Information Extraction USED-FOR texts\", \"rules FEATURE-OF cascades\", \"text PART-OF unambiguous structures\", \"chunks PART-OF text\", \"argumental relations FEATURE-OF text\", \"modifier attachment FEATURE-OF text\", \"global parse tree PART-OF text\", \"approach EVALUATE-FOR three languages\", \"approach EVALUATE-FOR different domains\", \"IE module PART-OF FACILE project\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  36%|███▌      | 180/500 [19:04<25:38,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"automatic abstracting systems USED-FOR training resources\", \"annotation scheme PART-OF scientific articles\", \"scheme BASED-ON rhetorical moves\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  36%|███▌      | 181/500 [19:10<27:41,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"sentence chunks USED-FOR parsing\", \"sentence chunks USED-FOR information extraction\", \"sentence chunks USED-FOR information retrieval\", \"Ramshaw and Marcus INTRODUCED data representation\", \"data representation HYPONYM-OF tagging task\", \"seven data representations EXAMINED for recognizing noun phrase chunks\", \"data representation choice has INFLUENCE ON chunking performance\", \"memory-based learning chunker IMPROVED chunking results\", \"memory-based learning chunker EVALUATE-FOR standard data set\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  36%|███▋      | 182/500 [19:16<29:02,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Tree Adjoining Grammars HAVE extended domain of locality\", \"LEXSYS EDOL different from XTAG EDOL\", \"LEXSYS and XTAG are grammars of English\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  37%|███▋      | 183/500 [19:19<24:36,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"co-occurrence similarities FEATURE-OF query terms\", \"useful terms HYPONYM-OF query terms\", \"term similarities USED-FOR determining useful query terms\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  37%|███▋      | 184/500 [19:24<25:13,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"focus FEATURE-OF operable definition\", \"file card model PART-OF discourse model\", \"knowledge store PART-OF discourse model\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  37%|███▋      | 185/500 [19:27<22:39,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Image sequence processing techniques USED-FOR study exchange, growth, and transport processes\", \"low-level motion estimators FEATURE-OF performance and optimization\", \"tensor method yields reliable and dense displacement vector fields EVALUATE-FOR accuracy up to a few hundredth pixels/frame\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  37%|███▋      | 186/500 [19:31<21:26,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"photometric model USED-FOR image formation\", \"statistical model FEATURE-OF face appearance variation\", \"smoothness PART-OF geodesically local appearance manifold structure\", \"same-identity likelihood FEATURE-OF robustness to unseen head poses\", \"video sequence reillumination algorithm USED-FOR robustness to face motion patterns in video\", \"recognition system EVALUATE-FOR challenging data set\", \"system COMPARE state-of-the-art commercial software\", \"system COMPARE methods from the literature\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  37%|███▋      | 187/500 [19:36<23:30,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"non-rigid surfaces OPTIMIZATION-FOR non-sequential tracking\", \"non-sequential tracking APPROACHES-INTRODUCED reorder input data\", \"input sequences REPRESENTED-IN tree with reduced alignment path length\", \"reduced drift DEMONSTRATED by non-sequential tracking approaches\", \"increased robustness DEMONSTRATED by non-sequential tracking approaches\", \"jumps may occur in aligned mesh sequence where branches of tree meet\", \"optimization of tree MINIMIZES-ERRORS in temporal consistency\", \"novel cluster tree ENFORCES sequential tracking in local segments\", \"global non-sequential traversal ALLOWED-AMONG local segments\", \"tree structure REDUCES-NUMBER-AND-SIZE-OF jumps between branches\", \"comprehensive evaluation PERFORMED-ON variety of challenging non-rigid surfaces\", \"proposed cluster tree ACHIEVES better temporal consistency than previous approaches\", \"quantitative analysis SHOWS IMPROVEMENT by cluster tree\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  38%|███▊      | 188/500 [19:46<31:49,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"motion reconstruction USED-FOR 3D articulated tree\", \"motion reconstruction PART-OF trajectory basis\", \"trajectory basis FEATURE-OF smooth motion\", \"dynamic programming USED-FOR motion reconstruction\", \"compact high-pass filters FEATURE-OF general trajectories\", \"filter interactions PART-OF dynamic programming approach\", \"affine projection USED-FOR reconstruction without estimating cameras\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  38%|███▊      | 189/500 [19:50<29:19,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"paper goal discover set discriminative patches\", \"patches need satisfy two requirements: representative, occur frequently enough visual world\", \"patches need be discriminative, different enough from rest visual world\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  38%|███▊      | 190/500 [19:53<24:35,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"KAZE features FEATURE-OF multiscale 2D feature detection and description algorithm\", \"Gaussian blurring does not respect natural boundaries of objects\", \"nonlinear diffusion filtering USED-FOR 2D feature detection and description\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  38%|███▊      | 191/500 [19:57<22:29,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"predicting image or video interestingness FEATURE-OF low-level feature representations\", \"annotating interestingness value EVALUATE-FOR learning prediction model\", \"crowdsourcing tools USED-FOR pairwise comparisons\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  38%|███▊      | 192/500 [20:00<21:11,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach estimate intrinsic texture properties intrinsic textures\", \"method refine low-frequency shading estimate global lighting reconstruction\", \"method applied relighting free-viewpoint rendering\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  39%|███▊      | 193/500 [20:03<19:48,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach learning visual representation FEATURE-OF spatiotemporal signals\", \"representation learned without supervision\", \"method formulated as unsupervised sequential verification task\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  39%|███▉      | 194/500 [20:06<17:55,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"diagram interpretation study problem\", \"DPG representation model structure diagrams\", \"syntactic parsing learning infer DPGs\", \"semantic interpretation reasoning diagrams\", \"LSTM-based method syntactic parsing diagrams\", \"DPG-based attention model diagram question answering\", \"new dataset diagrams exhaustive annotations constituents relationships\", \"models syntactic parsing question answering diagrams using DPGs\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  39%|███▉      | 195/500 [20:11<19:38,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"computer vision USED-FOR high-capacity models\", \"large datasets USED-FOR pixel-level labels\", \"approach USED-FOR creating pixel-accurate semantic label maps\", \"images PART-OF semantic label maps\", \"modern computer games PART-OF images\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  39%|███▉      | 196/500 [20:15<19:59,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Mahalanobis distance USED-FOR person re-identification\", \"Weighted Approximate Rank Component Analysis (WARCA) FEATURE-OF metric learning formulation\", \"kernel trick USED-FOR non-linear extension of WARCA\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  39%|███▉      | 197/500 [20:19<20:26,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Template-based methods USED-FOR poorly-textured surfaces\", \"Non-rigid Structure from Motion techniques COMPARE Template-based methods\", \"points PART-OF video sequence\", \"template-free approach USED-FOR reconstructing poorly-textured, deformable surface\", \"surface isometry FEATURE-OF 3D reconstruction\", \"non-rigid image registration PART-OF 3D reconstruction\", \"depth estimation PART-OF 3D reconstruction\", \"approach EVALUATE-FOR accurate 3D reconstructions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  40%|███▉      | 198/500 [20:24<22:15,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"person re-identification CHALLENGE large variations\", \"pedestrian data DISTRIBUTED highly-curved manifolds feature space\", \"CNN CAPABILITY feature extraction\", \"geodesic distance COMPARE two samples\", \"deep embedding methods USE Euclidean distance\", \"manifold learning methods SUGGEST Euclidean distance local range\", \"positive training samples CRITICAL training CNN embedding\", \"moderate positive sample mining method PROPOSED train robust CNN person re-identification\", \"metric weight constraint IMPROVE learning\", \"deep model OUTPERFORM state-of-the-art methods person re-identification\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  40%|███▉      | 199/500 [20:31<25:38,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"joint filter FEATURE-OF image filters\", \"Convolution-al Neural Networks USED-FOR joint filter construction\", \"model EVALUATE-FOR effectiveness of joint filter\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  40%|████      | 200/500 [20:36<24:19,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"action detection USED-FOR streaming skeleton data\", \"multi-task end-to-end Joint Classification-Regression Recurrent Neural Network USED-FOR online action detection\", \"LSTM subnetwork FEATURE-OF proposed model\", \"streaming video dataset PART-OF proposed model\", \"experimental results EVALUATE-FOR scheme\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  40%|████      | 201/500 [20:39<22:51,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"oral communication USED-FOR documentation\", \"conversation PART-OF large database\", \"information retrieval techniques USED-FOR document representation\", \"keywords FEATURE-OF histogram\", \"indices FEATURE-OF oral communication\", \"time indices FEATURE-OF rejoinder\", \"place indices FEATURE-OF rejoinder\", \"attendance indices FEATURE-OF rejoinder\", \"activity indices FEATURE-OF rejoinder\", \"automatic detection USED-FOR activity detection\", \"TV shows PART-OF larger database\", \"emotions FEATURE-OF speakers\", \"dominance distribution FEATURE-OF speakers\", \"indices EVALUATE-FOR effectiveness\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  40%|████      | 202/500 [20:46<26:12,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"DARPA Communicator program USED-FOR development of distributed message-passing infrastructure\", \"dialogue systems PART-OF distributed message-passing infrastructure\", \"software infrastructure FEATURE-OF engaging human users in robust mixed-initiative speech dialogue interactions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  41%|████      | 203/500 [20:51<24:42,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"information extraction systems USED-FOR access to text collections\", \"named entity annotations FEATURE-OF information extraction systems\", \"scenario templates FEATURE-OF information extraction systems\", \"prototype system PART-OF industry watch function\", \"pharmaceutical news archive PART-OF industry watch function\", \"user evaluation EVALUATE-FOR IE-enhanced text browsers\", \"interface PART-OF IE-enhanced text browsers\", \"users AWARE-OF potential of IE-enhanced text browsers\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  41%|████      | 204/500 [20:56<25:23,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"CCLINC Korean-to-English translation system PART-OF Common Coalition Language System at Lincoln Laboratory\", \"language understanding module PART-OF CCLINC Korean-to-English translation system\", \"generation modules PART-OF CCLINC Korean-to-English translation system\", \"semantic frame FEATURE-OF language neutral meaning representation\", \"efficient parsing USED-FOR Korean\", \"word sense disambiguation FEATURE-OF high quality translation\", \"word order generation FEATURE-OF high quality translation\", \"knowledge-based automated acquisition of grammars USED-FOR rapid system development and porting to new domains\", \"Korean newspaper articles MATERIAL-OF system training\", \"translation output EVALUATE-FOR content understanding of original document\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  41%|████      | 205/500 [21:03<27:56,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"automated evaluation techniques USED-FOR evaluation of human language learners\", \"evaluation techniques PROVIDE information about human language learning process\", \"evaluation techniques PROVIDE information about translation process\", \"evaluation techniques PROVIDE information about development of machine translation systems\", \"experiment LOOKS AT intelligibility of MT output\", \"assessors CAN differentiate native from non-native language essays\", \"factors ON WHICH assessors made their decisions ELICITED from experiment using machine translation output\", \"subjects GIVEN extracts of translated newswire text\", \"extracts INCLUDE expert human translations\", \"extracts INCLUDE machine translation outputs\", \"subjects ASKED TO determine whether sample output expert human translation or machine translation\", \"subjects ASKED TO mark word at which they made decision\", \"preliminary analysis OF factors involved in decision making process presented here\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  41%|████      | 206/500 [21:12<32:56,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"spoken language understanding system PART-OF LCS paradigm\", \"intelligent mobile agents PART-OF LCS paradigm\", \"LCS-Marine USED-FOR information request\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  41%|████▏     | 207/500 [21:15<27:32,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Automatic Speech Recognition technology USED-FOR dialog systems\", \"speech recognition FEATURE-OF dialog systems\", \"dialog systems PART-OF natural language generation community\", \"natural language generation COMPARE knowledge-based generation systems\", \"machine learning techniques USED-FOR knowledge-based generation systems\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  42%|████▏     | 208/500 [21:20<25:42,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"language models INTERPOLATION-IMPROVES performance\", \"oracle SELECTS-BEST word string\", \"dynamic language model combination IMPROVES performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  42%|████▏     | 209/500 [21:22<21:30,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"n-gram models USED-FOR Thai key prediction\", \"n-gram models USED-FOR Thai-English language identification\", \"error-correction rules USED-FOR Thai key prediction\", \"error-correction rules USED-FOR Thai-English language identification\", \"rule-reduction algorithm FEATURE-OF error-correction rules\", \"mutual information USED-FOR rule-reduction algorithm\", \"accuracy EVALUATE-FOR language identification\", \"accuracy EVALUATE-FOR key prediction\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  42%|████▏     | 210/500 [21:28<23:07,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"information redundancy USED-FOR error correction\", \"multilingual input USED-FOR error correction\", \"machine translation USED-FOR error correction\", \"multilingual summaries EVALUATE-FOR quality improvement\", \"multi-document summarization PART-OF error correction\", \"documents PART-OF multi-document summarization\", \"Arabic PART-OF documents\", \"summary PART-OF multilingual summaries\", \"lexical-syntactic forms FEATURE-OF information\", \"machine translation systems PART-OF error correction\", \"redundancy FEATURE-OF information\", \"machine translations USED-FOR error correction\", \"Arabic documents PART-OF machine translations\", \"noun phrases FEATURE-OF redundancy\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  42%|████▏     | 211/500 [21:35<26:23,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"maximum entropy word alignment algorithm USED-FOR Arabic-English machine translation\", \"supervised training data FEATURE-OF maximum entropy word alignment algorithm\", \"training material USED-FOR machine translation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  42%|████▏     | 212/500 [21:40<25:51,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"learning method USED-FOR single-snippet answers\", \"definition questions EVALUATE-FOR question answering systems\", \"Web search engines PART-OF question answering systems\", \"on-line encyclopedias and dictionaries FEATURE-OF positive and negative definition examples\", \"svm USED-FOR separating two classes\", \"proposed method COMPARE alternative of training the system on questions and news articles from trec\", \"search engine EVALUATE-FOR handling definition questions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  43%|████▎     | 213/500 [21:46<26:12,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method representation NLP structures\", \"conditional log-linear model USED-FOR representation\", \"hidden variables FEATURE-OF lexical items\", \"hidden variables FEATURE-OF word clusters\", \"hidden variables FEATURE-OF word senses\", \"model learns assignments\", \"discriminative training criterion EVALUATE-FOR assignments\", \"dynamic programming USED-FOR summations\", \"model applied to parse reranking\", \"F-measure improvement EVALUATE-FOR base parser\", \"F-measure improvement EVALUATE-FOR Collins (2000) reranker\", \"techniques generalize to NLP structures\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  43%|████▎     | 214/500 [21:53<29:04,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"phrase-based statistical machine translation method FEATURE-OF statistical translation model\", \"non-contiguous phrases HYPONYM-OF phrases\", \"word-aligned corpora PART-OF producing phrases\", \"training method USED-FOR maximization of translation accuracy\", \"NIST evaluation metric EVALUATE-FOR translation accuracy\", \"translations PRODUCED-BY beam-search decoder\", \"proposed method allows to better generalize from training data\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  43%|████▎     | 215/500 [21:58<27:02,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"probabilistic translation models FEATURE-OF computational problems\", \"probabilistic translation models HYPONYM-OF probabilistic context-free grammars\", \"probabilistic context-free grammars PART-OF synchronous working\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  43%|████▎     | 216/500 [22:02<24:21,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"question-focused sentence retrieval USED-FOR news articles\", \"questions central to understanding story PART-OF corpus\", \"stories DESCRIBED-BY news articles\", \"questions TIME-SENSITIVE\", \"sentences PROVIDE answer TO questions\", \"stochastic, graph-based method FEATURE-OF sentence retrieval problem\", \"textual units COMPARED-BY stochastic, graph-based method\", \"generic summarization USED-FOR stochastic, graph-based method\", \"topic-sensitive version FEATURE-OF method\", \"competitive baseline COMPARED-TO topic-sensitive version\", \"similarity COMPARED-BY baseline\", \"method OUTPERFORMS baseline\", \"TRDR score EVALUATE-FOR method\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  43%|████▎     | 217/500 [22:13<32:10,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 217: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c07086430b94bf0e10312ab369105ff0 in your message.)\n",
      "Query: Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\n",
      "    ###\n",
      "    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\n",
      "    ###\n",
      "    Here are some examples of each type of entity that may be detected:\n",
      "    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\n",
      "    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\n",
      "    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\n",
      "    time complexity.\n",
      "    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\n",
      "    Panntreebank, WordNet, Wikipedia.\n",
      "    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\n",
      "    discourse structure, tree, node, tree kernel, features, noise, criteria.\n",
      "    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\n",
      "    ###\n",
      "    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [triple1, triple2, triple3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "     Following recent developments in the  automatic evaluation  of  machine translation  and  document summarization  , we present a similar approach, implemented in a measure called  POURPRE  , for  automatically evaluating answers to definition questions  . Until now, the only way to assess the correctness of answers to such questions involves manual determination of whether an information nugget appears in a system's response. The lack of automatic methods for  scoring system output  is an impediment to progress in the field, which we address with this work. Experiments with the  TREC 2003 and TREC 2004 QA tracks  indicate that  rankings  produced by our metric correlate highly with  official rankings  , and that  POURPRE  outperforms direct application of existing metrics. \n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"automatic evaluation COMPARE manual determination\", \"POURPRE EVALUATE-FOR answers to definition questions\", \"scoring system output EVALUATE-FOR progress in the field\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  44%|████▎     | 218/500 [22:52<1:17:38, 16.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method identifying patterns translation data FEATURE-OF diagnostic tool\", \"part-of-speech tag sequences PART-OF method identifying patterns translation data\", \"diagnostic tool USED-FOR developers machine translation systems\", \"application EVALUATE-FOR exploring patterns machine translation output\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  44%|████▍     | 219/500 [22:59<1:04:49, 13.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SUMMIT USED-FOR spoken language understanding system\", \"heuristic rules FEATURE-OF past efforts\", \"knowledge engineering FEATURE-OF heuristic rules\", \"speech knowledge FEATURE-OF formal framework\", \"features PART-OF system\", \"decision strategies PART-OF system\", \"speech data FEATURE-OF automatic discovery and training\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  44%|████▍     | 220/500 [23:04<51:15, 10.98s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Comparator USED-FOR evaluating Spoken Language Systems\", \"Common Answer Specification FEATURE-OF answer expressions\", \"Comparator checks answer accords with canonical answer\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  44%|████▍     | 221/500 [23:07<40:40,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"spoken language system USED-FOR interactive problem solving\", \"speech recognition FEATURE-OF recognition system\", \"natural language processing PART-OF recognition system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  44%|████▍     | 222/500 [23:14<37:18,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach UTILIZES advances\", \"approach DESCRIBES parsing\", \"parsing UTILIZES advances\", \"unification-based grammatical frameworks EXTENDED to handle descriptions\", \"grammatical frameworks SHARE properties with KL-ONE-like systems\", \"classification-based techniques APPLIED to linguistic descriptions\", \"merging SUPPORTS integration of semantic and syntactic information\", \"result EXPECTED TO BE more efficient parsing\", \"KL-ONE style representation USED FOR parsing and semantic interpretation\", \"parsing CHARACTERIZED AS inference process called incremental description refinement\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  45%|████▍     | 223/500 [23:20<34:53,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Spoken Language System PART-OF integrated Spoken Language System\", \"N-Best sentence hypotheses FEATURE-OF algorithms\", \"grammar coverage problems AVOIDED-BY fully-connected first-order statistical class grammar\", \"speech-search algorithm FEATURE-OF board\", \"Intel i860 chip PART-OF board\", \"board PLUGS-DIRECTLY-INTO VME bus\", \"natural language system PART-OF SUN4\", \"application back end PART-OF SUN4\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  45%|████▍     | 224/500 [23:26<32:19,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"hidden Markov models USED-FOR large vocabulary continuous speech recognition\", \"speaker-independent training USED-FOR hidden Markov models\", \"speech MATERIAL hidden Markov models\", \"training speakers PART-OF speaker-independent recognition\", \"statistics FEATURE-OF independently trained models\", \"speech data MATERIAL training\", \"word error rate EVALUATE-FOR SI recognition\", \"grammar MATERIAL test set\", \"DARPA Resource Management corpus MATERIAL test set\", \"performance COMPARE best condition\", \"training speakers PART-OF SI recognition\", \"speaker adaptation USED-FOR speaker-independent corpus\", \"probabilistic spectral mapping METHOD speaker adaptation\", \"reference model PART-OF probabilistic spectral mapping\", \"target speaker PART-OF probabilistic spectral mapping\", \"reference model TRANSFORMED-TO space of target speaker\", \"reference model COMBINED-BY averaging\", \"utterances MATERIAL target speaker\", \"error rate EVALUATE-FOR adaptation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  45%|████▌     | 225/500 [23:36<36:46,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Lincoln CSR system PART-OF semiphone modeling\", \"duration model FEATURE-OF triphone systems\", \"duration model FEATURE-OF semiphone systems\", \"training strategy USED-FOR rapid adaptation technique\", \"recognizer USED-FOR bigram back-off language models\", \"RM task HYPONYM-OF ATIS CSR task\", \"evaluation test results EVALUATE-FOR RM CSR task\", \"evaluation test results EVALUATE-FOR ATIS CSR task\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  45%|████▌     | 226/500 [23:43<34:11,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"program USED-FOR tagged text corpus\", \"subcategorization frames FEATURE-OF verb\", \"output list EVALUATE-FOR completeness\", \"output list PART-OF program\", \"false positive rates FEATURE-OF output list\", \"subcategorization frames COMPARE subcategorization dictionary\", \"subcategorization dictionary USED-FOR NLP community\", \"dictionaries TRAIN corpora\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  45%|████▌     | 227/500 [23:48<31:27,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"sense resolution USED-FOR text processing\", \"WordNet FEATURE-OF lexical database\", \"semantic relations FEATURE-OF WordNet\", \"synonymy HYPONYM-OF semantic relations\", \"antonymy HYPONYM-OF semantic relations\", \"hyponymy HYPONYM-OF semantic relations\", \"meronymy HYPONYM-OF semantic relations\", \"causal entailment HYPONYM-OF semantic relations\", \"troponymic entailment HYPONYM-OF semantic relations\", \"semantically related words FEATURE-OF WordNet\", \"polysemous word PART-OF context\", \"derived strings FEATURE-OF words\", \"textual corpus PART-OF derived strings\", \"sense EVALUATE-FOR derived string\", \"context USED-FOR search\", \"corpus PART-OF context\", \"semantic distance FEATURE-OF WordNet\", \"information retrieval USED-FOR sense resolution\", \"mechanical translation USED-FOR sense resolution\", \"intelligent tutoring systems USED-FOR sense resolution\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  46%|████▌     | 228/500 [23:59<36:32,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"spoken language corpus PART-OF ATIS domain\", \"data collection effort USED-FOR multi-site common evaluation\", \"MADCOW COREF Multi-site ATIS Data COllection Working group\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  46%|████▌     | 229/500 [24:02<30:06,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 229: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 117d32fabb254f27c19a5a3069a84192 in your message.)\n",
      "Query: Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\n",
      "    ###\n",
      "    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\n",
      "    ###\n",
      "    Here are some examples of each type of entity that may be detected:\n",
      "    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\n",
      "    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\n",
      "    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\n",
      "    time complexity.\n",
      "    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\n",
      "    Panntreebank, WordNet, Wikipedia.\n",
      "    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\n",
      "    discourse structure, tree, node, tree kernel, features, noise, criteria.\n",
      "    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\n",
      "    ###\n",
      "    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [triple1, triple2, triple3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "     \n",
      " The paper provides an overview of the research conducted at  LIMSI  in the field of  speech processing  , but also in the related areas of  Human-Machine Communication  , including  Natural Language Processing  ,  Non Verbal and Multimodal Communication  . Also presented are the commercial applications of some of the research projects. When applicable, the discussion is placed in the framework of international collaborations. \n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"research conducted AT LIMSI IN field OF speech processing\", \"Human-Machine Communication RELATED TO Natural Language Processing\", \"commercial applications PRESENTED OF research projects\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  46%|████▌     | 230/500 [24:41<1:13:12, 16.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Paramax spoken language understanding system PART-OF non-monotonic reasoning\", \"Paramax spoken language understanding system PART-OF implicit reference resolution\", \"Paramax spoken language understanding system PART-OF database query paraphrase\", \"February 1992 ATIS benchmark tests EVALUATE-FOR progress\", \"n-best speech/language integration architecture USED-FOR OCR accuracy\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  46%|████▌     | 231/500 [24:46<57:26, 12.81s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"generative probabilistic model HBG incorporates linguistic information\", \"HBG takes advantage of detailed linguistic information to resolve ambiguity\", \"HBG incorporates lexical, syntactic, semantic, and structural information from parse tree into disambiguation process\", \"corpus of bracketed sentences Treebank used in combination with decision tree building to determine correct parse of sentence\", \"HBG significantly outperforms P-CFG in head-to-head tests\", \"HBG increases parsing accuracy rate from 60% to 75%\", \"Treebank PART-OF corpus of bracketed sentences\", \"parse tree PART-OF disambiguation process\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  46%|████▋     | 232/500 [24:52<48:41, 10.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"CDHMM FEATURE-OF MLE reestimation algorithms\", \"forward-backward algorithm PART-OF CDHMM\", \"segmental k-means algorithm PART-OF CDHMM\", \"HMM with Gaussian mixture observation densities FEATURE-OF reestimation formulas\", \"Bayesian learning USED-FOR parameter smoothing\", \"Bayesian learning USED-FOR speaker adaptation\", \"Bayesian learning USED-FOR speaker group modeling\", \"Bayesian learning USED-FOR corrective training\", \"MAP estimation approach EVALUATE-FOR effectiveness of speech recognition applications\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  47%|████▋     | 233/500 [24:58<41:42,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"polysemous words HYPONYM-OF word-sense disambiguation systems\", \"bilingual material FEATURE-OF word-sense disambiguation systems\", \"Canadian Hansards FEATURE-OF bilingual material\", \"monolingual material FEATURE-OF word-sense disambiguation systems\", \"Roget's Thesaurus FEATURE-OF monolingual material\", \"Grolier's Encyclopedia FEATURE-OF monolingual material\", \"discourse effect GENERIC\", \"polysemous word HYPONYM-OF sentence\", \"well-written discourse HYPONYM-OF discourse\", \"polysemous word COREF sentence\", \"sense COREF sense\", \"experiment EVALUATE-FOR word-sense disambiguation algorithm\", \"discourse constraint FEATURE-OF word-sense disambiguation algorithm\", \"disambiguation algorithms EVALUATE-FOR discourse constraint\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  47%|████▋     | 234/500 [25:11<45:58, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"systems PROVIDE-FUNCTIONALITY-SIMILAR-TO text processors\", \"speech and text-image recognition RETRIEVE-INFO-FROM documents\", \"text-image editor FEATURE-OF systems\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  47%|████▋     | 235/500 [25:15<37:23,  8.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"LIMSI recognizer EVALUATE-FOR ARPA NOV93 CSR test\", \"LIMSI recognizer USED-FOR speech dictation\", \"continuous density HMM FEATURE-OF acoustic modeling\", \"Gaussian mixture FEATURE-OF acoustic modeling\", \"n-gram statistics FEATURE-OF language modeling\", \"newspaper texts FEATURE-OF language modeling\", \"time-synchronous graph-search strategy FEATURE-OF recognizer\", \"bigram back-off language models FEATURE-OF time-synchronous graph-search strategy\", \"word graph PART-OF forward pass\", \"trigram language model FEATURE-OF forward pass\", \"cepstrum-based features FEATURE-OF acoustic modeling\", \"context-dependent phone models FEATURE-OF acoustic modeling\", \"context-dependent phone models PART-OF intra and interword\", \"phone duration models FEATURE-OF acoustic modeling\", \"sex-dependent models FEATURE-OF acoustic modeling\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  47%|████▋     | 236/500 [25:24<38:01,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"continuous speech recognition techniques USED-FOR Spoken Language Systems\", \"speech recognition and understanding systems USED-FOR military and civilian systems\", \"CSR USED-FOR mobile military command and control\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  47%|████▋     | 237/500 [25:27<30:34,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ILIMP USED-FOR French text processing\", \"pronoun il TAGGED-WITH [ANA] or [IMP] or [expletive]\", \"anaphoric occurrences of il HYPONYM-OF anaphora resolution system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  48%|████▊     | 238/500 [25:31<26:49,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Automatic evaluation metrics EVALUATE-FOR Machine Translation systems\", \"BLEU FEATURE-OF word n-grams\", \"BLEU FEATURE-OF character level\", \"word segmentation problem PART-OF English-Chinese language pairs\", \"word segmentation problem PART-OF English-Japanese language pairs\", \"BLEU USED-FOR commercial systems outputting unsegmented texts\", \"statistical MT systems COMPARE commercial systems outputting unsegmented texts\", \"outputs PART-OF statistical MT systems\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  48%|████▊     | 239/500 [25:36<25:40,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Chinese-to-English SMT model EVALUATE-FOR word sense disambiguation performance\", \"BLEU scores FEATURE-OF statistical machine translation models\", \"SMT models COMPARE dedicated WSD models\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  48%|████▊     | 240/500 [25:40<22:17,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"natural language processing USED-FOR trend survey\", \"Japanese natural language processing studies PART-OF trend survey\", \"papers published FOR research organization\", \"papers published FOR research area\", \"relationship BETWEEN research organization AND research area\", \"paper useful FOR recognizing trends\", \"method supporting trend surveys USING NLP FEATURE-OF paper\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  48%|████▊     | 241/500 [25:46<23:20,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"verb dependents LEFT-SIDE-OF Chinese language\", \"ambiguity resolution RIGHT-SIDE-OF dependencies\", \"dependency parsing USED-FOR sentences\", \"shift-reduce dependency parsers COMPARE proposed method\", \"connectivity OF dependency tree\", \"two-phase shift-reduce dependency parser USED-FOR SVM learning\", \"left-side dependents DETECTED-IN Phase I\", \"right-side nominal dependents DETECTED-IN Phase I\", \"right-side verbal dependents DECIDED-IN Phase II\", \"dependency accuracy IMPROVED-BY 10.08%\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  48%|████▊     | 242/500 [25:53<25:02,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SMT gives competitive results to rule-based translation systems\", \"translation systems USED-FOR language pairs\", \"translation systems USED-FOR domains\", \"workshop INTENDED-FOR introduction to statistical machine translation\", \"participants ABLE-TO set out building an SMT system\", \"participants ABLE-TO achieve good baseline results\", \"STTK INTRODUCED-TO participants\", \"STTK USED-TO build a working translation system\", \"STTK USED-AS basis of CMU's SMT system\", \"source code MADE-AVAILABLE\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  49%|████▊     | 243/500 [25:59<25:14,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"word segmentation system FEATURE-OF France Telecom R&D Beijing\", \"system PARTICIPATED-IN PK-open track\", \"system PARTICIPATED-IN PK-closed track\", \"system PARTICIPATED-IN AS-open track\", \"system PARTICIPATED-IN AS-closed track\", \"system PARTICIPATED-IN HK-open track\", \"system PARTICIPATED-IN HK-closed track\", \"system PARTICIPATED-IN MSR-open track\", \"system PARTICIPATED-IN MSR-closed track\", \"system ACHIEVED state-of-the-art performance in MSR-open tracks\", \"system ACHIEVED state-of-the-art performance in MSR-closed tracks\", \"system ACHIEVED state-of-the-art performance in PK-open tracks\", \"each component CONTRIBUTED-TO scores\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  49%|████▉     | 244/500 [26:07<27:47,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Taiwan Child Language Corpus PART-OF Child Language Data Exchange System\", \"corpus USED-FOR applications\", \"corpus FEATURE-OF word segmentation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  49%|████▉     | 245/500 [26:09<22:56,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"English-Chinese bitexts USED-FOR empirical MT research\", \"bilingual corpus FEATURE-OF text collection\", \"English-Chinese bitexts PART-OF larger volume\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  49%|████▉     | 246/500 [26:13<20:02,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"machine translation evaluation RELATED-TO sentence-level semantic equivalence classification\", \"MT evaluation methods USED-FOR building classifiers\", \"BLEU USED-FOR building classifiers\", \"NIST USED-FOR building classifiers\", \"WER USED-FOR building classifiers\", \"PER USED-FOR building classifiers\", \"classification method FEATURE-OF PER\", \"part of speech information FEATURE-OF word matches and non-matches\", \"MT evaluation techniques USED-FOR features\", \"features EVALUATE-FOR paraphrase classification\", \"technique USED-FOR improvement\", \"improvement EVALUATE-FOR paraphrase classification accuracy\", \"models COMPARE technique\", \"PARAPHRASE classification COMPARE entailment\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  49%|████▉     | 247/500 [26:21<24:52,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"compositional classes HYPONYM-OF paraphrases\", \"class-oriented framework USED-FOR collecting paraphrase examples\", \"sentential paraphrases PART-OF paraphrase class\", \"automatic candidate generation USED-FOR collecting sentential paraphrases\", \"paraphrase corpus EVALUATE-FOR cost-efficiency\", \"paraphrase corpus EVALUATE-FOR exhaustiveness\", \"paraphrase corpus EVALUATE-FOR reliability\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  50%|████▉     | 248/500 [26:26<23:48,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method generates paraphrase sets\", \"paraphrase sets USED-FOR reference sets\", \"reference sets EVALUATE-FOR MT evaluation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  50%|████▉     | 249/500 [26:34<26:01,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"evaluation method FEATURE-OF latent variable model\", \"paraphrases EVALUATE-FOR same context\", \"proposed method achieves accuracy\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  50%|█████     | 250/500 [26:37<22:00,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"quantifying noun groups QUANTIFYING-OF German\", \"corpus-based investigations DESCRIBE corpus-based investigations\", \"information other than grammar sensu stricto FEATURE-OF treebank\", \"annotation ANNOTATION-OF treebank\", \"stochastic parsers TRAINED-ON treebank\", \"grammars INDUCED-FROM treebank\", \"treebank SOURCE-OF data\", \"corpus research GAINED-FROM corpus research\", \"analyses PROPOSED-IN SILVA\", \"parsing TOOL-OF SILVA\", \"extraction tool TOOL-OF SILVA\", \"German text corpora MATERIAL-OF SILVA\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  50%|█████     | 251/500 [26:44<24:07,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"annotating scheme USED-FOR honorifics\", \"honorifics FEATURE-OF Japanese\", \"referential information EVALUATE-FOR resolving zero pronouns\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  50%|█████     | 252/500 [26:49<22:59,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"word significance EVALUATE-FOR speech-based Information Retrieval\", \"weighted word error rate FEATURE-OF automatic speech recognition performance\", \"decoding strategy USED-FOR minimizing WWER\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  51%|█████     | 253/500 [26:53<21:25,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method automatically acquire paraphrases FEATURE-OF bilingual corpora\", \"paraphrasing method DISAMBIGUATE sense phrase USING bilingual context dependency relation\", \"paraphrasing method OBTAIN interchangeable paraphrases GIVEN context\", \"method acquire generalized translation knowledge USING extracted paraphrases\", \"method applied to acquire generalized translation knowledge FOR Korean-English translation\", \"paraphrasing method EXTRACT paraphrases WITH high precision 94.3% FOR Korean\", \"paraphrasing method EXTRACT paraphrases WITH high precision 84.6% FOR English\", \"translation knowledge EXTRACTED FROM bilingual corpora COULD BE generalized successfully USING paraphrases\", \"paraphrasing method USED-FOR acquire generalized translation knowledge\", \"paraphrasing method EVALUATE-FOR efficiency entity summarization\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  51%|█████     | 254/500 [27:02<25:10,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Automatic Speech Recognition System USED-FOR Utterance Verification\", \"Confidence tests FEATURE-OF decoded string hypotheses\", \"Word Spotting USED-FOR dealing with OOV words and noises\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  51%|█████     | 255/500 [27:05<21:57,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"nonstationary chaotic behavior FEATURE-OF practical interest\", \"methods CAPTURE nonstationary chaos\", \"examples INCLUDE biological signals, ocean waves, traffic flow\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  51%|█████     | 256/500 [27:11<21:50,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"LPC based speech coders USED-FOR synthetic speech\", \"simplifying assumptions MADE-ABOUT excitation source\", \"new LPC vocoder PRESENTED-IN paper\", \"LPC excitation SPLIT-INTO two frequency bands\", \"lower band RESPONSIBLE-FOR representing voiced parts of speech\", \"upper band REPRESENTS unvoiced speech\", \"coder's performance IMPROVED-DURING mixed voicing speech\", \"coder's performance IMPROVED-DURING speech containing acoustic noise\", \"new parameter determination techniques DESCRIBED-IN paper\", \"quantisation techniques DESCRIBED-IN paper\", \"operation of coder at low bit rates VITAL-TO parameter determination and quantisation techniques\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  51%|█████▏    | 257/500 [27:19<25:13,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm DETECT/COMPENSATE interference effects\", \"GNSS/INS coupling PERFORMED BY EKF\", \"EKF YIELDS accurate localization\", \"interference CAUSE GNSS measurement noise increase\", \"positioning accuracy DEGRADE\", \"impact of GNSS noise inflation STUDIED\", \"least square estimate COMPUTED\", \"potential variance jumps ESTIMATED\", \"Bayesian test USED TO decide interference corruption\", \"impaired measurements DISCARDED\", \"impact on navigation solution COMPENSATED\", \"performance of proposed approach SHOWN on simulated data\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  52%|█████▏    | 258/500 [27:25<25:19,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"motorized vehicle PART-OF vehicle\", \"frequency components FEATURE-OF signals\", \"speed EVALUATE-FOR estimates\", \"gear scale factors USED-FOR estimating\", \"training data MATERIAL speed measurements\", \"training data MATERIAL measurements\", \"estimation problem FEATURE-OF maximum likelihood estimation problem\", \"heuristics USED-FOR finding initial values\", \"numerical evaluation FEATURE-OF estimator\", \"measurement campaign MATERIAL real data\", \"estimation method EVALUATE-FOR functionality\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  52%|█████▏    | 259/500 [27:31<24:52,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"objective measures EVALUATE-FOR intelligibility prediction\", \"Dau measure COMPARE glimpse proportion\", \"Dau measure COMPARE Speech Intelligibility Index\", \"Dau measure EVALUATE-FOR intelligibility\", \"glimpse proportion EVALUATE-FOR intelligibility\", \"Speech Intelligibility Index EVALUATE-FOR intelligibility\", \"Perceptual Evaluation of Speech Quality EVALUATE-FOR quality\", \"HMM-based speech synthesis system USED-FOR synthesized speech generation\", \"additive noises PART-OF noisy conditions\", \"measures COMPARED-WITH subjective intelligibility scores\", \"Dau measure EVALUATE-FOR subjective scores\", \"glimpse proportion EVALUATE-FOR subjective scores\", \"SII measure EVALUATE-FOR subjective scores\", \"measures GAVE-LESS-ACCURATE-PREDICTIONS-OF intelligibility\", \"SII measure GAVE-LESS-ACCURATE-PREDICTIONS-OF intelligibility\", \"synthetic speech GAVE-LESS-ACCURATE-PREDICTIONS-OF intelligibility\", \"natural speech GAVE-MORE-ACCURATE-PREDICTIONS-OF intelligibility\", \"additional experiments CONJUNCTION ideal binary mask\", \"Glimpse measure GAVE-MOST-ACCURATE-PREDICTIONS intelligibility\", \"synthesized speech USED-FOR intelligibility prediction\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  52%|█████▏    | 260/500 [27:44<33:19,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"blind separation USED-FOR underdetermined instantaneous mixtures\", \"signals PART-OF piecewise stationary signals\", \"varying variances FEATURE-OF different epochs\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  52%|█████▏    | 261/500 [27:48<26:58,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"mobile speech application USED-FOR speaker DOA estimation accuracy\", \"AVS USED-FOR DOA estimation algorithm\", \"DOA estimation algorithm FEATURE-OF mobile speech application\", \"BISDR PART-OF inter-sensor data ratio model\", \"bispectrum FEATURE-OF DOA estimation algorithm\", \"bispectrum mask FEATURE-OF DOA cues\", \"DOA cues EVALUATE-FOR robustness\", \"NSI COMPARE speech\", \"NSI COMPARE bispectrum\", \"performance EVALUATE-FOR proposed algorithm\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  52%|█████▏    | 262/500 [27:54<26:53,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"speech-based depression detection USED-FOR depression prediction\", \"MFCCs suffer dramatically under test/train mismatch for both noise and reverberation EVALUATE-FOR depression prediction\", \"DOCC features are far more robust FEATURE-OF noise robustness features\", \"higher-order cepstral coefficients FEATURE-OF cepstral coefficients\", \"artificial neural networks COMPARE support vector regression\", \"spontaneous speech COMPARE read speech\", \"DOCCs are more noise and reverberation robust than MFCCs COMPARE MFCCs\", \"2014 AudioVisual Emotion Recognition Challenge PART-OF data\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  53%|█████▎    | 263/500 [28:01<27:08,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"HFOs biomarker OF epileptic brain tissue\", \"HFOs example OF challenges in analysis of discrete events in high-temporal resolution, intracranial EEG data\", \"dimensionality reduction ASSUMES data lie ON manifold with dimension less than that of features space\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  53%|█████▎    | 264/500 [28:05<23:04,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Wallflower system USED-FOR background maintenance\", \"pixel-level component PERFORMS Wiener filtering\", \"region-level component FILLS IN homogeneous regions of foreground objects\", \"frame-level component DETECTS sudden, global changes in the image\", \"Wallflower system COMPARE 8 other background subtraction algorithms\", \"Wallflower system OUTPERFORM previous algorithms\", \"normative principles PROPOSED FOR background maintenance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  53%|█████▎    | 265/500 [28:10<22:15,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"priori geometric constraints FEATURE-OF 3-D stereo reconstruction scheme\", \"image information USED-FOR accurately recover 3-D shape\", \"anisotropic meshing FEATURE-OF satisfactory reconstruction results\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  53%|█████▎    | 266/500 [28:13<18:43,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"model-based bundle adjustment algorithm USED-FOR recover 3D model\", \"scene/object REPRESENTED-BY surface controlled by parameters\", \"model space USED-FOR search space\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  53%|█████▎    | 267/500 [28:16<16:49,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"single-image highlight removal method FEATURE-OF image in-painting\", \"highlight pixels USED-FOR guiding inpainting process\", \"illumination constraints FEATURE-OF better recovery of shading and textures\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  54%|█████▎    | 268/500 [28:19<15:15,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm USED-FOR novel view generation\", \"video streams ACQUIRED-BY two cameras\", \"proposed algorithm SYNTHESISES images\", \"virtual camera POSITIONED-WITHIN monitor\", \"technique BASED-ON stereo algorithm\", \"three-plane graph USED-FOR dense-stereo dynamic-programming\", \"geometric derivation USED-FOR novel-view synthesis\", \"background model MAINTAINED-FOR occlusion rendering\", \"cost aggregation algorithm ACTS-ON matching cost space\", \"robustness DEMONSTRATED-FOR stereo video streams\", \"cyclopean views SYNTHESISED-FROM extended conversational sequences\", \"novel algorithm USED-FOR temporal maintenance\", \"temporal artefacts REDUCED-BY cost aggregation algorithm\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  54%|█████▍    | 269/500 [28:27<19:23,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm USED-FOR computing optical flow\", \"algorithm USED-FOR computing shape\", \"algorithm USED-FOR computing motion\", \"algorithm USED-FOR computing lighting\", \"algorithm USED-FOR computing albedo\", \"problem FORMULATED-IN manner that subsumes structure from motion\", \"problem FORMULATED-IN manner that subsumes multi-view stereo\", \"problem FORMULATED-IN manner that subsumes photo-metric stereo\", \"algorithm UTILIZES spatial intensity variation as cue\", \"algorithm UTILIZES temporal intensity variation as cue\", \"spatial intensity variation CONSTRAINS flow\", \"temporal intensity variation CONSTRAINS surface orientation\", \"combining both cues ENABLES dense reconstruction of both textured and texture-less surfaces\", \"algorithm ESTIMATES affine camera parameters\", \"algorithm ESTIMATES illumination\", \"algorithm ESTIMATES shape\", \"algorithm ESTIMATES albedo\", \"results DEMONSTRATED-ON videos of hand-held objects moving in front of a fixed light and camera\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  54%|█████▍    | 270/500 [28:37<25:04,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"transparent objects HYPONYM-OF hard problem in vision\", \"features imaged through transparent object FEATURE-OF model-based approach\", \"transparent objects PART-OF scenes\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  54%|█████▍    | 271/500 [28:41<22:08,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"face images PART-OF non-frontal views\", \"illumination EVALUATE-FOR face recognition accuracy\", \"recognition rate EVALUATE-FOR face recognition systems\", \"CCTV camera USED-FOR live input\", \"Bayesian framework USED-FOR face image super-resolution\", \"multi-modal super-resolution FEATURE-OF recognition in tensor space\", \"low-resolution face image USED-FOR multi-modal super-resolution\", \"training tensor USED-FOR super-resolution\", \"high-resolution reconstructions PART-OF super-resolution\", \"pixel-domain super-resolution COMPARE recognition\", \"maximum likelihood identity parameter vector USED-FOR recognition\", \"multi-modal super-resolution COMPARE tensorface and eigenface representations\", \"low-resolution images USED-FOR multi-modal super-resolution\", \"improved recognition rates EVALUATE-FOR multi-modal super-resolution and face recognition experiments\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  54%|█████▍    | 272/500 [28:51<26:55,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach learn object category from name\", \"model TSI-pLSA extends pLSA\", \"model TSI-pLSA includes spatial information\", \"approach handle intra-class variability\", \"approach handle unrelated images\", \"evaluate models on standard test sets\", \"performance competitive with existing methods\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  55%|█████▍    | 273/500 [28:55<23:20,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"technique FEATURE-OF robust estimation algorithm\", \"estimation procedure USED-FOR geometric estimation problems\", \"algorithm EVALUATE-FOR efficiency\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  55%|█████▍    | 274/500 [29:01<22:27,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method detecting 3D objects multi-modalities\", \"image FEATURE-OF object information\", \"dense depth map FEATURE-OF object information\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  55%|█████▌    | 275/500 [29:03<18:41,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm DETECT behaviours\", \"behaviours either NEVER-BEFORE-SEEN or few examples\", \"Global context MODELLED\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  55%|█████▌    | 276/500 [29:06<16:22,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"scanning method recovers dense sub-pixel camera-projector correspondence\", \"gray-level band-pass white noise patterns FEATURE-OF method\", \"our method EVALUATE-FOR scene geometry with high subpixel precision\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  55%|█████▌    | 277/500 [29:10<15:35,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"energy minimization strategy USED-FOR semantic video segmentation\", \"hierarchical abstraction PART-OF supervoxel graph\", \"energy minimization algorithm FEATURE-OF strategy\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  56%|█████▌    | 278/500 [29:13<13:45,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"functional objects LOCALIZED-IN surveillance videos\", \"functional objects AFFECT behavior of people\", \"functional objects VIEWED-AS dark matter\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  56%|█████▌    | 279/500 [29:15<12:34,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method synthesizing facade images FROM example image\", \"example image PART-OF semantic components\", \"tiling GENERATED-FOR example image\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  56%|█████▌    | 280/500 [29:18<12:00,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"light fields FEATURE-OF image-based representations\", \"3D lines PART-OF ray space\", \"triangulation USED-FOR light field super-resolution\", \"light field space HYPONYM-OF bilinear subspaces\", \"algorithm USED-FOR Constrained Delaunay Triangulation\", \"LAGC algorithm USED-FOR light field stereo matching\", \"triangulation EVALUATE-FOR accuracy\", \"LAGC algorithm EVALUATE-FOR accuracy\", \"LAGC algorithm EVALUATE-FOR visual quality\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  56%|█████▌    | 281/500 [29:29<20:28,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 281: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 73689e170d9704e7b7e801d878b0da83 in your message.)\n",
      "Query: Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\n",
      "    ###\n",
      "    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\n",
      "    ###\n",
      "    Here are some examples of each type of entity that may be detected:\n",
      "    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\n",
      "    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\n",
      "    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\n",
      "    time complexity.\n",
      "    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\n",
      "    Panntreebank, WordNet, Wikipedia.\n",
      "    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\n",
      "    discourse structure, tree, node, tree kernel, features, noise, criteria.\n",
      "    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\n",
      "    ###\n",
      "    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [triple1, triple2, triple3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    Regression-based techniques have shown promising results for people counting in crowded scenes. However, most existing techniques require expensive and laborious data annotation for model training. In this study, we propose to address this problem from three perspectives: (1) Instead of exhaustively annotating every single frame, the most informative frames are selected for annotation automatically and actively. (2) Rather than learning from only labelled data, the abundant unlabelled data are exploited. (3) Labelled data from other scenes are employed to further alleviate the burden for data annotation. All three ideas are implemented in a unified active and semi-supervised regression framework with ability to perform transfer learning, by exploiting the underlying geometric structure of crowd patterns via manifold analysis. Extensive experiments validate the effectiveness of our approach.\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"people counting USED-FOR crowded scenes\", \"regression-based techniques FEATURE-OF people counting\", \"data annotation EVALUATE-FOR model training\", \"informative frames FEATURE-OF annotation\", \"unlabelled data USED-FOR learning\", \"Labelled data USED-FOR data annotation\", \"active regression framework FEATURE-OF transfer learning\", \"geometric structure FEATURE-OF crowd patterns\", \"manifold analysis PART-OF regression framework\", \"Extensive experiments EVALUATE-FOR effectiveness of approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  56%|█████▋    | 282/500 [30:11<59:36, 16.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach GENERATE OOPs\", \"object regions LOCATE pixelwise object probability\", \"proposal generation problem FORMULATE generative probabilistic model\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  57%|█████▋    | 283/500 [30:14<44:19, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"loss-aware predictions USED-FOR image segmentation settings\", \"evaluation function EVALUATE-FOR image segmentation systems\", \"Intersection-over-Union measure EVALUATE-FOR image segmentation systems\", \"Expected-IoU score FEATURE-OF loss-aware predictions\", \"Expected-Intersection-over-Expected-Union approximation FEATURE-OF Expected-IoU score\", \"EIoU COMPUTED-BY second approach\", \"candidate solutions PART-OF second approach\", \"new methods FEATURE-OF both existing approaches\", \"EIoEU approximation USED-FOR new methods\", \"high quality candidate solutions PART-OF new methods\", \"performance IMPROVED-BY new approaches\", \"image segmentation tasks COMPARE image segmentation tasks\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  57%|█████▋    | 284/500 [30:22<39:50, 11.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"adaptive dither voting FEATURE-OF robust spatial verification\", \"correspondences USED-FOR transformation quantization\", \"Hough histogram FEATURE-OF spatial similarity\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  57%|█████▋    | 285/500 [30:27<32:52,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"paper aim render aging faces personalized way\", \"set age-group specific dictionaries learned\", \"dictionary bases corresponding index aging process pattern cross different age groups form\", \"linear combination patterns expresses personalized aging process\", \"two factors taken consideration dictionary learning process\", \"beyond aging dictionaries subject may have extra personalized facial characteristics\", \"personality-aware coupled reconstruction loss utilized learn dictionaries based face pairs neighboring age groups\", \"Extensive experiments well demonstrate advantages proposed solution state-of-the-arts term personalized aging progression\", \"performance gain cross-age face verification synthesizing aging faces\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  57%|█████▋    | 286/500 [30:33<29:23,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"change detection USED-FOR scene\", \"change detection COMPARE previous change detection methods\", \"end-to-end approach USED-FOR fine-grained change detection\", \"camera relocation USED-FOR active camera relocation\", \"group of images FEATURE-OF observation\", \"fine-grained change detection EVALUATE-FOR detection sensitivity\", \"fine-grained change detection EVALUATE-FOR accuracy\", \"fine-grained change detection COMPARE large-scale significant changes\", \"fine-grained change detection COMPARE minute changes\", \"fine-grained change detection PART-OF joint optimization problem\", \"normal-aware lighting difference PART-OF joint optimization problem\", \"camera geometry correction flow PART-OF joint optimization problem\", \"real scene change mask PART-OF joint optimization problem\", \"real-world datasets FEATURE-OF fine-grained change detection\", \"misaligned scenes FEATURE-OF fine-grained change detection\", \"multiple lighting conditions FEATURE-OF fine-grained change detection\", \"superior performance EVALUATE-FOR our approach\", \"real scene changes EVALUATE-FOR distinguish\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  57%|█████▋    | 287/500 [30:43<31:16,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Ant-Q algorithms USED-FOR solution of symmetric and asymmetric instances of traveling salesman problem\", \"Ant system HYPONYM-OF distributed algorithm for combinatorial optimization\", \"Ant-Q family COMPARE ant system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  58%|█████▊    | 288/500 [30:47<25:45,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"agent learns action models FROM experience\", \"agent learns action models FROM observation\", \"GOLEM USED-FOR learn action models\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  58%|█████▊    | 289/500 [30:49<20:50,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"boosting methods not overfit training data\", \"Schapire et al. attempted to explain phenomenon in terms of margins classifier achieves on training examples\", \"Breiman cast serious doubt on explanation by introducing boosting algorithm arc-gv that can generate higher margins distribution than AdaBoost and yet performs worse\", \"we take close look at Breiman's compelling but puzzling results\", \"poorer performance of arc-gv can be explained by increased complexity of base classifiers it uses\", \"explanation supported by our experiments and entirely consistent with margins theory\", \"maximizing margins is desirable but not necessarily at expense of other factors especially base-classifier complexity\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  58%|█████▊    | 290/500 [30:56<21:38,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"multiclass Perceptron USED-FOR multiclass categorization\", \"unique hypothesis FEATURE-OF class\", \"single common hypothesis FEATURE-OF class\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  58%|█████▊    | 291/500 [30:59<17:49,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"learning PREDICT moves board game Go\", \"probability distribution legal moves professional play\", \"distribution APPLICATIONS computer Go\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  58%|█████▊    | 292/500 [31:02<15:32,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"model-based policy search approach USED-FOR reinforcement learning\", \"policies FOUND-USING model of Markov decision process\", \"high-dimensional continuous-state tasks DIFFICULT-TO-BUILD accurate model\", \"algorithm RETURNS policy THAT-WORKS-IN simulation\", \"model-free RL REQUIRES large numbers of real-life trials\", \"hybrid algorithm REQUIRES approximate model\", \"small number of real-life trials REQUIRED\", \"policy evaluations GROUNDED using real-life trials\", \"approximate model SUGGESTS local changes\", \"algorithm ACHIEVES near-optimal performance in real system\", \"crude model GIVEN\", \"algorithm OBTAINS near-optimal performance in real system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  59%|█████▊    | 293/500 [31:12<21:00,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"sampling probabilities EVALUATE-FOR aggregate queries\", \"regression problems COMPARE standard regression problems\", \"regularized Empirical Risk Minimization PART-OF algorithm\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  59%|█████▉    | 294/500 [31:15<18:15,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"robust PCA USED-FOR machine learning applications\", \"data matrix PART-OF robust PCA problem\", \"low rank matrix PART-OF robust PCA\", \"sparse residual PART-OF robust PCA\", \"side information EVALUATE-FOR robust PCA\", \"prior structure FEATURE-OF entities\", \"features FEATURE-OF entities\", \"convex problem USED-FOR robust PCA\", \"low rank matrix EXACTLY-RECOVERED-BY proposed method\", \"standard robust PCA COMPARE proposed method\", \"substantial amount of low rank matrices RECOVERABLE-BY proposed method\", \"effectiveness of features EVALUATED-BY proposed method\", \"synthetic experiments CONDUCTED-FOR proposed method\", \"real application CONDUCTED-FOR proposed method\", \"noisy image classification EVALUATE-FOR proposed method\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  59%|█████▉    | 295/500 [31:23<21:22,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Object Recognition task PART-OF di-chotomy\", \"categorization of objects HYPONYM-OF object category recognition\", \"estimating object pose HYPONYM-OF object pose estimation\", \"view-invariant representation FEATURE-OF categorization of objects\", \"representation capable of capturing pose information FEATURE-OF estimating object pose\", \"deep learning methods USED-FOR object category recognition\", \"Convolutional Neural Networks USED-FOR object recognition and pose estimation\", \"layers of distributed representations PART-OF CNNs\", \"object pose information FEATURE-OF distributed representations within CNNs\", \"object category representations COMPARE object pose representations\", \"multi-view datasets EVALUATE-FOR experiment\", \"state-of-the-art COMPARE better than\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  59%|█████▉    | 296/500 [31:34<25:45,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"limited-memory stochastic block BFGS update USED-FOR stochastic approximation methods\", \"estimate of inverse Hessian matrix FEATURE-OF method\", \"quasi-Newton method USED-FOR stochastic gradients\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  59%|█████▉    | 297/500 [31:38<21:25,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"process model USED-FOR hierarchical perceptual sound organization\", \"perceptual sound organization PART-OF scene analysis problem\", \"model CONSISTS-OF processing modules\", \"model CONSISTS-OF hypothesis network\", \"processing module RISES-TO input information\", \"processing module WRITES output information\", \"information INTEGRATED-ON hypothesis network\", \"internal model CONSTRUCTED-FOR perceptual sounds\", \"music scene analysis system DEVELOPED-FOR acoustic signals\", \"system RECOGNIZES rhythm\", \"system RECOGNIZES chords\", \"system RECOGNIZES source-separated musical notes\", \"experimental results SHOW method PERMITTED autonomous information integration\", \"experimental results SHOW method PERMITTED stable information integration\", \"experimental results SHOW method PERMITTED effective information integration\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  60%|█████▉    | 298/500 [31:46<23:51,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm MINPATH USED-FOR wireless web navigation\", \"MINPATH finds shortcuts EVALUATE-FOR savings of shortcut links\", \"predictive models COMPARE Naive Bayes mixture models and mixtures of Markov models\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  60%|█████▉    | 299/500 [31:50<20:16,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm USED-FOR three dimensional container packing problem\", \"algorithm deviates FROM traditional approach\", \"algorithm USES concept of building growing\", \"method EVALUATE-FOR average packing utilization\", \"experimental results INDICATE new algorithm achieves packing utilization of more than 87%\", \"experimental results COMPARE results reported in literature\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  60%|██████    | 300/500 [31:54<18:34,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 300: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d6f3a2fee9e3d177c6c9eae0f3ce4036 in your message.)\n",
      "Query: Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\n",
      "    ###\n",
      "    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\n",
      "    ###\n",
      "    Here are some examples of each type of entity that may be detected:\n",
      "    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\n",
      "    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\n",
      "    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\n",
      "    time complexity.\n",
      "    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\n",
      "    Panntreebank, WordNet, Wikipedia.\n",
      "    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\n",
      "    discourse structure, tree, node, tree kernel, features, noise, criteria.\n",
      "    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\n",
      "    ###\n",
      "    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [triple1, triple2, triple3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "    Helping end users build and check process models is a challenge for many science and engineering fields. Many AI researchers have investigated useful ways of verifying and validating knowledge bases for ontologies and rules, but it is not easy to directly apply them to checking process models. Other techniques developed for checking and refining planning knowledge tend to focus on automated plan generation rather than helping users author process information. In this paper, we propose a complementary approach which helps users author and check process models. Our system, called KANAL, relates pieces of information in process models among themselves and to the existing KB, analyzing how different pieces of input are put together to achieve some effect. It builds interdepen-dency models from this analysis and uses them to find errors and propose fixes. Our initial evaluation shows that KANAL was able to find most of the errors in the process models and suggest useful fixes including the fixes that directly point to the sources of the errors.\n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"KANAL system USED-FOR authoring and checking process models\", \"KANAL system RELATES process model information to existing KB\", \"KANAL system EVALUATE-FOR finding errors and proposing fixes in process models\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  60%|██████    | 301/500 [32:34<52:04, 15.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"DLs combine knowledge representation on an abstract, logical level with an interface to concrete domains\", \"we propose to extend DLs with key constraints\", \"US citizens uniquely identified by their social security number FEATURE-OF key constraints\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  60%|██████    | 302/500 [32:37<39:47, 12.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Bayesian machine learning USES conjugate priors\", \"conjugate priors HAVE inherent geometry\", \"hyperparameters of conjugate priors ARE effective sample points\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  61%|██████    | 303/500 [32:45<35:02, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"linear classification USED-FOR document classification\", \"training methods FEATURE-OF existing training methods\", \"data FEATURE-OF data larger than memory capacity\", \"block minimization framework USED-FOR data larger than memory size\", \"block of data PART-OF each step\", \"learning methods FEATURE-OF certain learning methods\", \"primal SVM COMPARE dual SVM\", \"design considerations FEATURE-OF traditional algorithms\", \"experiments EVALUATE-FOR effectiveness of proposed method\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  61%|██████    | 304/500 [32:51<30:10,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Interval Algebra USED-FOR representing qualitative temporal relations\", \"Region Connection Calculus USED-FOR reasoning about topological relations\", \"Qualitative Constraint Network (QCN) FEATURE-OF minimal labeling problem (MLP)\", \"algorithm USED-FOR deriving feasible base relations of a QCN\", \"chordal QCNs PART-OF proposed algorithm\", \"partial consistency FEATURE-OF proposed algorithm\", \"G-consistency FEATURE-OF proposed algorithm\", \"tractable subclasses of relations FEATURE-OF proposed algorithm\", \"patchwork property FEATURE-OF tractable subclasses of relations\", \"consistency EVALUATE-FOR which-consistency, consistency of the input QCN\", \"experimentations with QCNs of IA and RCC-8 COMPARE importance and efficiency of this new approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  61%|██████    | 305/500 [32:59<29:08,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"high-level program execution CHALLENGE-OF multi-agent settings\", \"high-level program execution RELATED-WORK\", \"completed work DESCRIBE\", \"future work DESCRIBE\", \"future work APPROACH\", \"research CONTRIBUTION-OF expected\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  61%|██████    | 306/500 [33:03<23:55,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"constraint propagation USED-FOR constraint programming\", \"short supports FEATURE-OF constraint propagation algorithms\", \"subset PART-OF short supports\", \"variable-value pair PART-OF solution\", \"SHORTSTR2 HYPONYM-OF Simple Tabular Reduction algorithm\", \"SHORTSTR2 COMPARE SHORTGAC\", \"SHORTSTR2 COMPARE HAGGISGAC\", \"short support set PART-OF constraint propagation\", \"SHORTSTR2 USED-FOR many constraints\", \"STR2+ USED-FOR memory\", \"SHORTSTR2 COMPARE STR2+\", \"algorithm IDENTIFY short supports\", \"SHORTSTR2 PART-OF drop-in replacement\", \"constraint amenable to short supports EVALUATE-FOR SHORTSTR2\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  61%|██████▏   | 307/500 [33:10<24:04,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"hashtag recommendation task USED-FOR microblogs\", \"CNNs USED-FOR hashtag recommendation problem\", \"trigger words FEATURE-OF proposed architecture\", \"proposed model EVALUATE-FOR state-of-the-art methods\", \"trigger words EVALUATE-FOR proposed method\", \"proposed method COMPARE state-of-the-art method\", \"attention mechanism PART-OF proposed architecture\", \"experiments EVALUATE-FOR proposed model\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  62%|██████▏   | 308/500 [33:17<23:05,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"auction domains HAVE UNCERTAINTY regarding final availability of goods\", \"government auction OFF spectrum from public safety network\", \"standard combinatorial auctions PERFORM POORLY in this domain\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  62%|██████▏   | 309/500 [33:20<18:57,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Coupled Marginalized Denoising Auto-encoders framework USED-FOR cross-domain learning\", \"marginalized denoising auto-encoders FEATURE-OF target and source\", \"feature mapping PART-OF Coupled Marginalized Denoising Auto-encoders framework\", \"maximum margin criterion EVALUATE-FOR discriminative features\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  62%|██████▏   | 310/500 [33:26<18:21,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"video representation USED-FOR video recognition tasks\", \"triplet sampling mechanism FEATURE-OF deep video representation\", \"graph structure PART-OF video\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  62%|██████▏   | 311/500 [33:28<15:07,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"automatic image annotation FEATURE-OF technique\", \"semantic image retrieval EVALUATE-FOR automatic image annotation\", \"Maximum Entropy Model-based approach USED-FOR automatic image annotation\", \"visual vocabulary PART-OF Maximum Entropy Model\", \"blob-tokens PART-OF visual vocabulary\", \"statistical relationship MODELED-BY Maximum Entropy Model\", \"training set EVALUATE-FOR Maximum Entropy Model\", \"unlabeled image EVALUATE-FOR predicted keywords\", \"blob-token set EXTRACTED-FROM image\", \"experimental results DEMONSTRATED annotation performance outperforms traditional annotation methods\", \"Maximum Entropy Model USED-FOR automatic image annotation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  62%|██████▏   | 312/500 [33:39<20:29,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"WSJ data USED-FOR train recognizer\", \"recognizer ADAPTED-EVALUATED-IN Phonebook domain\", \"Phonebook training corpus PART-OF adaptation data\", \"recognition performance EVALUATE-FOR Phonebook-trained baseline acoustic model\", \"out-of-domain training data USED-FOR improve recognition performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  63%|██████▎   | 313/500 [33:43<18:23,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"N-gram models USED-FOR statistical language modeling\", \"artificial neural networks USED-FOR learn language model\", \"neural network EVALUATE-FOR performance better than standard statistical methods\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  63%|██████▎   | 314/500 [33:47<16:04,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"multimodal dialog system USED-FOR speech, gesture, and mimics input and output\", \"speech understanding COMBINED-WITH video-based recognition\", \"computational methods DESIGNED-FOR integration and mutual disambiguation of multimodal input and output\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  63%|██████▎   | 315/500 [33:50<14:34,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"speaker verification system USED-FOR access control to rooms\", \"speech data PART-OF data base\", \"Hidden Markov Models FEATURE-OF recent experiments\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  63%|██████▎   | 316/500 [33:54<13:18,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method based-on statistical model USED-FOR blind estimation of reverberation times\", \"algorithm COMPUTE Maximum Likelihood estimate of room full-band reverberation time FOR speech utterance\", \"estimation method PERFORM satisfactorily\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  63%|██████▎   | 317/500 [33:57<12:24,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"language model adaptation methods USED-FOR word list and raw corpus\", \"general method USED-FOR segment raw corpus automatically using word list\", \"output sentences PART-OF segmented corpus\", \"sentence-by-sentence error correction method EVALUATE-FOR productivity\", \"word FEATURE-OF language model\", \"method COMPARE variety of methods for preparing segmented corpus\", \"language models COMPARE speech recognition accuracies\", \"our method USED-FOR language models\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  64%|██████▎   | 318/500 [34:02<13:33,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"automatic phonetic transcriptions USED-FOR large corpus-based study\", \"manually verified phonetic transcriptions USED-FOR large corpus-based study\", \"classifiers trained on speech processes FEATURE-OF APT and MPT alignments\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  64%|██████▍   | 319/500 [34:06<12:50,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"PASCAL challenge ORGANIZED-TO design statistical machine learning algorithm\", \"algorithm SEGMENT-WORDS-INTO morphemes\", \"morphemes SUITABLE-FOR speech and text understanding, machine translation, information retrieval, and statistical language modeling\", \"Twelve research groups PARTICIPATED-IN challenge\", \"research groups SUBMITTED segmentation results\", \"segmentation algorithms EVALUATED-FOR large vocabulary speech recognition\", \"language models BASED-ON proposed word segments\", \"Experiments DONE-FOR Finnish and Turkish languages\", \"various segmentations COMBINED-TO improve performance of recognizer\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  64%|██████▍   | 320/500 [34:14<15:31,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"dialogue management USED-FOR information navigation system\", \"information navigation system PART-OF document knowledge base\", \"N-best candidates FEATURE-OF ASR\", \"contextual information FEATURE-OF system performance\", \"selection OPTIMIZED-AS minimization of Bayes risk\", \"reward EVALUATE-FOR correct information presentation\", \"penalty EVALUATE-FOR redundant turns\", \"strategy EVALUATED-WITH spoken dialogue system\", \"spoken dialogue system COREF Dialogue Navigator for Kyoto City\", \"success rate EVALUATE-FOR retrieval\", \"average number of turns EVALUATE-FOR information access\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  64%|██████▍   | 321/500 [34:21<17:13,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"HMMs have weak duration constraints\", \"decoder produce word matches with unrealistic durations\", \"word duration probabilities applied directly to state transitions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  64%|██████▍   | 322/500 [34:23<13:59,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm USED-FOR Extra Large Vocabulary Continuous Speech recognition\", \"approach USED-FOR large vocabulary speech recognition\", \"first pass USED-FOR build words subset for second pass recognition\", \"information retrieval procedure FEATURE-OF word graph composition\", \"recognition process PART-OF two-pass algorithm\", \"second pass recognition EVALUATE-FOR large vocabulary speech recognition\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  65%|██████▍   | 323/500 [34:32<17:26,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"HMM-based TTS system USED-FOR German speech\", \"system adapted TO football announcements\", \"expressivity EVALUATE-FOR small size of football dataset\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  65%|██████▍   | 324/500 [34:36<15:50,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"information distillation USED-FOR extract relevant pieces of information\", \"our approach augment document retrieval for distillation\", \"distillation queries ASSOCIATED-WITH annotation elements\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  65%|██████▌   | 325/500 [34:39<13:41,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"study USED-FOR expressive speech communication\", \"emotion perceived BY listener\", \"intended emotion conveyed BY speaker\", \"analysis BASED-ON hypothesis\", \"people better decoders OF own emotions\", \"self-assessments closer TO intended emotions\", \"IEMOCAP database MATERIAL\", \"emotional assessments evaluated BY actors\", \"emotional assessments evaluated BY naive listeners\", \"mismatch BETWEEN expression AND perception OF emotion\", \"speakers assigned own emotions TO emotional categories\", \"extreme values IN activation-valence space\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  65%|██████▌   | 326/500 [34:45<14:56,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Czech talking head system USED-FOR visual speech animation\", \"3D animation model FEATURE-OF pseudo-muscular animation schema\", \"animation schema PART-OF visual speech animation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  65%|██████▌   | 327/500 [34:49<13:53,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"pool models DO NOT REPRODUCE dead time period\", \"OA IMPROVED phase locking in AN\", \"OA is crucial for auditory processing by ONs\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  66%|██████▌   | 328/500 [34:53<13:07,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"n-gram models lack structures\", \"dependency parser USED-FOR speech syntax modeling\", \"hand-crafted rules FEATURE-OF syntactic knowledge\", \"Bayesian inference samples rules\", \"rules disambiguate and combine to create tree structures\", \"tree structures MAXIMIZE posterior on target corpus\", \"posterior encodes selectional preferences\", \"model EVALUATE-FOR English and Czech newspaper texts\", \"model VALIDATE-FOR French broadcast news transcriptions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  66%|██████▌   | 329/500 [35:03<17:16,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SMT-style stochastic transduction grammar USED-FOR hip hop lyrics\", \"challenge-response system EVALUATE-FOR rhyming lyrics\", \"approach COMPLETELY UNSUPERVISED\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  66%|██████▌   | 330/500 [35:06<14:35,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"real-time VC USED-FOR silent speech enhancement\", \"real-time VC USED-FOR electrolaryngeal speech enhancement\", \"NAM PART-OF silent speech interface\", \"electrolaryngeal speech PART-OF alaryngeal speech\", \"VC FEATURE-OF speech enhancement systems\", \"DSP USED-FOR implementation of real-time VC\", \"computational resources COMPARE limited computational resources\", \"real-time VC EVALUATE-FOR running on a DSP\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  66%|██████▌   | 331/500 [35:14<16:53,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"multilingual feature-level data sharing FEATURE-OF Deep Neural Network\", \"language identification USED-FOR efficient use of multilingual resources\", \"bottleneck features trained on most similar source language EVALUATE-FOR better performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  66%|██████▋   | 332/500 [35:17<14:40,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"singing voice conversion USED-FOR convert singing voice characteristics\", \"SVC USED-FOR convert singing voice characteristics\", \"statistical singing voice conversion FEATURE-OF technique\", \"direct waveform modification FEATURE-OF statistical singing voice conversion\", \"spectrum differential FEATURE-OF statistical singing voice conversion\", \"source singer PART-OF singing voice conversion\", \"target singer PART-OF singing voice conversion\", \"vocoder USED-FOR generate converted singing voice waveforms\", \"speech quality EVALUATE-FOR converted singing voice\", \"analysis errors EVALUATE-FOR speech quality\", \"modeling errors EVALUATE-FOR speech quality\", \"statistical conversion process FEATURE-OF alleviate degradation\", \"signal FEATURE-OF statistical conversion process\", \"waveform domain FEATURE-OF statistical conversion process\", \"difference in spectra FEATURE-OF statistical conversion process\", \"differential Gaussian mixture model FEATURE-OF differential spectral feature\", \"traditional GMM USED-FOR conversion model\", \"conversion accuracy EVALUATE-FOR singer identity\", \"experimental results EVALUATE-FOR proposed method\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  67%|██████▋   | 333/500 [35:28<19:08,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"NIST i-vector challenge USED-FOR Speaker Recognition Evaluations\", \"i-vectors FEATURE-OF fixed-length feature vectors\", \"i-vector challenge COMPARE SRE series\", \"number of participants COMPARE factor of two increase\", \"number of systems submitted EVALUATE-FOR evaluation\", \"leading system achieved improvement EVALUATE-FOR baseline system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  67%|██████▋   | 334/500 [35:34<18:23,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"text input USED-FOR text-to-speech synthesis\", \"statistical model FEATURE-OF generating process\", \"Fujisaki model PART-OF discrete-time version\", \"algorithm EVALUATE-FOR estimating Fujisaki-model parameters\", \"sequence PART-OF Fujisaki-model parameters\", \"text input FEATURE-OF context-dependent model\", \"parameter training algorithm USED-FOR present model\", \"decision tree-based context clustering FEATURE-OF parameter training algorithm\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  67%|██████▋   | 335/500 [35:40<17:44,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Stacked Auto-Encoders USED-FOR learning imbalanced datasets\", \"Neural Network classifier furnished by SAE USED-FOR detecting errors made by ASR system\", \"ASR system HYPONYM-OF Automatic Speech Recognition system\", \"positive examples PART-OF training set for binary classifier\", \"different types of classifiers COMPARE classifier based on SAE\", \"performance EVALUATE-FOR predicting corresponding word error rate\", \"classifier based on SAE EVALUATE-FOR detecting ASR errors better than other classification methods\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  67%|██████▋   | 336/500 [35:47<18:08,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"text data scraped USED-FOR augment language models\", \"blogs FEATURE-OF language modeling of conversational telephone speech\", \"movie subtitles FEATURE-OF language modeling of conversational telephone speech\", \"web data EVALUATE-FOR Term Error Rate Performance\", \"web data EVALUATE-FOR Maximum Term-Weighted Value in Keyword Search\", \"reduction of out-of-vocabulary items PART-OF gain\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  67%|██████▋   | 337/500 [35:52<16:27,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"probabilistic parser USED-FOR candidate parses\", \"candidate parses PART-OF input sentence\", \"ranking EVALUATE-FOR parses\", \"model FEATURE-OF tree\", \"tree PART-OF features\", \"features PART-OF tree\", \"tree FEATURE-OF reranking task\", \"reranking task USED-FOR parsing\", \"Wall Street Journal treebank FEATURE-OF parsing data\", \"model EVALUATE-FOR F-measure\", \"baseline model EVALUATE-FOR F-measure error\", \"algorithm FEATURE-OF boosting approach\", \"feature space PART-OF parsing data\", \"boosting approach COMPARE feature selection methods\", \"NLP problems HYPONYM-OF ranking tasks\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  68%|██████▊   | 338/500 [36:00<18:13,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method USED-FOR discovering parallel sentences\", \"maximum entropy classifier FEATURE-OF method\", \"pair of sentences HYPONYM-OF translations\", \"parallel data PART-OF Chinese newspaper corpus\", \"parallel data PART-OF Arabic newspaper corpus\", \"parallel data PART-OF English newspaper corpus\", \"quality of extracted data EVALUATE-FOR performance of machine translation system\", \"MT system USED-FOR building from scratch\", \"small parallel corpus PART-OF building MT system\", \"large non-parallel corpus USED-FOR building MT system\", \"method USED-FOR language pairs with scarce resources\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  68%|██████▊   | 339/500 [36:07<18:24,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"natural language text CREATED-BY Fragment-and-Compose paradigm\", \"KDS EMBODIES Fragment-and-Compose paradigm\", \"propositional units CREATED-FOR knowledge\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  68%|██████▊   | 340/500 [36:10<15:16,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"natural language question answering system PART-OF Chat-80\", \"Chat-80 USED-FOR variety of applications\", \"Prolog FEATURE-OF Chat-80\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  68%|██████▊   | 341/500 [36:13<12:48,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"error correction DONE-BY parsing\", \"dialogue patterns USED-FOR predicting new inputs\", \"dialogue acquisition and tracking algorithm PART-OF voice interactive system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  68%|██████▊   | 342/500 [36:17<11:39,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"theory of discourse structure FEATURE-OF linguistic structure\", \"linguistic structure PART-OF discourse\", \"intentional structure PART-OF linguistic segments\", \"attentional state PART-OF discourse\", \"discourse phenomena EVALUATE-FOR cue phrases\", \"discourse processing USED-FOR recognizing intentions\", \"discourse processing USED-FOR tracking discourse\", \"discourse processing USED-FOR recognizing utterances\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  69%|██████▊   | 343/500 [36:22<12:36,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"work enrichment USED-FOR human-machine interactions\", \"speaker CONTEXT-OF beliefs\", \"listener CONTEXT-OF beliefs\", \"speaker CONTEXT-OF perceptions\", \"listener CONTEXT-OF perceptions\", \"speaker CONTEXT-OF backgrounds\", \"listener CONTEXT-OF backgrounds\", \"speaker CONTEXT-OF goals\", \"listener CONTEXT-OF goals\", \"difficulties ARISE-FROM conversation\", \"mistakes ARISE-FROM interpretation\", \"misunderstandings ARISE-FROM mistakes\", \"miscommunications ARISE-FROM misunderstandings\", \"mistakes SLOW communication\", \"mistakes BREAK-DOWN communication\", \"miscommunications EVALUATE-FOR recognition\", \"miscommunications EVALUATE-FOR isolation\", \"miscommunications CIRCUMVENTED-BY techniques\", \"miscommunications ARISE-FROM reference problems\", \"framework LESS-RESTRICTIVE-THAN earlier ones\", \"speaker LEEWAY-FOR forming utterance\", \"speaker DETERMINES conversational vehicle\", \"paper PROMOTES new view\", \"extensional reference FEATURE-OF new view\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  69%|██████▉   | 344/500 [36:35<18:26,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"English trans-context-free ON-BASIS-OF coordinations\", \"agreement INVOLVES number in nouns\", \"agreement INVOLVES reflexive pronouns\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  69%|██████▉   | 345/500 [36:39<16:25,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"dictionary word sense definitions FEATURE-OF Longman Dictionary of Contemporary English\", \"experimental system USED-FOR processing definitions\", \"restricted vocabulary FEATURE-OF word sense definitions\", \"structures GENERATED-FOR classification of new word senses\", \"phrasal analysis rules PART-OF analysis process\", \"hierarchy OF phrasal patterns HYPONYM-OF patterns\", \"patterns DOMINATE more specific ones\", \"incomplete analyses GENERATED-FOR definitions\", \"robust analysis mechanism EVALUATE-FOR incomplete analyses\", \"robustness problems ADDRESSED-BY work\", \"incomplete lexicon COMPARED-WITH incomplete knowledge of phrasal constructions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  69%|██████▉   | 346/500 [36:47<17:34,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"intelligent interactive systems COMMUNICATE-WITH humans\", \"user modeling ROLE-IN intelligent interactive systems\", \"user model CHARACTERIZATION-IS-OF user model\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  69%|██████▉   | 347/500 [36:50<14:10,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"model CHARACTERIZE class of languages\", \"model AUGMENTED-WITH ability to check reduplication\", \"class of languages STRICTLY-BETWEEN context-free languages and indexed languages\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  70%|██████▉   | 348/500 [36:54<12:41,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"editor USED-FOR dictionary\", \"lexicologists USED-FOR dictionary\", \"linguistic theory FEATURE-OF dictionary\", \"lexicons USED-FOR natural language processing\", \"grammars USED-FOR natural language processing\", \"linguistic databases PART-OF natural language processing\", \"coherence rules FEATURE-OF lexical entries\", \"interface FEATURE-OF browsing\", \"interface FEATURE-OF editing\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  70%|██████▉   | 349/500 [36:59<12:44,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"explanation system constructs multisentential and multi-paragraph explanations FROM large-scale knowledge base\", \"explanation generation FROM semantically rich, large-scale knowledge bases\", \"performance assessed WITH methodology\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  70%|███████   | 350/500 [37:02<11:38,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"language corpus annotation scenario USED-FOR discourse relations\", \"syntactically motivated relations FEATURE-OF discourse\", \"Prague Dependency Treebank 2.0 PART-OF theoretical background\", \"Penn Discourse Treebank 2 PART-OF theoretical background\", \"syntactico-semantic annotation FEATURE-OF Prague Dependency Treebank\", \"sentence-boundary-crossing representation USED-FOR syntactico-semantic annotation\", \"discourse level annotation USED-FOR syntactico-semantic annotation\", \"Praguian dependency-based approach COMPARE Penn discourse annotation\", \"discourse connectives PART-OF Penn discourse annotation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  70%|███████   | 351/500 [37:10<13:31,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"experiments REPORTED-OF acquisition of Italian and English verb subcategorization frames FROM general and domain corpora\", \"proposed technique operates ON syntactically shallow-parsed corpora\", \"search heuristics not relying ON previous lexico-syntactic knowledge ABOUT SCFs\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  70%|███████   | 352/500 [37:14<12:28,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"hypotheses graph PART-OF translation hypotheses\", \"nodes PART-OF hypotheses graph\", \"vectors representing morpho-syntactic properties FEATURE-OF nodes\", \"statistical feature functions FEATURE-OF vectors\", \"feature functions TRAINED-OFFLINE different types of text\", \"log-linear combination USED-FOR retrieve best M translation paths\", \"language modelling toolkits COMPARE CMU SRI toolkit\", \"word-lemma based feature function models COMPARE token-based models\", \"PoS-tag feature function FEATURE-OF word-lemma model\", \"weights SUITABLE-IF training material SIMILAR-TO texts\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  71%|███████   | 353/500 [37:21<14:03,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"term candidates EXTRACTED-BY looking for internal and contextual information associated with domain specific terms\", \"algorithms FACE-DILEMMA that fewer features are not enough to distinguish terms from non-terms\", \"more features LEAD-TO conflicts among selected features\", \"novel approach PRESENTED-FOR term extraction based on delimiters\", \"proposed approach NOT-SENSITIVE-TO term frequency\", \"proposed approach REQUIRES-NO prior domain knowledge and no additional training to adapt to new domains\", \"proposed approach APPLIED-TO different domains easily\", \"proposed approach USEFUL-FOR resource-limited domains\", \"evaluations CONDUCTED-ON two different domains for Chinese term extraction\", \"significant improvements SHOWN-OVER existing techniques\", \"proposed approach VERIFIES-EFFICIENCY and domain independent nature\", \"experiments ON new term extraction indicate that the proposed approach CAN-SERVE-AS effective tool for domain lexicon expansion\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  71%|███████   | 354/500 [37:32<17:46,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SyntLex project AIMING-AT lexicon grammar\", \"project MAIN computer-assisted acquisition of verb-noun collocations\", \"methodology and resources OBTAINED-IN three main project phases\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  71%|███████   | 355/500 [37:36<14:57,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Czech MWE database PART-OF Word Sketch Engine\", \"MWEs FEATURE-OF corpus data\", \"MWEs USED-FOR tagging and lemmatization\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  71%|███████   | 356/500 [37:40<13:16,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"PAKTUS USED-FOR building NLP systems\", \"core English lexicon PART-OF PAKTUS\", \"grammar PART-OF PAKTUS\", \"concept representations PART-OF PAKTUS\", \"NLP system USED-FOR text understanding\", \"electronic message stream FEATURE-OF input to NLP system\", \"JINTACCS messages HYPONYM-OF sublanguage\", \"RAINFORM messages HYPONYM-OF sublanguage\", \"news reports HYPONYM-OF sublanguage\", \"sublanguage FEATURE-OF domain-specific grammar\", \"words FEATURE-OF PAKTUS\", \"conceptual mappings FEATURE-OF PAKTUS\", \"discourse patterns FEATURE-OF PAKTUS\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  71%|███████▏  | 357/500 [37:48<15:07,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SPoT sentence planner USED-FOR sentence planning\", \"sentence scoping PART-OF sentence planning\", \"SPG FEATURE-OF sentence planning\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  72%|███████▏  | 358/500 [37:51<12:53,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"utterance classification FEATURE-OF method\", \"acoustic models FEATURE-OF method\", \"classifiers FEATURE-OF method\", \"word-trigram recognition COMPARE manual transcription\", \"unsupervised training USED-FOR phone n-gram model\", \"phone n-gram model FEATURE-OF domain\", \"recognition USED-FOR phone-string classifier\", \"method EVALUATE-FOR classification accuracy\", \"spoken language system domains FEATURE-OF evaluation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  72%|███████▏  | 359/500 [37:57<13:08,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ensemble methods USED-FOR machine learning\", \"multi-strategy approach USED-FOR question answering\", \"answering agents FEATURE-OF multi-level answer resolution algorithm\", \"knowledge-based mechanisms FEATURE-OF answering agents\", \"statistical techniques FEATURE-OF answering agents\", \"multi-level answer resolution algorithm EVALUATE-FOR effectiveness of answer resolution\", \"baseline system COMPARE answer resolution algorithm\", \"average precision metric EVALUATE-FOR effectiveness of answer resolution\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  72%|███████▏  | 360/500 [38:04<13:29,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ONTOSCORE system USED-FOR scoring sets of concepts\", \"ONTOSCORE system USED-FOR scoring speech recognition hypotheses\", \"ONTOSCORE system EVALUATE-FOR semantic coherence\", \"annotation experiment USED-FOR differentiating between semantically coherent and incoherent speech recognition hypotheses\", \"human annotators EVALUATE-FOR differentiating between semantically coherent and incoherent speech recognition hypotheses\", \"speech recognition hypotheses PART-OF sets of concepts\", \"ONTOSCORE system EVALUATE-FOR 73.2% classification accuracy\", \"German corpus PART-OF sets of speech recognition hypotheses\", \"baseline USED-FOR classification of speech recognition hypotheses\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  72%|███████▏  | 361/500 [38:12<15:00,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"phrase-based translation model FEATURE-OF decoding algorithm\", \"phrase-based translation models COMPARE word-based models\", \"phrase translations USED-FOR heuristic learning\", \"phrase translations FEATURE-OF lexical weighting\", \"phrases longer than three words COREF syntactically motivated phrases\", \"language pairs EVALUATE-FOR performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  72%|███████▏  | 362/500 [38:17<13:47,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"generative probabilistic OCR model USED-FOR error correction\", \"model USED-FOR post-processing OCR system output\", \"model REDUCES character error rate\", \"model REDUCES word error rate\", \"automatic extraction EVALUATE-FOR translation lexicons\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  73%|███████▎  | 363/500 [38:21<12:32,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ambiguity packing USED-FOR Lexical-Functional Grammars\", \"stochastic disambiguation techniques FEATURE-OF ambiguity packing\", \"sentence condensation TASK\", \"linguistic parser/generator PART-OF LFG\", \"transfer component PART-OF parse reduction\", \"packed parse forests MATERIAL\", \"maximum-entropy model PART-OF stochastic output selection\", \"parser evaluation methods FEATURE-OF summarization\", \"automatic parse-based evaluation EVALUATE-FOR summarization systems\", \"manual evaluation EVALUATE-FOR generated strings\", \"proposed system COMPARE state-of-the-art\", \"constraint-based parser/generator FEATURE-OF grammaticality\", \"system output PART-OF constraint-based parser/generator\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  73%|███████▎  | 364/500 [38:29<14:24,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"part-of-speech tagger FEATURE-OF dependency network representation\", \"part-of-speech tagger FEATURE-OF conditional loglinear models\", \"part-of-speech tagger EVALUATE-FOR accuracy\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  73%|███████▎  | 365/500 [38:33<12:42,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"training data USED-FOR language modeling\", \"conversational speech PART-OF language modeling\", \"training data FEATURE-OF language modeling\", \"text USED-FOR language modeling\", \"web USED-FOR language modeling\", \"style FEATURE-OF text\", \"topic FEATURE-OF text\", \"target recognition task USED-FOR text\", \"performance gains EVALUATE-FOR data\", \"class-dependent interpolation FEATURE-OF N-grams\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  73%|███████▎  | 366/500 [38:38<12:19,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"EBMT system USED-FOR translation quality\", \"out-of-domain bilingual corpus USED-FOR EBMT\", \"language model FEATURE-OF monolingual corpus\", \"BLEU score EVALUATE-FOR EBMT system\", \"NIST score EVALUATE-FOR EBMT system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  73%|███████▎  | 367/500 [38:43<11:28,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"unsupervised technique USED-FOR learning morphology\", \"node PART-OF graph\", \"word-trie PART-OF minimal DFA\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  74%|███████▎  | 368/500 [38:46<10:13,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"syntax-based constraint FEATURE-OF word alignment\", \"cohesion constraint FEATURE-OF word alignment\", \"English phrases PART-OF cohesion constraint\", \"non-overlapping intervals PART-OF cohesion constraint\", \"cohesion constraint USED-FOR word alignment\", \"two different algorithms EVALUATE-FOR utility\", \"significant improvement EVALUATE-FOR alignment quality\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  74%|███████▍  | 369/500 [38:51<09:55,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"bootstrapping approach USED-FOR Named Entity tagging\", \"concept-based seeds FEATURE-OF NE\", \"successive learners PART-OF bootstrapping procedure\", \"decision list USED-FOR parsing-based NE rules\", \"Hidden Markov Model USED-FOR corpus\", \"NE system EVALUATE-FOR supervised NE performance\", \"NE system HYPONYM-OF Named Entity system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  74%|███████▍  | 370/500 [38:57<11:05,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"phrase-based unigram model USED-FOR statistical machine translation\", \"units of translation PART-OF blocks\", \"block unigram model FEATURE-OF decoding\", \"word-based trigram language model FEATURE-OF decoding\", \"blocks LEARNED-FROM source interval projections\", \"block selection criteria EVALUATE-FOR unigram counts\", \"block selection criteria EVALUATE-FOR phrase length\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  74%|███████▍  | 371/500 [39:03<11:29,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Cooperative Model USED-FOR natural language understanding\", \"Cooperative Model USED-FOR dialogue system\", \"Finite State Model FEATURE-OF language understanding\", \"Statistical Learning Model FEATURE-OF language understanding\", \"Cooperative Model PART-OF all the three strategies\", \"Cooperative Model COMPARE Finite State Model and Statistical Learning Model\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  74%|███████▍  | 372/500 [39:08<11:01,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"TAP-XL Automated Analyst's Assistant USED-FOR topical report\", \"English-speaking analyst GENERIC analyst\", \"multilingual, multimedia data MATERIAL data\", \"human language technology FEATURE-OF TAP-XL Automated Analyst's Assistant\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  75%|███████▍  | 373/500 [39:13<11:04,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"JAVELIN system USED-FOR open-domain question answering capability\", \"JAVELIN system processes questions\", \"JAVELIN system retrieves answer candidates FEATURE-OF text corpus\", \"JAVELIN system creates data objects PART-OF question answering session\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  75%|███████▍  | 374/500 [39:16<09:52,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Question Answering system EVALUATE-FOR FAQ-like questions\", \"noisy-channel architecture USED-FOR building system\", \"language model FEATURE-OF answers\", \"transformation model FEATURE-OF answer/question terms\", \"corpus PART-OF training data\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  75%|███████▌  | 375/500 [39:20<09:10,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"MBR decoding USED-FOR statistical machine translation\", \"loss functions FEATURE-OF MBR decoding\", \"linguistic information PART-OF loss functions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  75%|███████▌  | 376/500 [39:23<08:25,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"CriterionSM Online Essay Evaluation Service includes capability labels sentences essay-based discourse elements\", \"new system enhances Criterion's capability evaluating multiple aspects coherence essays\", \"system identifies features sentences based semantic similarity measures discourse structure\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  75%|███████▌  | 377/500 [39:27<07:51,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"English text USED-FOR American Sign Language animation\", \"MT architectural designs LIMITS-OF traditional MT architectural designs\", \"semantic representation FEATURE-OF classifier predicates\", \"virtual reality 3D scene modeling software USED-FOR spatially complex ASL phenomena\", \"classifier predicates PART-OF ASL phenomena\", \"interlingua PART-OF multi-pathway MT architecture design\", \"transfer APPROACH-OF multi-pathway MT architecture design\", \"direct APPROACH-OF multi-pathway MT architecture design\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  76%|███████▌  | 378/500 [39:37<11:28,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"information extraction techniques USED-FOR structured databases\", \"systems EVALUATE-FOR accuracy\", \"linear-chain conditional random field (CRF) FEATURE-OF information extraction system\", \"probabilistic model FEATURE-OF linear-chain conditional random field (CRF)\", \"Markov model FEATURE-OF linear-chain conditional random field (CRF)\", \"confidence EVALUATE-FOR extracted fields\", \"confidence EVALUATE-FOR multi-field records\", \"average precision EVALUATE-FOR retrieving correct fields\", \"average precision EVALUATE-FOR multi-field records\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  76%|███████▌  | 379/500 [39:44<12:11,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"entailment acquisition COMPARE paraphrases acquisition\", \"method discovers verb entailment USING discourse relations\", \"proposed method COVERS wider range of verb entailment types\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  76%|███████▌  | 380/500 [39:48<11:09,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"temporal expressions ANCHOROR-OF TCNL\", \"TEA COMPARE baseline\", \"TEA EVALUATE-FOR temporal expression anchoring\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  76%|███████▌  | 381/500 [39:51<09:33,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"convolution kernel USED-FOR relation extraction\", \"parse tree FEATURE-OF syntactic structure features\", \"convolution tree kernel FEATURE-OF syntactic structure features\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  76%|███████▋  | 382/500 [39:54<08:29,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Question Answering systems EVALUATE-FOR paraphrased questions\", \"MT-based paraphrasing technique USED-FOR paraphrased questions\", \"MRR EVALUATE-FOR Question Answering systems\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  77%|███████▋  | 383/500 [39:58<07:51,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"information extraction USED-FOR token classification task\", \"tagging strategies FEATURE-OF token classification task\", \"BIA COMPARE other strategies\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  77%|███████▋  | 384/500 [40:00<07:01,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"interactive corpus exploration tool FEATURE-OF InfoMagnets\", \"exploratory corpus analysis USED-FOR researchers\", \"language RELATED-TO behavioral patterns\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  77%|███████▋  | 385/500 [40:03<06:38,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"temporal difference value estimation algorithms FEATURE-OF bias\", \"temporal difference value estimation algorithms FEATURE-OF variance\", \"offline updates USED-FOR temporal difference value estimation algorithms\", \"learning curve behavior FEATURE-OF absorbing Markov chains\", \"TD COMPARE step-size and eligibility trace parameters\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  77%|███████▋  | 386/500 [40:08<07:11,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"multilayer neural network USED-FOR computing function\", \"hidden layers REQUIRED-BY multilayer neural network\", \"function f COMPUTED-BY multilayer neural network\", \"dimension d=2\", \"Gibson CHARACTERIZED-FUNCTIONS-COMPUTABLE-WITH-ONE-HIDDEN-LAYER\", \"function f RESTRICTED-TO neighborhood of multiple intersection point COMPUTABLE-WITH-ONE-HIDDEN-LAYER\", \"function f RESTRICTED-TO neighborhood of infinity COMPUTABLE-WITH-ONE-HIDDEN-LAYER\", \"necessary conditions GIVEN-FOR local computability with one hidden layer\", \"sufficient conditions GIVEN-FOR local computability with one hidden layer\", \"Gibson's assumptions NOT-SUFFICIENT-FOR global computability with one hidden layer\", \"new non-local configuration EXHIBITED-CRITICAL-CYCLE\", \"critical cycle IMPLIES f NOT-COMPUTABLE-WITH-ONE-HIDDEN-LAYER\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  77%|███████▋  | 387/500 [40:18<10:48,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"arm reaching movements PART-OF distributed neural networks\", \"single neurons TUNED-TO parameters of movement\", \"appropriate commands ELABORATED-BY populations of neurons\", \"neuronal population vector (NPV) PROVIDES-ROUGH-ESTIMATE of movement parameters\", \"model DESIGNED-TO investigate relation between desired direction, actual direction, and direction of NPV\", \"self-organizing neural network COMBINES proprioceptive and visual information\", \"network TRAINED-BY motor babbling\", \"small deviations EXISTED-AT extremities of workspace\", \"deviations ACCOMPANIED-BY large deviations of NPV\", \"NPV DOES-NOT-GIVE faithful image of cortical processing during arm reaching movements\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  78%|███████▊  | 388/500 [40:28<13:09,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"new variant of AdaBoost USED-FOR training simple classifiers\", \"cascade of simple classifiers PART-OF final detector\", \"experimental results EVALUATE-FOR performance improvements\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  78%|███████▊  | 389/500 [40:32<10:57,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"high-density analog array PART-OF externally digital architecture\", \"partial matrix-vector multiplication FEATURE-OF analog array\", \"random modulation scheme FEATURE-OF near-Bernoulli statistics\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  78%|███████▊  | 390/500 [40:35<09:40,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"factor analysis models observations AS linear combination of normally distributed hidden variables\", \"product analysis is a nonlinear generalization of factor analysis\", \"product analysis models observed variables AS linear combination of products of normally distributed hidden variables\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  78%|███████▊  | 391/500 [40:39<08:45,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"problem blind source separation PART-OF set\", \"mixing matrix UNKNOWN\", \"sparsity FEATURE-OF sources\", \"representation FEATURE-OF signal dictionary\", \"multi scale transforms USED-FOR decompose signals\", \"local features PART-OF sets\", \"sparsity FEATURE-OF degrees\", \"best subsets SELECTED-FOR separation\", \"algorithm EVALUATE-FOR noise-free data\", \"algorithm EVALUATE-FOR noisy data\", \"experiments COMPARE previously reported results\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  78%|███████▊  | 392/500 [40:45<09:16,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"citation matching USED-FOR deciding which citations correspond to the same publication\", \"relational probability model FEATURE-OF generative model\", \"author and title corruption PART-OF domain\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  79%|███████▊  | 393/500 [40:48<08:00,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"study of clustering FEATURE-OF single-linkage\", \"study of clustering FEATURE-OF sum-of-pairs\", \"study of clustering FEATURE-OF k-means\", \"study of clustering FEATURE-OF k-median\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  79%|███████▉  | 394/500 [40:52<07:48,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"bio-inspired model USED-FOR analog programmable array processor\", \"model mimics PROCESSING-OF images in visual pathway\", \"prototype chip PART-OF feasible alternative for implementation of early vision applications\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  79%|███████▉  | 395/500 [40:56<07:13,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"visual classification USED-FOR gender classification task\", \"human subjects EVALUATE-FOR gender judgment\", \"human subjects EVALUATE-FOR reaction time\", \"human subjects EVALUATE-FOR confidence rating\", \"hyperplane learning algorithms USED-FOR classification task\", \"Principal Components FEATURE-OF texture representation\", \"Principal Components FEATURE-OF flowfield representation\", \"classification performance EVALUATE-FOR face database\", \"classification performance EVALUATE-FOR true gender of the faces\", \"classification performance EVALUATE-FOR gender estimated by the subjects\", \"human responses COREF brain\", \"stimuli PART-OF feature space\", \"brain needs EVALUATE-FOR processing for stimuli close to hyperplane\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  79%|███████▉  | 396/500 [41:03<08:42,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm USED-FOR learning time-varying shape\", \"non-rigid 3D object PART-OF shape motion\", \"shape motion FEATURE-OF rigid component\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  79%|███████▉  | 397/500 [41:07<08:04,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Kikuchi approximation USED-FOR estimating log partition function\", \"product distribution DEFINED-OVER region graph\", \"reweighted objective function CONCAVE with weight assignments in Kikuchi expansion\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  80%|███████▉  | 398/500 [41:10<07:21,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"weighted expert voting USED-FOR decision-theoretic problem\", \"optimal Nitzan-Paroush weighted majority EVALUATE-FOR decision-theoretic problem\", \"competence levels FEATURE-OF expert\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  80%|███████▉  | 399/500 [41:13<06:41,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"low-level features CANNOT-ADEQUATELY-CHARACTERIZE rich spatial-temporal structures\", \"actions ENCODED-BASED-ON attributes\", \"attributes DESCRIBE-ACTIONS high-level concepts\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  80%|████████  | 400/500 [41:17<06:16,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"optimization algorithms USED-FOR penalized empirical risk minimization problems\", \"local smoothness FEATURE-OF loss functions\", \"algorithms PERFORM-BETTER-IN practice\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  80%|████████  | 401/500 [41:20<06:04,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"multinomial distribution USED-FOR modeling nucleotides, children's names, and text documents\", \"dependency PART-OF draws from multinomial or categorical distributions\", \"logistic stick-breaking representation FEATURE-OF multinomial distribution\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  80%|████████  | 402/500 [41:24<06:05,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"convolutional neural networks USED-FOR image classification\", \"stochastic attention-based models USED-FOR computational efficiency\", \"Wake-Sleep Recurrent Attention Model FEATURE-OF stochastic attention networks\", \"training deep generative models COMPARE Wake-Sleep Recurrent Attention Model\", \"posterior inference EVALUATE-FOR Wake-Sleep Recurrent Attention Model\", \"stochastic gradients EVALUATE-FOR Wake-Sleep Recurrent Attention Model\", \"training time EVALUATE-FOR stochastic attention networks\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  81%|████████  | 403/500 [41:30<07:14,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"joint matrix triangularization USED-FOR estimating joint eigenstructure\", \"set M PART-OF joint matrix triangularization problem\", \"matrices in M' EVALUATE-FOR approximate joint triangularizer\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  81%|████████  | 404/500 [41:33<06:23,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach USED-FOR NN search\", \"embedding FEATURE-OF points\", \"random-projection based methods FEATURE-OF NN search\", \"locality-sensitive hashing COMPARE random projection trees\", \"methodology EVALUATE-FOR correctness\", \"methodology EVALUATE-FOR competitiveness\", \"experimentation EVALUATE-FOR competitiveness\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  81%|████████  | 405/500 [41:38<06:45,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"segment order COMPARE segmentation\", \"segmentation COMPARE segment contiguity\", \"segment contiguity FEATURE-OF translation memory system\", \"retrieval performance EVALUATE-FOR translation memory system\", \"bag-of-words methods COMPARE segment order-sensitive methods\", \"retrieval accuracy EVALUATE-FOR bag-of-words methods\", \"retrieval accuracy EVALUATE-FOR segment order-sensitive methods\", \"indexing USED-FOR character bigrams\", \"word N-gram models COMPARE character bigrams\", \"findings EVALUATE-FOR scalability\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  81%|████████  | 406/500 [41:46<08:33,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"range concatenation grammar USED-FOR NLP\", \"range concatenation languages PARSED-IN polynomial time\", \"grammatical formalisms TRANSLATED-INTO equivalent RCGs\", \"tree adjoining grammar PARSED-IN O(n6) time\", \"parsing technique IMPROVES practical efficiency of RCL parsers\", \"non-deterministic parsing choices DIRECTED-BY guide\", \"shared derivation forest OUTPUT-BY RCL parser\", \"practical evaluation GIVEN-ON wide coverage English grammar\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  81%|████████▏ | 407/500 [41:52<08:35,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"paraphrasing FEATURE-OF interpretation\", \"paraphrasing FEATURE-OF generation\", \"systems USED-FOR collection of paraphrases\", \"unsupervised learning algorithm USED-FOR identification of paraphrases\", \"corpus PART-OF multiple English translations\", \"source text PART-OF multiple English translations\", \"approach yields phrasal paraphrases\", \"approach yields single word lexical paraphrases\", \"approach yields syntactic paraphrases\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  82%|████████▏ | 408/500 [41:57<08:24,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"alternative markers PART-OF words\", \"natural language search engines PERFORM-POORLY-ON queries containing alternative markers\", \"performance CAN-BE-IMPROVED-BY incorporating formal analysis\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  82%|████████▏ | 409/500 [42:01<07:22,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Minimalist grammars PART-OF Stabler's formalization\", \"Minimalist grammars HYPONYM-OF Chomsky's minimalist program\", \"logical definition FEATURE-OF Minimalist grammars\", \"logical definition PART-OF parsing-as-deduction\", \"categorial grammar PART-OF logical definition\", \"Montague semantics PART-OF categorial grammar\", \"learning algorithm USED-FOR structured data\", \"typing-algorithm FEATURE-OF learning algorithm\", \"type-unification FEATURE-OF learning algorithm\", \"Montague semantics COMPARE formal computation\", \"logical form PART-OF Montague semantics\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  82%|████████▏ | 410/500 [42:08<08:12,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"trainable sentence planner EVALUATE-FOR spoken dialogue system\", \"trainable sentence planner COMPARE rule-based systems\", \"trainable sentence planner COMPARE baselines\", \"trainable sentence planner COMPARE hand-crafted system\", \"rule-based sentence planners EVALUATE-FOR spoken dialogue system\", \"baseline sentence planners EVALUATE-FOR spoken dialogue system\", \"hand-crafted template-based generation component EVALUATE-FOR spoken dialogue system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  82%|████████▏ | 411/500 [42:13<07:50,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"supervised machine learning experiments USED-FOR construction of statistical models\", \"models FEATURE-OF WH-questions\", \"models EMPLOYED-FOR predict target variables\", \"target variables REPRESENT user's informational goals\", \"predictive performance EVALUATE-FOR models\", \"training and testing factors INFLUENCE predictive performance\", \"target variables COMPARE relationships among\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  82%|████████▏ | 412/500 [42:17<07:30,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"language model USED-FOR Chinese text input\", \"LM pruning FEATURE-OF language model\", \"rank EVALUATE-FOR character error rate\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  83%|████████▎ | 413/500 [42:21<06:39,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"supervised learning FEATURE-OF integration\", \"unsupervised learning FEATURE-OF integration\", \"human biases EVALUATE-FOR summarization\", \"probabilistic decision tree PART-OF clustering framework\", \"human created summaries PART-OF corpus\", \"newspaper corpus PART-OF corpus\", \"probabilistic decision trees FEATURE-OF different flavors\", \"mixture USED-FOR boost in performance\", \"paradigms COMPARE alone\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  83%|████████▎ | 414/500 [42:27<07:18,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Hidden Markov Model USED-FOR named entity recognition system\", \"HMM-based chunk tagger PART-OF named entity recognition system\", \"NER problem EVALUATE-FOR effectiveness\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  83%|████████▎ | 415/500 [42:31<06:37,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"IE paradigm USED-FOR predicate-argument structures\", \"inductive decision tree learning FEATURE-OF predicate-argument structure identification\", \"predicate-argument structures FEATURE-OF high quality IE results\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  83%|████████▎ | 416/500 [42:34<06:00,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"HDAG Kernel USED-FOR question classification\", \"HDAG Kernel USED-FOR sentence alignment tasks\", \"HDAG Kernel COMPARE other kernel functions\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  83%|████████▎ | 417/500 [42:38<05:43,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"clustering USED-FOR inducing semantic verb classes\", \"subcategorization frame distributions PART-OF clustering\", \"polysemy EVALUATE-FOR clusters\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  84%|████████▎ | 418/500 [42:41<05:06,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"decision tree based approach FEATURE-OF pronoun resolution\", \"system EVALUATE-FOR Switchboard dialogues\", \"manually tuned system COMPARE our system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  84%|████████▍ | 419/500 [42:44<04:49,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Link detection USED-FOR Topic Detection and Tracking tasks\", \"new event detection USED-FOR Topic Detection and Tracking tasks\", \"story link detection HYPONYM-OF new event detection\", \"story link detection USED-FOR information retrieval task\", \"new event detection USED-FOR information retrieval task\", \"precision EVALUATE-FOR story link detection\", \"recall EVALUATE-FOR story link detection\", \"precision EVALUATE-FOR new event detection\", \"recall EVALUATE-FOR new event detection\", \"part of speech tagging PART-OF performance enhancing techniques\", \"similarity measures FEATURE-OF performance enhancing techniques\", \"stop lists FEATURE-OF performance enhancing techniques\", \"Experimental results EVALUATE-FOR hypothesis\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  84%|████████▍ | 420/500 [42:52<06:36,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"discourse understanding process ENABLES system TO understand user utterances\", \"context OF dialogue DETERMINES understanding of user utterances\", \"multiple candidates CAN BE OBTAINED FOR understanding result OF user utterance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  84%|████████▍ | 421/500 [42:56<06:04,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"user model PROPOSED-FOR spoken dialogue systems\", \"skill level DIMENSION-OF user models\", \"knowledge level DIMENSION-OF user models\", \"degree of hastiness DIMENSION-OF user models\", \"decision tree learning USED-FOR deriving models\", \"dialogue data COLLECTED-BY system\", \"classification accuracy EVALUATED-FOR dimensions\", \"dialogue strategies IMPLEMENTED-IN Kyoto city bus information system\", \"cooperative responses ADAPTIVE-TO individual users\", \"guidance PROVIDED-FOR novice users\", \"dialogue duration NOT-INCREASED-FOR skilled users\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  84%|████████▍ | 422/500 [43:03<07:03,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"NLG systems HAVE-GROWN-COMPLEX\", \"architectural modules WERE-ADDED-TO NLG systems\", \"referring expressions IS-LANGUAGE-FUNCTIONALITY\", \"lexical choice IS-LANGUAGE-FUNCTIONALITY\", \"revision IS-LANGUAGE-FUNCTIONALITY\", \"discourse markers IS-ASPECT-OF multi-paragraph text\", \"discourse marker insertion algorithm IS-ASPECT-OF pipelined NLG architecture\", \"approach TIE-TO revision component\", \"approach EVALUATE-FOR multi-page system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  85%|████████▍ | 423/500 [43:11<07:47,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"unsupervised learning approach USED-FOR building non-English stemmer\", \"stemming model FEATURE-OF statistical machine translation\", \"English stemmer PART-OF stemming model\", \"parallel corpus PART-OF stemming model\", \"training resources PART-OF stemming model\", \"parallel text NOT-NEEDED-AFTER training phase\", \"Monolingual unannotated text USED-FOR improving stemmer\", \"stemmer ADAPTS-TO desired domain or genre\", \"resource-frugal approach USED-FOR building Arabic stemmer\", \"unsupervised component PART-OF proprietary Arabic stemmer\", \"Task-based evaluation EVALUATE-FOR Arabic information retrieval\", \"improvement in average precision\", \"unstemmed text COMPARE stemmed text\", \"proprietary stemmer COMPARE unsupervised approach\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  85%|████████▍ | 424/500 [43:20<08:45,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response for prompt at index 424: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0a3805c8e7ab28b1eda6af694470eeb6 in your message.)\n",
      "Query: Give me a comma-separated list of detected triples from the provided abstract, as long as the entities and relationships are in this list of restricted entity and relationship types:\n",
      "    ###\n",
      "    The entity types must be in: [Task, Method, Evaluation Metric, Material, Other Scientific Terms, Generic].\n",
      "    ###\n",
      "    Here are some examples of each type of entity that may be detected:\n",
      "    Task: Applications, problems to solve, systems to construct. E.g. information extraction, machine reading system, image segmentation.\n",
      "    Method: Methods , models, systems to use, or tools, components of a system, frameworks. E.g. language model, CORENLP, POS parser, kernel method.\n",
      "    Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method. E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness,\n",
      "    time complexity.\n",
      "    Material: Data, datasets, resources, Corpus, Knowledge base. E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL,\n",
      "    Panntreebank, WordNet, Wikipedia.\n",
      "    Other Scientific Terms: Phrases that are a scientific terms but do not fall into any of the above classes E.g. physical or geometric constraints, qualitative prior knowledge, discourse structure, syntactic rule,\n",
      "    discourse structure, tree, node, tree kernel, features, noise, criteria.\n",
      "    Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. E.g model, approach, prior knowledge, them, it.\n",
      "    ###\n",
      "    The relationships types must be in: [USED-FOR, FEATURE-OF, HYPONYM-OF, PART-OF, EVALUATE-FOR, COMPARE, CONJUNCTION, COREF].\n",
      "    ###\n",
      "    Here are some examples of triples that may be detected, that pertain to the restricted entities and relationships (note that you do not need to give me the type of entity, just the entity itself):\n",
      "    USED-FOR: \"The TISPER system has been designed to enable many text applications, Our method models user proficiency\" would become \"TISPER system USED-FOR text applications\".\n",
      "    FEATURE-OF: \"prior knowledge of the model\" would become \"prior knowledge FEATURE-OF model\".\n",
      "    HYPONYM-OF: \"TUIT is a software library.\" would become \"TUIT HYPONYM-OF software library\".\n",
      "    PART-OF: \"We incorporate NLU module to the system.\" would become \"NLU module PART-OF system\".\n",
      "    EVALUATE-FOR: \"our work improves both the quality and the efficiency of entity summarization\" would become \"efficiency EVALUATE-FOR entity summarization\".\n",
      "    COMPARE: \"Unlike the quantitative prior, the qualitative prior is often ignored\" would become \"quantitative prior COMPARE qualitative prior\".\n",
      "    CONJUNCTION: \"obtained from human expert or knowledge base\" would become \"human expert CONJUNCTION knowledge base\".\n",
      "    COREF: \"We introduce a machine reading system... The system...\" would become \"machine reading system COREF system\".\n",
      "    ###\n",
      "    Desired response format: ###\n",
      "    [triple1, triple2, triple3]\n",
      "    ###\n",
      "    Example response: ###\n",
      "    [\"machine reading system COREF system\", \"prior knowledge FEATURE-OF model\", \"TISPER system USED-FOR text applications\"]\n",
      "    ###\n",
      "    The provided abstract is: ###\n",
      "     \n",
      "A central problem of  word sense disambiguation (WSD)  is the lack of  manually sense-tagged data  required for  supervised learning  . In this paper, we evaluate an approach to automatically acquire  sense-tagged training data  from  English-Chinese parallel corpora  , which are then used for disambiguating the  nouns  in the  SENSEVAL-2 English lexical sample task  . Our investigation reveals that this  method of acquiring sense-tagged data  is promising. On a subset of the most difficult  SENSEVAL-2 nouns  , the  accuracy  difference between the two approaches is only 14.0%, and the difference could narrow further to 6.5% if we disregard the advantage that  manually sense-tagged data  have in their  sense coverage  . Our analysis also highlights the importance of the issue of  domain dependence  in evaluating  WSD programs  . \n",
      "    ###\n",
      "    \n",
      "Retrying in 5 seconds...\n",
      "[\"word sense disambiguation USED-FOR supervised learning\", \"approach EVALUATE-FOR sense-tagged training data\", \"English-Chinese parallel corpora PART-OF approach\", \"nouns IN SENSEVAL-2 lexical sample task\", \"method of acquiring sense-tagged data FEATURE-OF promising\", \"accuracy COMPARE difference between two approaches\", \"manually sense-tagged data FEATURE-OF sense coverage\", \"domain dependence EVALUATE-FOR WSD programs\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  85%|████████▌ | 425/500 [44:06<23:17, 18.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"construction semantically annotated corpus resource USED-FOR acquisition word-semantic information\", \"domain-independent lexica PART-OF construction\", \"semantic roles FEATURE-OF annotation\", \"frame semantics paradigm FEATURE-OF semantic roles\", \"annotated data EVALUATE-FOR project stage\", \"vagueness EVALUATE-FOR semantic annotation\", \"ambiguity EVALUATE-FOR semantic annotation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  85%|████████▌ | 426/500 [44:11<18:10, 14.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"embodied conversational agents FEATURE-OF design\", \"signals USED-FOR establish common ground\", \"eye gaze PART-OF nonverbal behaviors\", \"head nods PART-OF nonverbal behaviors\", \"attentional focus PART-OF nonverbal behaviors\", \"dialogue move HYPONYM-OF direction-giving task\", \"nonverbal behaviors USED-FOR grounding\", \"negative feedback HYPONYM-OF lack\", \"ECA USED-FOR update dialogue state\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  85%|████████▌ | 427/500 [44:17<14:33, 11.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"CFG filtering techniques COMPARE HPSG\", \"approximation of HPSG USED-FOR CFG filter\", \"LTAG USED-FOR CFG filter\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  86%|████████▌ | 428/500 [44:20<11:22,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"head-driven statistical parsing model USED-FOR simultaneous language model\", \"head-driven statistical parsing model USED-FOR parser\", \"large-vocabulary speech recognition USED-FOR head-driven statistical parsing model\", \"model FEATURE-OF parser\", \"online left to right chart-parser PART-OF parser\", \"word lattices PART-OF online left to right chart-parser\", \"acoustic probabilities FEATURE-OF online left to right chart-parser\", \"n-gram probabilities FEATURE-OF online left to right chart-parser\", \"parser probabilities FEATURE-OF online left to right chart-parser\", \"parser USED-FOR recognition\", \"structural dependencies FEATURE-OF parser\", \"lexical dependencies FEATURE-OF parser\", \"n-gram models COMPARE parser\", \"Wall Street Journal treebank PART-OF experiments\", \"lattice corpora PART-OF experiments\", \"word error rates EVALUATE-FOR speech understanding\", \"structural information FEATURE-OF speech understanding\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  86%|████████▌ | 429/500 [44:31<11:33,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach USED-FOR acquiring English topic signatures\", \"concept PART-OF topic signature\", \"words FEATURE-OF topic signature\", \"topic signatures USED-FOR NLP applications\", \"Word Sense Disambiguation (WSD) EVALUATE-FOR topic signatures\", \"method USED-FOR Word Sense Disambiguation (WSD)\", \"word senses HYPONYM-OF topic signatures\", \"English HYPONYM-OF topic signatures\", \"Chinese HYPONYM-OF topic signatures\", \"Chinese text FEATURE-OF method\", \"corpora FEATURE-OF method\", \"topic signatures EVALUATE-FOR WSD task\", \"second-order vector cooccurrence algorithm USED-FOR WSD task\", \"standard WSD datasets FEATURE-OF WSD task\", \"promising results EVALUATE-FOR WSD task\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  86%|████████▌ | 430/500 [44:42<11:44, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ensemble learning approach USED-FOR resolving German pronouns\", \"Boosting METHOD-OF ensemble learning approach\", \"classifiers HYPONYM-OF hypotheses\", \"ensemble learning approach FEATURE-OF decision-tree classifier\", \"standalone system USED-FOR resolving pronouns in unannotated text\", \"preprocessing modules PART-OF standalone system\", \"manual annotation process HYPONYM-OF preprocessing modules\", \"system EVALUATE-FOR limited textual domain\", \"research NEEDED-FOR effective open-domain question answering\", \"research NEEDED-FOR effective text summarisation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  86%|████████▌ | 431/500 [44:48<10:17,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"PCFG-LA model FEATURE-OF non-terminal symbols\", \"PCFG-LA model USED-FOR training\", \"PCFG-LA model EVALUATE-FOR performance\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  86%|████████▋ | 432/500 [44:51<08:13,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"automatic assessment EVALUATE-FOR local coherence\", \"entity-based representation FEATURE-OF discourse\", \"Centering Theory HYPONYM-OF coherence assessment\", \"discourse representation PART-OF coherence assessment\", \"ranking function USED-FOR coherence assessment\", \"induced model COMPARE state-of-the-art coherence model\", \"accuracy EVALUATE-FOR induced model\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  87%|████████▋ | 433/500 [44:57<07:39,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"corpus study EXPLORES extent captions contribute recognizing intended message information graphic\", \"graphic interpretation system IMPLEMENTED takes into account variety communicative signals\", \"evidence obtained shallow processing caption IMPACT system success\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  87%|████████▋ | 434/500 [45:01<06:28,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"phrase-based statistical machine translation USED-FOR retrieval of arbitrarily long phrases\", \"suffix array-based data structure PART-OF our phrase-based statistical machine translation\", \"sampling FEATURE-OF reduction in retrieval time\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  87%|████████▋ | 435/500 [45:05<05:44,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach combines syntactic information WITH phrasal translation\", \"method requires source-language dependency parser\", \"method requires target language word segmentation\", \"method requires unsupervised word alignment component\", \"parallel corpus USED-FOR align\", \"source dependency parse PROJECTED-ONTO target sentence\", \"extract dependency treelet translation pairs\", \"tree-based ordering model TRAINED\", \"decoder DESCRIBED\", \"tree-based models USED-WITH conventional SMT models\", \"approach incorporates power OF phrasal SMT WITH linguistic generality available IN parser\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  87%|████████▋ | 436/500 [45:14<06:54,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"unlexicalized parser USED-FOR German\", \"smoothing FEATURE-OF unlexicalized parser\", \"suffix analysis FEATURE-OF unlexicalized parser\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  87%|████████▋ | 437/500 [45:17<05:38,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"information extraction USED-FOR classified advertisements\", \"information extraction USED-FOR bibliographic citations\", \"supervised training data EVALUATE-FOR applicability of information extraction techniques\", \"unsupervised HMM learning COMPARE supervised methods\", \"unsupervised methods EVALUATE-FOR accuracies\", \"semi-supervised methods EVALUATE-FOR small amounts of labeled data\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  88%|████████▊ | 438/500 [45:21<05:18,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"word sense disambiguation USED-FOR translation candidates\", \"Chinese word sense disambiguation model USED-FOR translation candidates\", \"word sense disambiguation EVALUATE-FOR translation quality\", \"statistical machine translation system EVALUATE-FOR translation quality\", \"word sense disambiguation COMPARE statistical machine translation system\", \"statistical MT architectures PART-OF current limitations\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  88%|████████▊ | 439/500 [45:27<05:23,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"sentence boundary detection USED-FOR speech recognition output\", \"hidden Markov model USED-FOR detecting sentence boundaries\", \"maximum entropy classifiers USED-FOR detecting sentence boundaries\", \"textual knowledge sources FEATURE-OF hidden Markov model\", \"prosodic knowledge sources FEATURE-OF hidden Markov model\", \"conditional random field USED-FOR sentence boundary detection\", \"lower error rate EVALUATE-FOR NIST sentence boundary detection task\", \"three-way voting COMPARE HMM and Max-ent models\", \"classifiers PART-OF three-way voting\", \"different strengths and weaknesses FEATURE-OF each model\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  88%|████████▊ | 440/500 [45:34<05:48,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"framework USED-FOR word alignment\", \"log-linear models FEATURE-OF alignment\", \"knowledge sources FEATURE-OF feature functions\", \"source language sentence PART-OF feature functions\", \"target language sentence PART-OF feature functions\", \"log-linear models FEATURE-OF statistical alignment models\", \"syntactic information FEATURE-OF log-linear models\", \"IBM Model 3 alignment probabilities FEATURE-OF log-linear models\", \"POS correspondence FEATURE-OF log-linear models\", \"bilingual dictionary coverage FEATURE-OF log-linear models\", \"log-linear models EVALUATE-FOR IBM translation models\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  88%|████████▊ | 441/500 [45:41<05:56,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"alignment adaptation approach USED-FOR domain-specific word alignment\", \"out-of-domain corpus USED-FOR improve in-domain word alignment results\", \"statistical word alignment models FEATURE-OF alignment adaptation approach\", \"out-of-domain corpus PART-OF statistical word alignment models\", \"in-domain corpus PART-OF statistical word alignment models\", \"interpolate COMPARE state-of-the-art technologies\", \"precision EVALUATE-FOR domain-specific word alignment\", \"recall EVALUATE-FOR domain-specific word alignment\", \"relative error rate reduction EVALUATE-FOR domain-specific word alignment\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  88%|████████▊ | 442/500 [45:47<05:53,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"syntax-based statistical machine translation system USED-FOR machine translation task\", \"probabilistic synchronous dependency insertion grammar FEATURE-OF syntax-based statistical machine translation system\", \"synchronous dependency insertion grammars HYPONYM-OF synchronous grammars\", \"parallel corpora PART-OF inducing grammar\", \"graphical model FEATURE-OF machine translation task\", \"stochastic tree-to-tree transducer HYPONYM-OF graphical model\", \"polynomial time decoding algorithm FEATURE-OF model\", \"MT system EVALUATE-FOR NIST automatic MT evaluation software\", \"MT system EVALUATE-FOR Bleu automatic MT evaluation software\", \"system COMPARE baseline system\", \"IBM models HYPONYM-OF baseline system\", \"system OUTPERFORMS baseline system in translation speed\", \"system OUTPERFORMS baseline system in quality\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  89%|████████▊ | 443/500 [45:57<06:50,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"training method USED-FOR localized phrase-based prediction model\", \"localized phrase-based prediction model FEATURE-OF statistical machine translation\", \"model PREDICTS blocks\", \"blocks FEATURE-OF local phrase re-ordering\", \"maximum likelihood criterion USED-FOR train log-linear block bigram model\", \"log-linear block bigram model USES real-valued features\", \"real-valued features FEATURE-OF language model score\", \"binary features FEATURE-OF block identities\", \"training algorithm CAN HANDLE millions of features\", \"system OBTAINS 18.6% improvement EVALUATE-FOR Arabic-English translation task\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  89%|████████▉ | 444/500 [46:03<06:38,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"semantic role labeling FEATURE-OF independent classifiers\", \"core argument frame HYPONYM-OF joint structure\", \"joint model USED-FOR argument frames\", \"features FEATURE-OF discriminative log-linear models\", \"error reduction EVALUATE-FOR all arguments\", \"error reduction EVALUATE-FOR core arguments\", \"classifier COMPARE state-of-the art independent classifier\", \"gold-standard parse trees PART-OF PropBank\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  89%|████████▉ | 445/500 [46:10<06:22,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"monolingual parallel corpora USED-FOR extract paraphrases\", \"bilingual parallel corpora USED-FOR extract paraphrases\", \"alignment techniques FEATURE-OF phrase-based statistical machine translation\", \"paraphrases HYPONYM-OF phrase\", \"paraphrase probability FEATURE-OF rank paraphrases\", \"bilingual parallel corpus PART-OF paraphrase extraction and ranking methods\", \"translation probabilities EVALUATE-FOR paraphrases\", \"paraphrase extraction and ranking methods COMPARE quality\", \"manual word alignments EVALUATE-FOR paraphrase extraction and ranking methods\", \"automatic alignments EVALUATE-FOR paraphrases\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  89%|████████▉ | 446/500 [46:21<07:23,  8.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"system incorporates decision-tree classifier USED-FOR scf types\", \"pattern-matching language FEATURE-OF classification of grs\", \"tool introduced FOR linguistic annotation of scfs\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  89%|████████▉ | 447/500 [46:24<05:54,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Sentiment Classification seeks to identify piece of text according to author's general feeling toward subject\", \"machine learning techniques applied to problem with reasonable success\", \"training and test data must have good match with respect to topic\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  90%|████████▉ | 448/500 [46:28<04:54,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Turkish agglutinating free word order language USED-FOR language theories\", \"CCG lexicon FEATURE-OF compact lexicon\", \"Turkish dependency treebank PART-OF CCG lexicon\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  90%|████████▉ | 449/500 [46:31<04:15,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Czech-English statistical machine translation system USED-FOR tree-to-tree translation\", \"dependency structures PART-OF tree-to-tree translation\", \"sentence-aligned parallel corpus FEATURE-OF bilingual resource\", \"evaluation method FEATURE-OF system's output\", \"system's output COMPARE benchmark system\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  90%|█████████ | 450/500 [46:35<03:50,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"dialogue system IDENTIFY objects\", \"modular architecture FEATURE-OF concise architecture\", \"processes REVERSIBLE\", \"information-state model OF reference\", \"links BETWEEN semantics AND collaborative problem solving\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  90%|█████████ | 451/500 [46:38<03:23,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method of interactively visualizing DIRECTING process\", \"user EXPLORE model\", \"model COMPARE other MT systems\", \"visualization method FIND problems\", \"visualization method ADDRESS problems\", \"MT system ADDRESS problems\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  90%|█████████ | 452/500 [46:41<03:07,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method of organizing reading materials FEATURE-OF vocabulary learning\", \"reading texts PART-OF target corpus\", \"target vocabulary USED-FOR vocabulary learning\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  91%|█████████ | 453/500 [46:44<02:54,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"word sense disambiguation systems EVALUATE-FOR domains\", \"sense priors FEATURE-OF words\", \"well calibrated probabilities USED-FOR estimating sense priors\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  91%|█████████ | 454/500 [46:48<02:46,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"system combination USED-FOR improving system performance\", \"unsupervised WSD FEATURE-OF combination methods\", \"voting- and arbiter-based combination strategies PART-OF combination methods\", \"unsupervised WSD systems PART-OF combination strategies\", \"predominant senses FEATURE-OF combination methods\", \"raw text USED-FOR deriving predominant senses\", \"SemCor EVALUATE-FOR ensembles\", \"Senseval-3 EVALUATE-FOR ensembles\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  91%|█████████ | 455/500 [46:54<03:16,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"mathematical formalism PROPOSES combination structures\", \"strings PART-OF mathematical formalism\", \"trees PART-OF mathematical formalism\", \"dags PART-OF mathematical formalism\", \"graphs PART-OF mathematical formalism\", \"polarization CONTROLS saturation\", \"objects ELEMENTARY STRUCTURES\", \"saturation EVALUATE-FOR final structure\", \"formalism SIMULATE grammar formalisms\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  91%|█████████ | 456/500 [47:00<03:29,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"algorithm USED-FOR redundancy elimination problem\", \"semantic representation PART-OF scope ambiguity\", \"USR EVALUATE-FOR degree of ambiguity\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  91%|█████████▏| 457/500 [47:03<03:00,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"syntactic priming FEATURE-OF psycholinguistic literature\", \"method FEATURE-OF incremental probabilistic parser\", \"models COMPARE involve priming of rules\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  92%|█████████▏| 458/500 [47:09<03:23,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"pos tagging USED-FOR language processing pipeline\", \"multi-tagging approach USED-FOR ccg parsing\", \"pos tagging EVALUATE-FOR ccg supertagging\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  92%|█████████▏| 459/500 [47:12<02:58,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"dependency relation paths COMPARE syntactic relation-based methods\", \"correlation measure EVALUATE-FOR answer extraction\", \"Maximum Entropy-based ranking model USED-FOR path weights estimation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  92%|█████████▏| 460/500 [47:16<02:53,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"machine learning techniques USED-FOR comma checker\", \"comma checker PART-OF grammar checker\", \"Basque GENERIC language\", \"corpus MATERIAL 100,000 words\", \"system EVALUATE-FOR placing commas\", \"precision EVALUATE-FOR placing commas\", \"recall EVALUATE-FOR placing commas\", \"results COMPARE improved using bigger and more homogeneous corpus\", \"corpus MATERIAL written by one unique author\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  92%|█████████▏| 461/500 [47:22<03:01,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"unsupervised learning approach USED-FOR disambiguate relations\", \"named entities FEATURE-OF relations\", \"lexical and syntactic features FEATURE-OF contexts\", \"eigenvectors OF adjacency graph's Laplacian\", \"submanifold PART-OF data\", \"cluster number estimation FEATURE-OF eigenvectors\", \"spectral clustering based approach USED-FOR disambiguate relations\", \"ACE corpora EVALUATE-FOR spectral clustering based approach\", \"spectral clustering based approach COMPARE other clustering methods\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  92%|█████████▏| 462/500 [47:28<03:13,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method building polarity-tagged corpus FEATURE-OF HTML documents\", \"method fully automatic\", \"method applied to arbitrary HTML documents\", \"layout structures USED-FOR extracting opinion sentences\", \"linguistic pattern USED-FOR extracting opinion sentences\", \"method construct corpus consisting of 126,610 sentences PART-OF experiment\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  93%|█████████▎| 463/500 [47:32<03:01,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Bikel's parser COMPARE current technology\", \"Bikel's parser EVALUATE-FOR parsing written language\", \"subcategorization cues EVALUATE-FOR spoken language\", \"current technology USED-FOR extracting subcategorization frames\", \"punctuation FEATURE-OF parsing and extraction\", \"punctuation EVALUATE-FOR spoken language\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  93%|█████████▎| 464/500 [47:37<02:59,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"word vectors CONSTRUCTED-BY LSA-based method\", \"word vectors CONSTRUCTED-BY cooccurrence-based method\", \"word vectors CONSTRUCTED-BY dictionary-based method\", \"dictionary-based word vectors REFLECT taxonomic similarity\", \"LSA-based word vectors REFLECT associative similarity\", \"cooccurrence-based word vectors REFLECT associative similarity\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  93%|█████████▎| 465/500 [47:42<02:52,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"event terms PART-OF events\", \"event elements PART-OF events\", \"independent approach USED-FOR identifying important contents\", \"frequency FEATURE-OF events\", \"relevant approach USED-FOR identifying important contents\", \"PageRank algorithm FEATURE-OF event map\", \"event map PART-OF documents\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  93%|█████████▎| 466/500 [47:48<02:50,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"rhetorical structure helpful discourse processing\", \"punctuation helpful discourse processing\", \"paper reports discursive usage Chinese punctuation marks\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  93%|█████████▎| 467/500 [47:50<02:18,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"FERRET interactive question-answering system\", \"predictive questioning FEATURE-OF Q/A\", \"user interacts with system USED-FOR gathering information\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  94%|█████████▎| 468/500 [47:54<02:10,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method involves automatically gathering large number of abstracts FROM Web\", \"sentences analyzed and labeled with specific move in light of various rhetorical functions\", \"prototype concordancer CARE exploits move-tagged abstracts for digital learning\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  94%|█████████▍| 469/500 [47:57<02:01,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"LOGON MT demonstrator USED-FOR machine translation pipeline\", \"NLP components PART-OF LOGON MT demonstrator\", \"output quality FEATURE-OF machine translation pipeline\", \"hand-built symbolic resources PART-OF LOGON MT demonstrator\", \"stochastic processes PART-OF LOGON MT demonstrator\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  94%|█████████▍| 470/500 [48:01<02:00,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"topical blog post retrieval USED-FOR ranking blog posts\", \"textual credibility indicators FEATURE-OF retrieval approach\", \"credibility indicators EVALUATE-FOR retrieval effectiveness\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  94%|█████████▍| 471/500 [48:05<01:50,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Lyric-based song sentiment classification seeks to assign songs appropriate sentiment labels such as light-hearted heavy-hearted\", \"vector space model (VSM)-based text classification approach ineffective\", \"sentiment vector space model (s-VSM) proposed to represent song lyric document\", \"s-VSM model outperforms VSM model in lyric-based song sentiment classification task\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  94%|█████████▍| 472/500 [48:10<02:00,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method analyzing metaphors FEATURE-OF language learning\", \"generalized metaphor contains recognition network PART-OF metaphor mapping\", \"method reduces metaphor interpretation to recognition task\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  95%|█████████▍| 473/500 [48:13<01:45,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"natural language interfaces CONJUNCTION non-literal aspects of communication\", \"personal computers USED-FOR non-literal aspects of communication\", \"interfaces FEATURE-OF natural language interfaces\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  95%|█████████▍| 474/500 [48:17<01:38,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"natural language input USED-FOR computer system\", \"human listeners COPES-WITH deviations\", \"FlexP FEATURE-OF bottom-up pattern-matching parser\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  95%|█████████▌| 475/500 [48:20<01:30,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"natural language interpretation REQUIRES semantic domain models\", \"parsing algorithm PRESENTED\", \"parsing algorithm INTEGRATES parsing strategies\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  95%|█████████▌| 476/500 [48:23<01:22,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"flexible parser can deal with input FEATURE-OF grammar\", \"parser corrects deviant input\", \"correction EVALUATE-FOR ambiguous possibilities\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  95%|█████████▌| 477/500 [48:26<01:17,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"GPSG grammatical formalism EXTENSION-PROPOSED non-terminals CONSIST-OF category labels\", \"schematic variables RANGE-OVER sequences\", \"extension PARSEABLE-BY parsing method for GPSG\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  96%|█████████▌| 478/500 [48:29<01:13,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"MPS grammars PART-OF metagrammatical formalisms\", \"MPS grammars FEATURE-OF syntax of natural languages\", \"MPS grammars EVALUATE-FOR computational tractability\", \"MPS grammars EVALUATE-FOR explanatory adequacy\", \"proposals COMPARE new directions for research on alternative metagrammatical formalisms\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  96%|█████████▌| 479/500 [48:35<01:23,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"natural language system USED-FOR computer aided second language learning\", \"system USED-FOR ungrammatical input\", \"principles USED-FOR general mechanism\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  96%|█████████▌| 480/500 [48:38<01:12,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"entity-oriented approach PROPOSED\", \"definitions GROUPED TOGETHER structure and surface representation of domain entities\", \"semantic grammar ALLOWS exploitation of limited domain semantics\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  96%|█████████▌| 481/500 [48:44<01:25,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Paul GENERIC computer text generation system\", \"cohesive text GENERIC\", \"lexical substitutions FEATURE-OF Paul\", \"system DESIGNED-FOR cohesive text\", \"system DESIGNED-FOR lexical substitutions\", \"pronominalization USED-FOR lexical substitutions\", \"superordinate substitution USED-FOR lexical substitutions\", \"definite noun phrase reiteration USED-FOR lexical substitutions\", \"system IDENTIFIES strength EVALUATE-FOR antecedence recovery\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  96%|█████████▋| 482/500 [48:50<01:27,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Plume approach BASED-ON semantic caseframe instantiation\", \"Plume ADAPTED-TO declarative and imperative utterances\", \"Plume HANDLES passives, relative clauses and interrogatives in ad hoc manner\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  97%|█████████▋| 483/500 [48:53<01:13,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Tree Adjoining Grammars HYPONYM-OF grammatical formalisms\", \"Head Grammars HYPONYM-OF grammatical formalisms\", \"Tree Adjoining Grammars COMPARE Head Grammars\", \"linguistic expressiveness COMPARE grammatical formalisms\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  97%|█████████▋| 484/500 [48:58<01:11,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"terminology structuring FOCUSES-ON lexical methods\", \"terms EXTRACTED-FROM corpora\", \"hierarchical relations IDENTIFIED-BETWEEN terms\", \"lexically-induced relations COMPARED-WITH MeSH relations\", \"quantitative evaluation SHOWS-LIMITS of lexical structuring method\", \"human analysis REVEALS structuring choices and naming conventions made by MeSH designers\", \"ontological commitments EMPHASIZED by MeSH designers\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  97%|█████████▋| 485/500 [49:03<01:12,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"method aligning terms USED-FOR extracting translations\", \"small, domain-specific corpus PART-OF sentence-aligned corpus\", \"translation equivalences FEATURE-OF parallel concordances\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  97%|█████████▋| 486/500 [49:08<01:04,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"natural language text PART-OF UNL graphs\", \"prototype USED-FOR sharing scenario\", \"naive users GENERIC interact with text\", \"graph PART-OF UNL-L0 deconverter\", \"errors EVALUATE-FOR graph\", \"graph USED-FOR deconverters in other languages\", \"versions FEATURE-OF original multilingual document\", \"document USED-FOR cooperative working\", \"liaisons ESTABLISHED-BETWEEN text and graph\", \"LO-English dictionary PART-OF liaisons\", \"morphosyntactic parser PART-OF liaisons\", \"canonical graph2tree transformation PART-OF liaisons\", \"correspondence ESTABLISHED-BETWEEN UNL-tree+L0 and MS-L0 structure\", \"lattice PART-OF correspondence\", \"pivot MT COMPARE interactive MT\", \"multilingual text authoring PART-OF research\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  97%|█████████▋| 487/500 [49:17<01:18,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"unsupervised learning method FEATURE-OF text classification problems\", \"EM algorithm USED-FOR text classification problems\", \"EM algorithm USED-FOR word sense disambiguation problems\", \"optimum iteration number PART-OF EM algorithm\", \"two methods EVALUATE-FOR optimum iteration number\", \"50 noun WSD problems PART-OF Japanese Dictionary Task\", \"our method EVALUATE-FOR best public score\", \"methods EVALUATE-FOR verb WSD problems\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  98%|█████████▊| 488/500 [49:23<01:13,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"approach USED-FOR unsupervised learning\", \"model FEATURE-OF POS learning\", \"morphology PROVIDES better clues to word's category than word order\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  98%|█████████▊| 489/500 [49:27<00:58,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"computational model OF word segmentation\", \"simulation results ON realistic acquisition\", \"statistical learning mechanisms IN cognitive psychology\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  98%|█████████▊| 490/500 [49:30<00:47,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"transfer dictionary FEATURE-OF machine translation system\", \"algorithm USED-FOR dictionary construction\", \"linguistic resources PART-OF dictionary construction\", \"language pairs PART-OF algorithm\", \"Korean-to-Japanese dictionary FEATURE-OF algorithm\", \"pivot FEATURE-OF algorithm\", \"one-time look up method USED-FOR automatic construction\", \"Korean-to-English dictionary PART-OF one-time look up method\", \"Japanese-to-English dictionary PART-OF one-time look up method\", \"overlapping constraint USED-FOR automatic construction\", \"English-to-Korean dictionary PART-OF overlapping constraint\", \"English-to-Japanese dictionary PART-OF overlapping constraint\", \"best result EVALUATE-FOR combining the three methods\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  98%|█████████▊| 491/500 [49:38<00:52,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Penn Discourse TreeBank USED-FOR annotation project\", \"approach annotating BASED-ON identifying discourse connectives and arguments\", \"PDTB PART-OF Penn TreeBank\", \"PDTB PART-OF Propbank\", \"PDTB FEATURE-OF practical algorithms development and evaluation\", \"inter-annotator agreement EVALUATE-FOR practical algorithms development and evaluation\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  98%|█████████▊| 492/500 [49:44<00:46,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"IntEx system USED-FOR gene and protein interactions\", \"approach BASED-ON splitting complex sentences into simple clausal structures\", \"biological entities TAGGED-WITH help of biomedical and linguistic ontologies\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  99%|█████████▊| 493/500 [49:48<00:35,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"framework USED-FOR derive distance\", \"categories FEATURE-OF coarse-grained concepts\", \"distance values FEATURE-OF concept-concept matrix\", \"concept-distance measures OUTPERFORM traditional distributional word-distance measures\", \"ranking word pairs EVALUATE-FOR semantic distance\", \"correcting real-word spelling errors EVALUATE-FOR distributional concept-distance measures\", \"WordNet-based measures COMPARE distributional concept-distance measures\", \"Jiang and Conrath COREF that proposed measure\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  99%|█████████▉| 494/500 [49:53<00:31,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"labeled directed graph USED-FOR linguistic structures\", \"NLP tasks VIEWED-AS graph transformations\", \"method for learning transformations FEATURE-OF annotated corpus\", \"identification of non-local dependencies PART-OF Penn Treebank data\", \"semantic role labeling PART-OF Proposition Bank data\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  99%|█████████▉| 495/500 [49:58<00:25,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"CoNLL 2008 shared task USED-FOR generative history-based latent variable model\", \"model YIELDS 79.1% macro-average F1 performance\", \"model trained AFTER deadline YIELDS 80.5% macro-average F1\", \"generative history-based latent variable model USED-FOR predict derivation of synchronous dependency parser\", \"synchronous dependency parser PART-OF both syntactic and semantic dependencies\", \"syntactic dependencies LAS EVALUATE-FOR joint task\", \"semantic dependencies F1 EVALUATE-FOR joint task\", \"syntactic dependencies LAS EVALUATE-FOR larger model\", \"semantic dependencies F1 EVALUATE-FOR larger model\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  99%|█████████▉| 496/500 [50:06<00:23,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ICICLE system USED-FOR language tutoring application\", \"user knowledge modeling architecture PART-OF ICICLE system\", \"language proficiency FEATURE-OF user\", \"model design MOTIVATED-BY research on second language and cognitive skill acquisition\", \"model design PROVIDES information base to language assessment/correction application\", \"user proficiency MODELED-BY model design\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses:  99%|█████████▉| 497/500 [50:12<00:17,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"TIPSTER Architecture USED-FOR text applications\", \"text processing modules PART-OF TIPSTER Architecture\", \"user interfaces USED-FOR applications\", \"user interface styles FEATURE-OF TIPSTER Architecture specification\", \"CRL DEVELOPED TUIT\", \"TUIT USED-FOR multilingual TIPSTER user interfaces\", \"TUIT PART-OF software library\", \"TUIT USED-FOR constructing user interfaces\", \"TIPSTER modules PART-OF TUIT\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses: 100%|█████████▉| 498/500 [50:18<00:12,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"proper nouns RECOGNITION-OF morphological analysis PROBLEM-OF Japanese text processing\", \"Japanese information extraction FRAMEWORK-OF recent years\", \"Multi-lingual Evaluation Task (MET) CONSIDER Japanese morphological analysis problem\", \"morphological analyzer AMORPH RECOGNIZES NE items\", \"NE items RECOGNITION-OF dictionary lookup stage\", \"NE items IDENTIFICATION-OF segmented strings RULE APPLICATION stage\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating responses: 100%|█████████▉| 499/500 [50:24<00:05,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"automatic summarization USED-FOR Internet services\", \"MUC USED-FOR next generation Internet\", \"SUMMAC USED-FOR next generation Internet\", \"automatic summarization PROPOSES models\", \"models FEATURE-OF summary generation\", \"tasks INITIATED-BY SUMMAC-1\", \"positive feature vectors USED-FOR generic summaries\", \"negative feature vectors USED-FOR generic summaries\", \"text model USED-FOR adhoc task\", \"relationship BETWEEN nouns AND verbs USED-FOR text model\", \"discourse segment PART-OF text model\", \"sentences RANKED-BY text model\", \"user-directed summaries GENERATED-BY text model\", \"NormF OF best summary EQUALS 0.456 FOR adhoc task\", \"NormF OF fixed summary EQUALS 0.447 FOR adhoc task\", \"NormF OF best summary EQUALS 0.4090 FOR categorization task\", \"NormF OF fixed summary EQUALS 0.4023 FOR categorization task\", \"system OUTPERFORMS average system IN categorization task\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses: 100%|██████████| 500/500 [50:34<00:00,  6.07s/it]\n"
     ]
    }
   ],
   "source": [
    "generate_responses(scierc_full_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9172e7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>prompt</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categori...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "      <td>Give me a comma-separated list of detected tri...</td>\n",
       "      <td>[\"system categorizing unknown words USED-FOR i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>\\nThis paper presents a new approach to  stati...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMP...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...</td>\n",
       "      <td>[ranking algorithm COMPARE lattice-based appro...</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>Give me a comma-separated list of detected tri...</td>\n",
       "      <td>[\"approach USED-FOR statistical sentence gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>\\n This paper describes a domain independent ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...</td>\n",
       "      <td>[feedback FEATURE-OF discourse, videodisc imag...</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "      <td>Give me a comma-separated list of detected tri...</td>\n",
       "      <td>[\"natural language interface USED-FOR database...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>\\n In this paper, we describe the  pronominal...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'prono...</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF...</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>Give me a comma-separated list of detected tri...</td>\n",
       "      <td>[\"pronominal anaphora resolution module PART-O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>\\nIn our current research into the design of  ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'displ...</td>\n",
       "      <td>[display of graphical information USED-FOR cog...</td>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>Give me a comma-separated list of detected tri...</td>\n",
       "      <td>[\"design cognitively well-motivated interfaces...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id                                               text                                           entities                                      relationships                                     populated_rels                          simplified_populated_rels  rel_count  word_count                                             prompt                                          responses\n",
       "0    A00-1024  \\nThis paper introduces a  system for categori...  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...  [multi-component architecture USED-FOR system,...         13          86  Give me a comma-separated list of detected tri...  [\"system categorizing unknown words USED-FOR i...\n",
       "1    A00-2023  \\nThis paper presents a new approach to  stati...  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...  {'R1': {'Relationship ID': 'R1', 'Type': 'COMP...  {'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...  [ranking algorithm COMPARE lattice-based appro...          9          85  Give me a comma-separated list of detected tri...  [\"approach USED-FOR statistical sentence gener...\n",
       "2    A88-1001   \\n This paper describes a domain independent ...  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...  {'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...  {'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...  [feedback FEATURE-OF discourse, videodisc imag...          9          58  Give me a comma-separated list of detected tri...  [\"natural language interface USED-FOR database...\n",
       "3    A88-1003   \\n In this paper, we describe the  pronominal...  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...  {'R1': {'Relationship ID': 'R1', 'Type': 'PART...  {'R1': {'Relationship ID': 'R1', 'Rel': 'prono...  [pronominal anaphora resolution module PART-OF...          3          77  Give me a comma-separated list of detected tri...  [\"pronominal anaphora resolution module PART-O...\n",
       "4    A92-1010  \\nIn our current research into the design of  ...  {'T1': {'Annotation ID': 'T1', 'Entity': 'Task...  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...  {'R1': {'Relationship ID': 'R1', 'Rel': 'displ...  [display of graphical information USED-FOR cog...          3          84  Give me a comma-separated list of detected tri...  [\"design cognitively well-motivated interfaces..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scierc_full_responses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4403399d",
   "metadata": {},
   "source": [
    "## Compare count of rels found to annotated count.\n",
    "* Very unlikely to get a hard match of the entire list of rels between simplified_populated_rels and responses.\n",
    "* Also unlikely to get items to match across lists.\n",
    "\n",
    "* Can analyse count of rels combined with manual evaluation.\n",
    "\n",
    "* seems to have formed new rel outside of restricted rel list: OFFERS-ADVANTAGES-IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "992641b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>prompt</th>\n",
       "      <th>responses</th>\n",
       "      <th>responses_rels_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categori...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "      <td>Give me a comma-separated list of detected tri...</td>\n",
       "      <td>[\"system categorizing unknown words USED-FOR i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>\\nThis paper presents a new approach to  stati...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMP...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...</td>\n",
       "      <td>[ranking algorithm COMPARE lattice-based appro...</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>Give me a comma-separated list of detected tri...</td>\n",
       "      <td>[\"approach USED-FOR statistical sentence gener...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>\\n This paper describes a domain independent ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...</td>\n",
       "      <td>[feedback FEATURE-OF discourse, videodisc imag...</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "      <td>Give me a comma-separated list of detected tri...</td>\n",
       "      <td>[\"natural language interface USED-FOR database...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>\\n In this paper, we describe the  pronominal...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'prono...</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF...</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>Give me a comma-separated list of detected tri...</td>\n",
       "      <td>[\"pronominal anaphora resolution module PART-O...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>\\nIn our current research into the design of  ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'displ...</td>\n",
       "      <td>[display of graphical information USED-FOR cog...</td>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>Give me a comma-separated list of detected tri...</td>\n",
       "      <td>[\"design cognitively well-motivated interfaces...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id                                               text                                           entities                                      relationships                                     populated_rels                          simplified_populated_rels  rel_count  word_count                                             prompt                                          responses  responses_rels_detected\n",
       "0    A00-1024  \\nThis paper introduces a  system for categori...  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...  [multi-component architecture USED-FOR system,...         13          86  Give me a comma-separated list of detected tri...  [\"system categorizing unknown words USED-FOR i...                        3\n",
       "1    A00-2023  \\nThis paper presents a new approach to  stati...  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...  {'R1': {'Relationship ID': 'R1', 'Type': 'COMP...  {'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...  [ranking algorithm COMPARE lattice-based appro...          9          85  Give me a comma-separated list of detected tri...  [\"approach USED-FOR statistical sentence gener...                        9\n",
       "2    A88-1001   \\n This paper describes a domain independent ...  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...  {'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...  {'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...  [feedback FEATURE-OF discourse, videodisc imag...          9          58  Give me a comma-separated list of detected tri...  [\"natural language interface USED-FOR database...                        3\n",
       "3    A88-1003   \\n In this paper, we describe the  pronominal...  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...  {'R1': {'Relationship ID': 'R1', 'Type': 'PART...  {'R1': {'Relationship ID': 'R1', 'Rel': 'prono...  [pronominal anaphora resolution module PART-OF...          3          77  Give me a comma-separated list of detected tri...  [\"pronominal anaphora resolution module PART-O...                        7\n",
       "4    A92-1010  \\nIn our current research into the design of  ...  {'T1': {'Annotation ID': 'T1', 'Entity': 'Task...  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...  {'R1': {'Relationship ID': 'R1', 'Rel': 'displ...  [display of graphical information USED-FOR cog...          3          84  Give me a comma-separated list of detected tri...  [\"design cognitively well-motivated interfaces...                        3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scierc_full_responses['responses_rels_detected'] = scierc_full_responses['responses'].apply(lambda x: len(x.split(',')))\n",
    "scierc_full_responses.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f88b16d",
   "metadata": {},
   "source": [
    "### Quantitative comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36b2d6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of rel_count: 6394\n",
      "Sum of responses_rels_detected: 3242\n"
     ]
    }
   ],
   "source": [
    "rel_count_sum = scierc_full_responses['rel_count'].sum()\n",
    "responses_rels_detected_sum = scierc_full_responses['responses_rels_detected'].sum()\n",
    "\n",
    "print(\"Sum of rel_count:\", rel_count_sum)\n",
    "print(\"Sum of responses_rels_detected:\", responses_rels_detected_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1f630e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'USED-FOR': 619, 'FEATURE-OF': 613, 'HYPONYM-OF': 77, 'PART-OF': 413, 'EVALUATE-FOR': 380, 'COMPARE': 162, 'CONJUNCTION': 3, 'COREF': 10}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(rel_summary)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Print the sum of values\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSum of Values:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrel_summary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Define the target texts\n",
    "target_texts = ['USED-FOR', 'FEATURE-OF', 'HYPONYM-OF', 'PART-OF', 'EVALUATE-FOR', 'COMPARE', 'CONJUNCTION', 'COREF']\n",
    "\n",
    "# Initialize the dictionary\n",
    "rel_summary = {text: 0 for text in target_texts}\n",
    "\n",
    "# Count the occurrences of each target text\n",
    "for row in scierc_full_responses['responses']:\n",
    "    phrases = row.split(', ')\n",
    "    for text in target_texts:\n",
    "        for phrase in phrases:\n",
    "            if text in phrase:\n",
    "                rel_summary[text] += 1\n",
    "\n",
    "# Print the summary statistics\n",
    "print(rel_summary)\n",
    "\n",
    "# Print the sum of values\n",
    "print(\"Sum of Values:\", sum(rel_summary.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fd2487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above implies that there are some rels generated outside of the restricted options;\n",
    "# Or, may be slight mis-matches with letter-casing, lack of hyphen, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520ce1ec",
   "metadata": {},
   "source": [
    "# Final export for manual verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15e819d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export to excel for manual verification:\n",
    "scierc_full_responses.to_excel(\"./benchmarking/results/scierc_rel_detection_with_ent_type_responses.xlsx\")\n",
    "\n",
    "# # export to pickle in case of future use.\n",
    "scierc_full_responses.to_pickle(\"./benchmarking/results/scierc_rel_detection_with_ent_type_responses.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a4109a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reimport_scierc_results = scierc_full_responses.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d83682",
   "metadata": {},
   "source": [
    "### remove rows where abstract ID had missing annotation file (C88-2132), or no rels detected (other 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ccad673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>prompt</th>\n",
       "      <th>responses</th>\n",
       "      <th>responses_rels_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categori...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "      <td>Give me a comma-separated list of detected tri...</td>\n",
       "      <td>[\"system categorizing unknown words USED-FOR i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id                                               text                                           entities                                      relationships                                     populated_rels                          simplified_populated_rels  rel_count  word_count                                             prompt                                          responses  responses_rels_detected\n",
       "0    A00-1024  \\nThis paper introduces a  system for categori...  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...  [multi-component architecture USED-FOR system,...         13          86  Give me a comma-separated list of detected tri...  [\"system categorizing unknown words USED-FOR i...                        3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# List of abstract values to be excluded\n",
    "excluded_abstracts = ['IJCAI_2013_4_abs', 'AAAI_2008_262_abs', 'C88-2132']\n",
    "\n",
    "# Filter out rows with excluded abstract values\n",
    "reimport_scierc_results = reimport_scierc_results[~reimport_scierc_results['abstract_id'].isin(excluded_abstracts)]\n",
    "print(len(reimport_scierc_results))\n",
    "reimport_scierc_results.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6823d6b7",
   "metadata": {},
   "source": [
    "## Add comparison cols:\n",
    "1) exact rel in annotated but not in responses.\n",
    "2) corresponding count of rels.\n",
    "3) exact rel in responses but not in annotated.\n",
    "4) corresponding count of rels. \n",
    "5) exact rel in responses and annotations.\n",
    "6) corresponding count of rels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58e33b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>prompt</th>\n",
       "      <th>responses</th>\n",
       "      <th>responses_rels_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categori...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "      <td>Give me a comma-separated list of detected tri...</td>\n",
       "      <td>system categorizing unknown words USED-FOR ide...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id                                               text                                           entities                                      relationships                                     populated_rels                          simplified_populated_rels  rel_count  word_count                                             prompt                                          responses  responses_rels_detected\n",
       "0    A00-1024  \\nThis paper introduces a  system for categori...  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...  [multi-component architecture USED-FOR system,...         13          86  Give me a comma-separated list of detected tri...  system categorizing unknown words USED-FOR ide...                        3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation contained in most responses\n",
    "reimport_scierc_results['responses'] = reimport_scierc_results['responses'].str.replace('[\\[\\]\"]', '', regex=True)\n",
    "\n",
    "# Trim leading and trailing spaces/newlines\n",
    "# reimport_scierc_results['responses'] = reimport_scierc_results['responses'].apply(lambda x: [item.strip() for item in x])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "reimport_scierc_results.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1db8b3e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m col_name \u001b[38;5;241m=\u001b[39m col\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Check the type of values in the column\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m value_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreimport_scierc_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Check if the column contains a list\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "# determine if comparison cols are list of items or string.\n",
    "# Assuming the column name is 'col_name'\n",
    "col_names = ('simplified_populated_rels', 'responses')\n",
    "\n",
    "for col in col_names:\n",
    "    col_name = col\n",
    "    # Check the type of values in the column\n",
    "    value_type = type(reimport_scierc_results.loc[0, col_name])\n",
    "\n",
    "    # Check if the column contains a list\n",
    "    if value_type == list:\n",
    "        print(f\"The '{col_name}' column contains a list of items.\")\n",
    "    else:\n",
    "        print(f\"The '{col_name}' column contains strings.\")\n",
    "\n",
    "# output must be same format for accurate comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "da739fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'responses' column has been converted to a list of items.\n"
     ]
    }
   ],
   "source": [
    "# Assuming the column name is 'responses'\n",
    "col_name = 'responses'\n",
    "\n",
    "# Convert the string to a list of items\n",
    "reimport_scierc_results[col_name] = reimport_scierc_results[col_name].str.split(',')\n",
    "\n",
    "# Check the updated type of values in the column\n",
    "value_type = type(reimport_scierc_results.loc[0, col_name])\n",
    "\n",
    "# Check if the column contains a list\n",
    "if value_type == list:\n",
    "    print(f\"The '{col_name}' column has been converted to a list of items.\")\n",
    "else:\n",
    "    print(f\"Error: The '{col_name}' column could not be converted to a list.\")\n",
    "reimport_scierc_results.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "05ec5fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip\n",
    "reimport_scierc_results['responses'] = reimport_scierc_results['responses'].apply(lambda x: [item.strip() for item in x])\n",
    "reimport_scierc_results.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4263b4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create 'rel_annotated_but_not_detected' column\n",
    "reimport_scierc_results['rel_annotated_but_not_detected'] = reimport_scierc_results.apply(lambda row: [rel for rel in row['simplified_populated_rels'] if rel not in row['responses']], axis=1)\n",
    "reimport_scierc_results['rel_annotated_but_not_detected_count'] = reimport_scierc_results['rel_annotated_but_not_detected'].apply(len)\n",
    "\n",
    "# Step 3: Create 'rel_detected_but_not_annotated' column\n",
    "reimport_scierc_results['rel_detected_but_not_annotated'] = reimport_scierc_results.apply(lambda row: [rel for rel in row['responses'] if rel not in row['simplified_populated_rels']], axis=1)\n",
    "reimport_scierc_results['rel_detected_but_not_annotated_count'] = reimport_scierc_results['rel_detected_but_not_annotated'].apply(len)\n",
    "\n",
    "# Step 4: Create 'annotated_rel_detected' column\n",
    "reimport_scierc_results['annotated_rel_detected'] = reimport_scierc_results.apply(lambda row: [rel for rel in row['responses'] if rel in row['simplified_populated_rels']], axis=1)\n",
    "reimport_scierc_results['annotated_rel_detected_count'] = reimport_scierc_results['annotated_rel_detected'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "68acf057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relationships</th>\n",
       "      <th>populated_rels</th>\n",
       "      <th>simplified_populated_rels</th>\n",
       "      <th>rel_count</th>\n",
       "      <th>prompt</th>\n",
       "      <th>responses</th>\n",
       "      <th>responses_rels_detected</th>\n",
       "      <th>rel_annotated_but_not_detected</th>\n",
       "      <th>rel_annotated_but_not_detected_count</th>\n",
       "      <th>rel_detected_but_not_annotated</th>\n",
       "      <th>rel_detected_but_not_annotated_count</th>\n",
       "      <th>annotated_rel_detected</th>\n",
       "      <th>annotated_rel_detected_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1024</td>\n",
       "      <td>\\nThis paper introduces a  system for categori...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'multi...</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "      <td>[system PART-OF multi-component architecture, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[multi-component architecture USED-FOR system,...</td>\n",
       "      <td>13</td>\n",
       "      <td>[system PART-OF multi-component architecture, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-2023</td>\n",
       "      <td>\\nThis paper presents a new approach to  stati...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'COMP...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...</td>\n",
       "      <td>[ranking algorithm COMPARE lattice-based appro...</td>\n",
       "      <td>9</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "      <td>[approach FEATURE-OF statistical sentence gene...</td>\n",
       "      <td>8</td>\n",
       "      <td>[ranking algorithm COMPARE lattice-based appro...</td>\n",
       "      <td>9</td>\n",
       "      <td>[approach FEATURE-OF statistical sentence gene...</td>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A88-1001</td>\n",
       "      <td>\\n This paper describes a domain independent ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...</td>\n",
       "      <td>[feedback FEATURE-OF discourse, videodisc imag...</td>\n",
       "      <td>9</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "      <td>[natural language interface USED-FOR database ...</td>\n",
       "      <td>7</td>\n",
       "      <td>[feedback FEATURE-OF discourse, videodisc imag...</td>\n",
       "      <td>8</td>\n",
       "      <td>[multimedia answers FEATURE-OF videodisc image...</td>\n",
       "      <td>6</td>\n",
       "      <td>[natural language interface USED-FOR database ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A88-1003</td>\n",
       "      <td>\\n In this paper, we describe the  pronominal...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'PART...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'prono...</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF...</td>\n",
       "      <td>3</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF...</td>\n",
       "      <td>7</td>\n",
       "      <td>[module COREF pronominal anaphora resolution m...</td>\n",
       "      <td>2</td>\n",
       "      <td>[anaphora resolution HYPONYM-OF theories, blac...</td>\n",
       "      <td>6</td>\n",
       "      <td>[pronominal anaphora resolution module PART-OF...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A92-1010</td>\n",
       "      <td>\\nIn our current research into the design of  ...</td>\n",
       "      <td>{'T1': {'Annotation ID': 'T1', 'Entity': 'Task...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Type': 'USED...</td>\n",
       "      <td>{'R1': {'Relationship ID': 'R1', 'Rel': 'displ...</td>\n",
       "      <td>[display of graphical information USED-FOR cog...</td>\n",
       "      <td>3</td>\n",
       "      <td>Give me a comma-separated list of relationship...</td>\n",
       "      <td>[natural language generation USED-FOR interact...</td>\n",
       "      <td>3</td>\n",
       "      <td>[display of graphical information USED-FOR cog...</td>\n",
       "      <td>2</td>\n",
       "      <td>[graphical information FEATURE-OF cognitively ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[natural language generation USED-FOR interact...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id  \\\n",
       "0    A00-1024   \n",
       "1    A00-2023   \n",
       "2    A88-1001   \n",
       "3    A88-1003   \n",
       "4    A92-1010   \n",
       "\n",
       "                                                text  \\\n",
       "0  \\nThis paper introduces a  system for categori...   \n",
       "1  \\nThis paper presents a new approach to  stati...   \n",
       "2   \\n This paper describes a domain independent ...   \n",
       "3   \\n In this paper, we describe the  pronominal...   \n",
       "4  \\nIn our current research into the design of  ...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "1  {'T1': {'Annotation ID': 'T1', 'Entity': 'Gene...   \n",
       "2  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "3  {'T1': {'Annotation ID': 'T1', 'Entity': 'Meth...   \n",
       "4  {'T1': {'Annotation ID': 'T1', 'Entity': 'Task...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Type': 'COMP...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Type': 'FEAT...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Type': 'PART...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Type': 'USED...   \n",
       "\n",
       "                                      populated_rels  \\\n",
       "0  {'R1': {'Relationship ID': 'R1', 'Rel': 'multi...   \n",
       "1  {'R1': {'Relationship ID': 'R1', 'Rel': 'ranki...   \n",
       "2  {'R1': {'Relationship ID': 'R1', 'Rel': 'feedb...   \n",
       "3  {'R1': {'Relationship ID': 'R1', 'Rel': 'prono...   \n",
       "4  {'R1': {'Relationship ID': 'R1', 'Rel': 'displ...   \n",
       "\n",
       "                           simplified_populated_rels  \\\n",
       "0  [multi-component architecture USED-FOR system,...   \n",
       "1  [ranking algorithm COMPARE lattice-based appro...   \n",
       "2  [feedback FEATURE-OF discourse, videodisc imag...   \n",
       "3  [pronominal anaphora resolution module PART-OF...   \n",
       "4  [display of graphical information USED-FOR cog...   \n",
       "\n",
       "   rel_count  \\\n",
       "0         13   \n",
       "1          9   \n",
       "2          9   \n",
       "3          3   \n",
       "4          3   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Give me a comma-separated list of relationship...   \n",
       "1  Give me a comma-separated list of relationship...   \n",
       "2  Give me a comma-separated list of relationship...   \n",
       "3  Give me a comma-separated list of relationship...   \n",
       "4  Give me a comma-separated list of relationship...   \n",
       "\n",
       "                                           responses  \\\n",
       "0  [system PART-OF multi-component architecture, ...   \n",
       "1  [approach FEATURE-OF statistical sentence gene...   \n",
       "2  [natural language interface USED-FOR database ...   \n",
       "3  [pronominal anaphora resolution module PART-OF...   \n",
       "4  [natural language generation USED-FOR interact...   \n",
       "\n",
       "   responses_rels_detected  \\\n",
       "0                        5   \n",
       "1                        8   \n",
       "2                        7   \n",
       "3                        7   \n",
       "4                        3   \n",
       "\n",
       "                      rel_annotated_but_not_detected  \\\n",
       "0  [multi-component architecture USED-FOR system,...   \n",
       "1  [ranking algorithm COMPARE lattice-based appro...   \n",
       "2  [feedback FEATURE-OF discourse, videodisc imag...   \n",
       "3  [module COREF pronominal anaphora resolution m...   \n",
       "4  [display of graphical information USED-FOR cog...   \n",
       "\n",
       "   rel_annotated_but_not_detected_count  \\\n",
       "0                                    13   \n",
       "1                                     9   \n",
       "2                                     8   \n",
       "3                                     2   \n",
       "4                                     2   \n",
       "\n",
       "                      rel_detected_but_not_annotated  \\\n",
       "0  [system PART-OF multi-component architecture, ...   \n",
       "1  [approach FEATURE-OF statistical sentence gene...   \n",
       "2  [multimedia answers FEATURE-OF videodisc image...   \n",
       "3  [anaphora resolution HYPONYM-OF theories, blac...   \n",
       "4  [graphical information FEATURE-OF cognitively ...   \n",
       "\n",
       "   rel_detected_but_not_annotated_count  \\\n",
       "0                                     5   \n",
       "1                                     8   \n",
       "2                                     6   \n",
       "3                                     6   \n",
       "4                                     2   \n",
       "\n",
       "                              annotated_rel_detected  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [natural language interface USED-FOR database ...   \n",
       "3  [pronominal anaphora resolution module PART-OF...   \n",
       "4  [natural language generation USED-FOR interact...   \n",
       "\n",
       "   annotated_rel_detected_count  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             1  \n",
       "3                             1  \n",
       "4                             1  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reimport_scierc_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0d1279",
   "metadata": {},
   "source": [
    "### Export scierc_full_responses with additional analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7897294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reimport_scierc_results.to_excel(\"./benchmarking/results/additional_stats_scierc_rel_detection_with_ent_type_responses.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d39050",
   "metadata": {},
   "source": [
    "## iterate over input annotations to get distribution of relation types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9e5f50b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'reimport_scierc_results' is your DataFrame\n",
    "simplified_populated_rels_list = [str(item) for item in reimport_scierc_results['simplified_populated_rels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "284ce299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'USED-FOR': 2437, 'FEATURE-OF': 264, 'HYPONYM-OF': 477, 'PART-OF': 270, 'EVALUATE-FOR': 454, 'COMPARE': 234, 'CONJUNCTION': 583, 'COREF': 1675}\n",
      "Sum of Values: 6394\n"
     ]
    }
   ],
   "source": [
    "# Define the target texts\n",
    "target_texts = ['USED-FOR', 'FEATURE-OF', 'HYPONYM-OF', 'PART-OF', 'EVALUATE-FOR', 'COMPARE', 'CONJUNCTION', 'COREF']\n",
    "\n",
    "# Initialize the dictionary\n",
    "rel_summary = {text: 0 for text in target_texts}\n",
    "\n",
    "# Count the occurrences of each target text\n",
    "for row in simplified_populated_rels_list:\n",
    "    phrases = row.split(', ')\n",
    "    for text in target_texts:\n",
    "        for phrase in phrases:\n",
    "            if text in phrase:\n",
    "                rel_summary[text] += 1\n",
    "\n",
    "# Print the summary statistics\n",
    "print(rel_summary)\n",
    "\n",
    "# Print the sum of values\n",
    "print(\"Sum of Values:\", sum(rel_summary.values()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67cb6a7",
   "metadata": {},
   "source": [
    "## Explore 10 randomly selected samples where ChatGPT detected more rels than was annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "722d10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seedset = 3409578\n",
    "\n",
    "# # Filter the DataFrame based on the condition\n",
    "# responses_more_than_annotated = reimport_scierc_results[reimport_scierc_results['responses_rels_detected'] > reimport_scierc_results['rel_count']]\n",
    "# responses_less_than_annotated = reimport_scierc_results[reimport_scierc_results['responses_rels_detected'] < reimport_scierc_results['rel_count']]\n",
    "\n",
    "\n",
    "# # Randomly select 10 samples from the filtered DataFrame\n",
    "# CGPT_detected_more = responses_more_than_annotated.sample(n=10, random_state=random.seed(seedset))\n",
    "# CGPT_detected_less = responses_less_than_annotated.sample(n=10, random_state=random.seed(seedset))\n",
    "\n",
    "# # Export the DataFrames to an Excel file with two sheets\n",
    "# with pd.ExcelWriter('./benchmarking/results/qual_analysis_scierc.xlsx') as writer:\n",
    "#     CGPT_detected_more.to_excel(writer, sheet_name='CGPT_detected_more')\n",
    "#     CGPT_detected_less.to_excel(writer, sheet_name='CGPT_detected_less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9807871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "426.649px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "316.84px",
    "left": "1543.99px",
    "right": "20px",
    "top": "120px",
    "width": "316.997px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
